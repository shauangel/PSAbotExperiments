INFO: ---Start Analyzing---
INFO: ---Train for 3 Topics---
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<300 unique tokens: ['=', 'access', 'aliasing', 'answer', 'append']...> from 10 documents (total 883 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<300 unique tokens: ['=', 'access', 'aliasing', 'answer', 'append']...> from 10 documents (total 883 corpus positions)", 'datetime': '2023-04-25T06:36:18.285405', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.33333334, 0.33333334, 0.33333334]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -6.423 per-word bound, 85.8 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
WARNING: updated prior is not positive
INFO: optimized alpha [0.33333334, 0.33333334, 0.33333334]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.333): 0.041*"value" + 0.040*"default" + 0.035*"instance" + 0.029*"class" + 0.024*"immutable" + 0.023*"method" + 0.021*"type" + 0.016*"str" + 0.015*"repr" + 0.015*"dunder"
INFO: topic #1 (0.333): 0.004*"method" + 0.004*"default" + 0.004*"dunder" + 0.004*"repr" + 0.004*"object" + 0.004*"value" + 0.004*"argument" + 0.004*"function" + 0.004*"time" + 0.004*"difference"
INFO: topic #2 (0.333): 0.075*"default" + 0.054*"value" + 0.040*"argument" + 0.036*"function" + 0.029*"class" + 0.027*"instance" + 0.025*"list" + 0.025*"time" + 0.024*"mutable" + 0.020*"code"
INFO: topic diff=1.611268, rho=1.000000
DEBUG: bound: at document #0
INFO: -6.867 per-word bound, 116.8 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.2134936, 0.35351717, 0.49434817]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.213): 0.044*"value" + 0.036*"default" + 0.025*"class" + 0.022*"instance" + 0.019*"method" + 0.015*"type" + 0.014*"field" + 0.012*"dataclass" + 0.012*"variable" + 0.012*"context"
INFO: topic #1 (0.354): 0.045*"l" + 0.023*"reset" + 0.014*"parameter" + 0.014*"operation" + 0.012*"plot" + 0.012*"approach" + 0.012*"file" + 0.009*"c." + 0.009*"deepcopy" + 0.009*"a."
INFO: topic #2 (0.494): 0.070*"default" + 0.062*"value" + 0.044*"function" + 0.035*"list" + 0.031*"argument" + 0.025*"class" + 0.024*"time" + 0.023*"none" + 0.023*"object" + 0.018*"mutable"
INFO: topic diff=0.857825, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 40.89249524171545
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -5.5776771555293605
DEBUG: bound: at document #0
INFO: -5.273 per-word bound, 38.7 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
WARNING: updated prior is not positive
INFO: optimized alpha [0.2134936, 0.35351717, 0.49434817]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.213): 0.036*"value" + 0.035*"class" + 0.035*"default" + 0.034*"instance" + 0.026*"type" + 0.023*"method" + 0.018*"immutable" + 0.015*"field" + 0.014*"attribute" + 0.014*"variable"
INFO: topic #1 (0.354): 0.030*"l" + 0.016*"reset" + 0.010*"parameter" + 0.010*"operation" + 0.009*"plot" + 0.009*"approach" + 0.009*"file" + 0.007*"c." + 0.007*"deepcopy" + 0.007*"a."
INFO: topic #2 (0.494): 0.076*"default" + 0.059*"value" + 0.040*"function" + 0.039*"argument" + 0.030*"list" + 0.026*"time" + 0.026*"class" + 0.023*"mutable" + 0.022*"object" + 0.022*"instance"
INFO: topic diff=0.442856, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.978 per-word bound, 63.1 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.18119413, 0.37564626, 0.6466006]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.181): 0.037*"value" + 0.033*"default" + 0.032*"class" + 0.027*"instance" + 0.022*"type" + 0.021*"method" + 0.018*"field" + 0.014*"variable" + 0.013*"dataclass" + 0.013*"context"
INFO: topic #1 (0.376): 0.045*"l" + 0.025*"reset" + 0.015*"operation" + 0.014*"parameter" + 0.013*"approach" + 0.013*"plot" + 0.013*"file" + 0.008*"b." + 0.008*"pointer" + 0.008*"c."
INFO: topic #2 (0.647): 0.074*"default" + 0.065*"value" + 0.045*"function" + 0.036*"list" + 0.033*"argument" + 0.026*"time" + 0.024*"none" + 0.024*"object" + 0.024*"class" + 0.020*"mutable"
INFO: topic diff=0.343937, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 38.86579094200754
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -5.588818469579555
DEBUG: bound: at document #0
INFO: -5.174 per-word bound, 36.1 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14354157, 0.021451652, 0.40424132]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.144): 0.042*"class" + 0.038*"default" + 0.038*"instance" + 0.036*"value" + 0.028*"type" + 0.022*"method" + 0.019*"immutable" + 0.017*"variable" + 0.016*"field" + 0.015*"attribute"
INFO: topic #1 (0.021): 0.032*"l" + 0.019*"reset" + 0.011*"operation" + 0.011*"parameter" + 0.010*"approach" + 0.010*"plot" + 0.010*"file" + 0.007*"b." + 0.007*"pointer" + 0.007*"c."
INFO: topic #2 (0.404): 0.077*"default" + 0.061*"value" + 0.043*"function" + 0.041*"argument" + 0.032*"list" + 0.028*"time" + 0.024*"object" + 0.024*"mutable" + 0.023*"class" + 0.022*"none"
INFO: topic diff=0.398069, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.975 per-word bound, 62.9 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.12229245, 0.026724113, 0.4522225]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.122): 0.039*"class" + 0.037*"value" + 0.036*"default" + 0.032*"instance" + 0.025*"type" + 0.021*"method" + 0.019*"field" + 0.016*"variable" + 0.015*"immutable" + 0.013*"example"
INFO: topic #1 (0.027): 0.045*"l" + 0.026*"reset" + 0.014*"operation" + 0.014*"plot" + 0.014*"approach" + 0.014*"file" + 0.014*"parameter" + 0.008*"symbolic" + 0.008*"c" + 0.008*"b."
INFO: topic #2 (0.452): 0.075*"default" + 0.067*"value" + 0.046*"function" + 0.038*"list" + 0.035*"argument" + 0.027*"time" + 0.025*"none" + 0.025*"object" + 0.021*"class" + 0.021*"mutable"
INFO: topic diff=0.285308, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 37.79647572549219
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -5.580797255270654
DEBUG: bound: at document #0
INFO: -5.101 per-word bound, 34.3 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.107735544, 0.02458411, 0.30983296]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.108): 0.045*"class" + 0.043*"default" + 0.039*"instance" + 0.038*"value" + 0.028*"type" + 0.021*"method" + 0.020*"immutable" + 0.018*"variable" + 0.016*"field" + 0.015*"attribute"
INFO: topic #1 (0.025): 0.034*"l" + 0.020*"reset" + 0.012*"operation" + 0.011*"plot" + 0.011*"approach" + 0.011*"file" + 0.011*"parameter" + 0.007*"symbolic" + 0.007*"c" + 0.007*"b."
INFO: topic #2 (0.310): 0.077*"default" + 0.062*"value" + 0.044*"function" + 0.042*"argument" + 0.034*"list" + 0.029*"time" + 0.024*"object" + 0.023*"mutable" + 0.023*"none" + 0.021*"class"
INFO: topic diff=0.329621, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.965 per-word bound, 62.5 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0975818, 0.029963905, 0.35634133]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.098): 0.042*"class" + 0.041*"default" + 0.039*"value" + 0.035*"instance" + 0.025*"type" + 0.021*"method" + 0.018*"field" + 0.018*"variable" + 0.016*"immutable" + 0.013*"example"
INFO: topic #1 (0.030): 0.044*"l" + 0.026*"reset" + 0.014*"operation" + 0.014*"file" + 0.014*"approach" + 0.014*"plot" + 0.014*"parameter" + 0.008*"symbolic" + 0.008*"a." + 0.008*"deepcopy"
INFO: topic #2 (0.356): 0.075*"default" + 0.066*"value" + 0.048*"function" + 0.038*"list" + 0.037*"argument" + 0.028*"time" + 0.026*"none" + 0.026*"object" + 0.021*"mutable" + 0.020*"class"
INFO: topic diff=0.254585, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 37.37999949065884
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -5.584942557403509
DEBUG: bound: at document #0
INFO: -5.071 per-word bound, 33.6 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.09062728, 0.027347133, 0.27320474]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.091): 0.047*"default" + 0.046*"class" + 0.040*"value" + 0.040*"instance" + 0.027*"type" + 0.021*"method" + 0.021*"immutable" + 0.019*"variable" + 0.016*"field" + 0.015*"attribute"
INFO: topic #1 (0.027): 0.035*"l" + 0.021*"reset" + 0.012*"operation" + 0.011*"file" + 0.011*"approach" + 0.011*"plot" + 0.011*"parameter" + 0.007*"symbolic" + 0.007*"a." + 0.007*"deepcopy"
INFO: topic #2 (0.273): 0.076*"default" + 0.062*"value" + 0.045*"function" + 0.043*"argument" + 0.035*"list" + 0.029*"time" + 0.025*"object" + 0.023*"none" + 0.023*"mutable" + 0.020*"class"
INFO: topic diff=0.281474, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.955 per-word bound, 62.1 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.08466238, 0.032782, 0.31558853]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.085): 0.046*"default" + 0.044*"class" + 0.042*"value" + 0.036*"instance" + 0.025*"type" + 0.020*"method" + 0.019*"variable" + 0.018*"field" + 0.017*"immutable" + 0.013*"new"
INFO: topic #1 (0.033): 0.044*"l" + 0.026*"reset" + 0.014*"operation" + 0.014*"file" + 0.014*"approach" + 0.014*"plot" + 0.014*"parameter" + 0.008*"b." + 0.008*"refer" + 0.008*"deepcopy"
INFO: topic #2 (0.316): 0.074*"default" + 0.066*"value" + 0.048*"function" + 0.039*"list" + 0.038*"argument" + 0.028*"time" + 0.026*"none" + 0.026*"object" + 0.020*"mutable" + 0.019*"class"
INFO: topic diff=0.237198, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 37.13861429704489
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -5.569506291536714
DEBUG: bound: at document #0
INFO: -5.053 per-word bound, 33.2 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.08061816, 0.029742207, 0.251057]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.081): 0.050*"default" + 0.046*"class" + 0.042*"value" + 0.040*"instance" + 0.027*"type" + 0.021*"immutable" + 0.021*"method" + 0.020*"variable" + 0.015*"field" + 0.015*"new"
INFO: topic #1 (0.030): 0.035*"l" + 0.021*"reset" + 0.012*"operation" + 0.012*"file" + 0.012*"approach" + 0.012*"plot" + 0.011*"parameter" + 0.007*"b." + 0.007*"refer" + 0.007*"deepcopy"
INFO: topic #2 (0.251): 0.075*"default" + 0.061*"value" + 0.046*"function" + 0.043*"argument" + 0.035*"list" + 0.030*"time" + 0.025*"object" + 0.023*"none" + 0.022*"mutable" + 0.020*"class"
INFO: topic diff=0.249201, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.949 per-word bound, 61.8 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.082826324, 0.03524706, 0.2921235]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.083): 0.049*"default" + 0.044*"class" + 0.044*"value" + 0.036*"instance" + 0.025*"type" + 0.020*"method" + 0.019*"variable" + 0.017*"field" + 0.017*"immutable" + 0.014*"new"
INFO: topic #1 (0.035): 0.043*"l" + 0.026*"reset" + 0.014*"operation" + 0.014*"file" + 0.014*"approach" + 0.014*"plot" + 0.013*"parameter" + 0.008*"b." + 0.008*"refer" + 0.008*"deepcopy"
INFO: topic #2 (0.292): 0.073*"default" + 0.065*"value" + 0.049*"function" + 0.039*"list" + 0.039*"argument" + 0.029*"time" + 0.026*"none" + 0.026*"object" + 0.020*"mutable" + 0.019*"class"
INFO: topic diff=0.221502, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 36.96392473245118
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -5.569506291536714
DEBUG: bound: at document #0
INFO: -5.040 per-word bound, 32.9 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.07910208, 0.031875953, 0.23824498]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.079): 0.051*"default" + 0.046*"class" + 0.043*"value" + 0.040*"instance" + 0.026*"type" + 0.020*"immutable" + 0.020*"method" + 0.020*"variable" + 0.015*"field" + 0.015*"new"
INFO: topic #1 (0.032): 0.035*"l" + 0.021*"reset" + 0.012*"operation" + 0.012*"file" + 0.012*"approach" + 0.012*"plot" + 0.011*"parameter" + 0.007*"b." + 0.007*"refer" + 0.007*"deepcopy"
INFO: topic #2 (0.238): 0.075*"default" + 0.061*"value" + 0.047*"function" + 0.044*"argument" + 0.036*"list" + 0.030*"time" + 0.024*"object" + 0.023*"none" + 0.022*"mutable" + 0.019*"class"
INFO: topic diff=0.226079, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.939 per-word bound, 61.3 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.081296645, 0.037351083, 0.27409947]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.081): 0.051*"default" + 0.046*"value" + 0.045*"class" + 0.036*"instance" + 0.024*"type" + 0.020*"method" + 0.020*"variable" + 0.017*"immutable" + 0.017*"field" + 0.014*"new"
INFO: topic #1 (0.037): 0.043*"l" + 0.025*"reset" + 0.014*"operation" + 0.013*"plot" + 0.013*"file" + 0.013*"approach" + 0.013*"parameter" + 0.008*"datum" + 0.008*"decorator" + 0.008*"context"
INFO: topic #2 (0.274): 0.073*"default" + 0.065*"value" + 0.049*"function" + 0.039*"list" + 0.039*"argument" + 0.029*"time" + 0.025*"none" + 0.025*"object" + 0.020*"mutable" + 0.019*"class"
INFO: topic diff=0.208684, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 36.8336386926491
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -4.092975541036368
DEBUG: bound: at document #0
INFO: -5.030 per-word bound, 32.7 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.075752914, 0.03326323, 0.18792331]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.076): 0.053*"default" + 0.046*"class" + 0.045*"value" + 0.040*"instance" + 0.026*"type" + 0.020*"immutable" + 0.020*"method" + 0.020*"variable" + 0.015*"new" + 0.015*"field"
INFO: topic #1 (0.033): 0.035*"l" + 0.021*"reset" + 0.012*"operation" + 0.012*"plot" + 0.012*"file" + 0.012*"approach" + 0.011*"parameter" + 0.007*"datum" + 0.007*"decorator" + 0.007*"context"
INFO: topic #2 (0.188): 0.074*"default" + 0.061*"value" + 0.047*"function" + 0.044*"argument" + 0.035*"list" + 0.030*"time" + 0.024*"object" + 0.022*"none" + 0.022*"mutable" + 0.019*"class"
INFO: topic diff=0.210812, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.930 per-word bound, 61.0 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.07763176, 0.038554385, 0.21859293]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.078): 0.053*"default" + 0.047*"value" + 0.045*"class" + 0.036*"instance" + 0.024*"type" + 0.020*"method" + 0.020*"variable" + 0.017*"immutable" + 0.017*"field" + 0.014*"new"
INFO: topic #1 (0.039): 0.042*"l" + 0.025*"reset" + 0.013*"operation" + 0.013*"approach" + 0.013*"plot" + 0.013*"file" + 0.013*"parameter" + 0.010*"datum" + 0.009*"decorator" + 0.008*"context"
INFO: topic #2 (0.219): 0.073*"default" + 0.064*"value" + 0.050*"function" + 0.040*"argument" + 0.039*"list" + 0.029*"time" + 0.025*"object" + 0.025*"none" + 0.020*"mutable" + 0.018*"class"
INFO: topic diff=0.197480, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 36.670442802509186
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -4.092975541036368
DEBUG: bound: at document #0
INFO: -5.020 per-word bound, 32.4 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.07295744, 0.03433446, 0.16946515]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.073): 0.054*"default" + 0.046*"class" + 0.046*"value" + 0.039*"instance" + 0.026*"type" + 0.020*"immutable" + 0.020*"method" + 0.020*"variable" + 0.015*"new" + 0.015*"field"
INFO: topic #1 (0.034): 0.035*"l" + 0.021*"reset" + 0.012*"operation" + 0.012*"approach" + 0.012*"plot" + 0.012*"file" + 0.011*"parameter" + 0.009*"datum" + 0.008*"decorator" + 0.007*"context"
INFO: topic #2 (0.169): 0.074*"default" + 0.061*"value" + 0.047*"function" + 0.044*"argument" + 0.035*"list" + 0.030*"time" + 0.024*"object" + 0.022*"none" + 0.022*"mutable" + 0.019*"class"
INFO: topic diff=0.194516, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.922 per-word bound, 60.6 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.07474499, 0.039465826, 0.19690697]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.075): 0.054*"default" + 0.048*"value" + 0.045*"class" + 0.036*"instance" + 0.024*"type" + 0.020*"method" + 0.020*"variable" + 0.017*"immutable" + 0.016*"field" + 0.014*"new"
INFO: topic #1 (0.039): 0.042*"l" + 0.025*"reset" + 0.013*"operation" + 0.013*"approach" + 0.013*"plot" + 0.013*"file" + 0.013*"parameter" + 0.012*"datum" + 0.009*"decorator" + 0.009*"context"
INFO: topic #2 (0.197): 0.072*"default" + 0.064*"value" + 0.050*"function" + 0.040*"argument" + 0.039*"list" + 0.029*"time" + 0.025*"object" + 0.025*"none" + 0.020*"mutable" + 0.018*"class"
INFO: topic diff=0.187303, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 36.584954519906105
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -4.092975541036368
DEBUG: bound: at document #0
INFO: -5.015 per-word bound, 32.3 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.070768036, 0.0351916, 0.16063015]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.071): 0.055*"default" + 0.046*"value" + 0.046*"class" + 0.039*"instance" + 0.026*"type" + 0.020*"method" + 0.020*"immutable" + 0.020*"variable" + 0.015*"new" + 0.015*"field"
INFO: topic #1 (0.035): 0.035*"l" + 0.021*"reset" + 0.012*"operation" + 0.012*"approach" + 0.012*"plot" + 0.012*"file" + 0.011*"parameter" + 0.010*"datum" + 0.008*"decorator" + 0.008*"context"
INFO: topic #2 (0.161): 0.074*"default" + 0.060*"value" + 0.048*"function" + 0.044*"argument" + 0.035*"list" + 0.029*"time" + 0.024*"object" + 0.022*"none" + 0.022*"mutable" + 0.019*"class"
INFO: topic diff=0.182808, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.912 per-word bound, 60.2 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.07252242, 0.040178116, 0.18588184]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.073): 0.055*"default" + 0.049*"value" + 0.045*"class" + 0.037*"instance" + 0.024*"type" + 0.020*"method" + 0.020*"variable" + 0.017*"immutable" + 0.016*"field" + 0.014*"way"
INFO: topic #1 (0.040): 0.041*"l" + 0.024*"reset" + 0.013*"datum" + 0.013*"operation" + 0.013*"approach" + 0.013*"plot" + 0.013*"file" + 0.013*"parameter" + 0.009*"name" + 0.009*"decorator"
INFO: topic #2 (0.186): 0.072*"default" + 0.063*"value" + 0.050*"function" + 0.041*"argument" + 0.039*"list" + 0.029*"time" + 0.025*"object" + 0.025*"none" + 0.020*"mutable" + 0.018*"class"
INFO: topic diff=0.178440, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 36.518811092171376
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -5.069624129818673
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5> in 0.21s', 'datetime': '2023-04-25T06:36:18.493082', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'auto-adjust_models/models/5/model_t3.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-25T06:36:18.493229', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'auto-adjust_models/models/5/model_t3.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/5/model_t3.state
DEBUG: {'uri': 'auto-adjust_models/models/5/model_t3.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'auto-adjust_models/models/5/model_t3', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['id2word', 'dispatcher', 'state'], 'datetime': '2023-04-25T06:36:18.496114', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to auto-adjust_models/models/5/model_t3.expElogbeta.npy
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
INFO: not storing attribute state
DEBUG: {'uri': 'auto-adjust_models/models/5/model_t3', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/5/model_t3
