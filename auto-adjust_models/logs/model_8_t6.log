INFO: ---Start Analyzing---
INFO: ---Train for 6 Topics---
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<494 unique tokens: ['=', '@andrea', '@blair', '@david', '@mark']...> from 9 documents (total 1884 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<494 unique tokens: ['=', '@andrea', '@blair', '@david', '@mark']...> from 9 documents (total 1884 corpus positions)", 'datetime': '2023-04-25T06:36:22.380103', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 6 topics, 10 passes over the supplied corpus of 9 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.459 per-word bound, 175.9 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 0, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0014076978, 0.11991002, 0.1794838, 0.11948794, 0.059641093, 0.0014159381]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.001): 0.002*"value" + 0.002*"function" + 0.002*"reference" + 0.002*"parameter" + 0.002*"return" + 0.002*"type" + 0.002*"object" + 0.002*"code" + 0.002*"output" + 0.002*"pointer"
INFO: topic #5 (0.001): 0.002*"value" + 0.002*"function" + 0.002*"reference" + 0.002*"parameter" + 0.002*"type" + 0.002*"object" + 0.002*"pass" + 0.002*"variable" + 0.002*"return" + 0.002*"output"
INFO: topic #3 (0.119): 0.056*"reference" + 0.050*"value" + 0.037*"object" + 0.034*"function" + 0.031*"variable" + 0.021*"parameter" + 0.019*"type" + 0.016*"change" + 0.016*"name" + 0.013*"new"
INFO: topic #1 (0.120): 0.057*"object" + 0.054*"reference" + 0.039*"function" + 0.032*"value" + 0.028*"variable" + 0.015*"parameter" + 0.015*"list" + 0.014*"new" + 0.012*"way" + 0.011*"change"
INFO: topic #2 (0.179): 0.060*"object" + 0.048*"reference" + 0.039*"value" + 0.035*"function" + 0.033*"variable" + 0.016*"parameter" + 0.016*"string" + 0.015*"mutable" + 0.015*"new" + 0.014*"change"
INFO: topic diff=3.111221, rho=1.000000
DEBUG: bound: at document #0
INFO: -9.725 per-word bound, 846.4 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 0, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.0016480787, 0.08473575, 0.12839578, 0.08254042, 0.054893635, 0.001909107]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.056*"arg" + 0.029*"test_obj" + 0.020*"testclass" + 0.020*"num" + 0.011*"test_func(test_obj" + 0.011*"test_func2(num" + 0.011*"test_obj.one" + 0.011*"execution" + 0.011*"arg.one" + 0.002*"second"
INFO: topic #5 (0.002): 0.055*"command" + 0.046*"line" + 0.034*"script" + 0.014*"dict.i" + 0.014*"look" + 0.014*"window" + 0.014*"well" + 0.014*"funny" + 0.014*"typemap" + 0.014*"os"
INFO: topic #3 (0.083): 0.051*"variable" + 0.043*"function" + 0.039*"reference" + 0.035*"value" + 0.026*"object" + 0.019*"parameter" + 0.017*"way" + 0.016*"input" + 0.014*"output" + 0.013*"type"
INFO: topic #1 (0.085): 0.073*"object" + 0.058*"function" + 0.050*"value" + 0.035*"reference" + 0.029*"variable" + 0.021*"integer" + 0.017*"new" + 0.017*"case" + 0.014*"instance" + 0.014*"original"
INFO: topic #2 (0.128): 0.049*"function" + 0.045*"object" + 0.041*"value" + 0.036*"reference" + 0.032*"variable" + 0.017*"argument" + 0.012*"pass" + 0.012*"name" + 0.012*"result" + 0.012*"parameter"
INFO: topic diff=0.800740, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 58.38385297420647
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -1.871040254507652
DEBUG: bound: at document #0
INFO: -5.823 per-word bound, 56.6 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 1, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0016360714, 0.065232515, 0.12233804, 0.06392677, 0.0488096, 0.001892995]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.030*"arg" + 0.016*"test_obj" + 0.011*"testclass" + 0.011*"num" + 0.007*"test_func2(num" + 0.007*"test_obj.one" + 0.007*"test_func(test_obj" + 0.007*"execution" + 0.007*"arg.one" + 0.002*"second"
INFO: topic #5 (0.002): 0.033*"command" + 0.028*"line" + 0.020*"script" + 0.009*"dict.i" + 0.009*"look" + 0.009*"window" + 0.009*"well" + 0.009*"funny" + 0.009*"typemap" + 0.009*"os"
INFO: topic #3 (0.064): 0.035*"variable" + 0.033*"function" + 0.032*"value" + 0.031*"reference" + 0.025*"parameter" + 0.025*"type" + 0.018*"object" + 0.018*"output" + 0.017*"pointer" + 0.015*"input"
INFO: topic #1 (0.065): 0.058*"object" + 0.048*"function" + 0.045*"value" + 0.034*"reference" + 0.019*"variable" + 0.017*"return" + 0.017*"case" + 0.014*"integer" + 0.012*"parameter" + 0.012*"array"
INFO: topic #2 (0.122): 0.056*"object" + 0.051*"reference" + 0.041*"value" + 0.039*"function" + 0.035*"variable" + 0.015*"parameter" + 0.015*"new" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: topic diff=0.490813, rho=0.512989
DEBUG: bound: at document #0
INFO: -7.075 per-word bound, 134.8 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 1, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.0016251614, 0.058884732, 0.105412476, 0.057439376, 0.04617148, 0.002366768]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.017*"arg" + 0.009*"test_obj" + 0.007*"testclass" + 0.007*"num" + 0.004*"execution" + 0.004*"test_obj.one" + 0.004*"arg.one" + 0.004*"test_func(test_obj" + 0.004*"test_func2(num" + 0.002*"second"
INFO: topic #5 (0.002): 0.057*"command" + 0.048*"line" + 0.035*"script" + 0.014*"dict.i" + 0.014*"dict.hpp" + 0.014*"window" + 0.014*"typemap" + 0.014*"funny" + 0.014*"look" + 0.014*"test"
INFO: topic #3 (0.057): 0.059*"variable" + 0.046*"function" + 0.028*"input" + 0.024*"output" + 0.022*"parameter" + 0.020*"value" + 0.020*"way" + 0.019*"reference" + 0.016*"type" + 0.012*"argument"
INFO: topic #1 (0.059): 0.071*"object" + 0.061*"function" + 0.055*"value" + 0.031*"arg" + 0.025*"integer" + 0.024*"variable" + 0.023*"case" + 0.022*"reference" + 0.018*"return" + 0.016*"test_obj"
INFO: topic #2 (0.105): 0.049*"object" + 0.046*"function" + 0.045*"reference" + 0.042*"value" + 0.034*"variable" + 0.015*"argument" + 0.014*"name" + 0.013*"parameter" + 0.013*"new" + 0.012*"change"
INFO: topic diff=0.389207, rho=0.512989
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 50.51811929419501
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.7448284095798703
DEBUG: bound: at document #0
INFO: -5.609 per-word bound, 48.8 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 2, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0016138435, 0.050945558, 0.102772415, 0.04982124, 0.042259105, 0.0023427638]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.010*"arg" + 0.006*"test_obj" + 0.005*"testclass" + 0.005*"num" + 0.003*"test_func2(num" + 0.003*"execution" + 0.003*"test_func(test_obj" + 0.003*"arg.one" + 0.003*"test_obj.one" + 0.002*"second"
INFO: topic #5 (0.002): 0.037*"command" + 0.032*"line" + 0.023*"script" + 0.010*"dict.i" + 0.010*"dict.hpp" + 0.010*"window" + 0.010*"typemap" + 0.010*"funny" + 0.010*"look" + 0.010*"test"
INFO: topic #3 (0.050): 0.036*"variable" + 0.033*"function" + 0.029*"type" + 0.028*"parameter" + 0.024*"output" + 0.022*"input" + 0.022*"value" + 0.021*"pointer" + 0.017*"reference" + 0.015*"pass"
INFO: topic #1 (0.051): 0.055*"object" + 0.049*"function" + 0.048*"value" + 0.024*"reference" + 0.023*"return" + 0.020*"case" + 0.019*"arg" + 0.017*"array" + 0.015*"integer" + 0.014*"variable"
INFO: topic #2 (0.103): 0.055*"object" + 0.052*"reference" + 0.041*"value" + 0.040*"function" + 0.035*"variable" + 0.015*"parameter" + 0.015*"new" + 0.015*"name" + 0.014*"change" + 0.014*"list"
INFO: topic diff=0.312229, rho=0.456435
DEBUG: bound: at document #0
INFO: -6.838 per-word bound, 114.4 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 2, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.0016035818, 0.04795647, 0.09253642, 0.046781722, 0.04059914, 0.002859687]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.006*"arg" + 0.004*"test_obj" + 0.003*"num" + 0.003*"testclass" + 0.003*"test_func(test_obj" + 0.003*"arg.one" + 0.003*"test_func2(num" + 0.003*"test_obj.one" + 0.003*"execution" + 0.002*"second"
INFO: topic #5 (0.003): 0.057*"command" + 0.049*"line" + 0.036*"script" + 0.014*"funny" + 0.014*"dict.i" + 0.014*"dict.hpp" + 0.014*"window" + 0.014*"multi" + 0.014*"test" + 0.014*"typemap"
INFO: topic #3 (0.047): 0.061*"variable" + 0.046*"function" + 0.033*"input" + 0.028*"output" + 0.024*"parameter" + 0.021*"way" + 0.018*"type" + 0.014*"value" + 0.013*"pointer" + 0.012*"argument"
INFO: topic #1 (0.048): 0.068*"object" + 0.061*"function" + 0.056*"value" + 0.036*"arg" + 0.026*"integer" + 0.024*"case" + 0.021*"return" + 0.021*"variable" + 0.018*"test_obj" + 0.017*"reference"
INFO: topic #2 (0.093): 0.050*"object" + 0.047*"reference" + 0.045*"function" + 0.042*"value" + 0.035*"variable" + 0.015*"argument" + 0.014*"name" + 0.014*"parameter" + 0.014*"new" + 0.012*"change"
INFO: topic diff=0.250515, rho=0.456435
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 49.169143568836176
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -1.7289872121200462
DEBUG: bound: at document #0
INFO: -5.560 per-word bound, 47.2 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 3, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0015929473, 0.043356966, 0.09146452, 0.042381, 0.03786229, 0.002825867]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.005*"arg" + 0.003*"test_obj" + 0.003*"testclass" + 0.003*"num" + 0.002*"test_func(test_obj" + 0.002*"arg.one" + 0.002*"execution" + 0.002*"test_func2(num" + 0.002*"test_obj.one" + 0.002*"second"
INFO: topic #5 (0.003): 0.039*"command" + 0.033*"line" + 0.025*"script" + 0.010*"funny" + 0.010*"dict.hpp" + 0.010*"window" + 0.010*"look" + 0.010*"typemap" + 0.010*"test" + 0.010*"dict.i"
INFO: topic #3 (0.042): 0.037*"variable" + 0.033*"function" + 0.031*"type" + 0.029*"parameter" + 0.027*"output" + 0.025*"input" + 0.023*"pointer" + 0.018*"value" + 0.016*"pass" + 0.016*"ctype"
INFO: topic #1 (0.043): 0.055*"object" + 0.050*"function" + 0.049*"value" + 0.024*"return" + 0.022*"arg" + 0.021*"case" + 0.019*"reference" + 0.019*"array" + 0.016*"integer" + 0.015*"my_fun"
INFO: topic #2 (0.091): 0.055*"object" + 0.053*"reference" + 0.041*"value" + 0.040*"function" + 0.035*"variable" + 0.015*"parameter" + 0.015*"new" + 0.015*"name" + 0.014*"list" + 0.014*"change"
INFO: topic diff=0.210448, rho=0.415227
DEBUG: bound: at document #0
INFO: -6.790 per-word bound, 110.7 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 3, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.0015833046, 0.041651625, 0.08433127, 0.04064646, 0.03676618, 0.0033873795]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.004*"arg" + 0.003*"test_obj" + 0.003*"testclass" + 0.003*"num" + 0.002*"test_func(test_obj" + 0.002*"execution" + 0.002*"arg.one" + 0.002*"test_func2(num" + 0.002*"test_obj.one" + 0.002*"second"
INFO: topic #5 (0.003): 0.057*"command" + 0.048*"line" + 0.036*"script" + 0.013*"funny" + 0.013*"dict.hpp" + 0.013*"window" + 0.013*"look" + 0.013*"typemap" + 0.013*"test" + 0.013*"dict.i"
INFO: topic #3 (0.041): 0.061*"variable" + 0.046*"function" + 0.035*"input" + 0.030*"output" + 0.025*"parameter" + 0.021*"way" + 0.019*"type" + 0.014*"pointer" + 0.012*"value" + 0.011*"argument"
INFO: topic #1 (0.042): 0.067*"object" + 0.060*"function" + 0.056*"value" + 0.037*"arg" + 0.025*"integer" + 0.024*"case" + 0.022*"return" + 0.020*"variable" + 0.019*"test_obj" + 0.016*"="
INFO: topic #2 (0.084): 0.051*"object" + 0.048*"reference" + 0.044*"function" + 0.042*"value" + 0.035*"variable" + 0.015*"argument" + 0.014*"name" + 0.014*"parameter" + 0.014*"new" + 0.013*"list"
INFO: topic diff=0.176602, rho=0.415227
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 48.75575404806244
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -1.72813124278313
DEBUG: bound: at document #0
INFO: -5.541 per-word bound, 46.6 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 4, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0015733, 0.0385678, 0.08402289, 0.0377022, 0.034727298, 0.003341587]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.003*"arg" + 0.002*"test_obj" + 0.002*"testclass" + 0.002*"num" + 0.002*"arg.one" + 0.002*"test_func2(num" + 0.002*"test_obj.one" + 0.002*"test_func(test_obj" + 0.002*"execution" + 0.002*"second"
INFO: topic #5 (0.003): 0.041*"command" + 0.035*"line" + 0.026*"script" + 0.010*"funny" + 0.010*"dict.hpp" + 0.010*"window" + 0.010*"look" + 0.010*"typemap" + 0.010*"test" + 0.010*"dict.i"
INFO: topic #3 (0.038): 0.038*"variable" + 0.033*"function" + 0.031*"type" + 0.029*"parameter" + 0.028*"output" + 0.026*"input" + 0.023*"pointer" + 0.017*"value" + 0.016*"pass" + 0.016*"ctype"
INFO: topic #1 (0.039): 0.055*"object" + 0.050*"function" + 0.050*"value" + 0.025*"return" + 0.024*"arg" + 0.022*"case" + 0.020*"array" + 0.017*"reference" + 0.016*"integer" + 0.015*"my_fun"
INFO: topic #2 (0.084): 0.055*"object" + 0.053*"reference" + 0.042*"value" + 0.040*"function" + 0.035*"variable" + 0.015*"parameter" + 0.015*"new" + 0.015*"name" + 0.014*"list" + 0.014*"change"
INFO: topic diff=0.159221, rho=0.383482
DEBUG: bound: at document #0
INFO: -6.767 per-word bound, 108.9 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 4, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.0015642232, 0.037495743, 0.07860621, 0.036608607, 0.03397873, 0.0039480696]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.003*"arg" + 0.002*"test_obj" + 0.002*"testclass" + 0.002*"num" + 0.002*"execution" + 0.002*"test_func2(num" + 0.002*"test_func(test_obj" + 0.002*"arg.one" + 0.002*"test_obj.one" + 0.002*"second"
INFO: topic #5 (0.004): 0.058*"command" + 0.048*"line" + 0.036*"script" + 0.013*"funny" + 0.013*"dict.hpp" + 0.013*"dict.i" + 0.013*"window" + 0.013*"test" + 0.013*"os" + 0.013*"multi"
INFO: topic #3 (0.037): 0.060*"variable" + 0.045*"function" + 0.035*"input" + 0.030*"output" + 0.025*"parameter" + 0.021*"way" + 0.020*"type" + 0.015*"pointer" + 0.011*"value" + 0.011*"argument"
INFO: topic #1 (0.037): 0.066*"object" + 0.060*"function" + 0.056*"value" + 0.037*"arg" + 0.025*"integer" + 0.024*"case" + 0.023*"return" + 0.019*"variable" + 0.019*"test_obj" + 0.015*"="
INFO: topic #2 (0.079): 0.051*"object" + 0.049*"reference" + 0.044*"function" + 0.042*"value" + 0.035*"variable" + 0.015*"argument" + 0.014*"name" + 0.014*"parameter" + 0.014*"new" + 0.013*"list"
INFO: topic diff=0.140440, rho=0.383482
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 48.55296896472755
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -1.7288065078082926
DEBUG: bound: at document #0
INFO: -5.530 per-word bound, 46.2 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 5, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0015547895, 0.03524809, 0.07870859, 0.03446521, 0.03238783, 0.0038879737]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.002*"arg" + 0.002*"test_obj" + 0.002*"num" + 0.002*"testclass" + 0.002*"test_obj.one" + 0.002*"arg.one" + 0.002*"execution" + 0.002*"test_func(test_obj" + 0.002*"test_func2(num" + 0.002*"second"
INFO: topic #5 (0.004): 0.042*"command" + 0.035*"line" + 0.026*"script" + 0.010*"funny" + 0.010*"dict.i" + 0.010*"dict.hpp" + 0.010*"window" + 0.010*"typemap" + 0.010*"test" + 0.010*"look"
INFO: topic #3 (0.034): 0.039*"variable" + 0.034*"function" + 0.031*"type" + 0.030*"parameter" + 0.028*"output" + 0.027*"input" + 0.023*"pointer" + 0.016*"value" + 0.016*"pass" + 0.016*"ctype"
INFO: topic #1 (0.035): 0.055*"object" + 0.051*"function" + 0.050*"value" + 0.025*"return" + 0.025*"arg" + 0.022*"case" + 0.020*"array" + 0.017*"integer" + 0.016*"reference" + 0.015*"my_fun"
INFO: topic #2 (0.079): 0.055*"object" + 0.053*"reference" + 0.042*"value" + 0.040*"function" + 0.035*"variable" + 0.015*"parameter" + 0.015*"new" + 0.015*"name" + 0.014*"list" + 0.014*"change"
INFO: topic diff=0.134759, rho=0.358057
DEBUG: bound: at document #0
INFO: -6.747 per-word bound, 107.4 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 5, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.0015462271, 0.034536842, 0.074377134, 0.03373606, 0.031864244, 0.0045390064]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.002*"arg" + 0.002*"test_obj" + 0.002*"num" + 0.002*"testclass" + 0.002*"test_func(test_obj" + 0.002*"execution" + 0.002*"arg.one" + 0.002*"test_obj.one" + 0.002*"test_func2(num" + 0.002*"second"
INFO: topic #5 (0.005): 0.058*"command" + 0.047*"line" + 0.036*"script" + 0.013*"dict.i" + 0.013*"look" + 0.013*"window" + 0.013*"typemap" + 0.013*"funny" + 0.013*"dict.hpp" + 0.013*"test"
INFO: topic #3 (0.034): 0.060*"variable" + 0.045*"function" + 0.035*"input" + 0.030*"output" + 0.025*"parameter" + 0.021*"way" + 0.021*"type" + 0.016*"pointer" + 0.011*"value" + 0.011*"argument"
INFO: topic #1 (0.035): 0.066*"object" + 0.060*"function" + 0.056*"value" + 0.036*"arg" + 0.025*"integer" + 0.024*"case" + 0.023*"return" + 0.019*"variable" + 0.019*"test_obj" + 0.015*"="
INFO: topic #2 (0.074): 0.052*"object" + 0.049*"reference" + 0.043*"function" + 0.042*"value" + 0.035*"variable" + 0.015*"name" + 0.014*"argument" + 0.014*"parameter" + 0.014*"new" + 0.013*"list"
INFO: topic diff=0.122208, rho=0.358057
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 48.41348401886479
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -1.7362395998486375
DEBUG: bound: at document #0
INFO: -5.522 per-word bound, 46.0 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 6, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0015373107, 0.032806437, 0.074723914, 0.032087203, 0.030579548, 0.0044621723]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.002*"arg" + 0.002*"test_obj" + 0.002*"num" + 0.002*"testclass" + 0.002*"arg.one" + 0.002*"test_func(test_obj" + 0.002*"test_obj.one" + 0.002*"execution" + 0.002*"test_func2(num" + 0.002*"second"
INFO: topic #5 (0.004): 0.043*"command" + 0.036*"line" + 0.027*"script" + 0.010*"funny" + 0.010*"dict.hpp" + 0.010*"dict.i" + 0.010*"window" + 0.010*"test" + 0.010*"os" + 0.010*"typemap"
INFO: topic #3 (0.032): 0.039*"variable" + 0.034*"function" + 0.030*"type" + 0.029*"parameter" + 0.028*"output" + 0.027*"input" + 0.023*"pointer" + 0.016*"value" + 0.016*"pass" + 0.016*"ctype"
INFO: topic #1 (0.033): 0.055*"object" + 0.051*"function" + 0.050*"value" + 0.026*"return" + 0.025*"arg" + 0.022*"case" + 0.019*"array" + 0.017*"integer" + 0.015*"reference" + 0.015*"my_fun"
INFO: topic #2 (0.075): 0.055*"object" + 0.053*"reference" + 0.042*"value" + 0.040*"function" + 0.035*"variable" + 0.015*"parameter" + 0.015*"new" + 0.015*"name" + 0.014*"list" + 0.014*"change"
INFO: topic diff=0.120217, rho=0.337100
DEBUG: bound: at document #0
INFO: -6.728 per-word bound, 106.0 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 6, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.0015292191, 0.03232203, 0.07116347, 0.031586878, 0.030207658, 0.0051566786]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.002*"arg" + 0.002*"test_obj" + 0.002*"num" + 0.002*"testclass" + 0.002*"test_func2(num" + 0.002*"test_func(test_obj" + 0.002*"test_obj.one" + 0.002*"execution" + 0.002*"arg.one" + 0.002*"second"
INFO: topic #5 (0.005): 0.057*"command" + 0.047*"line" + 0.035*"script" + 0.013*"funny" + 0.013*"dict.hpp" + 0.013*"dict.i" + 0.013*"look" + 0.013*"typemap" + 0.013*"test" + 0.013*"window"
INFO: topic #3 (0.032): 0.059*"variable" + 0.045*"function" + 0.035*"input" + 0.030*"output" + 0.026*"parameter" + 0.021*"type" + 0.020*"way" + 0.016*"pointer" + 0.011*"value" + 0.011*"pass"
INFO: topic #1 (0.032): 0.065*"object" + 0.059*"function" + 0.056*"value" + 0.036*"arg" + 0.024*"integer" + 0.024*"case" + 0.023*"return" + 0.018*"variable" + 0.018*"test_obj" + 0.015*"="
INFO: topic #2 (0.071): 0.052*"object" + 0.050*"reference" + 0.043*"function" + 0.042*"value" + 0.035*"variable" + 0.015*"name" + 0.015*"parameter" + 0.014*"argument" + 0.014*"new" + 0.013*"list"
INFO: topic diff=0.110615, rho=0.337100
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 48.31017959013035
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -1.7377118107318126
DEBUG: bound: at document #0
INFO: -5.517 per-word bound, 45.8 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 7, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0015207733, 0.030937273, 0.07166232, 0.030268187, 0.029143084, 0.0050606453]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.002*"arg" + 0.002*"test_obj" + 0.002*"num" + 0.002*"testclass" + 0.002*"arg.one" + 0.002*"test_obj.one" + 0.002*"execution" + 0.002*"test_func(test_obj" + 0.002*"test_func2(num" + 0.002*"second"
INFO: topic #5 (0.005): 0.044*"command" + 0.036*"line" + 0.027*"script" + 0.010*"funny" + 0.010*"dict.hpp" + 0.010*"dict.i" + 0.010*"window" + 0.010*"multi" + 0.010*"test" + 0.010*"typemap"
INFO: topic #3 (0.030): 0.040*"variable" + 0.034*"function" + 0.030*"type" + 0.029*"parameter" + 0.029*"output" + 0.028*"input" + 0.023*"pointer" + 0.016*"value" + 0.016*"pass" + 0.016*"ctype"
INFO: topic #1 (0.031): 0.055*"object" + 0.051*"function" + 0.050*"value" + 0.026*"return" + 0.025*"arg" + 0.022*"case" + 0.019*"array" + 0.017*"integer" + 0.015*"reference" + 0.015*"my_fun"
INFO: topic #2 (0.072): 0.055*"object" + 0.053*"reference" + 0.042*"value" + 0.040*"function" + 0.035*"variable" + 0.015*"parameter" + 0.015*"new" + 0.015*"name" + 0.014*"list" + 0.014*"change"
INFO: topic diff=0.110020, rho=0.319438
DEBUG: bound: at document #0
INFO: -6.711 per-word bound, 104.8 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 7, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.0015131137, 0.030605253, 0.06867238, 0.02992145, 0.028877934, 0.0057970053]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.002*"arg" + 0.002*"test_obj" + 0.002*"num" + 0.002*"testclass" + 0.002*"test_func2(num" + 0.002*"test_func(test_obj" + 0.002*"arg.one" + 0.002*"execution" + 0.002*"test_obj.one" + 0.002*"second"
INFO: topic #5 (0.006): 0.057*"command" + 0.046*"line" + 0.035*"script" + 0.013*"funny" + 0.013*"dict.hpp" + 0.013*"dict.i" + 0.013*"look" + 0.013*"typemap" + 0.013*"test" + 0.013*"window"
INFO: topic #3 (0.030): 0.058*"variable" + 0.044*"function" + 0.035*"input" + 0.030*"output" + 0.026*"parameter" + 0.021*"type" + 0.020*"way" + 0.016*"pointer" + 0.011*"value" + 0.011*"pass"
INFO: topic #1 (0.031): 0.065*"object" + 0.059*"function" + 0.055*"value" + 0.036*"arg" + 0.024*"case" + 0.024*"integer" + 0.023*"return" + 0.018*"variable" + 0.018*"test_obj" + 0.015*"="
INFO: topic #2 (0.069): 0.052*"object" + 0.050*"reference" + 0.043*"function" + 0.042*"value" + 0.035*"variable" + 0.015*"parameter" + 0.015*"name" + 0.014*"argument" + 0.014*"new" + 0.013*"list"
INFO: topic diff=0.102289, rho=0.319438
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 48.23502460462945
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -1.7503088380713023
DEBUG: bound: at document #0
INFO: -5.512 per-word bound, 45.6 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 8, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.001505098, 0.029464634, 0.069268286, 0.028835813, 0.027977837, 0.005679358]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.002): 0.002*"arg" + 0.002*"test_obj" + 0.002*"testclass" + 0.002*"num" + 0.002*"test_obj.one" + 0.002*"test_func(test_obj" + 0.002*"execution" + 0.002*"arg.one" + 0.002*"test_func2(num" + 0.002*"second"
INFO: topic #5 (0.006): 0.045*"command" + 0.036*"line" + 0.027*"script" + 0.010*"funny" + 0.010*"dict.hpp" + 0.010*"dict.i" + 0.010*"look" + 0.010*"typemap" + 0.010*"test" + 0.010*"window"
INFO: topic #3 (0.029): 0.040*"variable" + 0.034*"function" + 0.030*"type" + 0.029*"parameter" + 0.029*"output" + 0.028*"input" + 0.023*"pointer" + 0.016*"value" + 0.016*"pass" + 0.016*"ctype"
INFO: topic #1 (0.029): 0.055*"object" + 0.051*"function" + 0.051*"value" + 0.026*"return" + 0.026*"arg" + 0.022*"case" + 0.019*"array" + 0.017*"integer" + 0.015*"my_fun" + 0.015*"out_arr"
INFO: topic #2 (0.069): 0.055*"object" + 0.053*"reference" + 0.042*"value" + 0.040*"function" + 0.035*"variable" + 0.015*"parameter" + 0.015*"new" + 0.015*"name" + 0.014*"list" + 0.014*"change"
INFO: topic diff=0.102153, rho=0.304290
DEBUG: bound: at document #0
INFO: -6.698 per-word bound, 103.9 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 8, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.0014978353, 0.029240007, 0.06671005, 0.028597254, 0.027791174, 0.006455502]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.001): 0.002*"arg" + 0.002*"test_obj" + 0.002*"num" + 0.002*"testclass" + 0.002*"test_func2(num" + 0.002*"test_func(test_obj" + 0.002*"test_obj.one" + 0.002*"execution" + 0.002*"arg.one" + 0.002*"second"
INFO: topic #5 (0.006): 0.057*"command" + 0.046*"line" + 0.035*"script" + 0.013*"dict.i" + 0.013*"window" + 0.013*"dict.hpp" + 0.013*"look" + 0.013*"funny" + 0.013*"os" + 0.013*"typemap"
INFO: topic #3 (0.029): 0.058*"variable" + 0.044*"function" + 0.035*"input" + 0.030*"output" + 0.026*"parameter" + 0.022*"type" + 0.020*"way" + 0.017*"pointer" + 0.011*"value" + 0.011*"pass"
INFO: topic #1 (0.029): 0.064*"object" + 0.059*"function" + 0.055*"value" + 0.035*"arg" + 0.024*"case" + 0.024*"integer" + 0.024*"return" + 0.018*"variable" + 0.018*"test_obj" + 0.015*"="
INFO: topic #2 (0.067): 0.052*"object" + 0.050*"reference" + 0.043*"function" + 0.042*"value" + 0.035*"variable" + 0.015*"parameter" + 0.015*"name" + 0.014*"argument" + 0.014*"new" + 0.013*"list"
INFO: topic diff=0.096041, rho=0.304290
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 48.18051110357749
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -1.7477416262914505
DEBUG: bound: at document #0
INFO: -5.509 per-word bound, 45.5 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 9, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0014902138, 0.028279144, 0.06736908, 0.027683131, 0.02701766, 0.0063139405]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.001): 0.002*"arg" + 0.002*"test_obj" + 0.002*"num" + 0.002*"testclass" + 0.002*"test_func2(num" + 0.002*"test_func(test_obj" + 0.002*"test_obj.one" + 0.002*"execution" + 0.002*"arg.one" + 0.002*"second"
INFO: topic #5 (0.006): 0.045*"command" + 0.036*"line" + 0.028*"script" + 0.010*"funny" + 0.010*"dict.hpp" + 0.010*"dict.i" + 0.010*"window" + 0.010*"os" + 0.010*"typemap" + 0.010*"test"
INFO: topic #3 (0.028): 0.041*"variable" + 0.035*"function" + 0.030*"type" + 0.029*"parameter" + 0.029*"output" + 0.028*"input" + 0.023*"pointer" + 0.016*"value" + 0.016*"pass" + 0.016*"ctype"
INFO: topic #1 (0.028): 0.055*"object" + 0.052*"function" + 0.051*"value" + 0.026*"arg" + 0.026*"return" + 0.022*"case" + 0.019*"array" + 0.017*"integer" + 0.014*"my_fun" + 0.014*"out_arr"
INFO: topic #2 (0.067): 0.055*"object" + 0.053*"reference" + 0.042*"value" + 0.040*"function" + 0.035*"variable" + 0.015*"parameter" + 0.015*"new" + 0.015*"name" + 0.014*"list" + 0.014*"change"
INFO: topic diff=0.095708, rho=0.291111
DEBUG: bound: at document #0
INFO: -6.688 per-word bound, 103.1 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 9, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.0014833164, 0.028133074, 0.065145686, 0.027523676, 0.026890822, 0.007127435]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.001): 0.002*"arg" + 0.002*"test_obj" + 0.002*"testclass" + 0.002*"num" + 0.002*"test_obj.one" + 0.002*"execution" + 0.002*"arg.one" + 0.002*"test_func(test_obj" + 0.002*"test_func2(num" + 0.002*"second"
INFO: topic #5 (0.007): 0.057*"command" + 0.046*"line" + 0.035*"script" + 0.013*"dict.i" + 0.013*"look" + 0.013*"window" + 0.013*"dict.hpp" + 0.013*"typemap" + 0.013*"test" + 0.013*"funny"
INFO: topic #3 (0.028): 0.057*"variable" + 0.044*"function" + 0.034*"input" + 0.030*"output" + 0.026*"parameter" + 0.022*"type" + 0.020*"way" + 0.017*"pointer" + 0.012*"value" + 0.012*"pass"
INFO: topic #1 (0.028): 0.064*"object" + 0.059*"function" + 0.055*"value" + 0.035*"arg" + 0.024*"case" + 0.024*"return" + 0.024*"integer" + 0.018*"variable" + 0.018*"test_obj" + 0.015*"="
INFO: topic #2 (0.065): 0.052*"object" + 0.050*"reference" + 0.042*"function" + 0.042*"value" + 0.035*"variable" + 0.015*"parameter" + 0.015*"name" + 0.014*"argument" + 0.014*"new" + 0.013*"list"
INFO: topic diff=0.090975, rho=0.291111
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 48.13894425479813
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.7489583080209765
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=494, num_topics=6, decay=0.5, chunksize=5> in 0.26s', 'datetime': '2023-04-25T06:36:22.639929', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'auto-adjust_models/models/8/model_t6.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-25T06:36:22.640077', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'auto-adjust_models/models/8/model_t6.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/8/model_t6.state
DEBUG: {'uri': 'auto-adjust_models/models/8/model_t6.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'auto-adjust_models/models/8/model_t6', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['id2word', 'dispatcher', 'state'], 'datetime': '2023-04-25T06:36:22.643643', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to auto-adjust_models/models/8/model_t6.expElogbeta.npy
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
INFO: not storing attribute state
DEBUG: {'uri': 'auto-adjust_models/models/8/model_t6', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/8/model_t6
