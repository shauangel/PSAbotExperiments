INFO: ---Start Analyzing---
INFO: ---Train for 6 Topics---
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<327 unique tokens: ["'", '+', '2.x', '3.x', '=']...> from 10 documents (total 987 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<327 unique tokens: ["\'", \'+\', \'2.x\', \'3.x\', \'=\']...> from 10 documents (total 987 corpus positions)', 'datetime': '2023-04-25T06:36:15.293890', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 6 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.301 per-word bound, 157.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14794004, 0.09611321, 0.04343862, 0.04343801, 0.043346576, 0.20344678]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #4 (0.043): 0.003*"variable" + 0.003*"function" + 0.003*"value" + 0.003*"global" + 0.003*"loop" + 0.003*"appropriate" + 0.003*"other" + 0.003*"access" + 0.003*"local" + 0.003*"program"
INFO: topic #2 (0.043): 0.003*"variable" + 0.003*"global" + 0.003*"function" + 0.003*"value" + 0.003*"loop" + 0.003*"appropriate" + 0.003*"other" + 0.003*"access" + 0.003*"local" + 0.003*"program"
INFO: topic #1 (0.096): 0.065*"program" + 0.049*"variable" + 0.033*"loop" + 0.033*"value" + 0.033*"class" + 0.033*"definition" + 0.017*"scope" + 0.017*"mind" + 0.017*"revision" + 0.017*"highlight"
INFO: topic #0 (0.148): 0.046*"variable" + 0.044*"global" + 0.038*"local" + 0.034*"scope" + 0.033*"function" + 0.027*"c" + 0.026*"name" + 0.021*"=" + 0.020*"num" + 0.020*"line"
INFO: topic #5 (0.203): 0.085*"variable" + 0.042*"function" + 0.041*"local" + 0.039*"global" + 0.033*"scope" + 0.021*"assignment" + 0.020*"name" + 0.018*"line" + 0.018*"num" + 0.018*"error"
INFO: topic diff=3.447693, rho=1.000000
DEBUG: bound: at document #0
INFO: -8.222 per-word bound, 298.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.10239524, 0.06423059, 0.04324146, 0.05069253, 0.04350711, 0.2515946]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.043): 0.020*"force" + 0.020*"coffee_machine" + 0.020*"start" + 0.003*"global" + 0.003*"value" + 0.003*"variable" + 0.003*"function" + 0.003*"line" + 0.003*"local" + 0.003*"loop"
INFO: topic #4 (0.044): 0.023*"define" + 0.023*"condition" + 0.023*"instance" + 0.023*"long" + 0.023*"bit" + 0.023*"comment" + 0.023*"execute" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.064): 0.033*"program" + 0.025*"variable" + 0.018*"loop" + 0.018*"value" + 0.018*"class" + 0.018*"definition" + 0.010*"scope" + 0.010*"mind" + 0.010*"revision" + 0.010*"highlight"
INFO: topic #0 (0.102): 0.038*"variable" + 0.037*"global" + 0.032*"local" + 0.028*"scope" + 0.027*"function" + 0.024*"value" + 0.023*"c" + 0.023*"=" + 0.022*"name" + 0.017*"num"
INFO: topic #5 (0.252): 0.109*"variable" + 0.076*"global" + 0.065*"function" + 0.059*"local" + 0.034*"scope" + 0.022*"assignment" + 0.019*"value" + 0.019*"name" + 0.018*"error" + 0.016*"inside"
INFO: topic diff=0.779502, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 48.19637269931495
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -1.8306693671326222
DEBUG: bound: at document #0
INFO: -5.617 per-word bound, 49.1 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.09262191, 0.06159312, 0.038384877, 0.044024963, 0.038590837, 0.26286754]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.038): 0.012*"start" + 0.012*"coffee_machine" + 0.012*"force" + 0.003*"global" + 0.003*"value" + 0.003*"variable" + 0.003*"function" + 0.003*"line" + 0.003*"local" + 0.003*"loop"
INFO: topic #4 (0.039): 0.014*"execute" + 0.014*"condition" + 0.014*"comment" + 0.014*"define" + 0.014*"long" + 0.014*"bit" + 0.014*"instance" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.062): 0.053*"program" + 0.040*"variable" + 0.027*"definition" + 0.027*"class" + 0.027*"loop" + 0.027*"value" + 0.014*"revision" + 0.014*"highlight" + 0.014*"run" + 0.014*"mind"
INFO: topic #0 (0.093): 0.045*"variable" + 0.034*"global" + 0.034*"local" + 0.032*"scope" + 0.026*"c" + 0.025*"name" + 0.025*"function" + 0.022*"=" + 0.022*"num" + 0.021*"line"
INFO: topic #5 (0.263): 0.118*"variable" + 0.075*"global" + 0.074*"function" + 0.058*"local" + 0.033*"scope" + 0.022*"assignment" + 0.021*"value" + 0.018*"error" + 0.016*"access" + 0.016*"inside"
INFO: topic diff=0.330181, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.957 per-word bound, 62.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.08325742, 0.05233579, 0.038794447, 0.044512387, 0.039151147, 0.28965372]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.039): 0.022*"force" + 0.022*"coffee_machine" + 0.022*"start" + 0.003*"global" + 0.003*"line" + 0.003*"value" + 0.003*"function" + 0.003*"variable" + 0.003*"local" + 0.003*"loop"
INFO: topic #4 (0.039): 0.023*"define" + 0.023*"instance" + 0.023*"bit" + 0.023*"execute" + 0.023*"long" + 0.023*"comment" + 0.023*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.052): 0.035*"program" + 0.027*"variable" + 0.019*"definition" + 0.019*"class" + 0.019*"loop" + 0.019*"value" + 0.010*"revision" + 0.010*"highlight" + 0.010*"run" + 0.010*"mind"
INFO: topic #0 (0.083): 0.041*"variable" + 0.032*"global" + 0.031*"local" + 0.030*"scope" + 0.024*"c" + 0.023*"name" + 0.023*"function" + 0.023*"=" + 0.020*"num" + 0.019*"line"
INFO: topic #5 (0.290): 0.124*"variable" + 0.091*"global" + 0.079*"function" + 0.066*"local" + 0.034*"scope" + 0.022*"assignment" + 0.022*"value" + 0.020*"inside" + 0.018*"error" + 0.017*"name"
INFO: topic diff=0.329658, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 43.34915252620874
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -0.921967297423111
DEBUG: bound: at document #0
INFO: -5.451 per-word bound, 43.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.07832637, 0.051411446, 0.035173725, 0.0397491, 0.035463694, 0.27637452]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.035): 0.014*"coffee_machine" + 0.014*"start" + 0.014*"force" + 0.003*"global" + 0.003*"line" + 0.003*"value" + 0.003*"function" + 0.003*"variable" + 0.003*"local" + 0.003*"loop"
INFO: topic #4 (0.035): 0.015*"define" + 0.015*"comment" + 0.015*"instance" + 0.015*"bit" + 0.015*"long" + 0.015*"execute" + 0.015*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.051): 0.052*"program" + 0.039*"variable" + 0.027*"definition" + 0.027*"class" + 0.027*"loop" + 0.027*"value" + 0.014*"revision" + 0.014*"highlight" + 0.014*"run" + 0.014*"current"
INFO: topic #0 (0.078): 0.048*"variable" + 0.035*"local" + 0.034*"global" + 0.033*"scope" + 0.025*"name" + 0.025*"c" + 0.025*"function" + 0.022*"num" + 0.021*"=" + 0.021*"line"
INFO: topic #5 (0.276): 0.127*"variable" + 0.088*"global" + 0.087*"function" + 0.063*"local" + 0.032*"scope" + 0.024*"value" + 0.021*"inside" + 0.021*"assignment" + 0.019*"access" + 0.017*"error"
INFO: topic diff=0.267373, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.771 per-word bound, 54.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.073185146, 0.04554167, 0.035714023, 0.04039774, 0.03610084, 0.29536474]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.036): 0.023*"coffee_machine" + 0.023*"start" + 0.023*"force" + 0.003*"line" + 0.003*"global" + 0.003*"value" + 0.003*"function" + 0.003*"local" + 0.003*"variable" + 0.003*"loop"
INFO: topic #4 (0.036): 0.023*"define" + 0.023*"instance" + 0.023*"long" + 0.023*"bit" + 0.023*"execute" + 0.023*"comment" + 0.023*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.046): 0.037*"program" + 0.028*"variable" + 0.020*"definition" + 0.020*"class" + 0.020*"loop" + 0.020*"value" + 0.011*"revision" + 0.011*"highlight" + 0.011*"run" + 0.011*"current"
INFO: topic #0 (0.073): 0.045*"variable" + 0.033*"local" + 0.032*"global" + 0.031*"scope" + 0.024*"name" + 0.023*"c" + 0.023*"function" + 0.022*"=" + 0.020*"num" + 0.020*"line"
INFO: topic #5 (0.295): 0.129*"variable" + 0.098*"global" + 0.087*"function" + 0.069*"local" + 0.033*"scope" + 0.024*"value" + 0.022*"inside" + 0.022*"assignment" + 0.017*"error" + 0.016*"work"
INFO: topic diff=0.255929, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 42.06031411603141
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -0.9325664985380219
DEBUG: bound: at document #0
INFO: -5.398 per-word bound, 42.2 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.06999171, 0.04521445, 0.032806847, 0.036680046, 0.03313047, 0.27183104]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.033): 0.015*"coffee_machine" + 0.015*"start" + 0.015*"force" + 0.003*"line" + 0.003*"global" + 0.003*"value" + 0.003*"function" + 0.003*"local" + 0.003*"variable" + 0.003*"loop"
INFO: topic #4 (0.033): 0.016*"long" + 0.016*"instance" + 0.016*"bit" + 0.016*"execute" + 0.016*"define" + 0.016*"comment" + 0.016*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.045): 0.051*"program" + 0.039*"variable" + 0.027*"definition" + 0.027*"class" + 0.027*"loop" + 0.027*"value" + 0.014*"revision" + 0.014*"highlight" + 0.014*"run" + 0.014*"current"
INFO: topic #0 (0.070): 0.051*"variable" + 0.035*"local" + 0.034*"global" + 0.033*"scope" + 0.025*"name" + 0.025*"function" + 0.024*"c" + 0.021*"num" + 0.021*"=" + 0.021*"line"
INFO: topic #5 (0.272): 0.129*"variable" + 0.093*"function" + 0.093*"global" + 0.064*"local" + 0.032*"scope" + 0.026*"value" + 0.024*"inside" + 0.020*"access" + 0.020*"assignment" + 0.016*"error"
INFO: topic diff=0.197947, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.724 per-word bound, 52.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.06661471, 0.040969573, 0.033369083, 0.037352398, 0.033764176, 0.2868165]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.033): 0.024*"force" + 0.024*"coffee_machine" + 0.024*"start" + 0.003*"line" + 0.003*"global" + 0.003*"value" + 0.003*"function" + 0.003*"local" + 0.003*"variable" + 0.003*"loop"
INFO: topic #4 (0.034): 0.023*"bit" + 0.023*"instance" + 0.023*"execute" + 0.023*"define" + 0.023*"long" + 0.023*"comment" + 0.023*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.041): 0.038*"program" + 0.029*"variable" + 0.020*"definition" + 0.020*"class" + 0.020*"loop" + 0.020*"value" + 0.011*"highlight" + 0.011*"revision" + 0.011*"run" + 0.011*"current"
INFO: topic #0 (0.067): 0.048*"variable" + 0.034*"local" + 0.033*"global" + 0.031*"scope" + 0.024*"name" + 0.024*"function" + 0.023*"c" + 0.022*"=" + 0.020*"num" + 0.020*"line"
INFO: topic #5 (0.287): 0.130*"variable" + 0.100*"global" + 0.090*"function" + 0.069*"local" + 0.033*"scope" + 0.025*"value" + 0.024*"inside" + 0.021*"assignment" + 0.017*"error" + 0.017*"work"
INFO: topic diff=0.199726, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 41.6790741694091
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -0.9397735731641527
DEBUG: bound: at document #0
INFO: -5.377 per-word bound, 41.6 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.06429253, 0.040911805, 0.030936845, 0.034306128, 0.031274103, 0.26095122]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.031): 0.016*"coffee_machine" + 0.016*"start" + 0.016*"force" + 0.003*"line" + 0.003*"global" + 0.003*"value" + 0.003*"function" + 0.003*"local" + 0.003*"variable" + 0.003*"loop"
INFO: topic #4 (0.031): 0.016*"bit" + 0.016*"define" + 0.016*"comment" + 0.016*"long" + 0.016*"instance" + 0.016*"execute" + 0.016*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.041): 0.051*"program" + 0.038*"variable" + 0.026*"definition" + 0.026*"class" + 0.026*"loop" + 0.026*"value" + 0.014*"highlight" + 0.014*"revision" + 0.014*"run" + 0.014*"current"
INFO: topic #0 (0.064): 0.052*"variable" + 0.036*"local" + 0.035*"global" + 0.033*"scope" + 0.025*"function" + 0.025*"name" + 0.024*"c" + 0.021*"num" + 0.021*"line" + 0.021*"="
INFO: topic #5 (0.261): 0.129*"variable" + 0.095*"function" + 0.094*"global" + 0.065*"local" + 0.031*"scope" + 0.027*"value" + 0.025*"inside" + 0.020*"access" + 0.019*"assignment" + 0.016*"work"
INFO: topic diff=0.156391, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.710 per-word bound, 52.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.061854873, 0.03761417, 0.03148926, 0.034963597, 0.031883694, 0.2739113]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.031): 0.024*"start" + 0.024*"force" + 0.024*"coffee_machine" + 0.003*"line" + 0.003*"global" + 0.003*"value" + 0.003*"function" + 0.003*"local" + 0.003*"variable" + 0.003*"loop"
INFO: topic #4 (0.032): 0.022*"comment" + 0.022*"define" + 0.022*"instance" + 0.022*"execute" + 0.022*"long" + 0.022*"bit" + 0.022*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.038): 0.039*"program" + 0.030*"variable" + 0.020*"definition" + 0.020*"class" + 0.020*"loop" + 0.020*"value" + 0.011*"highlight" + 0.011*"revision" + 0.011*"run" + 0.011*"current"
INFO: topic #0 (0.062): 0.049*"variable" + 0.034*"local" + 0.033*"global" + 0.031*"scope" + 0.024*"function" + 0.024*"name" + 0.023*"c" + 0.021*"=" + 0.020*"num" + 0.020*"line"
INFO: topic #5 (0.274): 0.130*"variable" + 0.101*"global" + 0.091*"function" + 0.069*"local" + 0.033*"scope" + 0.026*"value" + 0.025*"inside" + 0.021*"assignment" + 0.017*"work" + 0.017*"error"
INFO: topic diff=0.166285, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 41.51814847609007
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -0.9418462242305802
DEBUG: bound: at document #0
INFO: -5.365 per-word bound, 41.2 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.060053766, 0.037697043, 0.029400121, 0.03238893, 0.029741973, 0.24899194]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.029): 0.017*"coffee_machine" + 0.017*"start" + 0.017*"force" + 0.003*"line" + 0.003*"global" + 0.003*"value" + 0.003*"function" + 0.003*"local" + 0.003*"variable" + 0.003*"loop"
INFO: topic #4 (0.030): 0.016*"long" + 0.016*"instance" + 0.016*"execute" + 0.016*"define" + 0.016*"comment" + 0.016*"bit" + 0.016*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.038): 0.051*"program" + 0.038*"variable" + 0.026*"definition" + 0.026*"class" + 0.026*"loop" + 0.026*"value" + 0.014*"revision" + 0.014*"highlight" + 0.014*"run" + 0.014*"key"
INFO: topic #0 (0.060): 0.053*"variable" + 0.036*"local" + 0.035*"global" + 0.033*"scope" + 0.026*"function" + 0.025*"name" + 0.024*"c" + 0.021*"num" + 0.021*"line" + 0.021*"="
INFO: topic #5 (0.249): 0.128*"variable" + 0.095*"function" + 0.095*"global" + 0.065*"local" + 0.031*"scope" + 0.028*"value" + 0.026*"inside" + 0.020*"access" + 0.019*"assignment" + 0.016*"work"
INFO: topic diff=0.143020, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.703 per-word bound, 52.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.058188666, 0.035016175, 0.029933248, 0.03302016, 0.030322826, 0.26069957]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.030): 0.024*"start" + 0.024*"coffee_machine" + 0.024*"force" + 0.003*"line" + 0.003*"global" + 0.003*"value" + 0.003*"function" + 0.003*"local" + 0.003*"variable" + 0.003*"loop"
INFO: topic #4 (0.030): 0.022*"long" + 0.022*"execute" + 0.022*"define" + 0.022*"bit" + 0.022*"instance" + 0.022*"comment" + 0.022*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.035): 0.040*"program" + 0.030*"variable" + 0.021*"definition" + 0.021*"class" + 0.021*"loop" + 0.021*"value" + 0.011*"highlight" + 0.011*"revision" + 0.011*"formatting" + 0.011*"current"
INFO: topic #0 (0.058): 0.050*"variable" + 0.035*"local" + 0.034*"global" + 0.032*"scope" + 0.025*"function" + 0.024*"name" + 0.023*"c" + 0.021*"=" + 0.020*"num" + 0.020*"line"
INFO: topic #5 (0.261): 0.130*"variable" + 0.101*"global" + 0.092*"function" + 0.069*"local" + 0.033*"scope" + 0.026*"value" + 0.025*"inside" + 0.021*"assignment" + 0.017*"work" + 0.017*"error"
INFO: topic diff=0.146746, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 41.42674176434997
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -0.9418462242305802
DEBUG: bound: at document #0
INFO: -5.357 per-word bound, 41.0 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.056739707, 0.035181195, 0.028106395, 0.030797752, 0.02844818, 0.23807025]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.028): 0.017*"coffee_machine" + 0.017*"force" + 0.017*"start" + 0.003*"line" + 0.003*"global" + 0.003*"value" + 0.003*"function" + 0.003*"local" + 0.003*"variable" + 0.003*"loop"
INFO: topic #4 (0.028): 0.016*"instance" + 0.016*"execute" + 0.016*"long" + 0.016*"define" + 0.016*"comment" + 0.016*"bit" + 0.016*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.035): 0.050*"program" + 0.038*"variable" + 0.026*"definition" + 0.026*"class" + 0.026*"loop" + 0.026*"value" + 0.014*"highlight" + 0.014*"revision" + 0.014*"project" + 0.014*"formatting"
INFO: topic #0 (0.057): 0.053*"variable" + 0.036*"local" + 0.036*"global" + 0.033*"scope" + 0.026*"function" + 0.025*"name" + 0.024*"c" + 0.021*"num" + 0.021*"line" + 0.021*"assignment"
INFO: topic #5 (0.238): 0.128*"variable" + 0.095*"function" + 0.095*"global" + 0.065*"local" + 0.031*"scope" + 0.028*"value" + 0.027*"inside" + 0.020*"access" + 0.019*"assignment" + 0.016*"work"
INFO: topic diff=0.134983, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.698 per-word bound, 51.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.05525802, 0.032932922, 0.028618805, 0.031401336, 0.029001515, 0.24891524]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.029): 0.024*"start" + 0.024*"force" + 0.024*"coffee_machine" + 0.003*"line" + 0.003*"global" + 0.003*"value" + 0.003*"function" + 0.003*"local" + 0.003*"variable" + 0.003*"loop"
INFO: topic #4 (0.029): 0.022*"comment" + 0.022*"instance" + 0.022*"execute" + 0.022*"long" + 0.022*"define" + 0.022*"bit" + 0.022*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.033): 0.040*"program" + 0.030*"variable" + 0.021*"definition" + 0.021*"class" + 0.021*"loop" + 0.021*"value" + 0.012*"revision" + 0.012*"highlight" + 0.012*"project" + 0.012*"current"
INFO: topic #0 (0.055): 0.051*"variable" + 0.035*"local" + 0.034*"global" + 0.032*"scope" + 0.025*"function" + 0.024*"name" + 0.023*"c" + 0.021*"=" + 0.020*"num" + 0.020*"line"
INFO: topic #5 (0.249): 0.130*"variable" + 0.101*"global" + 0.092*"function" + 0.069*"local" + 0.033*"scope" + 0.026*"value" + 0.025*"inside" + 0.021*"assignment" + 0.017*"work" + 0.017*"error"
INFO: topic diff=0.134146, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 41.36651102841778
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -0.9418462242305802
DEBUG: bound: at document #0
INFO: -5.351 per-word bound, 40.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.05406211, 0.033148255, 0.026998792, 0.02945149, 0.027337939, 0.22868586]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.027): 0.017*"coffee_machine" + 0.017*"force" + 0.017*"start" + 0.003*"line" + 0.003*"global" + 0.003*"value" + 0.003*"function" + 0.003*"local" + 0.003*"variable" + 0.003*"loop"
INFO: topic #4 (0.027): 0.016*"bit" + 0.016*"comment" + 0.016*"instance" + 0.016*"execute" + 0.016*"define" + 0.016*"long" + 0.016*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.033): 0.050*"program" + 0.038*"variable" + 0.026*"definition" + 0.026*"class" + 0.026*"loop" + 0.026*"value" + 0.014*"highlight" + 0.014*"information" + 0.014*"current" + 0.014*"formatting"
INFO: topic #0 (0.054): 0.054*"variable" + 0.037*"local" + 0.036*"global" + 0.033*"scope" + 0.026*"function" + 0.025*"name" + 0.024*"c" + 0.021*"num" + 0.021*"line" + 0.021*"assignment"
INFO: topic #5 (0.229): 0.128*"variable" + 0.095*"function" + 0.095*"global" + 0.065*"local" + 0.031*"scope" + 0.028*"value" + 0.027*"inside" + 0.020*"access" + 0.019*"assignment" + 0.016*"work"
INFO: topic diff=0.127805, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.694 per-word bound, 51.8 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.052852325, 0.03121871, 0.027491048, 0.030028487, 0.027865985, 0.23881973]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.027): 0.023*"force" + 0.023*"coffee_machine" + 0.023*"start" + 0.003*"line" + 0.003*"global" + 0.003*"value" + 0.003*"function" + 0.003*"local" + 0.003*"variable" + 0.003*"loop"
INFO: topic #4 (0.028): 0.022*"comment" + 0.022*"define" + 0.022*"bit" + 0.022*"long" + 0.022*"execute" + 0.022*"instance" + 0.022*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.031): 0.040*"program" + 0.031*"variable" + 0.021*"definition" + 0.021*"class" + 0.021*"loop" + 0.021*"value" + 0.012*"revision" + 0.012*"project" + 0.012*"setup" + 0.012*"run"
INFO: topic #0 (0.053): 0.052*"variable" + 0.035*"local" + 0.035*"global" + 0.032*"scope" + 0.026*"function" + 0.024*"name" + 0.023*"c" + 0.021*"=" + 0.020*"num" + 0.020*"line"
INFO: topic #5 (0.239): 0.129*"variable" + 0.100*"global" + 0.092*"function" + 0.069*"local" + 0.032*"scope" + 0.026*"value" + 0.026*"inside" + 0.021*"assignment" + 0.017*"work" + 0.016*"error"
INFO: topic diff=0.125071, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 41.321868121591294
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -0.9418462242305802
DEBUG: bound: at document #0
INFO: -5.346 per-word bound, 40.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.051840875, 0.031463776, 0.026036568, 0.028293507, 0.026371608, 0.22049347]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.026): 0.018*"coffee_machine" + 0.018*"force" + 0.018*"start" + 0.003*"line" + 0.003*"global" + 0.003*"value" + 0.003*"function" + 0.003*"local" + 0.003*"variable" + 0.003*"loop"
INFO: topic #4 (0.026): 0.017*"bit" + 0.017*"instance" + 0.017*"execute" + 0.017*"define" + 0.017*"long" + 0.017*"comment" + 0.017*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.031): 0.050*"program" + 0.038*"variable" + 0.026*"definition" + 0.026*"class" + 0.026*"loop" + 0.026*"value" + 0.014*"current" + 0.014*"formatting" + 0.014*"highlight" + 0.014*"information"
INFO: topic #0 (0.052): 0.054*"variable" + 0.037*"local" + 0.036*"global" + 0.033*"scope" + 0.027*"function" + 0.025*"name" + 0.024*"c" + 0.021*"num" + 0.021*"line" + 0.021*"assignment"
INFO: topic #5 (0.220): 0.127*"variable" + 0.095*"function" + 0.095*"global" + 0.065*"local" + 0.031*"scope" + 0.028*"value" + 0.027*"inside" + 0.019*"access" + 0.019*"assignment" + 0.016*"work"
INFO: topic diff=0.121329, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.690 per-word bound, 51.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.050832342, 0.029777922, 0.026509827, 0.02884568, 0.026876643, 0.23005521]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.027): 0.023*"force" + 0.023*"coffee_machine" + 0.023*"start" + 0.003*"line" + 0.003*"global" + 0.003*"value" + 0.003*"function" + 0.003*"local" + 0.003*"variable" + 0.003*"loop"
INFO: topic #4 (0.027): 0.022*"long" + 0.022*"define" + 0.022*"instance" + 0.022*"execute" + 0.022*"bit" + 0.022*"comment" + 0.022*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.030): 0.041*"program" + 0.031*"variable" + 0.021*"definition" + 0.021*"class" + 0.021*"loop" + 0.021*"value" + 0.012*"highlight" + 0.012*"mind" + 0.012*"try" + 0.012*"formatting"
INFO: topic #0 (0.051): 0.052*"variable" + 0.035*"local" + 0.035*"global" + 0.032*"scope" + 0.026*"function" + 0.024*"name" + 0.023*"c" + 0.021*"=" + 0.020*"num" + 0.020*"line"
INFO: topic #5 (0.230): 0.129*"variable" + 0.100*"global" + 0.092*"function" + 0.068*"local" + 0.032*"scope" + 0.026*"value" + 0.026*"inside" + 0.021*"assignment" + 0.017*"work" + 0.016*"error"
INFO: topic diff=0.117974, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 41.28527024611774
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -0.9367118006709508
DEBUG: bound: at document #0
INFO: -5.342 per-word bound, 40.6 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.04995801, 0.03003956, 0.025190046, 0.027283385, 0.025520127, 0.21316573]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.025): 0.018*"coffee_machine" + 0.018*"start" + 0.018*"force" + 0.003*"line" + 0.003*"global" + 0.003*"value" + 0.003*"function" + 0.003*"local" + 0.003*"variable" + 0.003*"loop"
INFO: topic #4 (0.026): 0.017*"long" + 0.017*"define" + 0.017*"instance" + 0.017*"execute" + 0.017*"bit" + 0.017*"comment" + 0.017*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.030): 0.050*"program" + 0.038*"variable" + 0.026*"definition" + 0.026*"class" + 0.026*"loop" + 0.026*"value" + 0.014*"project" + 0.014*"mind" + 0.014*"revision" + 0.014*"key"
INFO: topic #0 (0.050): 0.054*"variable" + 0.037*"local" + 0.036*"global" + 0.033*"scope" + 0.027*"function" + 0.025*"name" + 0.024*"c" + 0.021*"num" + 0.021*"line" + 0.021*"assignment"
INFO: topic #5 (0.213): 0.127*"variable" + 0.095*"function" + 0.095*"global" + 0.064*"local" + 0.031*"scope" + 0.028*"value" + 0.027*"inside" + 0.019*"access" + 0.019*"assignment" + 0.016*"work"
INFO: topic diff=0.115493, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.686 per-word bound, 51.5 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.04910343, 0.028545499, 0.025645582, 0.027812613, 0.026004225, 0.2222808]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #2 (0.026): 0.023*"coffee_machine" + 0.023*"force" + 0.023*"start" + 0.003*"line" + 0.003*"global" + 0.003*"value" + 0.003*"function" + 0.003*"local" + 0.003*"variable" + 0.003*"loop"
INFO: topic #4 (0.026): 0.021*"comment" + 0.021*"define" + 0.021*"bit" + 0.021*"long" + 0.021*"execute" + 0.021*"instance" + 0.021*"condition" + 0.003*"solution" + 0.003*"note" + 0.003*"table"
INFO: topic #1 (0.029): 0.041*"program" + 0.031*"variable" + 0.022*"class" + 0.022*"definition" + 0.022*"loop" + 0.022*"value" + 0.012*"spirit" + 0.012*"mind" + 0.012*"testing" + 0.012*"setup"
INFO: topic #0 (0.049): 0.052*"variable" + 0.036*"local" + 0.035*"global" + 0.032*"scope" + 0.026*"function" + 0.024*"name" + 0.023*"c" + 0.021*"=" + 0.020*"num" + 0.020*"line"
INFO: topic #5 (0.222): 0.129*"variable" + 0.100*"global" + 0.092*"function" + 0.068*"local" + 0.032*"scope" + 0.026*"value" + 0.026*"inside" + 0.021*"assignment" + 0.016*"work" + 0.016*"error"
INFO: topic diff=0.112120, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 41.25519286953218
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -0.9392790124508025
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=327, num_topics=6, decay=0.5, chunksize=5> in 0.23s', 'datetime': '2023-04-25T06:36:15.520815', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'auto-adjust_models/models/1/model_t6.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-25T06:36:15.520964', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'auto-adjust_models/models/1/model_t6.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/1/model_t6.state
DEBUG: {'uri': 'auto-adjust_models/models/1/model_t6.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'auto-adjust_models/models/1/model_t6', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['id2word', 'dispatcher', 'state'], 'datetime': '2023-04-25T06:36:15.523567', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to auto-adjust_models/models/1/model_t6.expElogbeta.npy
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
INFO: not storing attribute state
DEBUG: {'uri': 'auto-adjust_models/models/1/model_t6', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/1/model_t6
