INFO: ---Start Analyzing---
INFO: ---Train for 5 Topics---
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<226 unique tokens: ['argument', 'callable', 'class', 'convenient', 'debate']...> from 9 documents (total 555 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<226 unique tokens: ['argument', 'callable', 'class', 'convenient', 'debate']...> from 9 documents (total 555 corpus positions)", 'datetime': '2023-04-25T06:36:23.302061', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 5 topics, 10 passes over the supplied corpus of 9 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.241 per-word bound, 151.3 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 0, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
WARNING: updated prior is not positive
INFO: optimized alpha [0.2, 0.2, 0.2, 0.2, 0.2]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.200): 0.005*"function" + 0.005*"argument" + 0.004*"decorator" + 0.004*"high" + 0.004*"order" + 0.004*"positional" + 0.004*"type" + 0.004*"f" + 0.004*"return" + 0.004*"solution"
INFO: topic #1 (0.200): 0.071*"function" + 0.059*"argument" + 0.025*"order" + 0.025*"simple" + 0.025*"default" + 0.025*"change" + 0.025*"unnamed" + 0.025*"choice" + 0.025*"func" + 0.024*"type"
INFO: topic #2 (0.200): 0.169*"function" + 0.071*"argument" + 0.039*"high" + 0.036*"decorator" + 0.032*"name" + 0.032*"order" + 0.025*"call" + 0.018*"positional" + 0.014*"expression" + 0.014*"way"
INFO: topic #3 (0.200): 0.005*"function" + 0.005*"argument" + 0.004*"decorator" + 0.004*"order" + 0.004*"return" + 0.004*"type" + 0.004*"high" + 0.004*"f" + 0.004*"https://docs.python.org/3/library/typing.html#callable" + 0.004*"ref"
INFO: topic #4 (0.200): 0.005*"function" + 0.005*"argument" + 0.004*"type" + 0.004*"order" + 0.004*"decorator" + 0.004*"high" + 0.004*"ref" + 0.004*"f" + 0.004*"element" + 0.004*"solution"
INFO: topic diff=3.321907, rho=1.000000
DEBUG: bound: at document #0
INFO: -7.689 per-word bound, 206.3 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 0, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.1871296, 0.22934394, 0.29931784, 0.0827907, 0.19776097]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.187): 0.059*"html_tag" + 0.048*"second" + 0.026*"lst" + 0.025*"new" + 0.025*"different" + 0.025*"reason" + 0.014*"problem" + 0.014*"attribute" + 0.014*"mode" + 0.014*"core"
INFO: topic #1 (0.229): 0.065*"function" + 0.063*"time" + 0.052*"first" + 0.040*"result" + 0.030*"argument" + 0.028*"value" + 0.021*"return" + 0.021*"func" + 0.021*"change" + 0.020*"way"
INFO: topic #2 (0.299): 0.201*"function" + 0.065*"argument" + 0.042*"example" + 0.037*"return" + 0.037*"class" + 0.036*"high" + 0.029*"order" + 0.020*"decorator" + 0.020*"reference" + 0.017*"f"
INFO: topic #3 (0.083): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.198): 0.041*"new" + 0.032*"hof" + 0.032*"version" + 0.022*"datum" + 0.022*"operation" + 0.021*"single" + 0.021*"make_function_print_arg" + 0.012*"state" + 0.012*"key" + 0.012*"machine"
INFO: topic diff=1.183662, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 37.06693719901574
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -8.03564990028864
DEBUG: bound: at document #0
INFO: -5.163 per-word bound, 35.8 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 1, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.096476585, 0.17508677, 0.27942815, 0.06442551, 0.096961856]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.096): 0.041*"html_tag" + 0.034*"second" + 0.019*"lst" + 0.018*"new" + 0.018*"different" + 0.018*"reason" + 0.011*"attribute" + 0.011*"problem" + 0.011*"mode" + 0.011*"core"
INFO: topic #1 (0.175): 0.068*"function" + 0.046*"argument" + 0.036*"time" + 0.031*"first" + 0.025*"result" + 0.023*"func" + 0.023*"change" + 0.022*"order" + 0.020*"value" + 0.018*"simple"
INFO: topic #2 (0.279): 0.182*"function" + 0.068*"argument" + 0.038*"high" + 0.031*"order" + 0.030*"decorator" + 0.025*"name" + 0.023*"return" + 0.023*"example" + 0.021*"call" + 0.021*"class"
INFO: topic #3 (0.064): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.097): 0.032*"new" + 0.025*"hof" + 0.025*"version" + 0.017*"datum" + 0.017*"operation" + 0.017*"single" + 0.017*"make_function_print_arg" + 0.010*"state" + 0.010*"key" + 0.010*"machine"
INFO: topic diff=0.398120, rho=0.512989
DEBUG: bound: at document #0
INFO: -5.624 per-word bound, 49.3 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 1, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.10746936, 0.19441581, 0.35847622, 0.05490931, 0.10945101]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.107): 0.063*"html_tag" + 0.051*"second" + 0.027*"lst" + 0.027*"different" + 0.027*"reason" + 0.026*"new" + 0.015*"attribute" + 0.015*"problem" + 0.015*"block" + 0.015*"mode"
INFO: topic #1 (0.194): 0.068*"time" + 0.062*"function" + 0.055*"first" + 0.043*"result" + 0.032*"argument" + 0.027*"value" + 0.023*"func" + 0.022*"change" + 0.021*"way" + 0.019*"return"
INFO: topic #2 (0.358): 0.207*"function" + 0.067*"argument" + 0.041*"example" + 0.038*"return" + 0.037*"high" + 0.036*"class" + 0.030*"order" + 0.022*"decorator" + 0.019*"reference" + 0.017*"f"
INFO: topic #3 (0.055): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.109): 0.042*"new" + 0.032*"version" + 0.032*"hof" + 0.022*"datum" + 0.022*"operation" + 0.022*"single" + 0.022*"make_function_print_arg" + 0.012*"extra" + 0.012*"accomplish" + 0.012*"machine"
INFO: topic diff=0.312469, rho=0.512989
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 35.50003809138064
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -8.234504036100107
DEBUG: bound: at document #0
INFO: -5.073 per-word bound, 33.7 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 2, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.079790056, 0.16344418, 0.31669927, 0.047598645, 0.08075752]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.080): 0.048*"html_tag" + 0.039*"second" + 0.021*"lst" + 0.021*"different" + 0.021*"reason" + 0.020*"new" + 0.012*"attribute" + 0.012*"problem" + 0.012*"block" + 0.012*"mode"
INFO: topic #1 (0.163): 0.066*"function" + 0.046*"argument" + 0.040*"time" + 0.034*"first" + 0.028*"result" + 0.024*"func" + 0.024*"change" + 0.022*"order" + 0.020*"value" + 0.018*"simple"
INFO: topic #2 (0.317): 0.186*"function" + 0.069*"argument" + 0.038*"high" + 0.031*"order" + 0.029*"decorator" + 0.025*"return" + 0.025*"name" + 0.024*"example" + 0.022*"class" + 0.021*"call"
INFO: topic #3 (0.048): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.081): 0.034*"new" + 0.026*"version" + 0.026*"hof" + 0.018*"datum" + 0.018*"operation" + 0.018*"single" + 0.018*"make_function_print_arg" + 0.010*"extra" + 0.010*"accomplish" + 0.010*"machine"
INFO: topic diff=0.311458, rho=0.456435
DEBUG: bound: at document #0
INFO: -5.549 per-word bound, 46.8 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 2, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.08965382, 0.18029124, 0.38577348, 0.042942263, 0.09153454]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.090): 0.064*"html_tag" + 0.052*"second" + 0.027*"lst" + 0.027*"different" + 0.027*"reason" + 0.026*"new" + 0.014*"attribute" + 0.014*"problem" + 0.014*"block" + 0.014*"mode"
INFO: topic #1 (0.180): 0.069*"time" + 0.060*"function" + 0.056*"first" + 0.044*"result" + 0.034*"argument" + 0.025*"value" + 0.024*"func" + 0.023*"change" + 0.021*"way" + 0.019*"variable"
INFO: topic #2 (0.386): 0.207*"function" + 0.068*"argument" + 0.039*"example" + 0.038*"return" + 0.037*"high" + 0.035*"class" + 0.031*"order" + 0.022*"decorator" + 0.017*"reference" + 0.017*"call"
INFO: topic #3 (0.043): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.092): 0.041*"new" + 0.032*"version" + 0.032*"hof" + 0.022*"datum" + 0.022*"operation" + 0.022*"single" + 0.022*"make_function_print_arg" + 0.012*"extra" + 0.012*"accomplish" + 0.012*"machine"
INFO: topic diff=0.244461, rho=0.456435
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 34.982253947291845
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -8.357490005479903
DEBUG: bound: at document #0
INFO: -5.034 per-word bound, 32.8 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 3, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.071784586, 0.15701419, 0.3329821, 0.03880661, 0.07291629]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.072): 0.051*"html_tag" + 0.041*"second" + 0.022*"lst" + 0.022*"different" + 0.022*"reason" + 0.022*"new" + 0.012*"attribute" + 0.012*"problem" + 0.012*"block" + 0.012*"mode"
INFO: topic #1 (0.157): 0.065*"function" + 0.046*"argument" + 0.042*"time" + 0.035*"first" + 0.029*"result" + 0.025*"func" + 0.024*"change" + 0.022*"order" + 0.019*"value" + 0.018*"simple"
INFO: topic #2 (0.333): 0.188*"function" + 0.069*"argument" + 0.038*"high" + 0.032*"order" + 0.029*"decorator" + 0.026*"return" + 0.025*"example" + 0.024*"name" + 0.023*"class" + 0.021*"call"
INFO: topic #3 (0.039): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.073): 0.035*"new" + 0.027*"version" + 0.027*"hof" + 0.019*"datum" + 0.019*"operation" + 0.018*"single" + 0.018*"make_function_print_arg" + 0.010*"extra" + 0.010*"accomplish" + 0.010*"machine"
INFO: topic diff=0.252833, rho=0.415227
DEBUG: bound: at document #0
INFO: -5.515 per-word bound, 45.7 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 3, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.08006618, 0.15336794, 0.3845742, 0.035836995, 0.08188715]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.080): 0.064*"html_tag" + 0.052*"second" + 0.027*"lst" + 0.027*"different" + 0.027*"reason" + 0.026*"new" + 0.014*"attribute" + 0.014*"problem" + 0.014*"block" + 0.014*"mode"
INFO: topic #1 (0.153): 0.069*"time" + 0.059*"function" + 0.057*"first" + 0.044*"result" + 0.036*"argument" + 0.025*"func" + 0.023*"value" + 0.022*"way" + 0.020*"variable" + 0.019*"order"
INFO: topic #2 (0.385): 0.207*"function" + 0.068*"argument" + 0.038*"example" + 0.037*"return" + 0.037*"high" + 0.034*"class" + 0.031*"order" + 0.023*"decorator" + 0.017*"call" + 0.017*"name"
INFO: topic #3 (0.036): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.082): 0.041*"new" + 0.031*"version" + 0.031*"hof" + 0.021*"datum" + 0.021*"operation" + 0.021*"single" + 0.021*"make_function_print_arg" + 0.011*"functools.partial" + 0.011*"know" + 0.011*"meat"
INFO: topic diff=0.218216, rho=0.415227
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 34.643174288543705
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -8.237584690235902
DEBUG: bound: at document #0
INFO: -5.011 per-word bound, 32.3 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 4, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.06647569, 0.13970341, 0.32786474, 0.033094116, 0.06767722]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.066): 0.052*"html_tag" + 0.042*"second" + 0.022*"lst" + 0.022*"different" + 0.022*"reason" + 0.022*"new" + 0.012*"attribute" + 0.012*"problem" + 0.012*"block" + 0.012*"mode"
INFO: topic #1 (0.140): 0.064*"function" + 0.046*"argument" + 0.043*"time" + 0.037*"first" + 0.030*"result" + 0.025*"func" + 0.021*"order" + 0.020*"change" + 0.019*"value" + 0.018*"simple"
INFO: topic #2 (0.328): 0.189*"function" + 0.069*"argument" + 0.038*"high" + 0.032*"order" + 0.029*"decorator" + 0.027*"return" + 0.025*"example" + 0.024*"name" + 0.023*"class" + 0.021*"call"
INFO: topic #3 (0.033): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.068): 0.035*"new" + 0.027*"version" + 0.027*"hof" + 0.019*"datum" + 0.019*"operation" + 0.019*"single" + 0.019*"make_function_print_arg" + 0.010*"functools.partial" + 0.010*"know" + 0.010*"meat"
INFO: topic diff=0.218242, rho=0.383482
DEBUG: bound: at document #0
INFO: -5.484 per-word bound, 44.8 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 4, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.07387148, 0.13915609, 0.37212715, 0.031064771, 0.0756163]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.074): 0.063*"html_tag" + 0.051*"second" + 0.026*"lst" + 0.026*"reason" + 0.026*"different" + 0.026*"new" + 0.023*"reference" + 0.014*"attribute" + 0.014*"block" + 0.014*"conditional"
INFO: topic #1 (0.139): 0.068*"time" + 0.059*"function" + 0.056*"first" + 0.044*"result" + 0.037*"argument" + 0.026*"func" + 0.022*"value" + 0.022*"way" + 0.020*"variable" + 0.019*"order"
INFO: topic #2 (0.372): 0.207*"function" + 0.068*"argument" + 0.037*"example" + 0.037*"high" + 0.037*"return" + 0.033*"class" + 0.032*"order" + 0.023*"decorator" + 0.018*"call" + 0.018*"name"
INFO: topic #3 (0.031): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.076): 0.041*"new" + 0.031*"version" + 0.031*"hof" + 0.021*"datum" + 0.021*"operation" + 0.021*"single" + 0.021*"make_function_print_arg" + 0.011*"functools.partial" + 0.011*"know" + 0.011*"meat"
INFO: topic diff=0.197647, rho=0.383482
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 34.45313785688155
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -7.686352261316659
DEBUG: bound: at document #0
INFO: -4.994 per-word bound, 31.9 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 5, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.062756464, 0.12939924, 0.3168037, 0.029086273, 0.06397426]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.063): 0.053*"html_tag" + 0.042*"second" + 0.022*"lst" + 0.022*"reason" + 0.022*"different" + 0.022*"new" + 0.019*"reference" + 0.012*"attribute" + 0.012*"block" + 0.012*"conditional"
INFO: topic #1 (0.129): 0.064*"function" + 0.046*"argument" + 0.044*"time" + 0.038*"first" + 0.031*"result" + 0.025*"func" + 0.021*"order" + 0.019*"change" + 0.018*"value" + 0.018*"simple"
INFO: topic #2 (0.317): 0.190*"function" + 0.069*"argument" + 0.038*"high" + 0.032*"order" + 0.029*"decorator" + 0.027*"return" + 0.026*"example" + 0.024*"name" + 0.023*"class" + 0.021*"call"
INFO: topic #3 (0.029): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.064): 0.035*"new" + 0.027*"version" + 0.027*"hof" + 0.019*"datum" + 0.019*"operation" + 0.019*"single" + 0.019*"make_function_print_arg" + 0.010*"functools.partial" + 0.010*"know" + 0.010*"meat"
INFO: topic diff=0.195328, rho=0.358057
DEBUG: bound: at document #0
INFO: -5.467 per-word bound, 44.2 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 5, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.069452316, 0.13023953, 0.35620248, 0.027599491, 0.071121894]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.069): 0.062*"html_tag" + 0.050*"second" + 0.032*"reference" + 0.026*"lst" + 0.026*"reason" + 0.026*"different" + 0.026*"new" + 0.014*"attribute" + 0.014*"block" + 0.014*"conditional"
INFO: topic #1 (0.130): 0.067*"time" + 0.059*"function" + 0.055*"first" + 0.043*"result" + 0.037*"argument" + 0.026*"func" + 0.022*"way" + 0.022*"value" + 0.020*"variable" + 0.019*"order"
INFO: topic #2 (0.356): 0.207*"function" + 0.069*"argument" + 0.037*"high" + 0.037*"example" + 0.037*"return" + 0.032*"class" + 0.032*"order" + 0.024*"decorator" + 0.018*"name" + 0.018*"call"
INFO: topic #3 (0.028): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.071): 0.041*"new" + 0.031*"version" + 0.031*"hof" + 0.021*"datum" + 0.021*"operation" + 0.021*"single" + 0.021*"make_function_print_arg" + 0.011*"functools.partial" + 0.011*"know" + 0.011*"meat"
INFO: topic diff=0.183096, rho=0.358057
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 34.31290016014945
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -7.699198358018421
DEBUG: bound: at document #0
INFO: -4.980 per-word bound, 31.6 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 6, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.05997229, 0.12252539, 0.30464125, 0.02609347, 0.061183892]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.060): 0.053*"html_tag" + 0.043*"second" + 0.027*"reference" + 0.022*"lst" + 0.022*"reason" + 0.022*"different" + 0.022*"new" + 0.012*"attribute" + 0.012*"block" + 0.012*"conditional"
INFO: topic #1 (0.123): 0.064*"function" + 0.046*"argument" + 0.045*"time" + 0.038*"first" + 0.031*"result" + 0.025*"func" + 0.021*"order" + 0.018*"change" + 0.018*"way" + 0.018*"simple"
INFO: topic #2 (0.305): 0.191*"function" + 0.070*"argument" + 0.038*"high" + 0.032*"order" + 0.029*"decorator" + 0.027*"return" + 0.026*"example" + 0.024*"name" + 0.023*"class" + 0.021*"call"
INFO: topic #3 (0.026): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.061): 0.036*"new" + 0.027*"version" + 0.027*"hof" + 0.019*"datum" + 0.019*"operation" + 0.019*"single" + 0.019*"make_function_print_arg" + 0.010*"functools.partial" + 0.010*"know" + 0.010*"meat"
INFO: topic diff=0.178968, rho=0.337100
DEBUG: bound: at document #0
INFO: -5.456 per-word bound, 43.9 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 6, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.06610938, 0.12402835, 0.34084916, 0.024952099, 0.06771409]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.066): 0.062*"html_tag" + 0.050*"second" + 0.038*"reference" + 0.026*"lst" + 0.026*"reason" + 0.026*"different" + 0.026*"new" + 0.014*"attribute" + 0.014*"block" + 0.014*"conditional"
INFO: topic #1 (0.124): 0.066*"time" + 0.060*"function" + 0.055*"first" + 0.043*"result" + 0.038*"argument" + 0.026*"func" + 0.022*"way" + 0.021*"value" + 0.019*"variable" + 0.019*"order"
INFO: topic #2 (0.341): 0.207*"function" + 0.069*"argument" + 0.038*"high" + 0.036*"return" + 0.036*"example" + 0.032*"order" + 0.031*"class" + 0.024*"decorator" + 0.018*"name" + 0.018*"call"
INFO: topic #3 (0.025): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.068): 0.040*"new" + 0.031*"version" + 0.031*"hof" + 0.021*"datum" + 0.021*"operation" + 0.021*"single" + 0.021*"make_function_print_arg" + 0.011*"functools.partial" + 0.011*"know" + 0.011*"meat"
INFO: topic diff=0.171116, rho=0.337100
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 34.20851926881163
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -7.707846847569778
DEBUG: bound: at document #0
INFO: -4.970 per-word bound, 31.3 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 7, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.057800546, 0.117571935, 0.29359627, 0.023761855, 0.058999643]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.058): 0.053*"html_tag" + 0.043*"second" + 0.033*"reference" + 0.022*"lst" + 0.022*"reason" + 0.022*"different" + 0.022*"new" + 0.012*"attribute" + 0.012*"block" + 0.012*"conditional"
INFO: topic #1 (0.118): 0.064*"function" + 0.046*"argument" + 0.046*"time" + 0.038*"first" + 0.031*"result" + 0.025*"func" + 0.021*"order" + 0.019*"way" + 0.018*"change" + 0.018*"value"
INFO: topic #2 (0.294): 0.192*"function" + 0.070*"argument" + 0.038*"high" + 0.032*"order" + 0.029*"decorator" + 0.028*"return" + 0.026*"example" + 0.024*"name" + 0.023*"class" + 0.021*"call"
INFO: topic #3 (0.024): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.059): 0.036*"new" + 0.027*"version" + 0.027*"hof" + 0.019*"datum" + 0.019*"operation" + 0.019*"single" + 0.019*"make_function_print_arg" + 0.010*"functools.partial" + 0.010*"know" + 0.010*"meat"
INFO: topic diff=0.166375, rho=0.319438
DEBUG: bound: at document #0
INFO: -5.447 per-word bound, 43.6 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 7, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.06348345, 0.11941355, 0.32737744, 0.022854976, 0.06503565]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.063): 0.061*"html_tag" + 0.049*"second" + 0.042*"reference" + 0.025*"lst" + 0.025*"reason" + 0.025*"different" + 0.025*"new" + 0.014*"attribute" + 0.014*"block" + 0.014*"conditional"
INFO: topic #1 (0.119): 0.065*"time" + 0.060*"function" + 0.054*"first" + 0.042*"result" + 0.038*"argument" + 0.026*"func" + 0.023*"way" + 0.021*"value" + 0.019*"order" + 0.019*"variable"
INFO: topic #2 (0.327): 0.207*"function" + 0.069*"argument" + 0.038*"high" + 0.036*"return" + 0.036*"example" + 0.032*"order" + 0.030*"class" + 0.024*"decorator" + 0.019*"name" + 0.018*"call"
INFO: topic #3 (0.023): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.065): 0.040*"new" + 0.030*"version" + 0.030*"hof" + 0.021*"datum" + 0.021*"operation" + 0.021*"single" + 0.021*"make_function_print_arg" + 0.011*"functools.partial" + 0.011*"know" + 0.011*"meat"
INFO: topic diff=0.161090, rho=0.319438
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 34.11636018574618
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -7.712729568852748
DEBUG: bound: at document #0
INFO: -4.961 per-word bound, 31.1 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 8, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.056059353, 0.11381899, 0.28425673, 0.021887703, 0.05724629]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.056): 0.053*"html_tag" + 0.043*"second" + 0.036*"reference" + 0.022*"lst" + 0.022*"reason" + 0.022*"different" + 0.022*"new" + 0.012*"attribute" + 0.012*"block" + 0.012*"conditional"
INFO: topic #1 (0.114): 0.064*"function" + 0.046*"time" + 0.046*"argument" + 0.039*"first" + 0.032*"result" + 0.025*"func" + 0.021*"order" + 0.019*"way" + 0.018*"value" + 0.018*"change"
INFO: topic #2 (0.284): 0.192*"function" + 0.070*"argument" + 0.038*"high" + 0.032*"order" + 0.029*"decorator" + 0.028*"return" + 0.026*"example" + 0.024*"name" + 0.023*"class" + 0.021*"call"
INFO: topic #3 (0.022): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"html_tag" + 0.004*"argument" + 0.004*"block" + 0.004*"attribute" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.057): 0.036*"new" + 0.027*"version" + 0.027*"hof" + 0.019*"datum" + 0.019*"operation" + 0.019*"single" + 0.019*"make_function_print_arg" + 0.010*"functools.partial" + 0.010*"know" + 0.010*"meat"
INFO: topic diff=0.156187, rho=0.304290
DEBUG: bound: at document #0
INFO: -5.439 per-word bound, 43.4 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 8, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.0613641, 0.11582981, 0.315832, 0.021147378, 0.06287657]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.061): 0.061*"html_tag" + 0.049*"second" + 0.044*"reference" + 0.025*"lst" + 0.025*"reason" + 0.025*"different" + 0.025*"new" + 0.014*"attribute" + 0.014*"block" + 0.014*"conditional"
INFO: topic #1 (0.116): 0.065*"time" + 0.060*"function" + 0.053*"first" + 0.042*"result" + 0.038*"argument" + 0.026*"func" + 0.023*"way" + 0.021*"value" + 0.020*"order" + 0.019*"variable"
INFO: topic #2 (0.316): 0.207*"function" + 0.069*"argument" + 0.038*"high" + 0.036*"return" + 0.035*"example" + 0.032*"order" + 0.028*"class" + 0.025*"decorator" + 0.019*"name" + 0.018*"call"
INFO: topic #3 (0.021): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"argument" + 0.004*"html_tag" + 0.004*"attribute" + 0.004*"block" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.063): 0.040*"new" + 0.030*"version" + 0.030*"hof" + 0.021*"datum" + 0.021*"operation" + 0.021*"single" + 0.021*"make_function_print_arg" + 0.014*"class" + 0.011*"meat" + 0.011*"know"
INFO: topic diff=0.152694, rho=0.304290
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 34.01196813423881
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -7.727539366675748
DEBUG: bound: at document #0
INFO: -4.954 per-word bound, 31.0 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 9, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.05463312, 0.11086888, 0.27644745, 0.020344011, 0.0558116]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.055): 0.053*"html_tag" + 0.043*"second" + 0.038*"reference" + 0.022*"lst" + 0.022*"reason" + 0.022*"different" + 0.022*"new" + 0.012*"attribute" + 0.012*"block" + 0.012*"conditional"
INFO: topic #1 (0.111): 0.064*"function" + 0.046*"time" + 0.046*"argument" + 0.039*"first" + 0.032*"result" + 0.025*"func" + 0.021*"order" + 0.019*"way" + 0.018*"value" + 0.018*"change"
INFO: topic #2 (0.276): 0.193*"function" + 0.070*"argument" + 0.038*"high" + 0.032*"order" + 0.029*"decorator" + 0.028*"return" + 0.026*"example" + 0.024*"name" + 0.022*"class" + 0.021*"call"
INFO: topic #3 (0.020): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"argument" + 0.004*"html_tag" + 0.004*"attribute" + 0.004*"block" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.056): 0.036*"new" + 0.027*"version" + 0.027*"hof" + 0.019*"datum" + 0.019*"operation" + 0.019*"single" + 0.019*"make_function_print_arg" + 0.013*"class" + 0.010*"meat" + 0.010*"know"
INFO: topic diff=0.147717, rho=0.291111
DEBUG: bound: at document #0
INFO: -5.429 per-word bound, 43.1 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 9, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.05961646, 0.11294848, 0.30586007, 0.01972625, 0.061101545]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.060): 0.060*"html_tag" + 0.049*"second" + 0.045*"reference" + 0.025*"lst" + 0.025*"reason" + 0.025*"different" + 0.025*"new" + 0.013*"attribute" + 0.013*"block" + 0.013*"conditional"
INFO: topic #1 (0.113): 0.064*"time" + 0.060*"function" + 0.053*"first" + 0.042*"result" + 0.039*"argument" + 0.026*"func" + 0.023*"way" + 0.021*"value" + 0.020*"order" + 0.019*"variable"
INFO: topic #2 (0.306): 0.207*"function" + 0.070*"argument" + 0.038*"high" + 0.036*"return" + 0.035*"example" + 0.032*"order" + 0.025*"decorator" + 0.024*"class" + 0.019*"name" + 0.019*"call"
INFO: topic #3 (0.020): 0.004*"lst" + 0.004*"new" + 0.004*"function" + 0.004*"argument" + 0.004*"html_tag" + 0.004*"attribute" + 0.004*"block" + 0.004*"instance" + 0.004*"mode" + 0.004*"conditional"
INFO: topic #4 (0.061): 0.039*"new" + 0.030*"version" + 0.030*"hof" + 0.023*"class" + 0.020*"datum" + 0.020*"operation" + 0.020*"single" + 0.020*"make_function_print_arg" + 0.011*"meat" + 0.011*"know"
INFO: topic diff=0.145616, rho=0.291111
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 33.885695646535495
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -7.739861983219036
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=226, num_topics=5, decay=0.5, chunksize=5> in 0.17s', 'datetime': '2023-04-25T06:36:23.469650', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'auto-adjust_models/models/9/model_t5.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-25T06:36:23.469852', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'auto-adjust_models/models/9/model_t5.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/9/model_t5.state
DEBUG: {'uri': 'auto-adjust_models/models/9/model_t5.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'auto-adjust_models/models/9/model_t5', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['id2word', 'dispatcher', 'state'], 'datetime': '2023-04-25T06:36:23.472390', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to auto-adjust_models/models/9/model_t5.expElogbeta.npy
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
INFO: not storing attribute state
DEBUG: {'uri': 'auto-adjust_models/models/9/model_t5', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/9/model_t5
