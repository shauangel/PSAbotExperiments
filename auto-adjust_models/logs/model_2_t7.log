INFO: ---Start Analyzing---
INFO: ---Train for 7 Topics---
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<310 unique tokens: ['42', '=', 'access', 'accidental', 'add']...> from 9 documents (total 996 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<310 unique tokens: ['42', '=', 'access', 'accidental', 'add']...> from 9 documents (total 996 corpus positions)", 'datetime': '2023-04-25T06:36:16.470116', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.14285715, 0.14285715, 0.14285715, 0.14285715, 0.14285715, 0.14285715, 0.14285715]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 7 topics, 10 passes over the supplied corpus of 9 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.587 per-word bound, 192.3 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 0, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.04541695, 0.045390777, 0.13145898, 0.13816811, 0.04536453, 0.045397103, 0.082610175]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #5 (0.045): 0.003*"local" + 0.003*"variable" + 0.003*"global" + 0.003*"function" + 0.003*"name" + 0.003*"non" + 0.003*"totalcarbs(global" + 0.003*"=" + 0.003*"one" + 0.003*"apple"
INFO: topic #0 (0.045): 0.003*"variable" + 0.003*"global" + 0.003*"local" + 0.003*"function" + 0.003*"name" + 0.003*"non" + 0.003*"one" + 0.003*"=" + 0.003*"totalcarbs(local" + 0.003*"apple"
INFO: topic #6 (0.083): 0.094*"local" + 0.064*"non" + 0.064*"name" + 0.033*"one" + 0.002*"variable" + 0.002*"global" + 0.002*"function" + 0.002*"=" + 0.002*"scope" + 0.002*"totalcarbs(local"
INFO: topic #2 (0.131): 0.132*"variable" + 0.088*"global" + 0.055*"local" + 0.034*"change" + 0.034*"function" + 0.023*"case" + 0.023*"value" + 0.023*"p2o" + 0.023*"bool" + 0.023*"type"
INFO: topic #3 (0.138): 0.127*"global" + 0.104*"variable" + 0.056*"function" + 0.040*"module" + 0.036*"local" + 0.029*"name" + 0.011*"example" + 0.011*"scope" + 0.010*"class" + 0.010*"keyword"
INFO: topic diff=4.723082, rho=1.000000
DEBUG: bound: at document #0
INFO: -7.810 per-word bound, 224.5 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 0, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.04618662, 0.03746894, 0.09796968, 0.21147236, 0.037451822, 0.056047816, 0.07421207]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #4 (0.037): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"name" + 0.003*"function" + 0.003*"non" + 0.003*"totalcarbs(global" + 0.003*"one" + 0.003*"=" + 0.003*"inside"
INFO: topic #1 (0.037): 0.003*"local" + 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"non" + 0.003*"name" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"=" + 0.003*"scope"
INFO: topic #6 (0.074): 0.049*"local" + 0.037*"name" + 0.035*"one" + 0.019*"non" + 0.011*"fct1" + 0.011*"programming" + 0.011*"project" + 0.011*"big" + 0.011*"bad" + 0.011*"programmer"
INFO: topic #2 (0.098): 0.105*"variable" + 0.076*"global" + 0.045*"local" + 0.027*"value" + 0.025*"function" + 0.024*"case" + 0.017*"change" + 0.012*"try" + 0.012*"function1" + 0.012*"tell"
INFO: topic #3 (0.211): 0.135*"global" + 0.101*"variable" + 0.070*"function" + 0.043*"module" + 0.034*"local" + 0.030*"name" + 0.020*"value" + 0.016*"assign" + 0.015*"keyword" + 0.012*"attribute"
INFO: topic diff=0.704202, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 35.417040982199225
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=7, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -3.3344629101750938
DEBUG: bound: at document #0
INFO: -5.056 per-word bound, 33.3 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 1, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.03978089, 0.03324853, 0.09690339, 0.16705993, 0.033235263, 0.0466287, 0.06669983]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #1 (0.033): 0.003*"local" + 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"non" + 0.003*"name" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"=" + 0.003*"scope"
INFO: topic #4 (0.033): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"name" + 0.003*"function" + 0.003*"non" + 0.003*"totalcarbs(global" + 0.003*"one" + 0.003*"=" + 0.003*"inside"
INFO: topic #6 (0.067): 0.071*"local" + 0.050*"name" + 0.041*"non" + 0.034*"one" + 0.007*"big" + 0.007*"bad" + 0.007*"fct1" + 0.007*"programmer" + 0.007*"project" + 0.007*"programming"
INFO: topic #2 (0.097): 0.122*"variable" + 0.084*"global" + 0.051*"local" + 0.031*"function" + 0.028*"change" + 0.024*"value" + 0.023*"case" + 0.019*"p2o" + 0.019*"bool" + 0.019*"type"
INFO: topic #3 (0.167): 0.129*"global" + 0.103*"variable" + 0.061*"function" + 0.041*"module" + 0.035*"local" + 0.030*"name" + 0.012*"value" + 0.012*"keyword" + 0.011*"scope" + 0.011*"example"
INFO: topic diff=0.261667, rho=0.512989
DEBUG: bound: at document #0
INFO: -5.884 per-word bound, 59.0 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 1, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.04093899, 0.030212982, 0.087452054, 0.22700025, 0.03020213, 0.054674756, 0.06319747]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #1 (0.030): 0.003*"local" + 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"non" + 0.003*"name" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"=" + 0.003*"scope"
INFO: topic #4 (0.030): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"name" + 0.003*"function" + 0.003*"non" + 0.003*"totalcarbs(global" + 0.003*"one" + 0.003*"=" + 0.003*"inside"
INFO: topic #6 (0.063): 0.042*"local" + 0.041*"one" + 0.031*"name" + 0.024*"non" + 0.005*"big" + 0.005*"project" + 0.005*"fct1" + 0.005*"programming" + 0.005*"bad" + 0.005*"programmer"
INFO: topic #2 (0.087): 0.107*"variable" + 0.077*"global" + 0.045*"local" + 0.026*"value" + 0.025*"function" + 0.023*"case" + 0.018*"change" + 0.014*"try" + 0.014*"decoration" + 0.014*"tell"
INFO: topic #3 (0.227): 0.135*"global" + 0.102*"variable" + 0.070*"function" + 0.043*"module" + 0.035*"local" + 0.031*"name" + 0.019*"value" + 0.015*"assign" + 0.015*"keyword" + 0.012*"scope"
INFO: topic diff=0.233575, rho=0.512989
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 34.53294910007948
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=7, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -3.327692478250668
DEBUG: bound: at document #0
INFO: -5.016 per-word bound, 32.4 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 2, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.03628714, 0.027676435, 0.08763586, 0.17455931, 0.027667403, 0.046393793, 0.058790565]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #4 (0.028): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"name" + 0.003*"function" + 0.003*"non" + 0.003*"totalcarbs(global" + 0.003*"one" + 0.003*"=" + 0.003*"inside"
INFO: topic #1 (0.028): 0.003*"local" + 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"non" + 0.003*"name" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"=" + 0.003*"scope"
INFO: topic #6 (0.059): 0.067*"local" + 0.046*"name" + 0.043*"non" + 0.037*"one" + 0.004*"big" + 0.004*"bad" + 0.004*"programmer" + 0.004*"programming" + 0.004*"fct1" + 0.004*"project"
INFO: topic #2 (0.088): 0.121*"variable" + 0.083*"global" + 0.051*"local" + 0.030*"function" + 0.027*"change" + 0.024*"value" + 0.023*"case" + 0.018*"p2o" + 0.018*"type" + 0.018*"bool"
INFO: topic #3 (0.175): 0.130*"global" + 0.103*"variable" + 0.061*"function" + 0.042*"module" + 0.036*"local" + 0.030*"name" + 0.013*"value" + 0.012*"keyword" + 0.011*"scope" + 0.011*"example"
INFO: topic diff=0.207551, rho=0.456435
DEBUG: bound: at document #0
INFO: -5.794 per-word bound, 55.5 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 2, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.037509046, 0.025804255, 0.08171606, 0.22902589, 0.025796447, 0.05353705, 0.057103693]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #4 (0.026): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"name" + 0.003*"function" + 0.003*"non" + 0.003*"totalcarbs(global" + 0.003*"one" + 0.003*"=" + 0.003*"inside"
INFO: topic #1 (0.026): 0.003*"local" + 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"non" + 0.003*"name" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"=" + 0.003*"scope"
INFO: topic #6 (0.057): 0.043*"one" + 0.042*"local" + 0.029*"name" + 0.027*"non" + 0.004*"programmer" + 0.004*"big" + 0.004*"programming" + 0.004*"project" + 0.004*"bad" + 0.004*"fct1"
INFO: topic #2 (0.082): 0.108*"variable" + 0.078*"global" + 0.046*"local" + 0.026*"function" + 0.025*"value" + 0.023*"case" + 0.018*"change" + 0.014*"try" + 0.014*"decoration" + 0.014*"tell"
INFO: topic #3 (0.229): 0.134*"global" + 0.102*"variable" + 0.069*"function" + 0.043*"module" + 0.036*"local" + 0.032*"name" + 0.019*"value" + 0.015*"assign" + 0.014*"keyword" + 0.012*"scope"
INFO: topic diff=0.173995, rho=0.456435
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 34.23161777312787
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=7, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -3.325492011010795
DEBUG: bound: at document #0
INFO: -4.994 per-word bound, 31.9 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 3, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.033849806, 0.024070468, 0.08225644, 0.17650181, 0.024063708, 0.04609854, 0.05404083]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #4 (0.024): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"name" + 0.003*"function" + 0.003*"non" + 0.003*"totalcarbs(global" + 0.003*"one" + 0.003*"=" + 0.003*"inside"
INFO: topic #1 (0.024): 0.003*"local" + 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"non" + 0.003*"name" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"=" + 0.003*"scope"
INFO: topic #6 (0.054): 0.065*"local" + 0.045*"name" + 0.043*"non" + 0.038*"one" + 0.003*"fct1" + 0.003*"programmer" + 0.003*"project" + 0.003*"big" + 0.003*"bad" + 0.003*"programming"
INFO: topic #2 (0.082): 0.120*"variable" + 0.083*"global" + 0.051*"local" + 0.030*"function" + 0.026*"change" + 0.024*"value" + 0.023*"case" + 0.018*"p2o" + 0.018*"type" + 0.018*"bool"
INFO: topic #3 (0.177): 0.130*"global" + 0.103*"variable" + 0.062*"function" + 0.042*"module" + 0.036*"local" + 0.030*"name" + 0.013*"value" + 0.012*"keyword" + 0.011*"scope" + 0.011*"example"
INFO: topic diff=0.169120, rho=0.415227
DEBUG: bound: at document #0
INFO: -5.765 per-word bound, 54.4 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 3, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.035043098, 0.022776663, 0.077966906, 0.2260462, 0.022770628, 0.05255683, 0.053161144]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #1 (0.023): 0.003*"local" + 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"non" + 0.003*"name" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"=" + 0.003*"scope"
INFO: topic #4 (0.023): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"name" + 0.003*"function" + 0.003*"non" + 0.003*"totalcarbs(global" + 0.003*"one" + 0.003*"=" + 0.003*"inside"
INFO: topic #6 (0.053): 0.043*"local" + 0.043*"one" + 0.030*"name" + 0.028*"non" + 0.003*"programming" + 0.003*"programmer" + 0.003*"fct1" + 0.003*"project" + 0.003*"big" + 0.003*"bad"
INFO: topic #2 (0.078): 0.109*"variable" + 0.079*"global" + 0.046*"local" + 0.026*"function" + 0.025*"value" + 0.023*"case" + 0.019*"change" + 0.014*"try" + 0.014*"decoration" + 0.014*"tell"
INFO: topic #3 (0.226): 0.134*"global" + 0.102*"variable" + 0.069*"function" + 0.043*"module" + 0.036*"local" + 0.032*"name" + 0.018*"value" + 0.014*"keyword" + 0.014*"assign" + 0.012*"scope"
INFO: topic diff=0.146989, rho=0.415227
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 34.07519874082191
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=7, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -3.3301774285340002
DEBUG: bound: at document #0
INFO: -4.980 per-word bound, 31.6 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 4, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.032022968, 0.021499412, 0.07862829, 0.17630509, 0.021494055, 0.04577909, 0.05082975]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #4 (0.021): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"name" + 0.003*"function" + 0.003*"non" + 0.003*"totalcarbs(global" + 0.003*"one" + 0.003*"=" + 0.003*"inside"
INFO: topic #1 (0.021): 0.003*"local" + 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"non" + 0.003*"name" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"=" + 0.003*"scope"
INFO: topic #6 (0.051): 0.064*"local" + 0.044*"name" + 0.043*"non" + 0.039*"one" + 0.003*"programming" + 0.003*"bad" + 0.003*"programmer" + 0.003*"big" + 0.003*"fct1" + 0.003*"project"
INFO: topic #2 (0.079): 0.120*"variable" + 0.083*"global" + 0.051*"local" + 0.029*"function" + 0.026*"change" + 0.024*"value" + 0.023*"case" + 0.018*"p2o" + 0.018*"type" + 0.018*"bool"
INFO: topic #3 (0.176): 0.130*"global" + 0.103*"variable" + 0.062*"function" + 0.042*"module" + 0.036*"local" + 0.030*"name" + 0.013*"value" + 0.012*"keyword" + 0.011*"scope" + 0.011*"example"
INFO: topic diff=0.145283, rho=0.383482
DEBUG: bound: at document #0
INFO: -5.750 per-word bound, 53.8 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 4, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.033164043, 0.020540973, 0.075268485, 0.22172272, 0.020536093, 0.051699754, 0.05036745]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #4 (0.021): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"name" + 0.003*"function" + 0.003*"non" + 0.003*"totalcarbs(global" + 0.003*"one" + 0.003*"inside" + 0.003*"="
INFO: topic #1 (0.021): 0.003*"local" + 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"non" + 0.003*"name" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"=" + 0.003*"scope"
INFO: topic #5 (0.052): 0.023*"f_value" + 0.023*"accessible" + 0.023*"mess" + 0.023*"programmer" + 0.023*"bad" + 0.023*"big" + 0.023*"fct1" + 0.023*"programming" + 0.023*"project" + 0.012*"singleton"
INFO: topic #2 (0.075): 0.110*"variable" + 0.079*"global" + 0.046*"local" + 0.026*"function" + 0.025*"value" + 0.023*"case" + 0.019*"change" + 0.014*"plan" + 0.014*"function2" + 0.014*"tell"
INFO: topic #3 (0.222): 0.134*"global" + 0.102*"variable" + 0.068*"function" + 0.043*"module" + 0.036*"local" + 0.032*"name" + 0.018*"value" + 0.014*"keyword" + 0.014*"assign" + 0.012*"scope"
INFO: topic diff=0.131589, rho=0.383482
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 33.97272196727735
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=7, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -3.3301774285340002
DEBUG: bound: at document #0
INFO: -4.970 per-word bound, 31.3 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 5, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.03058951, 0.01955228, 0.07596956, 0.17536743, 0.019547869, 0.045457836, 0.048490606]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #1 (0.020): 0.003*"local" + 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"non" + 0.003*"name" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"=" + 0.003*"scope"
INFO: topic #4 (0.020): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"name" + 0.003*"function" + 0.003*"non" + 0.003*"totalcarbs(global" + 0.003*"one" + 0.003*"inside" + 0.003*"="
INFO: topic #6 (0.048): 0.064*"local" + 0.043*"name" + 0.043*"non" + 0.039*"one" + 0.003*"fct1" + 0.003*"programmer" + 0.003*"big" + 0.003*"bad" + 0.003*"programming" + 0.003*"project"
INFO: topic #2 (0.076): 0.120*"variable" + 0.083*"global" + 0.050*"local" + 0.029*"function" + 0.026*"change" + 0.024*"value" + 0.023*"case" + 0.018*"type" + 0.018*"p2o" + 0.018*"bool"
INFO: topic #3 (0.175): 0.130*"global" + 0.103*"variable" + 0.062*"function" + 0.042*"module" + 0.036*"local" + 0.030*"name" + 0.013*"value" + 0.012*"keyword" + 0.011*"scope" + 0.011*"example"
INFO: topic diff=0.130017, rho=0.358057
DEBUG: bound: at document #0
INFO: -5.740 per-word bound, 53.4 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 5, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.031674825, 0.018808145, 0.07320851, 0.21737714, 0.01880407, 0.050944984, 0.04826958]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #4 (0.019): 0.003*"local" + 0.003*"variable" + 0.003*"global" + 0.003*"name" + 0.003*"function" + 0.003*"non" + 0.003*"totalcarbs(global" + 0.003*"one" + 0.003*"inside" + 0.003*"="
INFO: topic #1 (0.019): 0.003*"local" + 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"non" + 0.003*"name" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"scope" + 0.003*"="
INFO: topic #5 (0.051): 0.023*"f_value" + 0.023*"mess" + 0.023*"accessible" + 0.023*"programmer" + 0.023*"programming" + 0.023*"project" + 0.023*"big" + 0.023*"fct1" + 0.023*"bad" + 0.012*"run"
INFO: topic #2 (0.073): 0.110*"variable" + 0.079*"global" + 0.046*"local" + 0.026*"function" + 0.024*"value" + 0.023*"case" + 0.020*"change" + 0.014*"plan" + 0.014*"try" + 0.014*"tell"
INFO: topic #3 (0.217): 0.134*"global" + 0.102*"variable" + 0.068*"function" + 0.043*"module" + 0.036*"local" + 0.031*"name" + 0.018*"value" + 0.014*"keyword" + 0.014*"assign" + 0.012*"scope"
INFO: topic diff=0.121233, rho=0.358057
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 33.899360895345566
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=7, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -3.3310407101704556
DEBUG: bound: at document #0
INFO: -4.962 per-word bound, 31.2 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 6, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.029428262, 0.018015241, 0.073916554, 0.17424345, 0.018011509, 0.04514728, 0.046700213]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #4 (0.018): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"name" + 0.003*"function" + 0.003*"non" + 0.003*"totalcarbs(global" + 0.003*"one" + 0.003*"inside" + 0.003*"="
INFO: topic #1 (0.018): 0.003*"local" + 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"non" + 0.003*"name" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"=" + 0.003*"scope"
INFO: topic #6 (0.047): 0.063*"local" + 0.043*"name" + 0.042*"non" + 0.039*"one" + 0.003*"programming" + 0.003*"big" + 0.003*"programmer" + 0.003*"bad" + 0.003*"fct1" + 0.003*"project"
INFO: topic #2 (0.074): 0.119*"variable" + 0.083*"global" + 0.050*"local" + 0.029*"function" + 0.026*"change" + 0.024*"value" + 0.023*"case" + 0.017*"bool" + 0.017*"p2o" + 0.017*"p1o"
INFO: topic #3 (0.174): 0.130*"global" + 0.103*"variable" + 0.062*"function" + 0.042*"module" + 0.036*"local" + 0.030*"name" + 0.013*"value" + 0.012*"keyword" + 0.011*"scope" + 0.011*"example"
INFO: topic diff=0.119166, rho=0.337100
DEBUG: bound: at document #0
INFO: -5.732 per-word bound, 53.2 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 6, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.03046045, 0.017417526, 0.07157279, 0.21342596, 0.01741404, 0.05027699, 0.046629168]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #4 (0.017): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"function" + 0.003*"name" + 0.003*"non" + 0.003*"totalcarbs(global" + 0.003*"=" + 0.003*"inside" + 0.003*"one"
INFO: topic #1 (0.017): 0.003*"local" + 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"non" + 0.003*"name" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"=" + 0.003*"scope"
INFO: topic #5 (0.050): 0.023*"f_value" + 0.023*"mess" + 0.023*"accessible" + 0.023*"programmer" + 0.023*"project" + 0.023*"big" + 0.023*"fct1" + 0.023*"programming" + 0.023*"bad" + 0.012*"resource"
INFO: topic #2 (0.072): 0.110*"variable" + 0.079*"global" + 0.047*"local" + 0.026*"function" + 0.024*"value" + 0.023*"case" + 0.020*"change" + 0.014*"type" + 0.014*"bool" + 0.014*"p1o"
INFO: topic #3 (0.213): 0.134*"global" + 0.102*"variable" + 0.067*"function" + 0.043*"module" + 0.036*"local" + 0.031*"name" + 0.017*"value" + 0.014*"keyword" + 0.013*"assign" + 0.012*"scope"
INFO: topic diff=0.113185, rho=0.337100
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 33.84422067948203
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=7, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -3.331245594364543
DEBUG: bound: at document #0
INFO: -4.956 per-word bound, 31.0 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 7, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.028464768, 0.016764374, 0.07227214, 0.17310548, 0.01676115, 0.044853073, 0.04527985]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #1 (0.017): 0.003*"local" + 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"name" + 0.003*"non" + 0.003*"one" + 0.003*"=" + 0.003*"scope" + 0.003*"totalcarbs(global"
INFO: topic #4 (0.017): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"function" + 0.003*"name" + 0.003*"totalcarbs(global" + 0.003*"non" + 0.003*"=" + 0.003*"inside" + 0.003*"one"
INFO: topic #6 (0.045): 0.063*"local" + 0.043*"name" + 0.042*"non" + 0.039*"one" + 0.003*"bad" + 0.003*"project" + 0.003*"programming" + 0.003*"big" + 0.003*"programmer" + 0.003*"fct1"
INFO: topic #2 (0.072): 0.119*"variable" + 0.083*"global" + 0.050*"local" + 0.029*"function" + 0.025*"change" + 0.024*"value" + 0.023*"case" + 0.017*"type" + 0.017*"bool" + 0.017*"p1o"
INFO: topic #3 (0.173): 0.130*"global" + 0.103*"variable" + 0.062*"function" + 0.042*"module" + 0.036*"local" + 0.030*"name" + 0.013*"value" + 0.012*"keyword" + 0.011*"scope" + 0.011*"example"
INFO: topic diff=0.110817, rho=0.319438
DEBUG: bound: at document #0
INFO: -5.726 per-word bound, 52.9 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 7, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.029448114, 0.016271695, 0.07023518, 0.20990957, 0.01626866, 0.049682297, 0.045305952]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #4 (0.016): 0.003*"local" + 0.003*"variable" + 0.003*"global" + 0.003*"name" + 0.003*"function" + 0.003*"non" + 0.003*"inside" + 0.003*"totalcarbs(global" + 0.003*"totalcarbs(local" + 0.003*"="
INFO: topic #1 (0.016): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"function" + 0.003*"non" + 0.003*"name" + 0.003*"one" + 0.003*"change" + 0.003*"totalcarbs(global" + 0.003*"totalcarbs(local"
INFO: topic #5 (0.050): 0.023*"accessible" + 0.023*"mess" + 0.023*"fct1" + 0.023*"programmer" + 0.023*"programming" + 0.023*"project" + 0.023*"bad" + 0.023*"big" + 0.023*"f_value" + 0.012*"unavoidable"
INFO: topic #2 (0.070): 0.111*"variable" + 0.079*"global" + 0.047*"local" + 0.026*"function" + 0.024*"value" + 0.023*"case" + 0.020*"change" + 0.014*"type" + 0.014*"bool" + 0.014*"p1o"
INFO: topic #3 (0.210): 0.133*"global" + 0.102*"variable" + 0.067*"function" + 0.043*"module" + 0.036*"local" + 0.031*"name" + 0.017*"value" + 0.014*"keyword" + 0.013*"assign" + 0.012*"scope"
INFO: topic diff=0.106414, rho=0.319438
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 33.80106475002351
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=7, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -3.7615312876159854
DEBUG: bound: at document #0
INFO: -4.951 per-word bound, 30.9 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 8, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.027650317, 0.015722282, 0.070918754, 0.17202453, 0.01571945, 0.044577453, 0.0441213]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #1 (0.016): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"function" + 0.003*"non" + 0.003*"name" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"example" + 0.003*"inside"
INFO: topic #4 (0.016): 0.003*"local" + 0.003*"variable" + 0.003*"global" + 0.003*"function" + 0.003*"name" + 0.003*"totalcarbs(global" + 0.003*"non" + 0.003*"apple" + 0.003*"need" + 0.003*"type"
INFO: topic #5 (0.045): 0.020*"mess" + 0.020*"accessible" + 0.020*"project" + 0.020*"programming" + 0.020*"big" + 0.020*"bad" + 0.020*"fct1" + 0.020*"programmer" + 0.020*"f_value" + 0.011*"low"
INFO: topic #2 (0.071): 0.119*"variable" + 0.083*"global" + 0.050*"local" + 0.029*"function" + 0.025*"change" + 0.024*"value" + 0.023*"case" + 0.017*"type" + 0.017*"p1o" + 0.017*"p2o"
INFO: topic #3 (0.172): 0.131*"global" + 0.103*"variable" + 0.062*"function" + 0.042*"module" + 0.036*"local" + 0.031*"name" + 0.013*"value" + 0.012*"keyword" + 0.011*"scope" + 0.011*"example"
INFO: topic diff=0.104069, rho=0.304290
DEBUG: bound: at document #0
INFO: -5.720 per-word bound, 52.7 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 8, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.028589323, 0.015307822, 0.069116406, 0.2068005, 0.015305138, 0.04914999, 0.04421038]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #4 (0.015): 0.003*"local" + 0.003*"variable" + 0.003*"global" + 0.003*"function" + 0.003*"name" + 0.003*"value" + 0.003*"apple" + 0.003*"non" + 0.003*"need" + 0.003*"totalcarbs(local"
INFO: topic #1 (0.015): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"function" + 0.003*"non" + 0.003*"name" + 0.003*"scope" + 0.003*"inside" + 0.003*"totalcarbs(global" + 0.003*"totalcarbs(local"
INFO: topic #5 (0.049): 0.023*"programming" + 0.023*"programmer" + 0.023*"big" + 0.023*"bad" + 0.023*"project" + 0.023*"fct1" + 0.023*"mess" + 0.023*"accessible" + 0.023*"f_value" + 0.012*"tricky"
INFO: topic #2 (0.069): 0.111*"variable" + 0.079*"global" + 0.047*"local" + 0.026*"function" + 0.024*"value" + 0.023*"case" + 0.020*"change" + 0.014*"type" + 0.014*"p2o" + 0.014*"bool"
INFO: topic #3 (0.207): 0.133*"global" + 0.102*"variable" + 0.067*"function" + 0.043*"module" + 0.036*"local" + 0.031*"name" + 0.017*"value" + 0.014*"keyword" + 0.013*"assign" + 0.012*"scope"
INFO: topic diff=0.100701, rho=0.304290
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 33.765600586631855
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=7, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -3.6418749174963847
DEBUG: bound: at document #0
INFO: -4.948 per-word bound, 30.9 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 9, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.026951572, 0.01483786, 0.06978189, 0.17104691, 0.014835341, 0.044321176, 0.043153767]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #1 (0.015): 0.003*"local" + 0.003*"function" + 0.003*"global" + 0.003*"variable" + 0.003*"totalcarbs(local" + 0.003*"non" + 0.003*"name" + 0.003*"totalcarbs(global" + 0.003*"apple" + 0.003*"change"
INFO: topic #4 (0.015): 0.003*"local" + 0.003*"variable" + 0.003*"global" + 0.003*"totalcarbs(local" + 0.003*"inside" + 0.003*"function" + 0.003*"totalcarbs(global" + 0.003*"name" + 0.003*"scope" + 0.003*"non"
INFO: topic #5 (0.044): 0.021*"project" + 0.021*"bad" + 0.021*"programming" + 0.021*"programmer" + 0.021*"big" + 0.021*"fct1" + 0.021*"mess" + 0.021*"accessible" + 0.021*"f_value" + 0.011*"purpose"
INFO: topic #2 (0.070): 0.119*"variable" + 0.082*"global" + 0.050*"local" + 0.029*"function" + 0.025*"change" + 0.024*"value" + 0.023*"case" + 0.017*"bool" + 0.017*"p1o" + 0.017*"p2o"
INFO: topic #3 (0.171): 0.131*"global" + 0.103*"variable" + 0.062*"function" + 0.042*"module" + 0.036*"local" + 0.031*"name" + 0.013*"value" + 0.012*"keyword" + 0.011*"scope" + 0.011*"example"
INFO: topic diff=0.098445, rho=0.291111
DEBUG: bound: at document #0
INFO: -5.715 per-word bound, 52.5 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 9, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.027850455, 0.014483406, 0.06816439, 0.20407304, 0.014481007, 0.048671536, 0.04327699]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #1 (0.014): 0.003*"local" + 0.003*"global" + 0.003*"variable" + 0.003*"function" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"non" + 0.003*"name" + 0.003*"unexpected" + 0.003*"update_variables"
INFO: topic #4 (0.014): 0.003*"local" + 0.003*"variable" + 0.003*"global" + 0.003*"function" + 0.003*"one" + 0.003*"totalcarbs(global" + 0.003*"non" + 0.003*"name" + 0.003*"unexpected" + 0.003*"update_variables"
INFO: topic #5 (0.049): 0.023*"programmer" + 0.023*"fct1" + 0.023*"bad" + 0.023*"project" + 0.023*"programming" + 0.023*"big" + 0.023*"mess" + 0.023*"accessible" + 0.023*"f_value" + 0.012*"low"
INFO: topic #2 (0.068): 0.111*"variable" + 0.079*"global" + 0.047*"local" + 0.026*"function" + 0.024*"value" + 0.023*"case" + 0.021*"change" + 0.014*"type" + 0.014*"bool" + 0.014*"p1o"
INFO: topic #3 (0.204): 0.133*"global" + 0.102*"variable" + 0.067*"function" + 0.043*"module" + 0.036*"local" + 0.031*"name" + 0.017*"value" + 0.014*"keyword" + 0.013*"assign" + 0.012*"scope"
INFO: topic diff=0.095945, rho=0.291111
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 33.70028537301295
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=7, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -3.6453082724826955
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=310, num_topics=7, decay=0.5, chunksize=5> in 0.19s', 'datetime': '2023-04-25T06:36:16.659845', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'auto-adjust_models/models/2/model_t7.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-25T06:36:16.659996', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'auto-adjust_models/models/2/model_t7.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/2/model_t7.state
DEBUG: {'uri': 'auto-adjust_models/models/2/model_t7.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'auto-adjust_models/models/2/model_t7', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['id2word', 'dispatcher', 'state'], 'datetime': '2023-04-25T06:36:16.662892', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to auto-adjust_models/models/2/model_t7.expElogbeta.npy
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
INFO: not storing attribute state
DEBUG: {'uri': 'auto-adjust_models/models/2/model_t7', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/2/model_t7
