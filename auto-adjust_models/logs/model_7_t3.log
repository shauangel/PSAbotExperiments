INFO: ---Start Analyzing---
INFO: ---Train for 3 Topics---
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<397 unique tokens: ['1st', '2nd', '=', 'able', 'absolute']...> from 10 documents (total 1569 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<397 unique tokens: ['1st', '2nd', '=', 'able', 'absolute']...> from 10 documents (total 1569 corpus positions)", 'datetime': '2023-04-25T06:36:20.390136', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.33333334, 0.33333334, 0.33333334]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -6.636 per-word bound, 99.4 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
WARNING: updated prior is not positive
INFO: optimized alpha [0.33333334, 0.33333334, 0.33333334]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.333): 0.093*"parameter" + 0.085*"argument" + 0.070*"function" + 0.029*"value" + 0.019*"actual" + 0.017*"method" + 0.017*"name" + 0.016*"example" + 0.016*"variable" + 0.015*"type"
INFO: topic #1 (0.333): 0.087*"parameter" + 0.087*"argument" + 0.063*"function" + 0.043*"value" + 0.034*"variable" + 0.025*"method" + 0.024*"actual" + 0.017*"definition" + 0.017*"formal" + 0.015*"call"
INFO: topic #2 (0.333): 0.003*"function" + 0.003*"parameter" + 0.003*"argument" + 0.003*"variable" + 0.003*"object" + 0.003*"value" + 0.003*"program" + 0.003*"part" + 0.003*"type" + 0.003*"c++"
INFO: topic diff=1.476750, rho=1.000000
DEBUG: bound: at document #0
INFO: -6.141 per-word bound, 70.6 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.43350416, 0.40660992, 0.31335738]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.434): 0.097*"parameter" + 0.089*"argument" + 0.084*"function" + 0.035*"value" + 0.019*"actual" + 0.018*"b" + 0.017*"definition" + 0.017*"call" + 0.016*"name" + 0.015*"formal"
INFO: topic #1 (0.407): 0.084*"parameter" + 0.084*"argument" + 0.070*"function" + 0.052*"value" + 0.035*"definition" + 0.030*"variable" + 0.024*"call" + 0.023*"method" + 0.020*"name" + 0.017*"actual"
INFO: topic #2 (0.313): 0.070*"default" + 0.029*"positional" + 0.020*"keyword" + 0.015*"f2(x" + 0.015*"non" + 0.011*"f" + 0.011*"question" + 0.011*"arg" + 0.011*"def" + 0.011*"error"
INFO: topic diff=0.835080, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 34.432449328858105
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -2.6382454789858234
DEBUG: bound: at document #0
INFO: -5.182 per-word bound, 36.3 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.30774587, 0.184607, 0.02014482]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.308): 0.089*"parameter" + 0.083*"function" + 0.078*"argument" + 0.027*"value" + 0.018*"example" + 0.017*"actual" + 0.017*"type" + 0.014*"program" + 0.013*"definition" + 0.013*"call"
INFO: topic #1 (0.185): 0.091*"parameter" + 0.090*"argument" + 0.064*"function" + 0.044*"value" + 0.029*"variable" + 0.026*"method" + 0.022*"actual" + 0.021*"definition" + 0.018*"call" + 0.018*"name"
INFO: topic #2 (0.020): 0.045*"default" + 0.019*"positional" + 0.013*"keyword" + 0.010*"f2(x" + 0.010*"non" + 0.008*"f" + 0.008*"question" + 0.008*"arg" + 0.008*"def" + 0.008*"f2"
INFO: topic diff=0.437799, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.241 per-word bound, 37.8 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.19209951, 0.1590772, 0.023079978]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.192): 0.093*"parameter" + 0.084*"function" + 0.083*"argument" + 0.029*"value" + 0.021*"actual" + 0.015*"example" + 0.015*"program" + 0.015*"formal" + 0.013*"definition" + 0.011*"datum"
INFO: topic #1 (0.159): 0.089*"parameter" + 0.089*"argument" + 0.072*"function" + 0.050*"value" + 0.032*"definition" + 0.029*"variable" + 0.025*"call" + 0.025*"method" + 0.023*"name" + 0.017*"actual"
INFO: topic #2 (0.023): 0.080*"default" + 0.033*"positional" + 0.023*"keyword" + 0.017*"f2(x" + 0.017*"non" + 0.012*"f2" + 0.012*"error" + 0.012*"p" + 0.012*"arg" + 0.012*"def"
INFO: topic diff=0.350076, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 31.57699268531927
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -0.35373868847948975
DEBUG: bound: at document #0
INFO: -5.047 per-word bound, 33.1 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13428378, 0.11099603, 0.02085929]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.134): 0.084*"function" + 0.084*"parameter" + 0.072*"argument" + 0.024*"value" + 0.019*"type" + 0.018*"example" + 0.018*"program" + 0.018*"actual" + 0.011*"object" + 0.011*"definition"
INFO: topic #1 (0.111): 0.092*"parameter" + 0.091*"argument" + 0.066*"function" + 0.044*"value" + 0.028*"variable" + 0.025*"method" + 0.022*"definition" + 0.021*"actual" + 0.019*"call" + 0.019*"name"
INFO: topic #2 (0.021): 0.055*"default" + 0.023*"positional" + 0.016*"keyword" + 0.012*"f2(x" + 0.012*"non" + 0.009*"f2" + 0.009*"error" + 0.009*"p" + 0.009*"arg" + 0.009*"def"
INFO: topic diff=0.331089, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.121 per-word bound, 34.8 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.12321836, 0.108364716, 0.0233159]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.123): 0.090*"parameter" + 0.085*"function" + 0.078*"argument" + 0.027*"value" + 0.021*"actual" + 0.017*"program" + 0.016*"example" + 0.014*"formal" + 0.012*"type" + 0.012*"datum"
INFO: topic #1 (0.108): 0.091*"parameter" + 0.090*"argument" + 0.072*"function" + 0.049*"value" + 0.031*"definition" + 0.028*"variable" + 0.025*"method" + 0.024*"call" + 0.023*"name" + 0.018*"actual"
INFO: topic #2 (0.023): 0.083*"default" + 0.034*"positional" + 0.023*"keyword" + 0.018*"b" + 0.018*"f2(x" + 0.018*"non" + 0.012*"error" + 0.012*"p" + 0.012*"f2" + 0.012*"arg"
INFO: topic diff=0.254260, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 30.96258940541959
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -0.6259162376785893
DEBUG: bound: at document #0
INFO: -5.010 per-word bound, 32.2 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.10542564, 0.08838683, 0.021018717]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.105): 0.084*"function" + 0.082*"parameter" + 0.070*"argument" + 0.023*"value" + 0.020*"type" + 0.019*"program" + 0.018*"example" + 0.018*"actual" + 0.012*"object" + 0.011*"c++"
INFO: topic #1 (0.088): 0.093*"parameter" + 0.091*"argument" + 0.066*"function" + 0.044*"value" + 0.028*"variable" + 0.026*"method" + 0.022*"definition" + 0.021*"actual" + 0.019*"call" + 0.019*"name"
INFO: topic #2 (0.021): 0.060*"default" + 0.025*"positional" + 0.017*"keyword" + 0.014*"b" + 0.013*"f2(x" + 0.013*"non" + 0.010*"error" + 0.010*"p" + 0.010*"f2" + 0.009*"arg"
INFO: topic diff=0.254886, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.079 per-word bound, 33.8 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.10133028, 0.0888971, 0.021330364]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.101): 0.087*"parameter" + 0.084*"function" + 0.075*"argument" + 0.026*"value" + 0.021*"actual" + 0.018*"program" + 0.015*"example" + 0.013*"formal" + 0.013*"type" + 0.011*"datum"
INFO: topic #1 (0.089): 0.092*"parameter" + 0.091*"argument" + 0.072*"function" + 0.049*"value" + 0.030*"definition" + 0.028*"variable" + 0.026*"method" + 0.024*"call" + 0.022*"name" + 0.018*"actual"
INFO: topic #2 (0.021): 0.085*"default" + 0.035*"positional" + 0.029*"b" + 0.024*"keyword" + 0.018*"f2(x" + 0.018*"non" + 0.014*"key" + 0.013*"error" + 0.013*"f2" + 0.013*"p"
INFO: topic diff=0.214162, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 30.679074776459675
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -0.6443229536029819
DEBUG: bound: at document #0
INFO: -4.996 per-word bound, 31.9 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.09139872, 0.076636575, 0.01942423]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.091): 0.083*"function" + 0.080*"parameter" + 0.069*"argument" + 0.023*"value" + 0.020*"type" + 0.019*"program" + 0.018*"example" + 0.018*"actual" + 0.012*"object" + 0.011*"c++"
INFO: topic #1 (0.077): 0.093*"parameter" + 0.092*"argument" + 0.067*"function" + 0.044*"value" + 0.028*"variable" + 0.026*"method" + 0.022*"definition" + 0.021*"actual" + 0.020*"call" + 0.019*"name"
INFO: topic #2 (0.019): 0.063*"default" + 0.026*"positional" + 0.022*"b" + 0.018*"keyword" + 0.014*"f2(x" + 0.014*"non" + 0.011*"key" + 0.010*"error" + 0.010*"f2" + 0.010*"p"
INFO: topic diff=0.213088, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.030 per-word bound, 32.7 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0895796, 0.07812853, 0.01970837]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.090): 0.086*"parameter" + 0.083*"function" + 0.074*"argument" + 0.026*"value" + 0.021*"actual" + 0.018*"program" + 0.016*"example" + 0.013*"type" + 0.013*"formal" + 0.011*"datum"
INFO: topic #1 (0.078): 0.093*"parameter" + 0.092*"argument" + 0.072*"function" + 0.049*"value" + 0.030*"definition" + 0.028*"variable" + 0.026*"method" + 0.024*"call" + 0.022*"name" + 0.018*"actual"
INFO: topic #2 (0.020): 0.084*"default" + 0.041*"b" + 0.035*"positional" + 0.024*"keyword" + 0.021*"key" + 0.018*"f2(x" + 0.018*"non" + 0.013*"error" + 0.013*"f2" + 0.013*"p"
INFO: topic diff=0.192949, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 30.554082196759925
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -0.665733114772583
DEBUG: bound: at document #0
INFO: -4.987 per-word bound, 31.7 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.08291009, 0.069373176, 0.018108137]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.083): 0.083*"function" + 0.080*"parameter" + 0.068*"argument" + 0.022*"value" + 0.019*"program" + 0.019*"type" + 0.018*"actual" + 0.018*"example" + 0.011*"object" + 0.011*"c++"
INFO: topic #1 (0.069): 0.094*"parameter" + 0.092*"argument" + 0.067*"function" + 0.045*"value" + 0.028*"variable" + 0.026*"method" + 0.022*"definition" + 0.021*"actual" + 0.020*"call" + 0.019*"name"
INFO: topic #2 (0.018): 0.064*"default" + 0.031*"b" + 0.027*"positional" + 0.018*"keyword" + 0.016*"key" + 0.014*"f2(x" + 0.014*"non" + 0.010*"error" + 0.010*"f2" + 0.010*"p"
INFO: topic diff=0.187999, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.006 per-word bound, 32.1 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.08209927, 0.07119276, 0.018378386]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.082): 0.085*"parameter" + 0.083*"function" + 0.074*"argument" + 0.025*"value" + 0.021*"actual" + 0.018*"program" + 0.016*"example" + 0.013*"type" + 0.012*"formal" + 0.011*"datum"
INFO: topic #1 (0.071): 0.094*"parameter" + 0.092*"argument" + 0.072*"function" + 0.049*"value" + 0.029*"definition" + 0.028*"variable" + 0.026*"method" + 0.024*"call" + 0.022*"name" + 0.018*"actual"
INFO: topic #2 (0.018): 0.083*"default" + 0.050*"b" + 0.034*"positional" + 0.028*"key" + 0.023*"keyword" + 0.018*"f2(x" + 0.018*"non" + 0.012*"f2" + 0.012*"error" + 0.012*"p"
INFO: topic diff=0.179191, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 30.46749429834926
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -0.6708675383322863
DEBUG: bound: at document #0
INFO: -4.980 per-word bound, 31.6 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.07715032, 0.06439581, 0.017014245]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.077): 0.083*"function" + 0.080*"parameter" + 0.068*"argument" + 0.022*"value" + 0.019*"program" + 0.019*"type" + 0.018*"actual" + 0.018*"example" + 0.011*"object" + 0.011*"c++"
INFO: topic #1 (0.064): 0.094*"parameter" + 0.092*"argument" + 0.067*"function" + 0.045*"value" + 0.028*"variable" + 0.026*"method" + 0.023*"definition" + 0.021*"actual" + 0.020*"call" + 0.020*"name"
INFO: topic #2 (0.017): 0.064*"default" + 0.039*"b" + 0.027*"positional" + 0.022*"key" + 0.018*"keyword" + 0.014*"f2(x" + 0.014*"non" + 0.010*"f2" + 0.010*"error" + 0.010*"p"
INFO: topic diff=0.171427, rho=0.333333
DEBUG: bound: at document #0
INFO: -4.990 per-word bound, 31.8 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.076860756, 0.06631554, 0.017274894]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.077): 0.085*"parameter" + 0.083*"function" + 0.073*"argument" + 0.025*"value" + 0.021*"actual" + 0.019*"program" + 0.016*"example" + 0.014*"type" + 0.012*"formal" + 0.011*"datum"
INFO: topic #1 (0.066): 0.094*"parameter" + 0.093*"argument" + 0.072*"function" + 0.049*"value" + 0.029*"definition" + 0.028*"variable" + 0.026*"method" + 0.024*"call" + 0.022*"name" + 0.019*"actual"
INFO: topic #2 (0.017): 0.081*"default" + 0.057*"b" + 0.034*"key" + 0.033*"positional" + 0.023*"keyword" + 0.017*"f2(x" + 0.017*"non" + 0.012*"p" + 0.012*"f2" + 0.012*"error"
INFO: topic diff=0.167321, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 30.40647814994271
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -0.6760019618919898
DEBUG: bound: at document #0
INFO: -4.974 per-word bound, 31.4 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.07295135, 0.06075267, 0.01609473]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.073): 0.083*"function" + 0.080*"parameter" + 0.068*"argument" + 0.022*"value" + 0.019*"program" + 0.019*"type" + 0.018*"actual" + 0.018*"example" + 0.011*"object" + 0.011*"c++"
INFO: topic #1 (0.061): 0.094*"parameter" + 0.092*"argument" + 0.068*"function" + 0.045*"value" + 0.028*"variable" + 0.026*"method" + 0.023*"definition" + 0.021*"actual" + 0.020*"call" + 0.020*"name"
INFO: topic #2 (0.016): 0.064*"default" + 0.045*"b" + 0.027*"key" + 0.027*"positional" + 0.018*"keyword" + 0.014*"non" + 0.014*"f2(x" + 0.010*"p" + 0.010*"error" + 0.010*"f2"
INFO: topic diff=0.159963, rho=0.316228
DEBUG: bound: at document #0
INFO: -4.978 per-word bound, 31.5 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.07295819, 0.062681034, 0.016347265]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.073): 0.084*"parameter" + 0.083*"function" + 0.073*"argument" + 0.025*"value" + 0.020*"actual" + 0.019*"program" + 0.016*"example" + 0.014*"type" + 0.012*"formal" + 0.011*"datum"
INFO: topic #1 (0.063): 0.094*"parameter" + 0.093*"argument" + 0.072*"function" + 0.049*"value" + 0.029*"definition" + 0.029*"variable" + 0.026*"method" + 0.024*"call" + 0.022*"name" + 0.019*"actual"
INFO: topic #2 (0.016): 0.079*"default" + 0.061*"b" + 0.039*"key" + 0.033*"positional" + 0.022*"keyword" + 0.017*"f2(x" + 0.017*"non" + 0.012*"f2" + 0.012*"error" + 0.012*"p"
INFO: topic diff=0.156898, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 30.364024910746917
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -0.6760019618919898
DEBUG: bound: at document #0
INFO: -4.970 per-word bound, 31.3 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.06973516, 0.057960287, 0.015312665]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.070): 0.083*"function" + 0.080*"parameter" + 0.068*"argument" + 0.023*"value" + 0.019*"program" + 0.019*"type" + 0.018*"actual" + 0.018*"example" + 0.011*"object" + 0.010*"c++"
INFO: topic #1 (0.058): 0.094*"parameter" + 0.093*"argument" + 0.068*"function" + 0.045*"value" + 0.028*"variable" + 0.026*"method" + 0.023*"definition" + 0.021*"actual" + 0.020*"call" + 0.020*"name"
INFO: topic #2 (0.015): 0.064*"default" + 0.049*"b" + 0.031*"key" + 0.027*"positional" + 0.018*"keyword" + 0.014*"f2(x" + 0.014*"non" + 0.010*"f2" + 0.010*"error" + 0.010*"p"
INFO: topic diff=0.150636, rho=0.301511
DEBUG: bound: at document #0
INFO: -4.969 per-word bound, 31.3 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.06992146, 0.059857663, 0.015557716]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.070): 0.084*"parameter" + 0.083*"function" + 0.073*"argument" + 0.025*"value" + 0.020*"actual" + 0.019*"program" + 0.016*"example" + 0.014*"type" + 0.012*"formal" + 0.011*"datum"
INFO: topic #1 (0.060): 0.095*"parameter" + 0.093*"argument" + 0.072*"function" + 0.049*"value" + 0.029*"variable" + 0.028*"definition" + 0.026*"method" + 0.023*"call" + 0.022*"name" + 0.019*"actual"
INFO: topic #2 (0.016): 0.078*"default" + 0.063*"b" + 0.042*"key" + 0.032*"positional" + 0.022*"keyword" + 0.017*"non" + 0.017*"f2(x" + 0.012*"position" + 0.012*"p" + 0.012*"f2"
INFO: topic diff=0.148005, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 30.333186159161844
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -0.6748601050044544
DEBUG: bound: at document #0
INFO: -4.967 per-word bound, 31.3 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.06718107, 0.055745292, 0.014640136]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.067): 0.083*"function" + 0.080*"parameter" + 0.068*"argument" + 0.023*"value" + 0.019*"program" + 0.019*"type" + 0.018*"actual" + 0.018*"example" + 0.011*"object" + 0.010*"c++"
INFO: topic #1 (0.056): 0.094*"parameter" + 0.093*"argument" + 0.068*"function" + 0.045*"value" + 0.028*"variable" + 0.026*"method" + 0.023*"definition" + 0.021*"actual" + 0.020*"call" + 0.020*"name"
INFO: topic #2 (0.015): 0.064*"default" + 0.052*"b" + 0.034*"key" + 0.027*"positional" + 0.018*"keyword" + 0.014*"f2(x" + 0.014*"non" + 0.011*"position" + 0.010*"f2" + 0.010*"error"
INFO: topic diff=0.142723, rho=0.288675
DEBUG: bound: at document #0
INFO: -4.962 per-word bound, 31.2 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.067480795, 0.05759449, 0.014878064]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.067): 0.084*"parameter" + 0.083*"function" + 0.073*"argument" + 0.025*"value" + 0.020*"actual" + 0.019*"program" + 0.016*"example" + 0.014*"type" + 0.012*"formal" + 0.011*"datum"
INFO: topic #1 (0.058): 0.095*"parameter" + 0.093*"argument" + 0.072*"function" + 0.049*"value" + 0.029*"variable" + 0.028*"definition" + 0.026*"method" + 0.023*"call" + 0.022*"name" + 0.019*"actual"
INFO: topic #2 (0.015): 0.077*"default" + 0.065*"b" + 0.043*"key" + 0.032*"positional" + 0.022*"keyword" + 0.017*"f2(x" + 0.017*"non" + 0.013*"position" + 0.011*"error" + 0.011*"p"
INFO: topic diff=0.140413, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 30.308874219851187
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -0.6748601050044544
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5> in 0.30s', 'datetime': '2023-04-25T06:36:20.689532', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'auto-adjust_models/models/7/model_t3.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-25T06:36:20.689682', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'auto-adjust_models/models/7/model_t3.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/7/model_t3.state
DEBUG: {'uri': 'auto-adjust_models/models/7/model_t3.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'auto-adjust_models/models/7/model_t3', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['id2word', 'dispatcher', 'state'], 'datetime': '2023-04-25T06:36:20.693151', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to auto-adjust_models/models/7/model_t3.expElogbeta.npy
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
INFO: not storing attribute state
DEBUG: {'uri': 'auto-adjust_models/models/7/model_t3', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/7/model_t3
