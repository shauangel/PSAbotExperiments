INFO: ---Start Analyzing---
INFO: ---Train for 3 Topics---
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<193 unique tokens: ['answer', 'array', 'call', 'code', 'context']...> from 9 documents (total 531 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<193 unique tokens: ['answer', 'array', 'call', 'code', 'context']...> from 9 documents (total 531 corpus positions)", 'datetime': '2023-04-25T06:36:16.668639', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.33333334, 0.33333334, 0.33333334]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 9 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -6.395 per-word bound, 84.2 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 0, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
WARNING: updated prior is not positive
INFO: optimized alpha [0.33333334, 0.33333334, 0.33333334]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.333): 0.090*"value" + 0.052*"function" + 0.040*"lambda" + 0.040*"time" + 0.040*"closure" + 0.027*"loop" + 0.027*"last" + 0.027*"expression" + 0.027*"default" + 0.027*"late"
INFO: topic #1 (0.333): 0.095*"lambda" + 0.041*"value" + 0.041*"loop" + 0.040*"code" + 0.033*"final" + 0.025*"name" + 0.025*"variable" + 0.025*"context" + 0.025*"output" + 0.017*"function"
INFO: topic #2 (0.333): 0.084*"function" + 0.057*"value" + 0.048*"parameter" + 0.048*"default" + 0.029*"lambda" + 0.020*"way" + 0.020*"example" + 0.020*"simple" + 0.020*"necessary" + 0.020*"object"
INFO: topic diff=2.362512, rho=1.000000
DEBUG: bound: at document #0
INFO: -6.329 per-word bound, 80.4 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 0, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.42111003, 0.52285695, 0.47313854]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.421): 0.071*"value" + 0.060*"function" + 0.044*"time" + 0.036*"lambda" + 0.031*"argument" + 0.023*"variable" + 0.022*"default" + 0.021*"loop" + 0.019*"statement" + 0.015*"different"
INFO: topic #1 (0.523): 0.105*"lambda" + 0.032*"variable" + 0.032*"loop" + 0.028*"list" + 0.026*"output" + 0.025*"value" + 0.022*"code" + 0.022*"work" + 0.021*"example" + 0.021*"comprehension"
INFO: topic #2 (0.473): 0.092*"function" + 0.043*"example" + 0.037*"value" + 0.034*"default" + 0.032*"parameter" + 0.026*"lambda" + 0.024*"way" + 0.018*"list" + 0.016*"problem" + 0.014*"variable"
INFO: topic diff=1.398514, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 35.11882455005081
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -1.268885167389711
DEBUG: bound: at document #0
INFO: -5.158 per-word bound, 35.7 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 1, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.11839381, 0.28717667, 0.10516265]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.118): 0.078*"value" + 0.057*"function" + 0.043*"time" + 0.037*"lambda" + 0.025*"argument" + 0.024*"default" + 0.023*"loop" + 0.022*"closure" + 0.020*"variable" + 0.017*"last"
INFO: topic #1 (0.287): 0.101*"lambda" + 0.036*"loop" + 0.032*"value" + 0.030*"code" + 0.029*"variable" + 0.026*"output" + 0.021*"name" + 0.021*"final" + 0.020*"list" + 0.017*"time"
INFO: topic #2 (0.105): 0.089*"function" + 0.047*"value" + 0.040*"default" + 0.040*"parameter" + 0.032*"example" + 0.028*"lambda" + 0.022*"way" + 0.016*"simple" + 0.014*"list" + 0.014*"problem"
INFO: topic diff=0.450661, rho=0.512989
DEBUG: bound: at document #0
INFO: -5.302 per-word bound, 39.5 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 1, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.12843367, 0.36372545, 0.12692182]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.128): 0.072*"value" + 0.066*"function" + 0.038*"time" + 0.035*"lambda" + 0.028*"argument" + 0.028*"variable" + 0.025*"default" + 0.022*"statement" + 0.021*"loop" + 0.018*"different"
INFO: topic #1 (0.364): 0.104*"lambda" + 0.033*"list" + 0.031*"loop" + 0.028*"comprehension" + 0.027*"variable" + 0.026*"output" + 0.024*"example" + 0.023*"value" + 0.023*"code" + 0.023*"foo"
INFO: topic #2 (0.127): 0.091*"function" + 0.044*"example" + 0.036*"value" + 0.036*"parameter" + 0.033*"default" + 0.029*"way" + 0.023*"lambda" + 0.016*"simple" + 0.014*"problem" + 0.013*"good"
INFO: topic diff=0.418470, rho=0.512989
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 31.035831303100707
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.1171574235723283
DEBUG: bound: at document #0
INFO: -4.969 per-word bound, 31.3 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 2, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.09644589, 0.21442969, 0.096524045]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.096): 0.077*"value" + 0.062*"function" + 0.039*"time" + 0.037*"lambda" + 0.026*"default" + 0.024*"argument" + 0.024*"variable" + 0.023*"loop" + 0.019*"closure" + 0.016*"statement"
INFO: topic #1 (0.214): 0.101*"lambda" + 0.035*"loop" + 0.030*"value" + 0.029*"code" + 0.026*"variable" + 0.026*"output" + 0.024*"list" + 0.021*"name" + 0.019*"final" + 0.019*"example"
INFO: topic #2 (0.097): 0.088*"function" + 0.046*"value" + 0.041*"parameter" + 0.040*"default" + 0.033*"example" + 0.026*"lambda" + 0.025*"way" + 0.018*"simple" + 0.014*"necessary" + 0.014*"object"
INFO: topic diff=0.354751, rho=0.456435
DEBUG: bound: at document #0
INFO: -5.138 per-word bound, 35.2 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 2, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.10261571, 0.25809655, 0.08526992]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.103): 0.071*"function" + 0.070*"value" + 0.036*"lambda" + 0.034*"time" + 0.030*"variable" + 0.027*"default" + 0.025*"argument" + 0.022*"statement" + 0.021*"loop" + 0.018*"different"
INFO: topic #1 (0.258): 0.104*"lambda" + 0.035*"list" + 0.031*"comprehension" + 0.030*"loop" + 0.029*"example" + 0.026*"output" + 0.024*"foo" + 0.024*"code" + 0.023*"variable" + 0.023*"value"
INFO: topic #2 (0.085): 0.085*"function" + 0.039*"example" + 0.035*"value" + 0.033*"way" + 0.032*"default" + 0.029*"parameter" + 0.022*"lambda" + 0.019*"simple" + 0.015*"clean" + 0.015*"good"
INFO: topic diff=0.330052, rho=0.456435
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 30.20727863000078
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -1.090167770911215
DEBUG: bound: at document #0
INFO: -4.947 per-word bound, 30.9 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 3, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.08251623, 0.18454307, 0.07282961]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.083): 0.075*"value" + 0.067*"function" + 0.037*"lambda" + 0.036*"time" + 0.027*"default" + 0.027*"variable" + 0.023*"loop" + 0.023*"argument" + 0.018*"closure" + 0.017*"statement"
INFO: topic #1 (0.185): 0.101*"lambda" + 0.033*"loop" + 0.029*"code" + 0.029*"value" + 0.026*"list" + 0.026*"output" + 0.024*"variable" + 0.022*"example" + 0.021*"comprehension" + 0.021*"name"
INFO: topic #2 (0.073): 0.085*"function" + 0.045*"value" + 0.040*"default" + 0.038*"parameter" + 0.030*"example" + 0.027*"way" + 0.025*"lambda" + 0.020*"simple" + 0.015*"necessary" + 0.015*"object"
INFO: topic diff=0.295361, rho=0.415227
DEBUG: bound: at document #0
INFO: -5.067 per-word bound, 33.5 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 3, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.0883938, 0.21991217, 0.06799734]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.088): 0.074*"function" + 0.068*"value" + 0.037*"lambda" + 0.033*"time" + 0.032*"variable" + 0.027*"default" + 0.023*"argument" + 0.022*"loop" + 0.021*"statement" + 0.017*"different"
INFO: topic #1 (0.220): 0.104*"lambda" + 0.036*"list" + 0.033*"comprehension" + 0.030*"example" + 0.029*"loop" + 0.027*"output" + 0.025*"foo" + 0.024*"code" + 0.023*"value" + 0.021*"variable"
INFO: topic #2 (0.068): 0.078*"function" + 0.036*"value" + 0.035*"way" + 0.035*"example" + 0.032*"default" + 0.028*"parameter" + 0.021*"lambda" + 0.021*"simple" + 0.016*"clean" + 0.016*"good"
INFO: topic diff=0.266322, rho=0.415227
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 29.95301262462437
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -1.1077020199047825
DEBUG: bound: at document #0
INFO: -4.943 per-word bound, 30.8 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 4, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.07400958, 0.16785876, 0.06083208]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.074): 0.073*"value" + 0.069*"function" + 0.037*"lambda" + 0.034*"time" + 0.028*"variable" + 0.027*"default" + 0.023*"loop" + 0.022*"argument" + 0.017*"statement" + 0.017*"closure"
INFO: topic #1 (0.168): 0.101*"lambda" + 0.033*"loop" + 0.030*"code" + 0.028*"value" + 0.027*"list" + 0.026*"output" + 0.023*"example" + 0.023*"comprehension" + 0.022*"variable" + 0.021*"name"
INFO: topic #2 (0.061): 0.081*"function" + 0.046*"value" + 0.039*"default" + 0.037*"parameter" + 0.028*"way" + 0.028*"example" + 0.025*"lambda" + 0.021*"simple" + 0.015*"necessary" + 0.015*"object"
INFO: topic diff=0.251833, rho=0.383482
DEBUG: bound: at document #0
INFO: -5.029 per-word bound, 32.7 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 4, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.07937996, 0.1969376, 0.058242552]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.079): 0.074*"function" + 0.067*"value" + 0.038*"lambda" + 0.032*"variable" + 0.032*"time" + 0.026*"default" + 0.022*"loop" + 0.022*"argument" + 0.020*"statement" + 0.016*"scope"
INFO: topic #1 (0.197): 0.104*"lambda" + 0.037*"list" + 0.034*"comprehension" + 0.029*"example" + 0.029*"loop" + 0.027*"output" + 0.025*"code" + 0.025*"foo" + 0.022*"value" + 0.020*"name"
INFO: topic #2 (0.058): 0.072*"function" + 0.037*"way" + 0.036*"value" + 0.032*"default" + 0.031*"example" + 0.028*"parameter" + 0.022*"simple" + 0.021*"lambda" + 0.016*"clean" + 0.016*"good"
INFO: topic diff=0.235450, rho=0.383482
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 29.6122125852479
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -1.459096277820352
DEBUG: bound: at document #0
INFO: -4.935 per-word bound, 30.6 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 5, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.06821615, 0.15649979, 0.053443395]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.068): 0.071*"value" + 0.070*"function" + 0.039*"lambda" + 0.033*"time" + 0.029*"variable" + 0.026*"default" + 0.023*"loop" + 0.021*"argument" + 0.017*"statement" + 0.016*"scope"
INFO: topic #1 (0.156): 0.101*"lambda" + 0.032*"loop" + 0.030*"code" + 0.029*"list" + 0.028*"value" + 0.027*"output" + 0.024*"comprehension" + 0.023*"example" + 0.021*"name" + 0.021*"variable"
INFO: topic #2 (0.053): 0.078*"function" + 0.046*"value" + 0.039*"default" + 0.037*"parameter" + 0.029*"way" + 0.026*"example" + 0.025*"lambda" + 0.021*"simple" + 0.016*"necessary" + 0.016*"object"
INFO: topic diff=0.220203, rho=0.358057
DEBUG: bound: at document #0
INFO: -4.995 per-word bound, 31.9 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 5, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.0729998, 0.17936395, 0.051839788]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.073): 0.074*"function" + 0.066*"value" + 0.041*"lambda" + 0.032*"variable" + 0.031*"time" + 0.025*"default" + 0.023*"loop" + 0.021*"argument" + 0.019*"statement" + 0.016*"scope"
INFO: topic #1 (0.179): 0.103*"lambda" + 0.038*"list" + 0.035*"comprehension" + 0.029*"output" + 0.028*"loop" + 0.026*"foo" + 0.026*"code" + 0.025*"example" + 0.022*"value" + 0.019*"name"
INFO: topic #2 (0.052): 0.069*"function" + 0.040*"way" + 0.037*"value" + 0.032*"default" + 0.029*"parameter" + 0.028*"example" + 0.022*"simple" + 0.022*"lambda" + 0.016*"clean" + 0.016*"good"
INFO: topic diff=0.216082, rho=0.358057
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 29.22361931652081
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -1.4281630292924807
DEBUG: bound: at document #0
INFO: -4.930 per-word bound, 30.5 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 6, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.06389092, 0.1471489, 0.048335437]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.064): 0.070*"function" + 0.070*"value" + 0.041*"lambda" + 0.032*"time" + 0.030*"variable" + 0.026*"default" + 0.024*"loop" + 0.020*"argument" + 0.017*"statement" + 0.016*"scope"
INFO: topic #1 (0.147): 0.101*"lambda" + 0.032*"loop" + 0.030*"code" + 0.030*"list" + 0.028*"value" + 0.028*"output" + 0.025*"comprehension" + 0.021*"name" + 0.020*"variable" + 0.020*"example"
INFO: topic #2 (0.048): 0.076*"function" + 0.045*"value" + 0.039*"default" + 0.037*"parameter" + 0.031*"way" + 0.025*"lambda" + 0.025*"example" + 0.021*"simple" + 0.016*"necessary" + 0.016*"object"
INFO: topic diff=0.197865, rho=0.337100
DEBUG: bound: at document #0
INFO: -4.957 per-word bound, 31.1 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 6, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.066463746, 0.14179514, 0.046283547]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.066): 0.072*"function" + 0.064*"value" + 0.043*"lambda" + 0.032*"variable" + 0.030*"time" + 0.025*"default" + 0.024*"loop" + 0.020*"argument" + 0.019*"statement" + 0.018*"example"
INFO: topic #1 (0.142): 0.102*"lambda" + 0.040*"list" + 0.036*"comprehension" + 0.030*"output" + 0.028*"loop" + 0.027*"foo" + 0.025*"code" + 0.023*"value" + 0.021*"example" + 0.019*"time"
INFO: topic #2 (0.046): 0.067*"function" + 0.043*"way" + 0.037*"value" + 0.032*"default" + 0.029*"parameter" + 0.024*"example" + 0.022*"simple" + 0.022*"lambda" + 0.015*"clean" + 0.015*"good"
INFO: topic diff=0.201794, rho=0.337100
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 28.886508516007645
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -0.8243744964437739
DEBUG: bound: at document #0
INFO: -4.931 per-word bound, 30.5 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 7, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.058937654, 0.124751076, 0.043590385]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.059): 0.070*"function" + 0.068*"value" + 0.043*"lambda" + 0.032*"time" + 0.030*"variable" + 0.025*"default" + 0.024*"loop" + 0.020*"argument" + 0.016*"scope" + 0.016*"statement"
INFO: topic #1 (0.125): 0.100*"lambda" + 0.031*"loop" + 0.031*"list" + 0.029*"code" + 0.029*"output" + 0.028*"value" + 0.026*"comprehension" + 0.020*"foo" + 0.020*"variable" + 0.019*"name"
INFO: topic #2 (0.044): 0.074*"function" + 0.045*"value" + 0.039*"default" + 0.037*"parameter" + 0.034*"way" + 0.025*"lambda" + 0.023*"example" + 0.021*"simple" + 0.016*"necessary" + 0.016*"object"
INFO: topic diff=0.184643, rho=0.319438
DEBUG: bound: at document #0
INFO: -4.923 per-word bound, 30.3 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 7, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.06127577, 0.12258186, 0.042040147]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.061): 0.072*"function" + 0.063*"value" + 0.045*"lambda" + 0.032*"variable" + 0.030*"time" + 0.024*"default" + 0.024*"loop" + 0.020*"example" + 0.020*"argument" + 0.018*"statement"
INFO: topic #1 (0.123): 0.101*"lambda" + 0.041*"list" + 0.037*"comprehension" + 0.031*"output" + 0.028*"foo" + 0.028*"loop" + 0.023*"value" + 0.022*"code" + 0.019*"time" + 0.018*"example"
INFO: topic #2 (0.042): 0.066*"function" + 0.041*"way" + 0.038*"value" + 0.033*"default" + 0.030*"parameter" + 0.022*"simple" + 0.022*"lambda" + 0.021*"example" + 0.015*"clean" + 0.015*"good"
INFO: topic diff=0.189557, rho=0.319438
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 28.63129790166187
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -0.8253636178706222
DEBUG: bound: at document #0
INFO: -4.935 per-word bound, 30.6 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 8, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.054940417, 0.11131264, 0.03990816]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.055): 0.069*"function" + 0.067*"value" + 0.045*"lambda" + 0.031*"time" + 0.030*"variable" + 0.025*"default" + 0.024*"loop" + 0.019*"argument" + 0.018*"example" + 0.016*"scope"
INFO: topic #1 (0.111): 0.100*"lambda" + 0.032*"list" + 0.031*"loop" + 0.029*"output" + 0.028*"value" + 0.028*"code" + 0.027*"comprehension" + 0.020*"foo" + 0.019*"variable" + 0.019*"final"
INFO: topic #2 (0.040): 0.073*"function" + 0.045*"value" + 0.039*"default" + 0.037*"parameter" + 0.033*"way" + 0.025*"lambda" + 0.021*"simple" + 0.021*"example" + 0.016*"necessary" + 0.016*"object"
INFO: topic diff=0.175204, rho=0.304290
DEBUG: bound: at document #0
INFO: -4.892 per-word bound, 29.7 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 8, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.05589026, 0.09590067, 0.0380239]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.056): 0.071*"function" + 0.062*"value" + 0.047*"lambda" + 0.032*"variable" + 0.029*"time" + 0.024*"default" + 0.024*"loop" + 0.022*"example" + 0.019*"argument" + 0.017*"statement"
INFO: topic #1 (0.096): 0.101*"lambda" + 0.039*"list" + 0.036*"comprehension" + 0.032*"output" + 0.029*"foo" + 0.028*"loop" + 0.022*"value" + 0.020*"code" + 0.019*"time" + 0.017*"example"
INFO: topic #2 (0.038): 0.064*"function" + 0.039*"value" + 0.035*"way" + 0.033*"default" + 0.031*"parameter" + 0.022*"simple" + 0.022*"lambda" + 0.019*"example" + 0.014*"necessary" + 0.014*"object"
INFO: topic diff=0.183480, rho=0.304290
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 28.271816269588186
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -0.9007270560707518
DEBUG: bound: at document #0
INFO: -4.937 per-word bound, 30.6 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 9, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.050448664, 0.090914175, 0.036250234]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (0.050): 0.069*"function" + 0.066*"value" + 0.046*"lambda" + 0.031*"time" + 0.030*"variable" + 0.024*"default" + 0.024*"loop" + 0.019*"example" + 0.019*"argument" + 0.016*"scope"
INFO: topic #1 (0.091): 0.099*"lambda" + 0.031*"loop" + 0.031*"list" + 0.030*"output" + 0.028*"value" + 0.026*"comprehension" + 0.025*"code" + 0.021*"foo" + 0.019*"variable" + 0.019*"final"
INFO: topic #2 (0.036): 0.072*"function" + 0.046*"value" + 0.039*"default" + 0.037*"parameter" + 0.029*"way" + 0.025*"lambda" + 0.021*"simple" + 0.019*"example" + 0.016*"object" + 0.016*"necessary"
INFO: topic diff=0.168068, rho=0.291111
DEBUG: bound: at document #0
INFO: -4.855 per-word bound, 28.9 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 9, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
INFO: optimized alpha [0.051046185, 0.08093743, 0.03176702]
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (0.051): 0.071*"function" + 0.062*"value" + 0.047*"lambda" + 0.031*"variable" + 0.029*"time" + 0.024*"default" + 0.024*"loop" + 0.022*"example" + 0.019*"argument" + 0.017*"statement"
INFO: topic #1 (0.081): 0.100*"lambda" + 0.038*"list" + 0.035*"comprehension" + 0.032*"output" + 0.029*"foo" + 0.028*"loop" + 0.023*"value" + 0.019*"time" + 0.018*"code" + 0.016*"variable"
INFO: topic #2 (0.032): 0.062*"function" + 0.040*"value" + 0.034*"default" + 0.033*"parameter" + 0.026*"way" + 0.022*"lambda" + 0.019*"simple" + 0.017*"example" + 0.015*"object" + 0.015*"necessary"
INFO: topic diff=0.177205, rho=0.291111
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 28.111297402639273
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.092128994194528
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5> in 0.17s', 'datetime': '2023-04-25T06:36:16.843776', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'auto-adjust_models/models/3/model_t3.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-25T06:36:16.843962', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'auto-adjust_models/models/3/model_t3.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/3/model_t3.state
DEBUG: {'uri': 'auto-adjust_models/models/3/model_t3.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'auto-adjust_models/models/3/model_t3', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['id2word', 'dispatcher', 'state'], 'datetime': '2023-04-25T06:36:16.846231', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to auto-adjust_models/models/3/model_t3.expElogbeta.npy
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
INFO: not storing attribute state
DEBUG: {'uri': 'auto-adjust_models/models/3/model_t3', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/3/model_t3
