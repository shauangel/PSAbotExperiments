INFO: ---Start Analyzing---
INFO: ---Train for 5 Topics---
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<221 unique tokens: ['argument', 'caller', 'default', 'example', 'function']...> from 10 documents (total 546 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<221 unique tokens: ['argument', 'caller', 'default', 'example', 'function']...> from 10 documents (total 546 corpus positions)", 'datetime': '2023-04-25T06:36:19.818878', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 5 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.357 per-word bound, 163.9 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14881398, 0.004644692, 0.1937337, 0.0045134723, 0.0042711645]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.149): 0.087*"argument" + 0.082*"parameter" + 0.034*"optional" + 0.029*"positional" + 0.025*"keyword" + 0.025*"b" + 0.025*"kwargs" + 0.020*"default" + 0.020*"args" + 0.015*"value"
INFO: topic #1 (0.005): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"parameter" + 0.005*"name" + 0.005*"code"
INFO: topic #2 (0.194): 0.101*"argument" + 0.061*"value" + 0.051*"function" + 0.051*"default" + 0.041*"name" + 0.041*"code" + 0.031*"decorator" + 0.031*"none" + 0.021*"keyword" + 0.021*"implementation"
INFO: topic #3 (0.005): 0.005*"argument" + 0.005*"default" + 0.005*"value" + 0.005*"optional" + 0.005*"none" + 0.005*"b" + 0.005*"function" + 0.005*"parameter" + 0.005*"keyword" + 0.005*"name"
INFO: topic #4 (0.004): 0.005*"default" + 0.005*"argument" + 0.005*"value" + 0.005*"none" + 0.005*"parameter" + 0.005*"function" + 0.005*"b" + 0.005*"name" + 0.005*"optional" + 0.005*"keyword"
INFO: topic diff=3.399378, rho=1.000000
DEBUG: bound: at document #0
INFO: -7.500 per-word bound, 181.0 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1922828, 0.0045340145, 0.09543512, 0.006356232, 0.0047870735]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.192): 0.106*"argument" + 0.081*"parameter" + 0.058*"positional" + 0.055*"keyword" + 0.052*"optional" + 0.037*"args" + 0.031*"default" + 0.024*"function" + 0.022*"kwargs" + 0.021*"value"
INFO: topic #1 (0.005): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"parameter" + 0.005*"name" + 0.005*"code"
INFO: topic #2 (0.095): 0.109*"function" + 0.095*"argument" + 0.048*"value" + 0.035*"default" + 0.032*"decorator" + 0.028*"implementation" + 0.027*"code" + 0.025*"example" + 0.024*"note" + 0.021*"keyword"
INFO: topic #3 (0.006): 0.032*"line" + 0.031*"multiple" + 0.026*"different" + 0.026*"dispatch" + 0.020*"approach" + 0.020*"support" + 0.020*"kwarg" + 0.014*"n’t" + 0.014*"conflict" + 0.014*"several"
INFO: topic #4 (0.005): 0.039*"length" + 0.039*"variable" + 0.022*"signature" + 0.022*"free" + 0.022*"base" + 0.022*"useme2declare" + 0.004*"note" + 0.004*"args" + 0.004*"case" + 0.004*"positional"
INFO: topic diff=1.090136, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 38.665007974420234
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -2.117787647164115
DEBUG: bound: at document #0
INFO: -5.252 per-word bound, 38.1 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.09394061, 0.004435564, 0.0902592, 0.0061627505, 0.004677326]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.094): 0.095*"argument" + 0.082*"parameter" + 0.042*"optional" + 0.042*"positional" + 0.038*"keyword" + 0.027*"args" + 0.025*"default" + 0.023*"kwargs" + 0.022*"b" + 0.018*"value"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"parameter" + 0.005*"name" + 0.005*"code"
INFO: topic #2 (0.090): 0.099*"argument" + 0.076*"function" + 0.056*"value" + 0.044*"default" + 0.035*"code" + 0.032*"decorator" + 0.031*"name" + 0.024*"implementation" + 0.024*"none" + 0.023*"example"
INFO: topic #3 (0.006): 0.027*"line" + 0.026*"multiple" + 0.022*"different" + 0.022*"dispatch" + 0.017*"approach" + 0.017*"support" + 0.017*"kwarg" + 0.012*"n’t" + 0.012*"conflict" + 0.012*"several"
INFO: topic #4 (0.005): 0.023*"length" + 0.023*"variable" + 0.014*"signature" + 0.014*"free" + 0.014*"base" + 0.014*"useme2declare" + 0.004*"note" + 0.004*"args" + 0.004*"case" + 0.004*"positional"
INFO: topic diff=0.346489, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.604 per-word bound, 48.6 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.120681256, 0.0043571307, 0.08036242, 0.007903413, 0.0050633694]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.121): 0.110*"argument" + 0.082*"parameter" + 0.056*"positional" + 0.055*"keyword" + 0.052*"optional" + 0.036*"args" + 0.032*"default" + 0.026*"function" + 0.022*"kwargs" + 0.022*"value"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"parameter" + 0.005*"name" + 0.005*"code"
INFO: topic #2 (0.080): 0.110*"function" + 0.094*"argument" + 0.050*"value" + 0.036*"default" + 0.035*"decorator" + 0.030*"implementation" + 0.030*"code" + 0.026*"note" + 0.025*"example" + 0.020*"name"
INFO: topic #3 (0.008): 0.033*"line" + 0.032*"multiple" + 0.027*"different" + 0.027*"dispatch" + 0.020*"support" + 0.020*"approach" + 0.017*"kwarg" + 0.014*"env" + 0.014*"randint" + 0.014*"several"
INFO: topic #4 (0.005): 0.048*"length" + 0.048*"variable" + 0.026*"base" + 0.026*"free" + 0.026*"useme2declare" + 0.025*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"positional"
INFO: topic diff=0.259011, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 37.46650373595992
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.5793637526993596
DEBUG: bound: at document #0
INFO: -5.173 per-word bound, 36.1 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.08939524, 0.004271252, 0.078941725, 0.007620872, 0.0049473965]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.089): 0.098*"argument" + 0.082*"parameter" + 0.043*"optional" + 0.043*"positional" + 0.040*"keyword" + 0.028*"args" + 0.026*"default" + 0.023*"kwargs" + 0.021*"b" + 0.019*"value"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"parameter" + 0.005*"name" + 0.005*"code"
INFO: topic #2 (0.079): 0.098*"argument" + 0.078*"function" + 0.056*"value" + 0.044*"default" + 0.036*"code" + 0.033*"decorator" + 0.032*"name" + 0.025*"implementation" + 0.024*"none" + 0.023*"example"
INFO: topic #3 (0.008): 0.029*"line" + 0.028*"multiple" + 0.023*"different" + 0.023*"dispatch" + 0.018*"support" + 0.018*"approach" + 0.015*"kwarg" + 0.012*"env" + 0.012*"randint" + 0.012*"several"
INFO: topic #4 (0.005): 0.030*"length" + 0.030*"variable" + 0.017*"base" + 0.017*"free" + 0.017*"useme2declare" + 0.017*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"positional"
INFO: topic diff=0.264341, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.549 per-word bound, 46.8 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.11312186, 0.0042063002, 0.07379906, 0.0095165465, 0.005308398]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.113): 0.110*"argument" + 0.081*"parameter" + 0.055*"positional" + 0.055*"keyword" + 0.051*"optional" + 0.036*"args" + 0.032*"default" + 0.026*"function" + 0.022*"value" + 0.022*"kwargs"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"parameter" + 0.005*"name" + 0.005*"code"
INFO: topic #2 (0.074): 0.108*"function" + 0.092*"argument" + 0.051*"value" + 0.036*"default" + 0.036*"decorator" + 0.032*"code" + 0.031*"implementation" + 0.026*"note" + 0.024*"example" + 0.022*"name"
INFO: topic #3 (0.010): 0.033*"line" + 0.033*"multiple" + 0.027*"different" + 0.027*"dispatch" + 0.020*"approach" + 0.020*"support" + 0.014*"env" + 0.014*"randint" + 0.014*"pattern" + 0.014*"library"
INFO: topic #4 (0.005): 0.050*"length" + 0.050*"variable" + 0.027*"base" + 0.027*"free" + 0.027*"useme2declare" + 0.026*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"positional"
INFO: topic diff=0.202073, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 37.16305255452298
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -0.6818777926860438
DEBUG: bound: at document #0
INFO: -5.145 per-word bound, 35.4 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.08805533, 0.0041317428, 0.07372411, 0.009134955, 0.0051896544]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.088): 0.099*"argument" + 0.082*"parameter" + 0.043*"optional" + 0.043*"positional" + 0.041*"keyword" + 0.028*"args" + 0.026*"default" + 0.023*"kwargs" + 0.021*"b" + 0.019*"value"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"parameter" + 0.005*"name" + 0.005*"code"
INFO: topic #2 (0.074): 0.097*"argument" + 0.079*"function" + 0.056*"value" + 0.044*"default" + 0.036*"code" + 0.034*"decorator" + 0.032*"name" + 0.026*"implementation" + 0.024*"none" + 0.023*"example"
INFO: topic #3 (0.009): 0.030*"line" + 0.029*"multiple" + 0.024*"different" + 0.024*"dispatch" + 0.018*"approach" + 0.018*"support" + 0.013*"env" + 0.013*"randint" + 0.013*"pattern" + 0.013*"library"
INFO: topic #4 (0.005): 0.033*"length" + 0.033*"variable" + 0.019*"base" + 0.019*"free" + 0.019*"useme2declare" + 0.018*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"positional"
INFO: topic diff=0.213285, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.511 per-word bound, 45.6 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.109927185, 0.0040768455, 0.07056065, 0.011172736, 0.0055324547]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.110): 0.109*"argument" + 0.080*"parameter" + 0.054*"positional" + 0.054*"keyword" + 0.050*"optional" + 0.035*"args" + 0.032*"default" + 0.026*"function" + 0.022*"value" + 0.022*"kwargs"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"parameter" + 0.005*"name" + 0.005*"code"
INFO: topic #2 (0.071): 0.106*"function" + 0.092*"argument" + 0.051*"value" + 0.037*"default" + 0.036*"decorator" + 0.032*"code" + 0.031*"implementation" + 0.025*"note" + 0.024*"example" + 0.023*"name"
INFO: topic #3 (0.011): 0.034*"line" + 0.033*"multiple" + 0.027*"dispatch" + 0.027*"different" + 0.021*"approach" + 0.021*"support" + 0.014*"function_hint" + 0.014*"randint" + 0.014*"gen_pyi.py" + 0.014*"several"
INFO: topic #4 (0.006): 0.050*"length" + 0.050*"variable" + 0.027*"base" + 0.027*"free" + 0.027*"useme2declare" + 0.027*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"positional"
INFO: topic diff=0.185266, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 36.744075967555176
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -0.6818777926860438
DEBUG: bound: at document #0
INFO: -5.131 per-word bound, 35.0 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.08821196, 0.0040116576, 0.07109702, 0.010683226, 0.00541241]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.088): 0.100*"argument" + 0.081*"parameter" + 0.043*"optional" + 0.043*"positional" + 0.041*"keyword" + 0.028*"args" + 0.027*"default" + 0.023*"kwargs" + 0.021*"b" + 0.019*"function"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"parameter" + 0.005*"name" + 0.005*"code"
INFO: topic #2 (0.071): 0.096*"argument" + 0.080*"function" + 0.056*"value" + 0.043*"default" + 0.036*"code" + 0.034*"decorator" + 0.032*"name" + 0.026*"implementation" + 0.024*"none" + 0.023*"example"
INFO: topic #3 (0.011): 0.030*"line" + 0.030*"multiple" + 0.025*"dispatch" + 0.025*"different" + 0.019*"approach" + 0.019*"support" + 0.013*"function_hint" + 0.013*"randint" + 0.013*"gen_pyi.py" + 0.013*"several"
INFO: topic #4 (0.005): 0.035*"length" + 0.035*"variable" + 0.019*"base" + 0.019*"free" + 0.019*"useme2declare" + 0.019*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"positional"
INFO: topic diff=0.183115, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.468 per-word bound, 44.3 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.108772136, 0.0039643934, 0.0689469, 0.012849793, 0.005741234]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.109): 0.108*"argument" + 0.080*"parameter" + 0.053*"positional" + 0.053*"keyword" + 0.050*"optional" + 0.034*"args" + 0.031*"default" + 0.025*"function" + 0.022*"kwargs" + 0.022*"value"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"parameter" + 0.005*"name" + 0.005*"code"
INFO: topic #2 (0.069): 0.105*"function" + 0.092*"argument" + 0.051*"value" + 0.037*"default" + 0.036*"decorator" + 0.033*"code" + 0.031*"implementation" + 0.025*"note" + 0.024*"example" + 0.024*"name"
INFO: topic #3 (0.013): 0.034*"line" + 0.033*"multiple" + 0.027*"different" + 0.027*"dispatch" + 0.021*"support" + 0.021*"approach" + 0.014*"function_hint" + 0.014*"gen_pyi.py" + 0.014*"env" + 0.014*"library"
INFO: topic #4 (0.006): 0.049*"length" + 0.049*"variable" + 0.027*"base" + 0.027*"free" + 0.027*"useme2declare" + 0.026*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"example"
INFO: topic diff=0.171505, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 36.34387303210675
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -0.6721123501201531
DEBUG: bound: at document #0
INFO: -5.119 per-word bound, 34.8 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.089142844, 0.003906875, 0.06980308, 0.012245647, 0.0056206044]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.089): 0.100*"argument" + 0.081*"parameter" + 0.044*"positional" + 0.044*"optional" + 0.042*"keyword" + 0.029*"args" + 0.027*"default" + 0.023*"kwargs" + 0.021*"b" + 0.019*"function"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"parameter" + 0.005*"name" + 0.005*"code"
INFO: topic #2 (0.070): 0.096*"argument" + 0.081*"function" + 0.056*"value" + 0.043*"default" + 0.036*"code" + 0.034*"decorator" + 0.031*"name" + 0.026*"implementation" + 0.024*"none" + 0.023*"example"
INFO: topic #3 (0.012): 0.031*"line" + 0.030*"multiple" + 0.025*"different" + 0.025*"dispatch" + 0.019*"support" + 0.019*"approach" + 0.013*"function_hint" + 0.013*"gen_pyi.py" + 0.013*"env" + 0.013*"library"
INFO: topic #4 (0.006): 0.036*"length" + 0.036*"variable" + 0.020*"base" + 0.020*"free" + 0.020*"useme2declare" + 0.020*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"example"
INFO: topic diff=0.163017, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.438 per-word bound, 43.4 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.108730115, 0.0038655563, 0.068239324, 0.014527628, 0.0059382925]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.109): 0.108*"argument" + 0.080*"parameter" + 0.053*"positional" + 0.052*"keyword" + 0.049*"optional" + 0.034*"args" + 0.031*"default" + 0.025*"function" + 0.022*"kwargs" + 0.022*"value"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"name" + 0.005*"parameter" + 0.005*"code"
INFO: topic #2 (0.068): 0.105*"function" + 0.093*"argument" + 0.052*"value" + 0.037*"default" + 0.036*"decorator" + 0.033*"code" + 0.031*"implementation" + 0.025*"note" + 0.024*"example" + 0.024*"name"
INFO: topic #3 (0.015): 0.034*"line" + 0.033*"multiple" + 0.027*"dispatch" + 0.027*"different" + 0.021*"support" + 0.021*"approach" + 0.014*"randint" + 0.014*"several" + 0.014*"pattern" + 0.014*"function_hint"
INFO: topic #4 (0.006): 0.049*"length" + 0.049*"variable" + 0.026*"base" + 0.026*"free" + 0.026*"useme2declare" + 0.026*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"example"
INFO: topic diff=0.158266, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 36.13644134322171
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -0.6690316959843312
DEBUG: bound: at document #0
INFO: -5.109 per-word bound, 34.5 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.09050967, 0.0038143394, 0.06927612, 0.013804462, 0.0058174287]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.091): 0.100*"argument" + 0.081*"parameter" + 0.044*"positional" + 0.044*"optional" + 0.042*"keyword" + 0.029*"args" + 0.027*"default" + 0.023*"kwargs" + 0.021*"b" + 0.019*"value"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"name" + 0.005*"parameter" + 0.005*"code"
INFO: topic #2 (0.069): 0.097*"argument" + 0.082*"function" + 0.056*"value" + 0.043*"default" + 0.036*"code" + 0.034*"decorator" + 0.031*"name" + 0.026*"implementation" + 0.024*"none" + 0.023*"example"
INFO: topic #3 (0.014): 0.031*"line" + 0.030*"multiple" + 0.025*"dispatch" + 0.025*"different" + 0.019*"support" + 0.019*"approach" + 0.013*"randint" + 0.013*"several" + 0.013*"pattern" + 0.013*"function_hint"
INFO: topic #4 (0.006): 0.036*"length" + 0.036*"variable" + 0.020*"base" + 0.020*"free" + 0.020*"useme2declare" + 0.020*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"example"
INFO: topic diff=0.147938, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.410 per-word bound, 42.5 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.10898208, 0.0037770718, 0.067853175, 0.015267361, 0.0061243963]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.109): 0.107*"argument" + 0.081*"parameter" + 0.052*"positional" + 0.052*"keyword" + 0.049*"optional" + 0.034*"args" + 0.031*"default" + 0.024*"function" + 0.022*"kwargs" + 0.022*"value"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"name" + 0.005*"code" + 0.005*"parameter"
INFO: topic #2 (0.068): 0.105*"function" + 0.094*"argument" + 0.052*"value" + 0.037*"default" + 0.036*"decorator" + 0.033*"code" + 0.030*"implementation" + 0.024*"note" + 0.024*"name" + 0.024*"example"
INFO: topic #3 (0.015): 0.034*"line" + 0.030*"multiple" + 0.027*"dispatch" + 0.027*"different" + 0.021*"approach" + 0.021*"support" + 0.015*"method" + 0.015*"type" + 0.014*"env" + 0.014*"gen_pyi.py"
INFO: topic #4 (0.006): 0.049*"length" + 0.049*"variable" + 0.026*"base" + 0.026*"free" + 0.026*"useme2declare" + 0.026*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"example"
INFO: topic diff=0.147130, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 35.9693080186362
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -0.6733909371088498
DEBUG: bound: at document #0
INFO: -5.103 per-word bound, 34.4 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.09169629, 0.0037308177, 0.068941996, 0.014511896, 0.006002792]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.092): 0.100*"argument" + 0.081*"parameter" + 0.044*"positional" + 0.044*"optional" + 0.042*"keyword" + 0.029*"args" + 0.027*"default" + 0.023*"kwargs" + 0.021*"b" + 0.019*"value"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"code" + 0.005*"name" + 0.005*"parameter"
INFO: topic #2 (0.069): 0.097*"argument" + 0.083*"function" + 0.055*"value" + 0.043*"default" + 0.036*"code" + 0.034*"decorator" + 0.031*"name" + 0.027*"implementation" + 0.024*"none" + 0.023*"example"
INFO: topic #3 (0.015): 0.031*"line" + 0.027*"multiple" + 0.025*"dispatch" + 0.025*"different" + 0.019*"approach" + 0.019*"support" + 0.014*"method" + 0.014*"type" + 0.013*"env" + 0.013*"gen_pyi.py"
INFO: topic #4 (0.006): 0.036*"length" + 0.036*"variable" + 0.020*"base" + 0.020*"free" + 0.020*"useme2declare" + 0.020*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"example"
INFO: topic diff=0.137690, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.392 per-word bound, 42.0 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.10944519, 0.0036972754, 0.0677467, 0.015955845, 0.0063014915]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.109): 0.107*"argument" + 0.081*"parameter" + 0.052*"positional" + 0.052*"keyword" + 0.049*"optional" + 0.034*"args" + 0.031*"default" + 0.023*"function" + 0.022*"kwargs" + 0.022*"value"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"name" + 0.005*"code" + 0.005*"parameter"
INFO: topic #2 (0.068): 0.105*"function" + 0.095*"argument" + 0.052*"value" + 0.038*"default" + 0.036*"decorator" + 0.033*"code" + 0.030*"implementation" + 0.024*"name" + 0.024*"example" + 0.024*"note"
INFO: topic #3 (0.016): 0.033*"line" + 0.028*"multiple" + 0.027*"dispatch" + 0.027*"different" + 0.020*"approach" + 0.020*"support" + 0.017*"method" + 0.017*"type" + 0.014*"library" + 0.014*"several"
INFO: topic #4 (0.006): 0.048*"variable" + 0.048*"length" + 0.026*"base" + 0.026*"free" + 0.026*"useme2declare" + 0.026*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"example"
INFO: topic diff=0.136023, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 35.898269603629956
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -0.6764715912446719
DEBUG: bound: at document #0
INFO: -5.097 per-word bound, 34.2 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.09291263, 0.0036551831, 0.06885608, 0.01517222, 0.0061792256]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.093): 0.100*"argument" + 0.081*"parameter" + 0.044*"positional" + 0.044*"optional" + 0.043*"keyword" + 0.029*"args" + 0.027*"default" + 0.023*"kwargs" + 0.021*"b" + 0.019*"value"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"code" + 0.005*"parameter" + 0.005*"name"
INFO: topic #2 (0.069): 0.097*"argument" + 0.084*"function" + 0.055*"value" + 0.043*"default" + 0.036*"code" + 0.034*"decorator" + 0.031*"name" + 0.027*"implementation" + 0.023*"none" + 0.023*"example"
INFO: topic #3 (0.015): 0.031*"line" + 0.026*"multiple" + 0.025*"dispatch" + 0.025*"different" + 0.019*"approach" + 0.019*"support" + 0.016*"method" + 0.016*"type" + 0.013*"library" + 0.013*"several"
INFO: topic #4 (0.006): 0.037*"length" + 0.037*"variable" + 0.020*"useme2declare" + 0.020*"base" + 0.020*"free" + 0.020*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"example"
INFO: topic diff=0.129833, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.382 per-word bound, 41.7 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.110052526, 0.003624728, 0.06781842, 0.016598048, 0.0064707533]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.110): 0.106*"argument" + 0.081*"parameter" + 0.052*"positional" + 0.052*"keyword" + 0.049*"optional" + 0.034*"args" + 0.031*"default" + 0.023*"function" + 0.022*"kwargs" + 0.022*"value"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"name" + 0.005*"code" + 0.005*"parameter"
INFO: topic #2 (0.068): 0.105*"function" + 0.096*"argument" + 0.052*"value" + 0.038*"default" + 0.036*"decorator" + 0.033*"code" + 0.030*"implementation" + 0.025*"name" + 0.024*"example" + 0.024*"note"
INFO: topic #3 (0.017): 0.033*"line" + 0.027*"multiple" + 0.027*"different" + 0.027*"dispatch" + 0.020*"approach" + 0.020*"support" + 0.018*"method" + 0.018*"type" + 0.014*"gen_pyi.py" + 0.014*"@overload"
INFO: topic #4 (0.006): 0.048*"length" + 0.048*"variable" + 0.026*"useme2declare" + 0.026*"base" + 0.026*"free" + 0.026*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"example"
INFO: topic diff=0.127872, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 35.855689992614074
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -0.6764715912446719
DEBUG: bound: at document #0
INFO: -5.092 per-word bound, 34.1 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.09413672, 0.0035861663, 0.06893036, 0.015789818, 0.00634787]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.094): 0.100*"argument" + 0.081*"parameter" + 0.045*"positional" + 0.044*"optional" + 0.043*"keyword" + 0.029*"args" + 0.027*"default" + 0.023*"kwargs" + 0.021*"b" + 0.019*"value"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"function" + 0.005*"none" + 0.005*"optional" + 0.005*"b" + 0.005*"code" + 0.005*"name" + 0.005*"parameter"
INFO: topic #2 (0.069): 0.098*"argument" + 0.085*"function" + 0.055*"value" + 0.043*"default" + 0.036*"code" + 0.034*"decorator" + 0.031*"name" + 0.027*"implementation" + 0.023*"none" + 0.023*"example"
INFO: topic #3 (0.016): 0.031*"line" + 0.025*"multiple" + 0.025*"different" + 0.025*"dispatch" + 0.019*"approach" + 0.019*"support" + 0.017*"method" + 0.017*"type" + 0.013*"gen_pyi.py" + 0.013*"@overload"
INFO: topic #4 (0.006): 0.037*"variable" + 0.037*"length" + 0.020*"base" + 0.020*"useme2declare" + 0.020*"free" + 0.020*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"example"
INFO: topic diff=0.123286, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.376 per-word bound, 41.5 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.110754505, 0.0035583095, 0.06800574, 0.017198207, 0.0066330875]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.111): 0.106*"argument" + 0.081*"parameter" + 0.052*"positional" + 0.052*"keyword" + 0.049*"optional" + 0.034*"args" + 0.031*"default" + 0.023*"kwargs" + 0.022*"function" + 0.022*"value"
INFO: topic #1 (0.004): 0.005*"argument" + 0.005*"value" + 0.005*"default" + 0.005*"none" + 0.005*"function" + 0.005*"b" + 0.005*"optional" + 0.005*"name" + 0.005*"parameter" + 0.005*"decorator"
INFO: topic #2 (0.068): 0.105*"function" + 0.096*"argument" + 0.052*"value" + 0.038*"default" + 0.036*"decorator" + 0.033*"code" + 0.030*"implementation" + 0.025*"name" + 0.025*"example" + 0.024*"note"
INFO: topic #3 (0.017): 0.033*"line" + 0.027*"different" + 0.027*"dispatch" + 0.027*"multiple" + 0.020*"approach" + 0.020*"support" + 0.019*"method" + 0.019*"type" + 0.014*"gen_pyi.py" + 0.014*"@overload"
INFO: topic #4 (0.007): 0.048*"length" + 0.048*"variable" + 0.026*"base" + 0.026*"free" + 0.026*"useme2declare" + 0.026*"signature" + 0.004*"note" + 0.004*"case" + 0.004*"args" + 0.004*"example"
INFO: topic diff=0.121207, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 35.827294433203264
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=5, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -0.6659510418485314
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=221, num_topics=5, decay=0.5, chunksize=5> in 0.19s', 'datetime': '2023-04-25T06:36:20.012962', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'auto-adjust_models/models/6/model_t5.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-25T06:36:20.013142', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'auto-adjust_models/models/6/model_t5.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/6/model_t5.state
DEBUG: {'uri': 'auto-adjust_models/models/6/model_t5.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'auto-adjust_models/models/6/model_t5', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['id2word', 'dispatcher', 'state'], 'datetime': '2023-04-25T06:36:20.015745', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to auto-adjust_models/models/6/model_t5.expElogbeta.npy
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
INFO: not storing attribute state
DEBUG: {'uri': 'auto-adjust_models/models/6/model_t5', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/6/model_t5
