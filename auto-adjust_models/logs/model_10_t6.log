INFO: ---Start Analyzing---
INFO: ---Train for 6 Topics---
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<147 unique tokens: ['assignment', 'batchelder', 'case', 'copy', 'copy.deepcopy']...> from 10 documents (total 393 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<147 unique tokens: ['assignment', 'batchelder', 'case', 'copy', 'copy.deepcopy']...> from 10 documents (total 393 corpus positions)", 'datetime': '2023-04-25T06:36:24.330802', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 6 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -8.164 per-word bound, 286.8 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1520702, 0.04611644, 0.046119176, 0.046132796, 0.1932151, 0.046120487]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.046): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"reference" + 0.007*"list" + 0.007*"module" + 0.007*"instance" + 0.007*"shallow"
INFO: topic #3 (0.046): 0.007*"object" + 0.007*"copy" + 0.007*"deepcopy" + 0.007*"foo" + 0.007*"reference" + 0.007*"name" + 0.007*"df" + 0.007*"dictionary" + 0.007*"variable" + 0.007*"new"
INFO: topic #2 (0.046): 0.007*"object" + 0.007*"copy" + 0.007*"deepcopy" + 0.007*"foo" + 0.007*"reference" + 0.007*"list" + 0.007*"name" + 0.007*"df" + 0.007*"dictionary" + 0.007*"board"
INFO: topic #0 (0.152): 0.069*"object" + 0.058*"reference" + 0.046*"instance" + 0.046*"df" + 0.046*"new" + 0.046*"name" + 0.035*"copy" + 0.035*"variable" + 0.035*"list" + 0.024*"dict_b"
INFO: topic #4 (0.193): 0.101*"deepcopy" + 0.072*"copy" + 0.072*"object" + 0.030*"dictionary" + 0.030*"memo" + 0.030*"lots_of_data" + 0.030*"answer" + 0.030*"foo" + 0.015*"several" + 0.015*"solution"
INFO: topic diff=4.210933, rho=1.000000
DEBUG: bound: at document #0
INFO: -7.275 per-word bound, 154.9 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.20231496, 0.046495054, 0.05465108, 0.046141483, 0.23962857, 0.039254725]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.039): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"reference" + 0.007*"list" + 0.007*"module" + 0.007*"instance" + 0.007*"shallow"
INFO: topic #3 (0.046): 0.049*"customize" + 0.049*"method" + 0.049*"hook" + 0.006*"object" + 0.006*"deepcopy" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"df"
INFO: topic #2 (0.055): 0.067*"deep" + 0.058*"method" + 0.042*"change" + 0.035*"immutable" + 0.035*"interior" + 0.033*"mutable" + 0.026*"tuple" + 0.026*"container" + 0.026*"recursive" + 0.025*"attribute"
INFO: topic #0 (0.202): 0.114*"copy" + 0.105*"object" + 0.073*"new" + 0.069*"list" + 0.045*"original" + 0.043*"reference" + 0.034*"shallow" + 0.033*"memory" + 0.031*"instance" + 0.021*"case"
INFO: topic #4 (0.240): 0.230*"copy" + 0.146*"object" + 0.072*"deepcopy" + 0.057*"shallow" + 0.054*"class" + 0.021*"answer" + 0.019*"dictionary" + 0.018*"value" + 0.018*"function" + 0.014*"memo"
INFO: topic diff=1.270014, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 30.142938017169776
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -3.5538703128313753
DEBUG: bound: at document #0
INFO: -5.495 per-word bound, 45.1 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17159279, 0.040967282, 0.047023144, 0.040697195, 0.22021914, 0.03531084]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.035): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"reference" + 0.007*"list" + 0.007*"module" + 0.007*"instance" + 0.007*"shallow"
INFO: topic #3 (0.041): 0.029*"customize" + 0.029*"method" + 0.029*"hook" + 0.006*"object" + 0.006*"deepcopy" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"df"
INFO: topic #2 (0.047): 0.058*"deep" + 0.050*"method" + 0.037*"change" + 0.030*"immutable" + 0.030*"interior" + 0.029*"mutable" + 0.023*"tuple" + 0.023*"container" + 0.023*"recursive" + 0.022*"attribute"
INFO: topic #0 (0.172): 0.086*"object" + 0.074*"copy" + 0.059*"new" + 0.052*"list" + 0.050*"reference" + 0.039*"instance" + 0.031*"df" + 0.031*"name" + 0.029*"original" + 0.028*"memory"
INFO: topic #4 (0.220): 0.164*"copy" + 0.115*"object" + 0.084*"deepcopy" + 0.040*"shallow" + 0.038*"class" + 0.025*"answer" + 0.024*"dictionary" + 0.021*"memo" + 0.017*"value" + 0.017*"function"
INFO: topic diff=0.342944, rho=0.500000
DEBUG: bound: at document #0
INFO: -4.875 per-word bound, 29.3 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.20710088, 0.04173322, 0.053274147, 0.04125669, 0.25073186, 0.03250374]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.033): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"reference" + 0.007*"list" + 0.007*"module" + 0.007*"instance" + 0.007*"shallow"
INFO: topic #3 (0.041): 0.052*"customize" + 0.052*"hook" + 0.046*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"df"
INFO: topic #2 (0.053): 0.067*"deep" + 0.058*"method" + 0.043*"change" + 0.035*"interior" + 0.035*"immutable" + 0.034*"mutable" + 0.026*"tuple" + 0.026*"container" + 0.026*"recursive" + 0.026*"attribute"
INFO: topic #0 (0.207): 0.111*"copy" + 0.097*"object" + 0.076*"new" + 0.072*"list" + 0.047*"original" + 0.047*"reference" + 0.034*"memory" + 0.034*"instance" + 0.030*"shallow" + 0.022*"case"
INFO: topic #4 (0.251): 0.240*"copy" + 0.160*"object" + 0.076*"deepcopy" + 0.063*"shallow" + 0.055*"class" + 0.022*"answer" + 0.021*"dictionary" + 0.019*"value" + 0.019*"function" + 0.015*"memo"
INFO: topic diff=0.287995, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 28.782702302985072
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -3.5343816101559047
DEBUG: bound: at document #0
INFO: -5.354 per-word bound, 40.9 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1765338, 0.03770721, 0.046724193, 0.03732186, 0.22756907, 0.030059021]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.030): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"reference" + 0.007*"list" + 0.007*"module" + 0.007*"instance" + 0.007*"shallow"
INFO: topic #3 (0.037): 0.033*"hook" + 0.033*"customize" + 0.030*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"df"
INFO: topic #2 (0.047): 0.060*"deep" + 0.052*"method" + 0.038*"change" + 0.032*"interior" + 0.031*"immutable" + 0.031*"mutable" + 0.024*"tuple" + 0.024*"container" + 0.024*"recursive" + 0.023*"attribute"
INFO: topic #0 (0.177): 0.084*"object" + 0.075*"copy" + 0.062*"new" + 0.055*"list" + 0.052*"reference" + 0.040*"instance" + 0.031*"df" + 0.031*"name" + 0.031*"original" + 0.029*"memory"
INFO: topic #4 (0.228): 0.176*"copy" + 0.127*"object" + 0.086*"deepcopy" + 0.045*"shallow" + 0.040*"class" + 0.025*"answer" + 0.024*"dictionary" + 0.021*"memo" + 0.018*"value" + 0.018*"function"
INFO: topic diff=0.263352, rho=0.447214
DEBUG: bound: at document #0
INFO: -4.811 per-word bound, 28.1 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.20783794, 0.03856444, 0.05230418, 0.03802022, 0.2535623, 0.028236097]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.028): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"reference" + 0.007*"list" + 0.007*"module" + 0.007*"instance" + 0.007*"shallow"
INFO: topic #3 (0.038): 0.052*"hook" + 0.052*"customize" + 0.046*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"df"
INFO: topic #2 (0.052): 0.067*"deep" + 0.058*"method" + 0.043*"change" + 0.035*"interior" + 0.035*"immutable" + 0.034*"mutable" + 0.026*"tuple" + 0.026*"container" + 0.026*"recursive" + 0.026*"attribute"
INFO: topic #0 (0.208): 0.107*"copy" + 0.092*"object" + 0.077*"new" + 0.073*"list" + 0.048*"reference" + 0.047*"original" + 0.036*"instance" + 0.035*"memory" + 0.027*"shallow" + 0.022*"case"
INFO: topic #4 (0.254): 0.243*"copy" + 0.167*"object" + 0.078*"deepcopy" + 0.065*"shallow" + 0.055*"class" + 0.023*"answer" + 0.021*"dictionary" + 0.019*"value" + 0.019*"function" + 0.016*"memo"
INFO: topic diff=0.226460, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 28.334525385701806
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -3.532879887533282
DEBUG: bound: at document #0
INFO: -5.290 per-word bound, 39.1 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17868122, 0.035391305, 0.04647804, 0.034935813, 0.22999682, 0.026533224]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.027): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"reference" + 0.007*"list" + 0.007*"module" + 0.007*"instance" + 0.007*"shallow"
INFO: topic #3 (0.035): 0.035*"hook" + 0.035*"customize" + 0.032*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"df"
INFO: topic #2 (0.046): 0.061*"deep" + 0.053*"method" + 0.039*"change" + 0.032*"interior" + 0.032*"immutable" + 0.032*"mutable" + 0.024*"tuple" + 0.024*"container" + 0.024*"recursive" + 0.024*"attribute"
INFO: topic #0 (0.179): 0.082*"object" + 0.076*"copy" + 0.064*"new" + 0.056*"list" + 0.052*"reference" + 0.040*"instance" + 0.032*"original" + 0.031*"df" + 0.031*"name" + 0.030*"memory"
INFO: topic #4 (0.230): 0.183*"copy" + 0.134*"object" + 0.086*"deepcopy" + 0.048*"shallow" + 0.041*"class" + 0.025*"answer" + 0.024*"dictionary" + 0.021*"memo" + 0.018*"value" + 0.018*"function"
INFO: topic diff=0.206767, rho=0.408248
DEBUG: bound: at document #0
INFO: -4.783 per-word bound, 27.5 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.20691997, 0.036254004, 0.051548272, 0.035671625, 0.2529499, 0.025231851]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.025): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"reference" + 0.007*"list" + 0.007*"module" + 0.007*"instance" + 0.007*"shallow"
INFO: topic #3 (0.036): 0.051*"hook" + 0.051*"customize" + 0.048*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"df"
INFO: topic #2 (0.052): 0.068*"deep" + 0.059*"method" + 0.043*"change" + 0.035*"interior" + 0.035*"immutable" + 0.035*"mutable" + 0.026*"tuple" + 0.026*"container" + 0.026*"recursive" + 0.026*"attribute"
INFO: topic #0 (0.207): 0.104*"copy" + 0.088*"object" + 0.078*"new" + 0.073*"list" + 0.049*"reference" + 0.047*"original" + 0.036*"instance" + 0.035*"memory" + 0.025*"shallow" + 0.022*"case"
INFO: topic #4 (0.253): 0.243*"copy" + 0.169*"object" + 0.079*"deepcopy" + 0.067*"shallow" + 0.055*"class" + 0.023*"answer" + 0.022*"dictionary" + 0.019*"value" + 0.019*"function" + 0.016*"memo"
INFO: topic diff=0.184582, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 28.13720231791034
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -3.532879887533282
DEBUG: bound: at document #0
INFO: -5.253 per-word bound, 38.1 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17947465, 0.03363098, 0.046255928, 0.033132035, 0.23023137, 0.023959987]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.024): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"reference" + 0.007*"list" + 0.007*"module" + 0.007*"instance" + 0.007*"shallow"
INFO: topic #3 (0.033): 0.036*"hook" + 0.036*"customize" + 0.034*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"df"
INFO: topic #2 (0.046): 0.062*"deep" + 0.054*"method" + 0.040*"change" + 0.032*"interior" + 0.032*"immutable" + 0.032*"mutable" + 0.025*"tuple" + 0.025*"container" + 0.025*"recursive" + 0.024*"attribute"
INFO: topic #0 (0.179): 0.080*"object" + 0.076*"copy" + 0.065*"new" + 0.057*"list" + 0.053*"reference" + 0.040*"instance" + 0.033*"original" + 0.031*"df" + 0.031*"name" + 0.030*"memory"
INFO: topic #4 (0.230): 0.188*"copy" + 0.138*"object" + 0.086*"deepcopy" + 0.050*"shallow" + 0.042*"class" + 0.025*"answer" + 0.024*"dictionary" + 0.020*"memo" + 0.018*"value" + 0.018*"function"
INFO: topic diff=0.170809, rho=0.377964
DEBUG: bound: at document #0
INFO: -4.767 per-word bound, 27.2 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.20536315, 0.034471437, 0.050924156, 0.033867117, 0.25085688, 0.022973131]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.023): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"reference" + 0.007*"list" + 0.007*"module" + 0.007*"instance" + 0.007*"shallow"
INFO: topic #3 (0.034): 0.050*"hook" + 0.050*"customize" + 0.048*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"df"
INFO: topic #2 (0.051): 0.068*"deep" + 0.059*"method" + 0.043*"change" + 0.035*"interior" + 0.035*"immutable" + 0.035*"mutable" + 0.026*"tuple" + 0.026*"container" + 0.026*"recursive" + 0.026*"attribute"
INFO: topic #0 (0.205): 0.101*"copy" + 0.086*"object" + 0.077*"new" + 0.073*"list" + 0.050*"reference" + 0.046*"original" + 0.037*"instance" + 0.035*"memory" + 0.023*"shallow" + 0.022*"case"
INFO: topic #4 (0.251): 0.242*"copy" + 0.170*"object" + 0.079*"deepcopy" + 0.067*"shallow" + 0.054*"class" + 0.023*"answer" + 0.022*"dictionary" + 0.019*"value" + 0.019*"function" + 0.016*"memo"
INFO: topic diff=0.158743, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 28.029019928204047
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -3.532879887533282
DEBUG: bound: at document #0
INFO: -5.228 per-word bound, 37.5 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1795826, 0.03223244, 0.046048097, 0.0317058, 0.22938472, 0.021977685]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.022): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"reference" + 0.007*"list" + 0.007*"module" + 0.007*"instance" + 0.007*"shallow"
INFO: topic #3 (0.032): 0.036*"hook" + 0.036*"customize" + 0.035*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"df"
INFO: topic #2 (0.046): 0.063*"deep" + 0.055*"method" + 0.040*"change" + 0.032*"interior" + 0.032*"immutable" + 0.032*"mutable" + 0.025*"tuple" + 0.025*"container" + 0.025*"recursive" + 0.025*"attribute"
INFO: topic #0 (0.180): 0.079*"object" + 0.076*"copy" + 0.065*"new" + 0.058*"list" + 0.053*"reference" + 0.040*"instance" + 0.033*"original" + 0.031*"memory" + 0.031*"df" + 0.031*"name"
INFO: topic #4 (0.229): 0.191*"copy" + 0.141*"object" + 0.086*"deepcopy" + 0.051*"shallow" + 0.042*"class" + 0.025*"answer" + 0.024*"dictionary" + 0.020*"memo" + 0.018*"value" + 0.018*"function"
INFO: topic diff=0.148472, rho=0.353553
DEBUG: bound: at document #0
INFO: -4.756 per-word bound, 27.0 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.20359494, 0.033042893, 0.05039142, 0.032425825, 0.24832422, 0.021197723]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.021): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"reference" + 0.007*"list" + 0.007*"module" + 0.007*"instance" + 0.007*"shallow"
INFO: topic #3 (0.032): 0.050*"hook" + 0.050*"customize" + 0.049*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"df"
INFO: topic #2 (0.050): 0.068*"deep" + 0.059*"method" + 0.043*"change" + 0.035*"interior" + 0.035*"immutable" + 0.035*"mutable" + 0.026*"tuple" + 0.026*"container" + 0.026*"recursive" + 0.026*"attribute"
INFO: topic #0 (0.204): 0.099*"copy" + 0.084*"object" + 0.077*"new" + 0.072*"list" + 0.050*"reference" + 0.046*"original" + 0.037*"instance" + 0.035*"memory" + 0.022*"shallow" + 0.022*"case"
INFO: topic #4 (0.248): 0.241*"copy" + 0.170*"object" + 0.080*"deepcopy" + 0.067*"shallow" + 0.054*"class" + 0.023*"answer" + 0.022*"dictionary" + 0.019*"value" + 0.019*"function" + 0.017*"memo"
INFO: topic diff=0.142367, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 27.958887888059387
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -3.532879887533282
DEBUG: bound: at document #0
INFO: -5.210 per-word bound, 37.0 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17933962, 0.031087074, 0.0458526, 0.030542258, 0.22812079, 0.020392006]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.020): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"reference" + 0.007*"list" + 0.007*"module" + 0.007*"instance" + 0.007*"shallow"
INFO: topic #3 (0.031): 0.037*"customize" + 0.037*"hook" + 0.036*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"df"
INFO: topic #2 (0.046): 0.063*"deep" + 0.055*"method" + 0.040*"change" + 0.032*"interior" + 0.032*"immutable" + 0.032*"mutable" + 0.025*"tuple" + 0.025*"container" + 0.025*"recursive" + 0.025*"attribute"
INFO: topic #0 (0.179): 0.079*"object" + 0.076*"copy" + 0.066*"new" + 0.059*"list" + 0.053*"reference" + 0.040*"instance" + 0.034*"original" + 0.031*"memory" + 0.030*"df" + 0.030*"name"
INFO: topic #4 (0.228): 0.193*"copy" + 0.143*"object" + 0.086*"deepcopy" + 0.052*"shallow" + 0.043*"class" + 0.025*"answer" + 0.024*"dictionary" + 0.020*"memo" + 0.018*"value" + 0.018*"function"
INFO: topic diff=0.134784, rho=0.333333
DEBUG: bound: at document #0
INFO: -4.748 per-word bound, 26.9 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.20179757, 0.03186618, 0.0499271, 0.031241825, 0.24580039, 0.019756528]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.020): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"reference" + 0.007*"list" + 0.007*"module" + 0.007*"instance" + 0.007*"shallow"
INFO: topic #3 (0.031): 0.049*"customize" + 0.049*"hook" + 0.049*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"dictionary"
INFO: topic #2 (0.050): 0.068*"deep" + 0.059*"method" + 0.043*"change" + 0.035*"interior" + 0.035*"immutable" + 0.035*"mutable" + 0.026*"container" + 0.026*"tuple" + 0.026*"recursive" + 0.026*"attribute"
INFO: topic #0 (0.202): 0.098*"copy" + 0.083*"object" + 0.077*"new" + 0.072*"list" + 0.050*"reference" + 0.046*"original" + 0.037*"instance" + 0.035*"memory" + 0.022*"case" + 0.022*"datum"
INFO: topic #4 (0.246): 0.240*"copy" + 0.170*"object" + 0.080*"deepcopy" + 0.067*"shallow" + 0.053*"class" + 0.023*"answer" + 0.022*"dictionary" + 0.019*"value" + 0.019*"function" + 0.017*"memo"
INFO: topic diff=0.130821, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 27.911462227947837
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -3.4435760330939438
DEBUG: bound: at document #0
INFO: -5.196 per-word bound, 36.6 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17891245, 0.030127704, 0.045668975, 0.0295707, 0.22676237, 0.019087642]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.019): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"module" + 0.007*"list" + 0.007*"reference" + 0.007*"instance" + 0.007*"df"
INFO: topic #3 (0.030): 0.037*"customize" + 0.037*"hook" + 0.037*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"dictionary"
INFO: topic #2 (0.046): 0.063*"deep" + 0.056*"method" + 0.040*"change" + 0.033*"interior" + 0.033*"immutable" + 0.033*"mutable" + 0.025*"tuple" + 0.025*"container" + 0.025*"recursive" + 0.025*"attribute"
INFO: topic #0 (0.179): 0.078*"object" + 0.076*"copy" + 0.066*"new" + 0.059*"list" + 0.053*"reference" + 0.040*"instance" + 0.034*"original" + 0.031*"memory" + 0.030*"name" + 0.030*"df"
INFO: topic #4 (0.227): 0.195*"copy" + 0.144*"object" + 0.085*"deepcopy" + 0.053*"shallow" + 0.043*"class" + 0.025*"answer" + 0.024*"dictionary" + 0.020*"memo" + 0.018*"value" + 0.018*"function"
INFO: topic diff=0.125050, rho=0.316228
DEBUG: bound: at document #0
INFO: -4.742 per-word bound, 26.8 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.20005898, 0.030876447, 0.049516678, 0.030248184, 0.24345319, 0.018557644]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.019): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"reference" + 0.007*"list" + 0.007*"instance" + 0.007*"module" + 0.007*"shallow"
INFO: topic #3 (0.030): 0.049*"customize" + 0.049*"hook" + 0.048*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"name" + 0.006*"reference" + 0.006*"dictionary"
INFO: topic #2 (0.050): 0.068*"deep" + 0.059*"method" + 0.043*"change" + 0.035*"interior" + 0.035*"immutable" + 0.035*"mutable" + 0.026*"tuple" + 0.026*"container" + 0.026*"recursive" + 0.026*"attribute"
INFO: topic #0 (0.200): 0.097*"copy" + 0.082*"object" + 0.076*"new" + 0.071*"list" + 0.050*"reference" + 0.045*"original" + 0.037*"instance" + 0.035*"memory" + 0.022*"name" + 0.022*"df"
INFO: topic #4 (0.243): 0.239*"copy" + 0.170*"object" + 0.080*"deepcopy" + 0.067*"shallow" + 0.053*"class" + 0.024*"answer" + 0.022*"dictionary" + 0.019*"value" + 0.019*"function" + 0.017*"memo"
INFO: topic diff=0.121704, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 27.878317368390622
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -3.6547352171922207
DEBUG: bound: at document #0
INFO: -5.184 per-word bound, 36.4 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17839485, 0.029309938, 0.045496892, 0.028744686, 0.22544576, 0.017991228]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.018): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"shallow" + 0.007*"list" + 0.007*"reference" + 0.007*"module" + 0.007*"instance"
INFO: topic #3 (0.029): 0.037*"hook" + 0.037*"customize" + 0.037*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"variable"
INFO: topic #2 (0.045): 0.064*"deep" + 0.056*"method" + 0.040*"change" + 0.033*"interior" + 0.033*"immutable" + 0.033*"mutable" + 0.025*"tuple" + 0.025*"container" + 0.025*"recursive" + 0.025*"attribute"
INFO: topic #0 (0.178): 0.078*"object" + 0.076*"copy" + 0.066*"new" + 0.059*"list" + 0.053*"reference" + 0.040*"instance" + 0.034*"original" + 0.031*"memory" + 0.030*"df" + 0.030*"name"
INFO: topic #4 (0.225): 0.196*"copy" + 0.145*"object" + 0.085*"deepcopy" + 0.054*"shallow" + 0.043*"class" + 0.025*"answer" + 0.024*"dictionary" + 0.020*"memo" + 0.018*"value" + 0.018*"function"
INFO: topic diff=0.117295, rho=0.301511
DEBUG: bound: at document #0
INFO: -4.737 per-word bound, 26.7 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.19841588, 0.030029966, 0.04914979, 0.02939999, 0.24129313, 0.017540868]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.018): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"module" + 0.007*"list" + 0.007*"reference" + 0.007*"instance" + 0.007*"way"
INFO: topic #3 (0.029): 0.048*"hook" + 0.048*"customize" + 0.048*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"dictionary"
INFO: topic #2 (0.049): 0.068*"deep" + 0.059*"method" + 0.043*"change" + 0.034*"interior" + 0.034*"immutable" + 0.034*"mutable" + 0.026*"tuple" + 0.026*"container" + 0.026*"recursive" + 0.026*"attribute"
INFO: topic #0 (0.198): 0.096*"copy" + 0.081*"object" + 0.076*"new" + 0.071*"list" + 0.051*"reference" + 0.045*"original" + 0.038*"instance" + 0.035*"memory" + 0.022*"name" + 0.022*"df"
INFO: topic #4 (0.241): 0.237*"copy" + 0.169*"object" + 0.080*"deepcopy" + 0.067*"shallow" + 0.052*"class" + 0.024*"answer" + 0.022*"dictionary" + 0.019*"value" + 0.019*"function" + 0.017*"memo"
INFO: topic diff=0.114325, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 27.853052615862943
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -3.8538847999888155
DEBUG: bound: at document #0
INFO: -5.174 per-word bound, 36.1 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17784098, 0.028602844, 0.045335572, 0.028032036, 0.22419722, 0.017053502]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.017): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"name" + 0.007*"list" + 0.007*"instance" + 0.007*"module" + 0.007*"reference" + 0.007*"dictionary"
INFO: topic #3 (0.028): 0.037*"hook" + 0.037*"customize" + 0.037*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"reference" + 0.006*"name" + 0.006*"instance"
INFO: topic #2 (0.045): 0.064*"deep" + 0.056*"method" + 0.040*"change" + 0.033*"interior" + 0.033*"immutable" + 0.033*"mutable" + 0.025*"tuple" + 0.025*"container" + 0.025*"recursive" + 0.025*"attribute"
INFO: topic #0 (0.178): 0.077*"object" + 0.076*"copy" + 0.067*"new" + 0.059*"list" + 0.053*"reference" + 0.040*"instance" + 0.035*"original" + 0.031*"memory" + 0.030*"name" + 0.030*"df"
INFO: topic #4 (0.224): 0.197*"copy" + 0.146*"object" + 0.085*"deepcopy" + 0.054*"shallow" + 0.043*"class" + 0.025*"answer" + 0.024*"dictionary" + 0.020*"memo" + 0.018*"value" + 0.018*"function"
INFO: topic diff=0.110858, rho=0.288675
DEBUG: bound: at document #0
INFO: -4.733 per-word bound, 26.6 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.19689111, 0.029296294, 0.048819356, 0.028666042, 0.23935004, 0.016665023]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #5 (0.017): 0.007*"object" + 0.007*"copy" + 0.007*"foo" + 0.007*"deepcopy" + 0.007*"reference" + 0.007*"instance" + 0.007*"name" + 0.007*"shallow" + 0.007*"module" + 0.007*"df"
INFO: topic #3 (0.029): 0.048*"customize" + 0.048*"hook" + 0.048*"method" + 0.006*"deepcopy" + 0.006*"object" + 0.006*"copy" + 0.006*"foo" + 0.006*"df" + 0.006*"name" + 0.006*"reference"
INFO: topic #2 (0.049): 0.068*"deep" + 0.059*"method" + 0.043*"change" + 0.034*"interior" + 0.034*"immutable" + 0.034*"mutable" + 0.026*"tuple" + 0.026*"container" + 0.026*"recursive" + 0.026*"attribute"
INFO: topic #0 (0.197): 0.095*"copy" + 0.081*"object" + 0.076*"new" + 0.071*"list" + 0.051*"reference" + 0.045*"original" + 0.038*"instance" + 0.035*"memory" + 0.022*"name" + 0.022*"df"
INFO: topic #4 (0.239): 0.236*"copy" + 0.169*"object" + 0.080*"deepcopy" + 0.066*"shallow" + 0.052*"class" + 0.024*"answer" + 0.022*"dictionary" + 0.019*"value" + 0.019*"function" + 0.017*"memo"
INFO: topic diff=0.108203, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 27.832108865321835
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=6, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -3.953893735012876
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=147, num_topics=6, decay=0.5, chunksize=5> in 0.16s', 'datetime': '2023-04-25T06:36:24.494482', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'auto-adjust_models/models/10/model_t6.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-25T06:36:24.494628', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'auto-adjust_models/models/10/model_t6.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/10/model_t6.state
DEBUG: {'uri': 'auto-adjust_models/models/10/model_t6.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'auto-adjust_models/models/10/model_t6', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['id2word', 'dispatcher', 'state'], 'datetime': '2023-04-25T06:36:24.497153', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to auto-adjust_models/models/10/model_t6.expElogbeta.npy
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
INFO: not storing attribute state
DEBUG: {'uri': 'auto-adjust_models/models/10/model_t6', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/10/model_t6
