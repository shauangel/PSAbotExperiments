INFO: ---Start Analyzing---
INFO: ---Train for 4 Topics---
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<327 unique tokens: ["'", '+', '2.x', '3.x', '=']...> from 10 documents (total 987 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<327 unique tokens: ["\'", \'+\', \'2.x\', \'3.x\', \'=\']...> from 10 documents (total 987 corpus positions)', 'datetime': '2023-04-25T06:36:14.903131', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.25, 0.25, 0.25, 0.25]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 4 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -6.725 per-word bound, 105.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13503268, 0.1025725, 0.096693024, 0.1364559]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.135): 0.108*"variable" + 0.097*"function" + 0.065*"global" + 0.044*"local" + 0.033*"access" + 0.023*"value" + 0.023*"scope" + 0.023*"inside" + 0.012*"good" + 0.012*"error"
INFO: topic #1 (0.103): 0.062*"variable" + 0.033*"global" + 0.032*"local" + 0.031*"scope" + 0.029*"function" + 0.024*"name" + 0.024*"c" + 0.021*"assignment" + 0.021*"=" + 0.020*"line"
INFO: topic #2 (0.097): 0.042*"local" + 0.041*"global" + 0.040*"variable" + 0.033*"scope" + 0.024*"name" + 0.023*"function" + 0.022*"num" + 0.021*"c" + 0.020*"line" + 0.018*"assignment"
INFO: topic #3 (0.136): 0.050*"program" + 0.038*"variable" + 0.038*"value" + 0.038*"loop" + 0.026*"class" + 0.026*"definition" + 0.014*"scope" + 0.014*"test" + 0.014*"object" + 0.014*"testing"
INFO: topic diff=2.275022, rho=1.000000
DEBUG: bound: at document #0
INFO: -7.390 per-word bound, 167.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17809372, 0.084631994, 0.11312407, 0.11998576]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.178): 0.108*"variable" + 0.089*"global" + 0.083*"function" + 0.049*"local" + 0.033*"var1" + 0.033*"f" + 0.024*"inside" + 0.022*"value" + 0.021*"scope" + 0.015*"work"
INFO: topic #1 (0.085): 0.056*"variable" + 0.033*"local" + 0.027*"global" + 0.027*"scope" + 0.026*"function" + 0.023*"assignment" + 0.022*"name" + 0.018*"c" + 0.016*"=" + 0.016*"case"
INFO: topic #2 (0.113): 0.037*"global" + 0.037*"local" + 0.034*"variable" + 0.029*"scope" + 0.024*"name" + 0.021*"line" + 0.020*"code" + 0.017*"function" + 0.015*"assignment" + 0.015*"reference"
INFO: topic #3 (0.120): 0.045*"value" + 0.021*"program" + 0.019*"variable" + 0.016*"other" + 0.016*"loop" + 0.015*"print" + 0.014*"code" + 0.013*"point" + 0.011*"class" + 0.011*"definition"
INFO: topic diff=0.798956, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 44.50228664726516
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=4, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -1.0968473139259307
DEBUG: bound: at document #0
INFO: -5.515 per-word bound, 45.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13179342, 0.07516615, 0.07275151, 0.106487006]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.132): 0.108*"variable" + 0.088*"function" + 0.080*"global" + 0.047*"local" + 0.023*"inside" + 0.022*"value" + 0.021*"scope" + 0.021*"f" + 0.021*"var1" + 0.017*"access"
INFO: topic #1 (0.075): 0.056*"variable" + 0.037*"local" + 0.036*"global" + 0.032*"scope" + 0.028*"function" + 0.025*"name" + 0.023*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (0.073): 0.030*"global" + 0.029*"local" + 0.027*"variable" + 0.023*"scope" + 0.019*"name" + 0.017*"line" + 0.017*"code" + 0.014*"function" + 0.012*"assignment" + 0.012*"reference"
INFO: topic #3 (0.106): 0.041*"value" + 0.037*"program" + 0.030*"variable" + 0.029*"loop" + 0.020*"class" + 0.020*"definition" + 0.015*"other" + 0.014*"print" + 0.014*"code" + 0.013*"point"
INFO: topic diff=0.372298, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.779 per-word bound, 54.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.15789476, 0.07632683, 0.07551931, 0.088272795]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.158): 0.108*"variable" + 0.089*"global" + 0.080*"function" + 0.051*"local" + 0.034*"f" + 0.034*"var1" + 0.023*"scope" + 0.022*"inside" + 0.022*"value" + 0.015*"work"
INFO: topic #1 (0.076): 0.053*"variable" + 0.036*"local" + 0.032*"global" + 0.030*"scope" + 0.026*"function" + 0.024*"name" + 0.022*"assignment" + 0.020*"c" + 0.019*"line" + 0.017*"num"
INFO: topic #2 (0.076): 0.024*"code" + 0.023*"local" + 0.023*"global" + 0.023*"name" + 0.022*"variable" + 0.020*"scope" + 0.019*"reference" + 0.018*"time" + 0.018*"module" + 0.018*"statement"
INFO: topic #3 (0.088): 0.047*"value" + 0.023*"program" + 0.019*"variable" + 0.018*"loop" + 0.013*"code" + 0.013*"class" + 0.013*"definition" + 0.012*"condition" + 0.012*"comment" + 0.012*"long"
INFO: topic diff=0.331730, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 40.13170977112577
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=4, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -2.5687258699211375
DEBUG: bound: at document #0
INFO: -5.343 per-word bound, 40.6 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.12213476, 0.06866115, 0.057857323, 0.08394472]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.122): 0.108*"variable" + 0.086*"function" + 0.081*"global" + 0.049*"local" + 0.023*"var1" + 0.023*"f" + 0.023*"scope" + 0.022*"inside" + 0.022*"value" + 0.016*"access"
INFO: topic #1 (0.069): 0.055*"variable" + 0.037*"local" + 0.036*"global" + 0.032*"scope" + 0.027*"function" + 0.025*"name" + 0.023*"c" + 0.021*"assignment" + 0.021*"line" + 0.020*"num"
INFO: topic #2 (0.058): 0.018*"code" + 0.018*"local" + 0.018*"global" + 0.017*"name" + 0.017*"variable" + 0.015*"scope" + 0.014*"reference" + 0.014*"time" + 0.014*"module" + 0.014*"statement"
INFO: topic #3 (0.084): 0.042*"value" + 0.037*"program" + 0.029*"variable" + 0.028*"loop" + 0.019*"class" + 0.019*"definition" + 0.013*"code" + 0.012*"other" + 0.012*"print" + 0.011*"point"
INFO: topic diff=0.248834, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.670 per-word bound, 50.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.143769, 0.06998693, 0.061064385, 0.07451667]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.144): 0.108*"variable" + 0.089*"global" + 0.079*"function" + 0.052*"local" + 0.033*"f" + 0.033*"var1" + 0.024*"scope" + 0.022*"inside" + 0.021*"value" + 0.015*"work"
INFO: topic #1 (0.070): 0.053*"variable" + 0.037*"local" + 0.033*"global" + 0.030*"scope" + 0.026*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.018*"num"
INFO: topic #2 (0.061): 0.026*"code" + 0.023*"name" + 0.021*"reference" + 0.021*"time" + 0.020*"module" + 0.020*"statement" + 0.019*"problem" + 0.018*"print" + 0.014*"line" + 0.013*"local"
INFO: topic #3 (0.075): 0.048*"value" + 0.024*"program" + 0.019*"variable" + 0.019*"loop" + 0.013*"class" + 0.013*"definition" + 0.013*"code" + 0.012*"comment" + 0.012*"bit" + 0.012*"define"
INFO: topic diff=0.250225, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 39.51817214154252
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=4, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -2.7344053866195055
DEBUG: bound: at document #0
INFO: -5.310 per-word bound, 39.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.11526397, 0.063763626, 0.049877815, 0.072675854]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.115): 0.108*"variable" + 0.084*"function" + 0.082*"global" + 0.050*"local" + 0.024*"f" + 0.024*"var1" + 0.024*"scope" + 0.022*"inside" + 0.022*"value" + 0.015*"access"
INFO: topic #1 (0.064): 0.055*"variable" + 0.037*"local" + 0.036*"global" + 0.032*"scope" + 0.027*"function" + 0.025*"name" + 0.023*"c" + 0.021*"assignment" + 0.021*"line" + 0.020*"num"
INFO: topic #2 (0.050): 0.020*"code" + 0.017*"name" + 0.016*"reference" + 0.015*"time" + 0.015*"module" + 0.015*"statement" + 0.014*"problem" + 0.014*"print" + 0.011*"line" + 0.010*"local"
INFO: topic #3 (0.073): 0.043*"value" + 0.037*"program" + 0.028*"variable" + 0.028*"loop" + 0.019*"class" + 0.019*"definition" + 0.013*"code" + 0.011*"other" + 0.011*"print" + 0.011*"point"
INFO: topic diff=0.204586, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.647 per-word bound, 50.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13391022, 0.06516079, 0.052924167, 0.066550076]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.134): 0.108*"variable" + 0.088*"global" + 0.079*"function" + 0.053*"local" + 0.033*"var1" + 0.033*"f" + 0.025*"scope" + 0.021*"inside" + 0.021*"value" + 0.015*"work"
INFO: topic #1 (0.065): 0.053*"variable" + 0.037*"local" + 0.034*"global" + 0.031*"scope" + 0.026*"function" + 0.024*"name" + 0.021*"assignment" + 0.021*"c" + 0.020*"line" + 0.018*"num"
INFO: topic #2 (0.053): 0.028*"code" + 0.023*"name" + 0.022*"reference" + 0.021*"time" + 0.021*"module" + 0.021*"statement" + 0.019*"print" + 0.018*"problem" + 0.013*"=" + 0.012*"line"
INFO: topic #3 (0.067): 0.049*"value" + 0.025*"program" + 0.020*"variable" + 0.019*"loop" + 0.014*"class" + 0.014*"definition" + 0.013*"code" + 0.012*"bit" + 0.012*"comment" + 0.012*"execute"
INFO: topic diff=0.207400, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 39.39711105965324
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=4, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -2.769717095845344
DEBUG: bound: at document #0
INFO: -5.298 per-word bound, 39.4 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.11017721, 0.05999068, 0.044796426, 0.0657317]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.110): 0.108*"variable" + 0.083*"function" + 0.082*"global" + 0.051*"local" + 0.025*"scope" + 0.024*"var1" + 0.024*"f" + 0.022*"inside" + 0.022*"value" + 0.015*"access"
INFO: topic #1 (0.060): 0.055*"variable" + 0.037*"local" + 0.036*"global" + 0.032*"scope" + 0.027*"function" + 0.025*"name" + 0.023*"c" + 0.021*"assignment" + 0.021*"line" + 0.020*"num"
INFO: topic #2 (0.045): 0.020*"code" + 0.017*"name" + 0.016*"reference" + 0.016*"time" + 0.016*"module" + 0.016*"statement" + 0.014*"print" + 0.014*"problem" + 0.010*"=" + 0.010*"line"
INFO: topic #3 (0.066): 0.044*"value" + 0.036*"program" + 0.028*"variable" + 0.028*"loop" + 0.019*"class" + 0.019*"definition" + 0.013*"code" + 0.011*"other" + 0.011*"print" + 0.011*"point"
INFO: topic diff=0.183365, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.638 per-word bound, 49.8 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.12669052, 0.061372664, 0.047604132, 0.061275605]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.127): 0.108*"variable" + 0.088*"global" + 0.078*"function" + 0.053*"local" + 0.032*"f" + 0.032*"var1" + 0.026*"scope" + 0.021*"value" + 0.021*"inside" + 0.015*"work"
INFO: topic #1 (0.061): 0.053*"variable" + 0.037*"local" + 0.034*"global" + 0.031*"scope" + 0.026*"function" + 0.024*"name" + 0.021*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic #2 (0.048): 0.028*"code" + 0.023*"name" + 0.022*"reference" + 0.022*"time" + 0.022*"module" + 0.022*"statement" + 0.018*"print" + 0.016*"problem" + 0.013*"=" + 0.012*"side"
INFO: topic #3 (0.061): 0.049*"value" + 0.026*"program" + 0.020*"variable" + 0.020*"loop" + 0.014*"class" + 0.014*"definition" + 0.013*"code" + 0.011*"execute" + 0.011*"define" + 0.011*"long"
INFO: topic diff=0.181360, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 39.34772429166733
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=4, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -2.7954331331374296
DEBUG: bound: at document #0
INFO: -5.292 per-word bound, 39.2 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.10626014, 0.056982942, 0.041237768, 0.06096496]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.106): 0.108*"variable" + 0.083*"function" + 0.082*"global" + 0.051*"local" + 0.025*"scope" + 0.025*"f" + 0.025*"var1" + 0.021*"value" + 0.021*"inside" + 0.014*"work"
INFO: topic #1 (0.057): 0.054*"variable" + 0.037*"local" + 0.036*"global" + 0.032*"scope" + 0.027*"function" + 0.025*"name" + 0.023*"c" + 0.021*"assignment" + 0.021*"line" + 0.020*"num"
INFO: topic #2 (0.041): 0.021*"code" + 0.017*"name" + 0.017*"reference" + 0.017*"time" + 0.017*"module" + 0.016*"statement" + 0.014*"print" + 0.013*"problem" + 0.010*"=" + 0.010*"side"
INFO: topic #3 (0.061): 0.044*"value" + 0.036*"program" + 0.028*"variable" + 0.027*"loop" + 0.019*"class" + 0.019*"definition" + 0.013*"code" + 0.010*"other" + 0.010*"print" + 0.010*"point"
INFO: topic diff=0.167959, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.617 per-word bound, 49.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.12061171, 0.058981173, 0.040432774, 0.05729723]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.121): 0.105*"variable" + 0.086*"global" + 0.077*"function" + 0.052*"local" + 0.032*"f" + 0.032*"var1" + 0.024*"scope" + 0.021*"inside" + 0.021*"value" + 0.015*"work"
INFO: topic #1 (0.059): 0.053*"variable" + 0.037*"local" + 0.034*"global" + 0.031*"scope" + 0.026*"function" + 0.026*"name" + 0.021*"assignment" + 0.021*"c" + 0.020*"line" + 0.018*"num"
INFO: topic #2 (0.040): 0.018*"code" + 0.014*"=" + 0.014*"side" + 0.014*"default" + 0.014*"table" + 0.014*"solution" + 0.014*"note" + 0.012*"name" + 0.012*"reference" + 0.012*"time"
INFO: topic #3 (0.057): 0.049*"value" + 0.026*"program" + 0.020*"variable" + 0.020*"loop" + 0.014*"class" + 0.014*"definition" + 0.013*"code" + 0.011*"define" + 0.011*"instance" + 0.011*"long"
INFO: topic diff=0.158090, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 39.039045663211525
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=4, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -2.787952017137414
DEBUG: bound: at document #0
INFO: -5.282 per-word bound, 38.9 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.10257074, 0.05499209, 0.035948634, 0.057236437]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.103): 0.105*"variable" + 0.082*"function" + 0.081*"global" + 0.050*"local" + 0.025*"var1" + 0.025*"f" + 0.024*"scope" + 0.021*"inside" + 0.021*"value" + 0.014*"work"
INFO: topic #1 (0.055): 0.055*"variable" + 0.037*"local" + 0.036*"global" + 0.032*"scope" + 0.027*"function" + 0.026*"name" + 0.022*"c" + 0.021*"assignment" + 0.021*"line" + 0.020*"num"
INFO: topic #2 (0.036): 0.014*"code" + 0.011*"=" + 0.011*"side" + 0.011*"default" + 0.011*"table" + 0.011*"solution" + 0.011*"note" + 0.010*"name" + 0.009*"reference" + 0.009*"time"
INFO: topic #3 (0.057): 0.045*"value" + 0.036*"program" + 0.027*"variable" + 0.027*"loop" + 0.019*"class" + 0.019*"definition" + 0.013*"code" + 0.010*"other" + 0.010*"print" + 0.010*"point"
INFO: topic diff=0.150581, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.567 per-word bound, 47.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.11559988, 0.056793377, 0.035606276, 0.054244988]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.116): 0.103*"variable" + 0.085*"global" + 0.076*"function" + 0.051*"local" + 0.031*"var1" + 0.031*"f" + 0.024*"scope" + 0.021*"inside" + 0.021*"value" + 0.014*"work"
INFO: topic #1 (0.057): 0.053*"variable" + 0.037*"local" + 0.034*"global" + 0.031*"scope" + 0.027*"name" + 0.026*"function" + 0.021*"assignment" + 0.021*"c" + 0.020*"line" + 0.018*"num"
INFO: topic #2 (0.036): 0.015*"=" + 0.015*"side" + 0.015*"default" + 0.015*"table" + 0.014*"solution" + 0.014*"note" + 0.013*"code" + 0.007*"name" + 0.007*"reference" + 0.007*"time"
INFO: topic #3 (0.054): 0.049*"value" + 0.027*"program" + 0.021*"variable" + 0.021*"loop" + 0.014*"class" + 0.014*"definition" + 0.014*"code" + 0.011*"execute" + 0.011*"instance" + 0.011*"long"
INFO: topic diff=0.141256, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 38.875876640047444
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=4, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -2.7601399007832645
DEBUG: bound: at document #0
INFO: -5.278 per-word bound, 38.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.09945629, 0.05317196, 0.03220901, 0.054335546]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.099): 0.104*"variable" + 0.081*"function" + 0.081*"global" + 0.050*"local" + 0.025*"var1" + 0.025*"f" + 0.024*"scope" + 0.021*"inside" + 0.021*"value" + 0.014*"work"
INFO: topic #1 (0.053): 0.055*"variable" + 0.037*"local" + 0.036*"global" + 0.032*"scope" + 0.027*"function" + 0.026*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (0.032): 0.012*"=" + 0.011*"side" + 0.011*"default" + 0.011*"table" + 0.011*"solution" + 0.011*"note" + 0.010*"code" + 0.006*"name" + 0.006*"reference" + 0.006*"time"
INFO: topic #3 (0.054): 0.045*"value" + 0.036*"program" + 0.027*"variable" + 0.027*"loop" + 0.019*"class" + 0.019*"definition" + 0.014*"code" + 0.010*"other" + 0.010*"print" + 0.010*"point"
INFO: topic diff=0.137507, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.539 per-word bound, 46.5 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.11142083, 0.0548074, 0.03211046, 0.051816836]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.111): 0.102*"variable" + 0.084*"global" + 0.076*"function" + 0.051*"local" + 0.031*"var1" + 0.031*"f" + 0.024*"scope" + 0.021*"inside" + 0.020*"value" + 0.014*"work"
INFO: topic #1 (0.055): 0.053*"variable" + 0.037*"local" + 0.034*"global" + 0.031*"scope" + 0.027*"name" + 0.026*"function" + 0.021*"assignment" + 0.021*"c" + 0.019*"line" + 0.018*"num"
INFO: topic #2 (0.032): 0.015*"=" + 0.015*"side" + 0.015*"default" + 0.015*"table" + 0.015*"solution" + 0.015*"note" + 0.009*"code" + 0.005*"name" + 0.005*"reference" + 0.005*"time"
INFO: topic #3 (0.052): 0.049*"value" + 0.027*"program" + 0.021*"variable" + 0.021*"loop" + 0.015*"code" + 0.015*"class" + 0.015*"definition" + 0.011*"long" + 0.011*"execute" + 0.011*"instance"
INFO: topic diff=0.132694, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 38.78993170149716
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=4, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -2.771692353792597
DEBUG: bound: at document #0
INFO: -5.277 per-word bound, 38.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.096798226, 0.051513255, 0.029408691, 0.052002687]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.097): 0.103*"variable" + 0.080*"global" + 0.080*"function" + 0.049*"local" + 0.025*"f" + 0.025*"var1" + 0.023*"scope" + 0.021*"inside" + 0.021*"value" + 0.014*"work"
INFO: topic #1 (0.052): 0.054*"variable" + 0.037*"local" + 0.036*"global" + 0.032*"scope" + 0.027*"function" + 0.026*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (0.029): 0.012*"=" + 0.012*"side" + 0.012*"default" + 0.012*"table" + 0.012*"solution" + 0.012*"note" + 0.007*"code" + 0.004*"name" + 0.004*"reference" + 0.004*"time"
INFO: topic #3 (0.052): 0.045*"value" + 0.035*"program" + 0.027*"variable" + 0.027*"loop" + 0.019*"class" + 0.019*"definition" + 0.014*"code" + 0.010*"other" + 0.010*"print" + 0.010*"point"
INFO: topic diff=0.126987, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.517 per-word bound, 45.8 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.107881576, 0.053003673, 0.029448856, 0.049829803]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.108): 0.102*"variable" + 0.083*"global" + 0.075*"function" + 0.051*"local" + 0.030*"var1" + 0.030*"f" + 0.024*"scope" + 0.020*"inside" + 0.020*"value" + 0.014*"work"
INFO: topic #1 (0.053): 0.053*"variable" + 0.037*"local" + 0.034*"global" + 0.031*"scope" + 0.027*"name" + 0.026*"function" + 0.021*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"num"
INFO: topic #2 (0.029): 0.015*"=" + 0.015*"side" + 0.015*"default" + 0.015*"table" + 0.015*"solution" + 0.015*"note" + 0.007*"code" + 0.004*"name" + 0.004*"reference" + 0.004*"time"
INFO: topic #3 (0.050): 0.049*"value" + 0.027*"program" + 0.021*"variable" + 0.021*"loop" + 0.016*"code" + 0.015*"class" + 0.015*"definition" + 0.011*"bit" + 0.011*"comment" + 0.011*"instance"
INFO: topic diff=0.124665, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 38.723964292670246
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=4, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -2.771692353792597
DEBUG: bound: at document #0
INFO: -5.275 per-word bound, 38.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.09449814, 0.04999788, 0.027224334, 0.050077114]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.094): 0.103*"variable" + 0.080*"global" + 0.079*"function" + 0.049*"local" + 0.025*"var1" + 0.025*"f" + 0.024*"scope" + 0.021*"inside" + 0.021*"value" + 0.014*"work"
INFO: topic #1 (0.050): 0.054*"variable" + 0.037*"local" + 0.036*"global" + 0.032*"scope" + 0.027*"function" + 0.026*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (0.027): 0.012*"=" + 0.012*"side" + 0.012*"default" + 0.012*"table" + 0.012*"solution" + 0.012*"note" + 0.006*"code" + 0.004*"name" + 0.004*"reference" + 0.004*"time"
INFO: topic #3 (0.050): 0.045*"value" + 0.035*"program" + 0.027*"variable" + 0.027*"loop" + 0.019*"class" + 0.019*"definition" + 0.015*"code" + 0.010*"other" + 0.010*"print" + 0.010*"point"
INFO: topic diff=0.118481, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.498 per-word bound, 45.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.10483481, 0.051339123, 0.027346937, 0.048165232]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.105): 0.101*"variable" + 0.083*"global" + 0.074*"function" + 0.050*"local" + 0.030*"var1" + 0.030*"f" + 0.024*"scope" + 0.020*"value" + 0.020*"inside" + 0.014*"work"
INFO: topic #1 (0.051): 0.053*"variable" + 0.037*"local" + 0.034*"global" + 0.031*"scope" + 0.027*"name" + 0.026*"function" + 0.021*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"num"
INFO: topic #2 (0.027): 0.015*"=" + 0.015*"side" + 0.015*"default" + 0.015*"table" + 0.015*"solution" + 0.015*"note" + 0.005*"code" + 0.003*"name" + 0.003*"reference" + 0.003*"time"
INFO: topic #3 (0.048): 0.049*"value" + 0.028*"program" + 0.021*"variable" + 0.021*"loop" + 0.016*"code" + 0.015*"class" + 0.015*"definition" + 0.011*"instance" + 0.011*"execute" + 0.011*"bit"
INFO: topic diff=0.117715, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 38.58673493297332
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=4, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -2.7743034850661843
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=327, num_topics=4, decay=0.5, chunksize=5> in 0.19s', 'datetime': '2023-04-25T06:36:15.097020', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'auto-adjust_models/models/1/model_t4.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-25T06:36:15.097221', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'auto-adjust_models/models/1/model_t4.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/1/model_t4.state
DEBUG: {'uri': 'auto-adjust_models/models/1/model_t4.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'auto-adjust_models/models/1/model_t4', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['id2word', 'dispatcher', 'state'], 'datetime': '2023-04-25T06:36:15.099948', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to auto-adjust_models/models/1/model_t4.expElogbeta.npy
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
INFO: not storing attribute state
DEBUG: {'uri': 'auto-adjust_models/models/1/model_t4', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved auto-adjust_models/models/1/model_t4
