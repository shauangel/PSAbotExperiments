INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<323 unique tokens: ['answer', 'argument', 'assignment', 'date', 'documentation']...> from 61 documents (total 1399 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<323 unique tokens: ['answer', 'argument', 'assignment', 'date', 'documentation']...> from 61 documents (total 1399 corpus positions)", 'datetime': '2023-05-09T14:36:18.575336', 'gensim': '4.3.1', 'python': '3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 5 topics, 10 passes over the supplied corpus of 61 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.537 per-word bound, 185.7 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 0, at document #5/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.21323007, 0.12795052, 0.09155741, 0.09152285, 0.1590419]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.213): 0.119*"reference" + 0.071*"assignment" + 0.048*"argument" + 0.048*"list" + 0.024*"answer" + 0.024*"faq" + 0.024*"name" + 0.024*"page" + 0.024*"fn(a" + 0.024*"documentation"
INFO: topic #1 (0.128): 0.158*"answer" + 0.003*"reference" + 0.003*"assignment" + 0.003*"instance" + 0.003*"list" + 0.003*"argument" + 0.003*"c++" + 0.003*"function" + 0.003*"figure" + 0.003*"topic"
INFO: topic #2 (0.092): 0.004*"answer" + 0.003*"instance" + 0.003*"reference" + 0.003*"assignment" + 0.003*"c++" + 0.003*"function" + 0.003*"topic" + 0.003*"code" + 0.003*"list" + 0.003*"tutor"
INFO: topic #3 (0.092): 0.004*"answer" + 0.003*"c++" + 0.003*"reference" + 0.003*"instance" + 0.003*"assignment" + 0.003*"list" + 0.003*"argument" + 0.003*"code" + 0.003*"type" + 0.003*"topic"
INFO: topic #4 (0.159): 0.155*"instance" + 0.111*"c++" + 0.089*"function" + 0.067*"type" + 0.045*"object" + 0.044*"copy" + 0.023*"answer" + 0.022*"variable" + 0.022*"modifie" + 0.022*"address"
INFO: topic diff=3.976567, rho=1.000000
DEBUG: bound: at document #0
INFO: -8.513 per-word bound, 365.3 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 0, at document #10/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.23180082, 0.08458544, 0.1343069, 0.084067136, 0.20692864]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.232): 0.176*"reference" + 0.125*"way" + 0.053*"argument" + 0.041*"topic" + 0.037*"assignment" + 0.025*"list" + 0.023*"answer" + 0.018*"variable" + 0.013*"faq" + 0.013*"name"
INFO: topic #1 (0.085): 0.054*"answer" + 0.003*"reference" + 0.003*"assignment" + 0.003*"instance" + 0.003*"list" + 0.003*"argument" + 0.003*"c++" + 0.003*"function" + 0.003*"figure" + 0.003*"topic"
INFO: topic #2 (0.134): 0.057*"solution" + 0.041*"method" + 0.030*"dataclasse" + 0.029*"functionality" + 0.028*"language" + 0.028*"need" + 0.028*"work" + 0.028*"side" + 0.028*"self" + 0.015*"folk"
INFO: topic #3 (0.084): 0.081*"c" + 0.081*"ctype" + 0.081*"int" + 0.081*"integer" + 0.081*"thing" + 0.002*"reference" + 0.002*"answer" + 0.002*"c++" + 0.002*"instance" + 0.002*"assignment"
INFO: topic #4 (0.207): 0.169*"instance" + 0.084*"value" + 0.070*"function" + 0.065*"parameter" + 0.062*"type" + 0.054*"object" + 0.046*"change" + 0.046*"workaround" + 0.042*"variable" + 0.040*"c++"
INFO: topic diff=1.037952, rho=0.707107
DEBUG: bound: at document #0
INFO: -6.104 per-word bound, 68.8 perplexity estimate based on a held-out corpus of 5 documents with 187 words
INFO: PROGRESS: pass 0, at document #15/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.31705615, 0.09385383, 0.17128152, 0.06947863, 0.26967672]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.317): 0.289*"reference" + 0.094*"way" + 0.049*"name" + 0.040*"assignment" + 0.034*"code" + 0.034*"example" + 0.033*"documentation" + 0.027*"variable" + 0.021*"pass" + 0.019*"string"
INFO: topic #1 (0.094): 0.043*"hand" + 0.043*"effect" + 0.036*"idea" + 0.022*"answer" + 0.022*"rule" + 0.022*"reason" + 0.022*"consideration" + 0.022*"declaration" + 0.022*"point" + 0.022*"insight"
INFO: topic #2 (0.171): 0.066*"access" + 0.056*"class" + 0.050*"attribute" + 0.039*"method" + 0.038*"return" + 0.032*"side" + 0.032*"bit" + 0.032*"solution" + 0.030*"work" + 0.030*"language"
INFO: topic #3 (0.069): 0.046*"thing" + 0.046*"int" + 0.046*"c" + 0.046*"ctype" + 0.046*"integer" + 0.003*"reference" + 0.003*"answer" + 0.002*"c++" + 0.002*"instance" + 0.002*"assignment"
INFO: topic #4 (0.270): 0.169*"function" + 0.142*"object" + 0.098*"variable" + 0.087*"value" + 0.052*"parameter" + 0.044*"type" + 0.043*"instance" + 0.027*"copy" + 0.024*"c++" + 0.018*"change"
INFO: topic diff=1.025449, rho=0.577350
DEBUG: bound: at document #0
INFO: -7.016 per-word bound, 129.4 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 0, at document #20/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.39905506, 0.103915825, 0.19796252, 0.0875666, 0.33211687]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.399): 0.196*"reference" + 0.129*"argument" + 0.084*"name" + 0.045*"string" + 0.044*"way" + 0.031*"assignment" + 0.028*"example" + 0.028*"code" + 0.019*"variable" + 0.018*"pass"
INFO: topic #1 (0.104): 0.070*"effect" + 0.042*"time" + 0.036*"body" + 0.030*"call" + 0.029*"hand" + 0.024*"idea" + 0.019*"scope" + 0.015*"answer" + 0.015*"clutter" + 0.015*"break"
INFO: topic #2 (0.198): 0.078*"class" + 0.060*"work" + 0.046*"access" + 0.042*"solution" + 0.040*"language" + 0.040*"method" + 0.037*"case" + 0.036*"attribute" + 0.027*"return" + 0.023*"side"
INFO: topic #3 (0.088): 0.083*"namespace" + 0.063*"var" + 0.058*"field" + 0.058*"property" + 0.058*"print" + 0.030*"@refproperty" + 0.030*"compare" + 0.030*"decorator" + 0.030*"self.myvar" + 0.030*"member"
INFO: topic #4 (0.332): 0.228*"object" + 0.148*"function" + 0.084*"value" + 0.078*"variable" + 0.035*"parameter" + 0.029*"type" + 0.029*"instance" + 0.021*"change" + 0.020*"wrapper" + 0.018*"copy"
INFO: topic diff=0.686394, rho=0.500000
DEBUG: bound: at document #0
INFO: -6.273 per-word bound, 77.3 perplexity estimate based on a held-out corpus of 5 documents with 122 words
INFO: PROGRESS: pass 0, at document #25/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.46746793, 0.10192683, 0.22191569, 0.106096886, 0.43155038]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.467): 0.144*"name" + 0.140*"reference" + 0.078*"list" + 0.066*"argument" + 0.054*"string" + 0.046*"assignment" + 0.033*"way" + 0.025*"example" + 0.025*"code" + 0.019*"variable"
INFO: topic #1 (0.102): 0.051*"effect" + 0.031*"time" + 0.027*"body" + 0.025*"store" + 0.025*"dictionary" + 0.025*"dict" + 0.022*"call" + 0.021*"hand" + 0.018*"idea" + 0.014*"scope"
INFO: topic #2 (0.222): 0.087*"class" + 0.057*"work" + 0.055*"method" + 0.049*"question" + 0.045*"solution" + 0.044*"language" + 0.040*"attribute" + 0.029*"access" + 0.023*"case" + 0.022*"problem"
INFO: topic #3 (0.106): 0.060*"var" + 0.056*"int" + 0.040*"member" + 0.040*"namespace" + 0.032*"setattr" + 0.031*"thing" + 0.031*"integer" + 0.028*"property" + 0.028*"field" + 0.028*"print"
INFO: topic #4 (0.432): 0.187*"object" + 0.166*"function" + 0.097*"value" + 0.087*"variable" + 0.045*"change" + 0.045*"parameter" + 0.033*"type" + 0.025*"instance" + 0.012*"wrapper" + 0.010*"copy"
INFO: topic diff=0.550510, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.736 per-word bound, 53.3 perplexity estimate based on a held-out corpus of 5 documents with 167 words
INFO: PROGRESS: pass 0, at document #30/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.59409237, 0.11219072, 0.27076843, 0.115172714, 0.57274574]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.594): 0.248*"reference" + 0.075*"list" + 0.069*"name" + 0.063*"string" + 0.046*"way" + 0.042*"example" + 0.039*"argument" + 0.030*"assignment" + 0.027*"code" + 0.017*"store"
INFO: topic #1 (0.112): 0.065*"effect" + 0.040*"update" + 0.040*"thread" + 0.035*"reading" + 0.030*"point" + 0.021*"process" + 0.021*"simulate" + 0.018*"scope" + 0.017*"time" + 0.017*"output"
INFO: topic #2 (0.271): 0.137*"method" + 0.096*"class" + 0.046*"work" + 0.042*"question" + 0.039*"language" + 0.037*"attribute" + 0.027*"problem" + 0.025*"return" + 0.025*"solution" + 0.018*"show"
INFO: topic #3 (0.115): 0.105*"thing" + 0.056*"var" + 0.040*"int" + 0.029*"member" + 0.029*"namespace" + 0.023*"setattr" + 0.022*"integer" + 0.020*"print" + 0.020*"property" + 0.020*"field"
INFO: topic #4 (0.573): 0.206*"object" + 0.128*"function" + 0.112*"value" + 0.090*"change" + 0.057*"variable" + 0.057*"parameter" + 0.027*"instance" + 0.019*"copy" + 0.018*"type" + 0.010*"call"
INFO: topic diff=0.613263, rho=0.408248
DEBUG: bound: at document #0
INFO: -7.117 per-word bound, 138.8 perplexity estimate based on a held-out corpus of 5 documents with 85 words
INFO: PROGRESS: pass 0, at document #35/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.66431195, 0.1230041, 0.30734986, 0.115843974, 0.7155621]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.664): 0.248*"reference" + 0.062*"list" + 0.057*"name" + 0.052*"string" + 0.047*"way" + 0.043*"example" + 0.041*"argument" + 0.034*"assignment" + 0.022*"code" + 0.014*"call"
INFO: topic #1 (0.123): 0.106*"answer" + 0.036*"effect" + 0.028*"definition" + 0.023*"update" + 0.023*"thread" + 0.020*"reading" + 0.017*"point" + 0.015*"borderline" + 0.015*"vote" + 0.015*"bolt"
INFO: topic #2 (0.307): 0.105*"language" + 0.092*"method" + 0.065*"class" + 0.032*"post" + 0.031*"work" + 0.029*"question" + 0.025*"attribute" + 0.019*"problem" + 0.018*"other" + 0.017*"return"
INFO: topic #3 (0.116): 0.078*"thing" + 0.042*"var" + 0.032*"c" + 0.030*"int" + 0.030*"note" + 0.022*"member" + 0.022*"namespace" + 0.018*"setattr" + 0.017*"integer" + 0.016*"print"
INFO: topic #4 (0.716): 0.204*"object" + 0.132*"value" + 0.116*"function" + 0.062*"change" + 0.053*"parameter" + 0.052*"variable" + 0.021*"answer" + 0.018*"instance" + 0.013*"call" + 0.013*"copy"
INFO: topic diff=0.537945, rho=0.377964
DEBUG: bound: at document #0
INFO: -6.430 per-word bound, 86.2 perplexity estimate based on a held-out corpus of 5 documents with 178 words
INFO: PROGRESS: pass 0, at document #40/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7627635, 0.1508601, 0.3343157, 0.11736524, 0.7546075]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.763): 0.253*"reference" + 0.067*"list" + 0.050*"name" + 0.048*"string" + 0.043*"example" + 0.038*"assignment" + 0.031*"way" + 0.029*"argument" + 0.023*"element" + 0.020*"target"
INFO: topic #1 (0.151): 0.082*"answer" + 0.063*"point" + 0.048*"update" + 0.026*"target" + 0.021*"user" + 0.020*"effect" + 0.019*"wrap" + 0.016*"definition" + 0.015*"entry" + 0.015*"database"
INFO: topic #2 (0.334): 0.095*"method" + 0.090*"language" + 0.047*"class" + 0.040*"case" + 0.039*"work" + 0.026*"show" + 0.023*"post" + 0.021*"question" + 0.018*"attribute" + 0.017*"data"
INFO: topic #3 (0.117): 0.103*"integer" + 0.055*"print" + 0.041*"thing" + 0.035*"entry" + 0.035*"database" + 0.032*"namespace" + 0.022*"var" + 0.017*"c" + 0.016*"int" + 0.016*"note"
INFO: topic #4 (0.755): 0.219*"object" + 0.172*"value" + 0.078*"function" + 0.048*"variable" + 0.041*"change" + 0.031*"parameter" + 0.030*"type" + 0.018*"address" + 0.016*"answer" + 0.014*"target"
INFO: topic diff=0.742406, rho=0.353553
DEBUG: bound: at document #0
INFO: -7.235 per-word bound, 150.7 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 0, at document #45/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.78356767, 0.13822354, 0.39722186, 0.10944385, 0.8884991]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.784): 0.241*"reference" + 0.052*"list" + 0.041*"example" + 0.039*"name" + 0.037*"argument" + 0.037*"string" + 0.032*"way" + 0.030*"assignment" + 0.022*"code" + 0.021*"memory"
INFO: topic #1 (0.138): 0.071*"answer" + 0.055*"point" + 0.042*"update" + 0.023*"target" + 0.019*"user" + 0.018*"effect" + 0.017*"wrap" + 0.014*"definition" + 0.013*"entry" + 0.013*"database"
INFO: topic #2 (0.397): 0.059*"method" + 0.057*"language" + 0.055*"case" + 0.052*"return" + 0.037*"output" + 0.030*"class" + 0.027*"array" + 0.024*"work" + 0.024*"problem" + 0.020*"my_fun"
INFO: topic #3 (0.109): 0.088*"integer" + 0.047*"print" + 0.035*"thing" + 0.030*"entry" + 0.030*"database" + 0.028*"namespace" + 0.019*"var" + 0.015*"c" + 0.014*"int" + 0.014*"note"
INFO: topic #4 (0.888): 0.198*"object" + 0.162*"value" + 0.090*"function" + 0.048*"parameter" + 0.044*"change" + 0.037*"variable" + 0.023*"type" + 0.017*"answer" + 0.014*"instance" + 0.014*"call"
INFO: topic diff=0.438098, rho=0.333333
DEBUG: bound: at document #0
INFO: -7.113 per-word bound, 138.4 perplexity estimate based on a held-out corpus of 5 documents with 98 words
INFO: PROGRESS: pass 0, at document #50/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.88153327, 0.14056872, 0.45606753, 0.10384367, 1.0327996]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.882): 0.200*"reference" + 0.069*"list" + 0.050*"string" + 0.044*"name" + 0.039*"way" + 0.038*"example" + 0.035*"argument" + 0.032*"code" + 0.030*"assignment" + 0.016*"memory"
INFO: topic #1 (0.141): 0.050*"answer" + 0.039*"point" + 0.030*"update" + 0.029*"support" + 0.021*"reason" + 0.019*"perl" + 0.016*"target" + 0.014*"user" + 0.013*"mat" + 0.013*"effect"
INFO: topic #2 (0.456): 0.081*"return" + 0.055*"class" + 0.046*"language" + 0.040*"method" + 0.035*"context" + 0.033*"case" + 0.022*"show" + 0.022*"output" + 0.019*"perl" + 0.018*"other"
INFO: topic #3 (0.104): 0.073*"integer" + 0.039*"print" + 0.030*"thing" + 0.025*"entry" + 0.025*"database" + 0.024*"namespace" + 0.017*"var" + 0.013*"c" + 0.012*"int" + 0.012*"note"
INFO: topic #4 (1.033): 0.161*"object" + 0.160*"value" + 0.112*"function" + 0.049*"parameter" + 0.046*"variable" + 0.039*"change" + 0.024*"type" + 0.019*"call" + 0.013*"answer" + 0.011*"body"
INFO: topic diff=0.522846, rho=0.316228
DEBUG: bound: at document #0
INFO: -6.657 per-word bound, 100.9 perplexity estimate based on a held-out corpus of 5 documents with 80 words
INFO: PROGRESS: pass 0, at document #55/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.93124723, 0.14031446, 0.49330723, 0.10591146, 1.1713783]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.931): 0.169*"reference" + 0.055*"list" + 0.054*"argument" + 0.051*"code" + 0.048*"way" + 0.044*"name" + 0.041*"string" + 0.031*"example" + 0.024*"assignment" + 0.017*"pass"
INFO: topic #1 (0.140): 0.040*"answer" + 0.033*"definition" + 0.031*"point" + 0.026*"idea" + 0.024*"update" + 0.023*"support" + 0.017*"reason" + 0.017*"dll" + 0.015*"perl" + 0.013*"target"
INFO: topic #2 (0.493): 0.138*"return" + 0.042*"class" + 0.035*"language" + 0.032*"output" + 0.031*"method" + 0.027*"context" + 0.025*"case" + 0.025*"practice" + 0.024*"situation" + 0.024*"problem"
INFO: topic #3 (0.106): 0.055*"ctype" + 0.049*"integer" + 0.027*"print" + 0.023*"pointer" + 0.020*"thing" + 0.018*"pointer(instance" + 0.018*"set" + 0.018*"input" + 0.018*"byref" + 0.018*"pointer(ctype"
INFO: topic #4 (1.171): 0.159*"value" + 0.124*"function" + 0.116*"object" + 0.054*"parameter" + 0.042*"type" + 0.035*"change" + 0.033*"variable" + 0.022*"call" + 0.019*"pass" + 0.017*"pointer"
INFO: topic diff=0.380966, rho=0.301511
DEBUG: bound: at document #0
INFO: -6.552 per-word bound, 93.8 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 0, at document #60/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7924216, 0.12824944, 0.4930211, 0.120325856, 1.3104697]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.792): 0.153*"reference" + 0.060*"way" + 0.055*"argument" + 0.047*"list" + 0.043*"code" + 0.037*"name" + 0.034*"string" + 0.026*"example" + 0.020*"assignment" + 0.020*"output"
INFO: topic #1 (0.128): 0.034*"answer" + 0.028*"definition" + 0.027*"point" + 0.022*"idea" + 0.021*"update" + 0.020*"support" + 0.015*"reason" + 0.015*"dll" + 0.013*"perl" + 0.012*"target"
INFO: topic #2 (0.493): 0.149*"return" + 0.061*"case" + 0.033*"class" + 0.028*"language" + 0.026*"output" + 0.024*"method" + 0.022*"work" + 0.021*"context" + 0.020*"practice" + 0.019*"situation"
INFO: topic #3 (0.120): 0.073*"command" + 0.063*"integer" + 0.047*"input" + 0.044*"script" + 0.044*"line" + 0.040*"arg" + 0.033*"print" + 0.029*"assign" + 0.027*"ctype" + 0.021*"testclass"
INFO: topic #4 (1.310): 0.159*"function" + 0.149*"value" + 0.122*"object" + 0.061*"variable" + 0.040*"parameter" + 0.027*"change" + 0.027*"type" + 0.020*"instance" + 0.017*"pass" + 0.015*"output"
INFO: topic diff=0.458556, rho=0.288675
DEBUG: bound: at document #0
INFO: -9.442 per-word bound, 695.5 perplexity estimate based on a held-out corpus of 1 documents with 12 words
INFO: PROGRESS: pass 0, at document #61/61
INFO: optimized alpha [0.87748355, 0.12071175, 0.5685814, 0.15169999, 1.1845051]
DEBUG: updating topics
INFO: merging changes from 1 documents into a model of 61 documents
INFO: topic #0 (0.877): 0.116*"reference" + 0.090*"argument" + 0.046*"way" + 0.036*"list" + 0.034*"output" + 0.033*"code" + 0.031*"issue" + 0.028*"name" + 0.026*"string" + 0.020*"example"
INFO: topic #1 (0.121): 0.029*"answer" + 0.024*"definition" + 0.023*"point" + 0.019*"idea" + 0.018*"update" + 0.017*"support" + 0.013*"reason" + 0.013*"dll" + 0.011*"perl" + 0.010*"target"
INFO: topic #2 (0.569): 0.110*"return" + 0.066*"solution" + 0.045*"case" + 0.043*"output" + 0.024*"class" + 0.021*"language" + 0.019*"look" + 0.019*"os" + 0.019*"test" + 0.019*"window"
INFO: topic #3 (0.152): 0.104*"line" + 0.048*"command" + 0.042*"integer" + 0.031*"input" + 0.030*"window" + 0.030*"dict.hpp" + 0.030*"test" + 0.030*"os" + 0.030*"look" + 0.030*"dict.i"
INFO: topic #4 (1.185): 0.144*"function" + 0.134*"value" + 0.110*"object" + 0.055*"variable" + 0.037*"result" + 0.036*"parameter" + 0.025*"change" + 0.024*"type" + 0.021*"output" + 0.018*"instance"
INFO: topic diff=0.321478, rho=0.277350
DEBUG: bound: at document #0
INFO: -6.725 per-word bound, 105.8 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 1, at document #5/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7831338, 0.11231956, 0.431158, 0.13857897, 0.962276]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.783): 0.118*"reference" + 0.076*"argument" + 0.040*"list" + 0.038*"way" + 0.035*"assignment" + 0.030*"code" + 0.027*"name" + 0.026*"string" + 0.023*"output" + 0.022*"example"
INFO: topic #1 (0.112): 0.024*"answer" + 0.020*"definition" + 0.019*"point" + 0.016*"idea" + 0.015*"update" + 0.014*"support" + 0.011*"reason" + 0.011*"dll" + 0.010*"perl" + 0.009*"target"
INFO: topic #2 (0.431): 0.100*"return" + 0.061*"solution" + 0.041*"case" + 0.040*"output" + 0.023*"class" + 0.019*"language" + 0.017*"look" + 0.017*"os" + 0.017*"dict.i" + 0.017*"dict.hpp"
INFO: topic #3 (0.139): 0.093*"line" + 0.043*"command" + 0.038*"integer" + 0.028*"input" + 0.028*"window" + 0.028*"dict.hpp" + 0.028*"test" + 0.028*"os" + 0.028*"look" + 0.028*"dict.i"
INFO: topic #4 (0.962): 0.127*"function" + 0.103*"value" + 0.091*"object" + 0.055*"instance" + 0.048*"variable" + 0.035*"type" + 0.032*"parameter" + 0.031*"c++" + 0.027*"result" + 0.024*"change"
INFO: topic diff=0.329177, rho=0.265372
DEBUG: bound: at document #0
INFO: -7.147 per-word bound, 141.7 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 1, at document #10/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.67495733, 0.103925295, 0.4890701, 0.13498802, 0.8777724]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.675): 0.137*"reference" + 0.073*"argument" + 0.070*"way" + 0.034*"list" + 0.030*"assignment" + 0.025*"code" + 0.023*"name" + 0.022*"string" + 0.019*"output" + 0.018*"example"
INFO: topic #1 (0.104): 0.020*"answer" + 0.017*"definition" + 0.016*"point" + 0.013*"idea" + 0.013*"update" + 0.012*"support" + 0.009*"reason" + 0.009*"dll" + 0.009*"perl" + 0.008*"target"
INFO: topic #2 (0.489): 0.062*"solution" + 0.052*"return" + 0.032*"method" + 0.027*"case" + 0.026*"language" + 0.025*"work" + 0.020*"need" + 0.019*"class" + 0.018*"dataclasse" + 0.017*"functionality"
INFO: topic #3 (0.135): 0.073*"line" + 0.051*"integer" + 0.034*"command" + 0.034*"ctype" + 0.027*"thing" + 0.024*"c" + 0.024*"int" + 0.023*"input" + 0.022*"look" + 0.022*"test"
INFO: topic #4 (0.878): 0.112*"function" + 0.105*"value" + 0.084*"object" + 0.081*"instance" + 0.050*"variable" + 0.044*"parameter" + 0.040*"type" + 0.031*"change" + 0.024*"c++" + 0.021*"answer"
INFO: topic diff=0.462756, rho=0.265372
DEBUG: bound: at document #0
INFO: -5.523 per-word bound, 46.0 perplexity estimate based on a held-out corpus of 5 documents with 187 words
INFO: PROGRESS: pass 1, at document #15/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.73788977, 0.110860504, 0.5029265, 0.123086885, 0.93869585]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.738): 0.219*"reference" + 0.078*"way" + 0.047*"argument" + 0.039*"name" + 0.035*"assignment" + 0.033*"code" + 0.028*"example" + 0.022*"string" + 0.022*"list" + 0.021*"documentation"
INFO: topic #1 (0.111): 0.045*"idea" + 0.040*"effect" + 0.036*"hand" + 0.027*"point" + 0.024*"reason" + 0.024*"support" + 0.022*"wrap" + 0.021*"reading" + 0.020*"time" + 0.018*"bar"
INFO: topic #2 (0.503): 0.056*"return" + 0.046*"solution" + 0.043*"access" + 0.041*"class" + 0.035*"attribute" + 0.032*"method" + 0.029*"case" + 0.028*"language" + 0.027*"work" + 0.026*"side"
INFO: topic #3 (0.123): 0.064*"line" + 0.045*"integer" + 0.030*"command" + 0.030*"ctype" + 0.023*"thing" + 0.021*"c" + 0.021*"int" + 0.020*"input" + 0.019*"look" + 0.019*"test"
INFO: topic #4 (0.939): 0.149*"function" + 0.121*"object" + 0.096*"value" + 0.082*"variable" + 0.047*"instance" + 0.046*"parameter" + 0.039*"type" + 0.022*"c++" + 0.021*"change" + 0.019*"copy"
INFO: topic diff=0.598792, rho=0.265372
DEBUG: bound: at document #0
INFO: -6.211 per-word bound, 74.1 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 1, at document #20/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.79031384, 0.11681125, 0.4873382, 0.1318065, 0.91586286]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.790): 0.180*"reference" + 0.104*"argument" + 0.063*"name" + 0.051*"way" + 0.037*"string" + 0.031*"assignment" + 0.029*"code" + 0.026*"example" + 0.022*"list" + 0.017*"var"
INFO: topic #1 (0.117): 0.069*"effect" + 0.038*"time" + 0.037*"idea" + 0.030*"hand" + 0.022*"point" + 0.020*"reason" + 0.020*"support" + 0.018*"wrap" + 0.017*"reading" + 0.015*"rule"
INFO: topic #2 (0.487): 0.056*"class" + 0.049*"solution" + 0.048*"return" + 0.044*"work" + 0.037*"access" + 0.035*"case" + 0.035*"language" + 0.031*"method" + 0.030*"attribute" + 0.022*"side"
INFO: topic #3 (0.132): 0.074*"namespace" + 0.049*"print" + 0.039*"property" + 0.039*"field" + 0.038*"line" + 0.027*"integer" + 0.021*"member" + 0.019*"var" + 0.019*"decorator" + 0.019*"@refproperty"
INFO: topic #4 (0.916): 0.171*"object" + 0.140*"function" + 0.092*"value" + 0.075*"variable" + 0.038*"instance" + 0.037*"parameter" + 0.032*"type" + 0.022*"change" + 0.018*"c++" + 0.016*"copy"
INFO: topic diff=0.365185, rho=0.265372
DEBUG: bound: at document #0
INFO: -5.953 per-word bound, 62.0 perplexity estimate based on a held-out corpus of 5 documents with 122 words
INFO: PROGRESS: pass 1, at document #25/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.87454903, 0.110477515, 0.4980741, 0.14819819, 1.0260203]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.875): 0.144*"reference" + 0.106*"name" + 0.068*"argument" + 0.060*"list" + 0.044*"string" + 0.040*"way" + 0.040*"assignment" + 0.025*"code" + 0.024*"example" + 0.023*"var"
INFO: topic #1 (0.110): 0.060*"effect" + 0.033*"time" + 0.032*"idea" + 0.026*"hand" + 0.019*"point" + 0.018*"reason" + 0.018*"support" + 0.016*"wrap" + 0.015*"reading" + 0.013*"rule"
INFO: topic #2 (0.498): 0.067*"class" + 0.050*"solution" + 0.046*"work" + 0.040*"method" + 0.039*"language" + 0.038*"return" + 0.035*"attribute" + 0.034*"question" + 0.029*"access" + 0.028*"case"
INFO: topic #3 (0.148): 0.052*"namespace" + 0.047*"int" + 0.038*"integer" + 0.034*"print" + 0.034*"member" + 0.030*"setattr" + 0.029*"thing" + 0.027*"field" + 0.027*"property" + 0.027*"line"
INFO: topic #4 (1.026): 0.160*"object" + 0.151*"function" + 0.097*"value" + 0.082*"variable" + 0.042*"parameter" + 0.036*"change" + 0.033*"type" + 0.033*"instance" + 0.013*"pass" + 0.013*"result"
INFO: topic diff=0.389187, rho=0.265372
DEBUG: bound: at document #0
INFO: -5.339 per-word bound, 40.5 perplexity estimate based on a held-out corpus of 5 documents with 167 words
INFO: PROGRESS: pass 1, at document #30/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0104346, 0.11900614, 0.54330206, 0.15524395, 1.2026095]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.010): 0.219*"reference" + 0.065*"name" + 0.064*"list" + 0.054*"string" + 0.047*"argument" + 0.046*"way" + 0.036*"example" + 0.030*"assignment" + 0.027*"code" + 0.025*"var"
INFO: topic #1 (0.119): 0.077*"effect" + 0.046*"update" + 0.035*"point" + 0.034*"reading" + 0.033*"thread" + 0.022*"time" + 0.022*"idea" + 0.021*"simulate" + 0.021*"process" + 0.017*"hand"
INFO: topic #2 (0.543): 0.089*"method" + 0.081*"class" + 0.044*"work" + 0.039*"language" + 0.038*"return" + 0.036*"solution" + 0.036*"attribute" + 0.036*"question" + 0.024*"problem" + 0.021*"access"
INFO: topic #3 (0.155): 0.084*"thing" + 0.043*"namespace" + 0.038*"int" + 0.031*"integer" + 0.028*"print" + 0.028*"member" + 0.025*"setattr" + 0.023*"field" + 0.023*"property" + 0.022*"line"
INFO: topic #4 (1.203): 0.179*"object" + 0.129*"function" + 0.105*"value" + 0.069*"change" + 0.063*"variable" + 0.051*"parameter" + 0.031*"instance" + 0.022*"type" + 0.017*"copy" + 0.014*"call"
INFO: topic diff=0.422531, rho=0.265372
DEBUG: bound: at document #0
INFO: -6.626 per-word bound, 98.8 perplexity estimate based on a held-out corpus of 5 documents with 85 words
INFO: PROGRESS: pass 1, at document #35/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0476981, 0.12185744, 0.5778544, 0.15440103, 1.3637629]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.048): 0.223*"reference" + 0.057*"name" + 0.056*"list" + 0.048*"argument" + 0.047*"string" + 0.047*"way" + 0.038*"example" + 0.033*"assignment" + 0.023*"code" + 0.022*"var"
INFO: topic #1 (0.122): 0.051*"effect" + 0.043*"definition" + 0.039*"answer" + 0.031*"update" + 0.024*"point" + 0.022*"reading" + 0.022*"thread" + 0.019*"user" + 0.016*"bolt" + 0.016*"borderline"
INFO: topic #2 (0.578): 0.088*"language" + 0.069*"method" + 0.063*"class" + 0.035*"work" + 0.030*"return" + 0.028*"solution" + 0.028*"attribute" + 0.028*"question" + 0.026*"post" + 0.019*"problem"
INFO: topic #3 (0.154): 0.072*"thing" + 0.036*"namespace" + 0.033*"int" + 0.028*"c" + 0.027*"integer" + 0.024*"print" + 0.024*"member" + 0.022*"setattr" + 0.020*"property" + 0.020*"field"
INFO: topic #4 (1.364): 0.180*"object" + 0.118*"value" + 0.117*"function" + 0.058*"variable" + 0.053*"change" + 0.048*"parameter" + 0.030*"answer" + 0.024*"instance" + 0.017*"type" + 0.015*"call"
INFO: topic diff=0.360708, rho=0.265372
DEBUG: bound: at document #0
INFO: -5.993 per-word bound, 63.7 perplexity estimate based on a held-out corpus of 5 documents with 178 words
INFO: PROGRESS: pass 1, at document #40/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.1182117, 0.13643256, 0.5453654, 0.15496588, 1.3426573]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.118): 0.230*"reference" + 0.060*"list" + 0.050*"name" + 0.044*"string" + 0.039*"example" + 0.036*"assignment" + 0.034*"argument" + 0.034*"way" + 0.026*"element" + 0.024*"target"
INFO: topic #1 (0.136): 0.074*"point" + 0.065*"update" + 0.035*"effect" + 0.030*"definition" + 0.029*"user" + 0.028*"answer" + 0.024*"wrap" + 0.021*"support" + 0.016*"reading" + 0.015*"thread"
INFO: topic #2 (0.545): 0.085*"language" + 0.071*"method" + 0.052*"class" + 0.041*"work" + 0.039*"case" + 0.025*"return" + 0.023*"show" + 0.023*"solution" + 0.023*"attribute" + 0.023*"question"
INFO: topic #3 (0.155): 0.088*"integer" + 0.050*"print" + 0.045*"database" + 0.045*"entry" + 0.040*"thing" + 0.038*"namespace" + 0.018*"int" + 0.016*"c" + 0.014*"heap" + 0.014*"math"
INFO: topic #4 (1.343): 0.200*"object" + 0.154*"value" + 0.089*"function" + 0.055*"variable" + 0.040*"change" + 0.033*"parameter" + 0.029*"type" + 0.028*"answer" + 0.016*"instance" + 0.015*"address"
INFO: topic diff=0.543022, rho=0.265372
DEBUG: bound: at document #0
INFO: -6.701 per-word bound, 104.0 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 1, at document #45/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.1237599, 0.12949787, 0.6219737, 0.14604539, 1.4461911]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.124): 0.223*"reference" + 0.049*"list" + 0.041*"name" + 0.040*"argument" + 0.038*"example" + 0.036*"string" + 0.034*"way" + 0.029*"assignment" + 0.024*"memory" + 0.022*"code"
INFO: topic #1 (0.129): 0.065*"point" + 0.057*"update" + 0.031*"effect" + 0.027*"definition" + 0.026*"user" + 0.025*"answer" + 0.022*"wrap" + 0.019*"support" + 0.014*"reading" + 0.014*"thread"
INFO: topic #2 (0.622): 0.057*"language" + 0.052*"return" + 0.050*"case" + 0.048*"method" + 0.035*"class" + 0.031*"output" + 0.030*"array" + 0.028*"work" + 0.023*"problem" + 0.022*"my_fun"
INFO: topic #3 (0.146): 0.078*"integer" + 0.045*"print" + 0.040*"database" + 0.040*"entry" + 0.035*"thing" + 0.034*"namespace" + 0.017*"int" + 0.014*"c" + 0.013*"heap" + 0.013*"math"
INFO: topic #4 (1.446): 0.190*"object" + 0.152*"value" + 0.098*"function" + 0.047*"parameter" + 0.045*"variable" + 0.043*"change" + 0.028*"answer" + 0.024*"type" + 0.018*"instance" + 0.016*"call"
INFO: topic diff=0.320368, rho=0.265372
DEBUG: bound: at document #0
INFO: -6.650 per-word bound, 100.4 perplexity estimate based on a held-out corpus of 5 documents with 98 words
INFO: PROGRESS: pass 1, at document #50/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.207575, 0.1319822, 0.6799235, 0.1388441, 1.5681381]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.208): 0.195*"reference" + 0.064*"list" + 0.048*"string" + 0.045*"name" + 0.039*"way" + 0.038*"argument" + 0.036*"example" + 0.030*"code" + 0.029*"assignment" + 0.019*"memory"
INFO: topic #1 (0.132): 0.051*"point" + 0.045*"update" + 0.038*"support" + 0.027*"reason" + 0.024*"effect" + 0.021*"definition" + 0.021*"user" + 0.020*"answer" + 0.017*"wrap" + 0.011*"reading"
INFO: topic #2 (0.680): 0.073*"return" + 0.052*"class" + 0.046*"language" + 0.033*"method" + 0.032*"context" + 0.031*"case" + 0.026*"perl" + 0.020*"show" + 0.020*"output" + 0.019*"array"
INFO: topic #3 (0.139): 0.068*"integer" + 0.039*"print" + 0.035*"database" + 0.035*"entry" + 0.031*"thing" + 0.030*"namespace" + 0.015*"int" + 0.013*"c" + 0.011*"heap" + 0.011*"math"
INFO: topic #4 (1.568): 0.162*"object" + 0.153*"value" + 0.115*"function" + 0.051*"variable" + 0.048*"parameter" + 0.040*"change" + 0.024*"type" + 0.022*"answer" + 0.021*"call" + 0.015*"instance"
INFO: topic diff=0.390819, rho=0.265372
DEBUG: bound: at document #0
INFO: -6.306 per-word bound, 79.1 perplexity estimate based on a held-out corpus of 5 documents with 80 words
INFO: PROGRESS: pass 1, at document #55/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.1764406, 0.13251033, 0.68324935, 0.13995649, 1.6460918]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.176): 0.173*"reference" + 0.055*"list" + 0.054*"argument" + 0.048*"way" + 0.047*"code" + 0.046*"name" + 0.041*"string" + 0.031*"example" + 0.025*"assignment" + 0.017*"memory"
INFO: topic #1 (0.133): 0.043*"definition" + 0.040*"point" + 0.036*"update" + 0.032*"idea" + 0.030*"support" + 0.022*"dll" + 0.022*"reason" + 0.020*"effect" + 0.017*"user" + 0.016*"answer"
INFO: topic #2 (0.683): 0.123*"return" + 0.042*"class" + 0.037*"language" + 0.026*"output" + 0.026*"method" + 0.025*"practice" + 0.025*"context" + 0.025*"case" + 0.022*"problem" + 0.022*"situation"
INFO: topic #3 (0.140): 0.053*"ctype" + 0.049*"integer" + 0.028*"print" + 0.025*"entry" + 0.025*"database" + 0.023*"input" + 0.022*"thing" + 0.022*"namespace" + 0.021*"pointer" + 0.019*"pointer(ctype"
INFO: topic #4 (1.646): 0.152*"value" + 0.124*"function" + 0.121*"object" + 0.052*"parameter" + 0.040*"type" + 0.039*"variable" + 0.035*"change" + 0.024*"call" + 0.024*"pass" + 0.017*"pointer"
INFO: topic diff=0.285450, rho=0.265372
DEBUG: bound: at document #0
INFO: -5.877 per-word bound, 58.8 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 1, at document #60/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.91829, 0.122408256, 0.6239641, 0.15624303, 1.6909168]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.918): 0.161*"reference" + 0.060*"way" + 0.056*"argument" + 0.048*"list" + 0.042*"code" + 0.040*"name" + 0.036*"string" + 0.027*"example" + 0.022*"assignment" + 0.020*"="
INFO: topic #1 (0.122): 0.037*"definition" + 0.034*"point" + 0.031*"update" + 0.028*"idea" + 0.026*"support" + 0.019*"dll" + 0.019*"reason" + 0.017*"effect" + 0.014*"user" + 0.014*"answer"
INFO: topic #2 (0.624): 0.138*"return" + 0.057*"case" + 0.034*"class" + 0.030*"language" + 0.024*"work" + 0.023*"output" + 0.022*"method" + 0.021*"practice" + 0.021*"context" + 0.019*"problem"
INFO: topic #3 (0.156): 0.086*"command" + 0.059*"integer" + 0.058*"input" + 0.055*"line" + 0.052*"script" + 0.032*"print" + 0.028*"arg" + 0.027*"ctype" + 0.020*"testclass" + 0.017*"condition"
INFO: topic #4 (1.691): 0.154*"function" + 0.144*"value" + 0.124*"object" + 0.063*"variable" + 0.039*"parameter" + 0.028*"change" + 0.026*"type" + 0.021*"pass" + 0.021*"instance" + 0.020*"arg"
INFO: topic diff=0.354919, rho=0.265372
DEBUG: bound: at document #0
INFO: -8.295 per-word bound, 314.0 perplexity estimate based on a held-out corpus of 1 documents with 12 words
INFO: PROGRESS: pass 1, at document #61/61
INFO: optimized alpha [0.9289968, 0.11459449, 0.6525509, 0.19507635, 1.2927047]
DEBUG: updating topics
INFO: merging changes from 1 documents into a model of 61 documents
INFO: topic #0 (0.929): 0.127*"reference" + 0.091*"argument" + 0.047*"way" + 0.040*"issue" + 0.038*"list" + 0.035*"output" + 0.033*"code" + 0.032*"name" + 0.028*"string" + 0.022*"example"
INFO: topic #1 (0.115): 0.031*"definition" + 0.029*"point" + 0.026*"update" + 0.023*"idea" + 0.022*"support" + 0.016*"dll" + 0.016*"reason" + 0.015*"effect" + 0.012*"user" + 0.012*"answer"
INFO: topic #2 (0.653): 0.108*"return" + 0.069*"solution" + 0.045*"case" + 0.038*"output" + 0.027*"class" + 0.024*"language" + 0.019*"work" + 0.017*"method" + 0.017*"practice" + 0.017*"context"
INFO: topic #3 (0.195): 0.104*"line" + 0.052*"command" + 0.043*"dict.hpp" + 0.043*"window" + 0.043*"dict.i" + 0.043*"os" + 0.043*"test" + 0.043*"look" + 0.036*"integer" + 0.035*"input"
INFO: topic #4 (1.293): 0.142*"function" + 0.133*"value" + 0.114*"object" + 0.058*"variable" + 0.042*"result" + 0.036*"parameter" + 0.026*"change" + 0.024*"type" + 0.022*"output" + 0.019*"pass"
INFO: topic diff=0.264839, rho=0.265372
DEBUG: bound: at document #0
INFO: -6.330 per-word bound, 80.4 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 2, at document #5/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.81686836, 0.10716358, 0.4750021, 0.17421545, 1.0370626]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.817): 0.125*"reference" + 0.077*"argument" + 0.042*"list" + 0.040*"way" + 0.036*"assignment" + 0.030*"code" + 0.030*"name" + 0.027*"string" + 0.027*"issue" + 0.024*"output"
INFO: topic #1 (0.107): 0.026*"definition" + 0.024*"point" + 0.021*"update" + 0.020*"idea" + 0.018*"support" + 0.014*"dll" + 0.013*"reason" + 0.012*"effect" + 0.011*"user" + 0.010*"answer"
INFO: topic #2 (0.475): 0.099*"return" + 0.064*"solution" + 0.041*"case" + 0.036*"output" + 0.025*"class" + 0.022*"language" + 0.018*"work" + 0.016*"method" + 0.016*"practice" + 0.016*"context"
INFO: topic #3 (0.174): 0.095*"line" + 0.048*"command" + 0.040*"dict.hpp" + 0.040*"window" + 0.040*"dict.i" + 0.040*"os" + 0.040*"test" + 0.040*"look" + 0.033*"integer" + 0.033*"input"
INFO: topic #4 (1.037): 0.127*"function" + 0.103*"value" + 0.095*"object" + 0.054*"instance" + 0.052*"variable" + 0.035*"type" + 0.032*"parameter" + 0.031*"result" + 0.031*"c++" + 0.025*"change"
INFO: topic diff=0.283167, rho=0.256495
DEBUG: bound: at document #0
INFO: -6.813 per-word bound, 112.4 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 2, at document #10/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.6935242, 0.09980319, 0.5333707, 0.16664343, 0.927942]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.694): 0.144*"reference" + 0.075*"argument" + 0.071*"way" + 0.036*"list" + 0.031*"assignment" + 0.026*"code" + 0.025*"name" + 0.023*"string" + 0.023*"issue" + 0.020*"output"
INFO: topic #1 (0.100): 0.021*"definition" + 0.020*"point" + 0.018*"update" + 0.016*"idea" + 0.015*"support" + 0.011*"dll" + 0.011*"reason" + 0.011*"effect" + 0.009*"user" + 0.009*"answer"
INFO: topic #2 (0.533): 0.063*"solution" + 0.051*"return" + 0.030*"method" + 0.027*"language" + 0.027*"case" + 0.025*"work" + 0.021*"need" + 0.020*"class" + 0.018*"side" + 0.018*"dataclasse"
INFO: topic #3 (0.167): 0.077*"line" + 0.045*"integer" + 0.039*"command" + 0.033*"dict.hpp" + 0.033*"window" + 0.033*"dict.i" + 0.033*"test" + 0.033*"look" + 0.033*"os" + 0.031*"ctype"
INFO: topic #4 (0.928): 0.113*"function" + 0.106*"value" + 0.087*"object" + 0.080*"instance" + 0.053*"variable" + 0.044*"parameter" + 0.040*"type" + 0.032*"change" + 0.025*"answer" + 0.025*"result"
INFO: topic diff=0.380291, rho=0.256495
DEBUG: bound: at document #0
INFO: -5.397 per-word bound, 42.1 perplexity estimate based on a held-out corpus of 5 documents with 187 words
INFO: PROGRESS: pass 2, at document #15/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.75029784, 0.10657205, 0.54364234, 0.14962135, 0.9969651]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.750): 0.226*"reference" + 0.079*"way" + 0.049*"argument" + 0.041*"name" + 0.037*"assignment" + 0.034*"code" + 0.029*"example" + 0.024*"string" + 0.024*"list" + 0.021*"documentation"
INFO: topic #1 (0.107): 0.046*"idea" + 0.043*"effect" + 0.039*"hand" + 0.028*"point" + 0.026*"support" + 0.024*"reason" + 0.023*"wrap" + 0.021*"reading" + 0.021*"time" + 0.019*"insight"
INFO: topic #2 (0.544): 0.055*"return" + 0.046*"solution" + 0.043*"access" + 0.041*"class" + 0.035*"attribute" + 0.030*"side" + 0.030*"method" + 0.029*"language" + 0.029*"case" + 0.028*"work"
INFO: topic #3 (0.150): 0.069*"line" + 0.040*"integer" + 0.035*"command" + 0.029*"dict.hpp" + 0.029*"window" + 0.029*"dict.i" + 0.029*"test" + 0.029*"look" + 0.029*"os" + 0.028*"ctype"
INFO: topic #4 (0.997): 0.149*"function" + 0.122*"object" + 0.097*"value" + 0.085*"variable" + 0.047*"instance" + 0.046*"parameter" + 0.039*"type" + 0.022*"c++" + 0.022*"change" + 0.019*"copy"
INFO: topic diff=0.526118, rho=0.256495
DEBUG: bound: at document #0
INFO: -6.036 per-word bound, 65.6 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 2, at document #20/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.8002597, 0.11228508, 0.5170716, 0.1585414, 0.9604166]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.800): 0.184*"reference" + 0.105*"argument" + 0.063*"name" + 0.052*"way" + 0.037*"string" + 0.031*"assignment" + 0.029*"code" + 0.026*"example" + 0.023*"var" + 0.023*"list"
INFO: topic #1 (0.112): 0.076*"effect" + 0.038*"time" + 0.038*"idea" + 0.032*"hand" + 0.023*"point" + 0.021*"support" + 0.020*"reason" + 0.019*"wrap" + 0.018*"reading" + 0.016*"rule"
INFO: topic #2 (0.517): 0.055*"class" + 0.050*"solution" + 0.048*"return" + 0.044*"work" + 0.037*"access" + 0.035*"language" + 0.035*"case" + 0.030*"attribute" + 0.027*"method" + 0.026*"side"
INFO: topic #3 (0.159): 0.074*"namespace" + 0.045*"print" + 0.043*"line" + 0.037*"field" + 0.037*"property" + 0.026*"integer" + 0.022*"command" + 0.020*"member" + 0.019*"os" + 0.019*"dict.i"
INFO: topic #4 (0.960): 0.171*"object" + 0.140*"function" + 0.093*"value" + 0.078*"variable" + 0.038*"instance" + 0.037*"parameter" + 0.032*"type" + 0.022*"change" + 0.018*"c++" + 0.017*"pass"
INFO: topic diff=0.300300, rho=0.256495
DEBUG: bound: at document #0
INFO: -5.870 per-word bound, 58.5 perplexity estimate based on a held-out corpus of 5 documents with 122 words
INFO: PROGRESS: pass 2, at document #25/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.88146067, 0.10661569, 0.5212219, 0.17611735, 1.0605336]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.881): 0.146*"reference" + 0.105*"name" + 0.069*"argument" + 0.060*"list" + 0.044*"string" + 0.041*"way" + 0.040*"assignment" + 0.028*"var" + 0.026*"code" + 0.024*"example"
INFO: topic #1 (0.107): 0.067*"effect" + 0.034*"time" + 0.033*"idea" + 0.028*"hand" + 0.020*"point" + 0.019*"support" + 0.018*"reason" + 0.017*"wrap" + 0.016*"reading" + 0.014*"rule"
INFO: topic #2 (0.521): 0.066*"class" + 0.051*"solution" + 0.046*"work" + 0.039*"language" + 0.038*"return" + 0.035*"attribute" + 0.034*"method" + 0.034*"question" + 0.029*"access" + 0.028*"case"
INFO: topic #3 (0.176): 0.054*"namespace" + 0.044*"int" + 0.036*"integer" + 0.033*"print" + 0.033*"setattr" + 0.032*"member" + 0.032*"line" + 0.027*"thing" + 0.027*"field" + 0.027*"property"
INFO: topic #4 (1.061): 0.159*"object" + 0.151*"function" + 0.097*"value" + 0.085*"variable" + 0.042*"parameter" + 0.036*"change" + 0.033*"instance" + 0.033*"type" + 0.017*"pass" + 0.015*"result"
INFO: topic diff=0.333249, rho=0.256495
DEBUG: bound: at document #0
INFO: -5.290 per-word bound, 39.1 perplexity estimate based on a held-out corpus of 5 documents with 167 words
INFO: PROGRESS: pass 2, at document #30/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0131897, 0.114725, 0.5599741, 0.18199658, 1.2308174]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.013): 0.216*"reference" + 0.065*"name" + 0.063*"list" + 0.053*"string" + 0.048*"argument" + 0.046*"way" + 0.036*"example" + 0.030*"assignment" + 0.028*"var" + 0.026*"code"
INFO: topic #1 (0.115): 0.087*"effect" + 0.048*"update" + 0.036*"point" + 0.034*"thread" + 0.033*"reading" + 0.023*"time" + 0.022*"idea" + 0.022*"simulate" + 0.022*"process" + 0.019*"hand"
INFO: topic #2 (0.560): 0.083*"class" + 0.070*"method" + 0.046*"work" + 0.040*"language" + 0.040*"return" + 0.038*"solution" + 0.037*"attribute" + 0.036*"question" + 0.025*"problem" + 0.022*"access"
INFO: topic #3 (0.182): 0.079*"thing" + 0.045*"namespace" + 0.037*"int" + 0.031*"integer" + 0.028*"print" + 0.028*"setattr" + 0.027*"member" + 0.027*"line" + 0.023*"field" + 0.023*"property"
INFO: topic #4 (1.231): 0.178*"object" + 0.129*"function" + 0.105*"value" + 0.068*"change" + 0.066*"variable" + 0.050*"parameter" + 0.031*"instance" + 0.023*"type" + 0.017*"call" + 0.017*"copy"
INFO: topic diff=0.369385, rho=0.256495
DEBUG: bound: at document #0
INFO: -6.538 per-word bound, 92.9 perplexity estimate based on a held-out corpus of 5 documents with 85 words
INFO: PROGRESS: pass 2, at document #35/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0425563, 0.1174102, 0.58989596, 0.1790657, 1.3874584]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.043): 0.222*"reference" + 0.057*"name" + 0.056*"list" + 0.048*"argument" + 0.047*"string" + 0.047*"way" + 0.038*"example" + 0.033*"assignment" + 0.024*"var" + 0.023*"code"
INFO: topic #1 (0.117): 0.060*"effect" + 0.044*"definition" + 0.033*"update" + 0.025*"point" + 0.023*"thread" + 0.023*"reading" + 0.021*"user" + 0.018*"extent" + 0.018*"vote" + 0.018*"fine"
INFO: topic #2 (0.590): 0.089*"language" + 0.065*"class" + 0.055*"method" + 0.036*"work" + 0.031*"return" + 0.030*"solution" + 0.029*"attribute" + 0.029*"question" + 0.026*"post" + 0.020*"problem"
INFO: topic #3 (0.179): 0.068*"thing" + 0.039*"namespace" + 0.032*"int" + 0.027*"integer" + 0.026*"c" + 0.024*"print" + 0.024*"setattr" + 0.024*"member" + 0.023*"line" + 0.020*"property"
INFO: topic #4 (1.387): 0.177*"object" + 0.117*"function" + 0.117*"value" + 0.060*"variable" + 0.052*"change" + 0.048*"parameter" + 0.037*"answer" + 0.024*"instance" + 0.017*"type" + 0.017*"pass"
INFO: topic diff=0.316042, rho=0.256495
DEBUG: bound: at document #0
INFO: -5.894 per-word bound, 59.5 perplexity estimate based on a held-out corpus of 5 documents with 178 words
INFO: PROGRESS: pass 2, at document #40/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.1052619, 0.13071227, 0.5461308, 0.1781928, 1.3486359]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.105): 0.224*"reference" + 0.059*"list" + 0.050*"name" + 0.043*"string" + 0.038*"example" + 0.035*"assignment" + 0.034*"argument" + 0.033*"way" + 0.029*"target" + 0.028*"element"
INFO: topic #1 (0.131): 0.076*"point" + 0.068*"update" + 0.043*"effect" + 0.033*"user" + 0.032*"definition" + 0.025*"wrap" + 0.024*"support" + 0.017*"thread" + 0.017*"reading" + 0.013*"piece"
INFO: topic #2 (0.546): 0.086*"language" + 0.056*"method" + 0.053*"class" + 0.042*"work" + 0.039*"case" + 0.026*"return" + 0.025*"solution" + 0.024*"attribute" + 0.024*"question" + 0.024*"show"
INFO: topic #3 (0.178): 0.082*"integer" + 0.050*"entry" + 0.050*"database" + 0.047*"print" + 0.038*"namespace" + 0.038*"thing" + 0.018*"int" + 0.015*"map" + 0.015*"mutate" + 0.015*"heap"
INFO: topic #4 (1.349): 0.201*"object" + 0.154*"value" + 0.091*"function" + 0.058*"variable" + 0.041*"change" + 0.034*"answer" + 0.034*"parameter" + 0.029*"type" + 0.017*"instance" + 0.016*"call"
INFO: topic diff=0.471890, rho=0.256495
DEBUG: bound: at document #0
INFO: -6.624 per-word bound, 98.6 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 2, at document #45/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.098794, 0.12436382, 0.62087566, 0.16660461, 1.4316934]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.099): 0.220*"reference" + 0.049*"list" + 0.041*"name" + 0.040*"argument" + 0.037*"example" + 0.036*"string" + 0.033*"way" + 0.029*"assignment" + 0.028*"memory" + 0.024*"target"
INFO: topic #1 (0.124): 0.067*"point" + 0.060*"update" + 0.038*"effect" + 0.029*"user" + 0.028*"definition" + 0.023*"wrap" + 0.021*"support" + 0.015*"thread" + 0.015*"reading" + 0.012*"piece"
INFO: topic #2 (0.621): 0.057*"language" + 0.051*"return" + 0.049*"case" + 0.038*"array" + 0.037*"method" + 0.035*"class" + 0.028*"work" + 0.028*"my_fun" + 0.026*"output" + 0.022*"problem"
INFO: topic #3 (0.167): 0.074*"integer" + 0.045*"entry" + 0.045*"database" + 0.043*"print" + 0.035*"namespace" + 0.034*"thing" + 0.016*"int" + 0.014*"map" + 0.014*"mutate" + 0.014*"heap"
INFO: topic #4 (1.432): 0.193*"object" + 0.154*"value" + 0.100*"function" + 0.049*"variable" + 0.047*"parameter" + 0.044*"change" + 0.033*"answer" + 0.025*"type" + 0.019*"instance" + 0.018*"call"
INFO: topic diff=0.293705, rho=0.256495
DEBUG: bound: at document #0
INFO: -6.558 per-word bound, 94.2 perplexity estimate based on a held-out corpus of 5 documents with 98 words
INFO: PROGRESS: pass 2, at document #50/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.1712115, 0.1263068, 0.67460597, 0.157401, 1.5407943]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.171): 0.194*"reference" + 0.063*"list" + 0.047*"string" + 0.045*"name" + 0.039*"way" + 0.038*"argument" + 0.036*"example" + 0.029*"code" + 0.029*"assignment" + 0.022*"memory"
INFO: topic #1 (0.126): 0.054*"point" + 0.049*"update" + 0.041*"support" + 0.031*"effect" + 0.027*"reason" + 0.024*"user" + 0.023*"definition" + 0.019*"wrap" + 0.013*"thread" + 0.012*"reading"
INFO: topic #2 (0.675): 0.070*"return" + 0.051*"class" + 0.045*"language" + 0.031*"case" + 0.030*"context" + 0.028*"perl" + 0.025*"method" + 0.024*"array" + 0.019*"show" + 0.018*"work"
INFO: topic #3 (0.157): 0.065*"integer" + 0.040*"entry" + 0.040*"database" + 0.038*"print" + 0.031*"namespace" + 0.030*"thing" + 0.015*"int" + 0.013*"map" + 0.013*"mutate" + 0.013*"heap"
INFO: topic #4 (1.541): 0.165*"object" + 0.154*"value" + 0.116*"function" + 0.054*"variable" + 0.048*"parameter" + 0.041*"change" + 0.027*"answer" + 0.025*"type" + 0.023*"call" + 0.016*"pass"
INFO: topic diff=0.340097, rho=0.256495
DEBUG: bound: at document #0
INFO: -6.247 per-word bound, 76.0 perplexity estimate based on a held-out corpus of 5 documents with 80 words
INFO: PROGRESS: pass 2, at document #55/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.1380303, 0.1269281, 0.67128074, 0.15755074, 1.6075795]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.138): 0.173*"reference" + 0.054*"list" + 0.053*"argument" + 0.047*"way" + 0.046*"code" + 0.046*"name" + 0.040*"string" + 0.031*"example" + 0.025*"assignment" + 0.019*"memory"
INFO: topic #1 (0.127): 0.045*"definition" + 0.043*"point" + 0.039*"update" + 0.034*"idea" + 0.033*"support" + 0.025*"effect" + 0.024*"dll" + 0.022*"reason" + 0.019*"user" + 0.015*"wrap"
INFO: topic #2 (0.671): 0.118*"return" + 0.041*"class" + 0.037*"language" + 0.025*"case" + 0.025*"context" + 0.025*"practice" + 0.023*"perl" + 0.022*"problem" + 0.022*"situation" + 0.021*"output"
INFO: topic #3 (0.158): 0.050*"ctype" + 0.047*"integer" + 0.029*"entry" + 0.029*"database" + 0.028*"print" + 0.026*"input" + 0.023*"namespace" + 0.022*"thing" + 0.021*"pointer" + 0.019*"pointer(ctype"
INFO: topic #4 (1.608): 0.153*"value" + 0.125*"function" + 0.125*"object" + 0.052*"parameter" + 0.041*"variable" + 0.040*"type" + 0.036*"change" + 0.028*"pass" + 0.026*"call" + 0.020*"answer"
INFO: topic diff=0.250505, rho=0.256495
DEBUG: bound: at document #0
INFO: -5.744 per-word bound, 53.6 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 2, at document #60/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.90392923, 0.1178879, 0.6071878, 0.17399615, 1.6506802]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.904): 0.161*"reference" + 0.058*"way" + 0.055*"argument" + 0.048*"list" + 0.041*"code" + 0.040*"name" + 0.036*"string" + 0.027*"example" + 0.024*"store" + 0.022*"assignment"
INFO: topic #1 (0.118): 0.038*"definition" + 0.037*"point" + 0.033*"update" + 0.029*"idea" + 0.028*"support" + 0.021*"effect" + 0.021*"dll" + 0.019*"reason" + 0.016*"user" + 0.013*"wrap"
INFO: topic #2 (0.607): 0.134*"return" + 0.056*"case" + 0.035*"class" + 0.031*"language" + 0.024*"work" + 0.021*"context" + 0.021*"practice" + 0.020*"perl" + 0.019*"output" + 0.018*"problem"
INFO: topic #3 (0.174): 0.086*"command" + 0.064*"input" + 0.059*"integer" + 0.055*"line" + 0.052*"script" + 0.032*"print" + 0.027*"ctype" + 0.017*"import" + 0.017*"condition" + 0.017*"calculation"
INFO: topic #4 (1.651): 0.153*"function" + 0.144*"value" + 0.125*"object" + 0.064*"variable" + 0.040*"parameter" + 0.029*"change" + 0.027*"type" + 0.026*"arg" + 0.023*"pass" + 0.021*"instance"
INFO: topic diff=0.310898, rho=0.256495
DEBUG: bound: at document #0
INFO: -7.920 per-word bound, 242.2 perplexity estimate based on a held-out corpus of 1 documents with 12 words
INFO: PROGRESS: pass 2, at document #61/61
INFO: optimized alpha [0.8470917, 0.10983615, 0.57893085, 0.21577817, 1.1772848]
DEBUG: updating topics
INFO: merging changes from 1 documents into a model of 61 documents
INFO: topic #0 (0.847): 0.133*"reference" + 0.092*"argument" + 0.048*"way" + 0.047*"issue" + 0.040*"list" + 0.037*"output" + 0.034*"code" + 0.034*"name" + 0.030*"string" + 0.023*"example"
INFO: topic #1 (0.110): 0.032*"definition" + 0.031*"point" + 0.028*"update" + 0.024*"idea" + 0.024*"support" + 0.018*"effect" + 0.018*"dll" + 0.016*"reason" + 0.014*"user" + 0.011*"wrap"
INFO: topic #2 (0.579): 0.113*"return" + 0.070*"solution" + 0.047*"case" + 0.029*"class" + 0.029*"output" + 0.026*"language" + 0.020*"work" + 0.018*"context" + 0.018*"practice" + 0.017*"perl"
INFO: topic #3 (0.216): 0.090*"line" + 0.057*"dict.i" + 0.057*"dict.hpp" + 0.057*"window" + 0.057*"look" + 0.057*"test" + 0.057*"os" + 0.047*"command" + 0.035*"input" + 0.032*"integer"
INFO: topic #4 (1.177): 0.142*"function" + 0.134*"value" + 0.116*"object" + 0.060*"variable" + 0.044*"result" + 0.037*"parameter" + 0.027*"change" + 0.026*"output" + 0.025*"type" + 0.024*"arg"
INFO: topic diff=0.247822, rho=0.256495
DEBUG: bound: at document #0
INFO: -6.252 per-word bound, 76.2 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 3, at document #5/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.76322436, 0.10332656, 0.439356, 0.1917083, 0.9868885]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.763): 0.130*"reference" + 0.078*"argument" + 0.043*"list" + 0.041*"way" + 0.037*"assignment" + 0.032*"issue" + 0.031*"code" + 0.031*"name" + 0.028*"string" + 0.025*"output"
INFO: topic #1 (0.103): 0.027*"definition" + 0.026*"point" + 0.023*"update" + 0.020*"idea" + 0.020*"support" + 0.015*"effect" + 0.015*"dll" + 0.014*"reason" + 0.012*"user" + 0.010*"wrap"
INFO: topic #2 (0.439): 0.104*"return" + 0.065*"solution" + 0.043*"case" + 0.027*"class" + 0.027*"output" + 0.024*"language" + 0.019*"work" + 0.017*"context" + 0.017*"practice" + 0.016*"perl"
INFO: topic #3 (0.192): 0.084*"line" + 0.053*"dict.i" + 0.053*"dict.hpp" + 0.053*"window" + 0.053*"look" + 0.053*"test" + 0.053*"os" + 0.043*"command" + 0.032*"input" + 0.030*"integer"
INFO: topic #4 (0.987): 0.127*"function" + 0.104*"value" + 0.096*"object" + 0.054*"variable" + 0.053*"instance" + 0.035*"type" + 0.033*"parameter" + 0.032*"result" + 0.030*"c++" + 0.028*"answer"
INFO: topic diff=0.261020, rho=0.248452
DEBUG: bound: at document #0
INFO: -6.715 per-word bound, 105.0 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 3, at document #10/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.6596356, 0.096610755, 0.49425456, 0.18167496, 0.8909374]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.660): 0.148*"reference" + 0.076*"argument" + 0.071*"way" + 0.037*"list" + 0.032*"assignment" + 0.027*"issue" + 0.027*"code" + 0.026*"name" + 0.024*"string" + 0.022*"output"
INFO: topic #1 (0.097): 0.022*"definition" + 0.021*"point" + 0.019*"update" + 0.017*"idea" + 0.016*"support" + 0.013*"effect" + 0.013*"dll" + 0.012*"reason" + 0.010*"user" + 0.009*"wrap"
INFO: topic #2 (0.494): 0.063*"solution" + 0.053*"return" + 0.028*"language" + 0.027*"case" + 0.027*"method" + 0.026*"work" + 0.022*"need" + 0.020*"class" + 0.019*"side" + 0.018*"dataclasse"
INFO: topic #3 (0.182): 0.070*"line" + 0.044*"window" + 0.044*"dict.i" + 0.044*"test" + 0.044*"os" + 0.044*"look" + 0.044*"dict.hpp" + 0.041*"integer" + 0.036*"command" + 0.028*"ctype"
INFO: topic #4 (0.891): 0.114*"function" + 0.107*"value" + 0.089*"object" + 0.078*"instance" + 0.055*"variable" + 0.044*"parameter" + 0.040*"type" + 0.032*"change" + 0.028*"answer" + 0.026*"result"
INFO: topic diff=0.349596, rho=0.248452
DEBUG: bound: at document #0
INFO: -5.349 per-word bound, 40.8 perplexity estimate based on a held-out corpus of 5 documents with 187 words
INFO: PROGRESS: pass 3, at document #15/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.71397847, 0.10306238, 0.50931597, 0.16208845, 0.9657515]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.714): 0.229*"reference" + 0.080*"way" + 0.051*"argument" + 0.042*"name" + 0.037*"assignment" + 0.034*"code" + 0.030*"example" + 0.025*"list" + 0.024*"string" + 0.021*"documentation"
INFO: topic #1 (0.103): 0.045*"idea" + 0.043*"effect" + 0.039*"hand" + 0.028*"point" + 0.026*"support" + 0.024*"reason" + 0.022*"wrap" + 0.021*"reading" + 0.021*"time" + 0.019*"insight"
INFO: topic #2 (0.509): 0.057*"return" + 0.047*"solution" + 0.042*"access" + 0.041*"class" + 0.034*"attribute" + 0.031*"side" + 0.030*"language" + 0.029*"case" + 0.028*"work" + 0.027*"method"
INFO: topic #3 (0.162): 0.063*"line" + 0.040*"window" + 0.040*"dict.i" + 0.040*"test" + 0.040*"os" + 0.040*"look" + 0.040*"dict.hpp" + 0.037*"integer" + 0.033*"command" + 0.025*"ctype"
INFO: topic #4 (0.966): 0.148*"function" + 0.122*"object" + 0.097*"value" + 0.086*"variable" + 0.047*"instance" + 0.046*"parameter" + 0.039*"type" + 0.022*"change" + 0.022*"c++" + 0.019*"pass"
INFO: topic diff=0.486422, rho=0.248452
DEBUG: bound: at document #0
INFO: -5.985 per-word bound, 63.3 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 3, at document #20/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.76390076, 0.10855642, 0.48890638, 0.17076272, 0.9347372]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.764): 0.186*"reference" + 0.105*"argument" + 0.063*"name" + 0.053*"way" + 0.038*"string" + 0.032*"assignment" + 0.030*"code" + 0.027*"example" + 0.024*"var" + 0.024*"list"
INFO: topic #1 (0.109): 0.078*"effect" + 0.038*"time" + 0.037*"idea" + 0.033*"hand" + 0.023*"point" + 0.021*"support" + 0.020*"reason" + 0.019*"wrap" + 0.018*"reading" + 0.016*"consideration"
INFO: topic #2 (0.489): 0.055*"class" + 0.050*"solution" + 0.049*"return" + 0.044*"work" + 0.036*"access" + 0.035*"language" + 0.035*"case" + 0.030*"attribute" + 0.027*"side" + 0.024*"method"
INFO: topic #3 (0.171): 0.069*"namespace" + 0.042*"print" + 0.042*"line" + 0.035*"field" + 0.035*"property" + 0.027*"test" + 0.027*"os" + 0.027*"look" + 0.027*"dict.i" + 0.027*"dict.hpp"
INFO: topic #4 (0.935): 0.170*"object" + 0.140*"function" + 0.094*"value" + 0.079*"variable" + 0.039*"instance" + 0.037*"parameter" + 0.032*"type" + 0.023*"change" + 0.020*"pass" + 0.018*"c++"
INFO: topic diff=0.267692, rho=0.248452
DEBUG: bound: at document #0
INFO: -5.831 per-word bound, 56.9 perplexity estimate based on a held-out corpus of 5 documents with 122 words
INFO: PROGRESS: pass 3, at document #25/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.8419014, 0.10333806, 0.49364504, 0.188232, 1.0266397]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.842): 0.148*"reference" + 0.104*"name" + 0.069*"argument" + 0.059*"list" + 0.044*"string" + 0.041*"way" + 0.040*"assignment" + 0.028*"var" + 0.026*"code" + 0.024*"example"
INFO: topic #1 (0.103): 0.068*"effect" + 0.033*"time" + 0.033*"idea" + 0.029*"hand" + 0.021*"point" + 0.019*"support" + 0.018*"reason" + 0.017*"wrap" + 0.016*"reading" + 0.015*"consideration"
INFO: topic #2 (0.494): 0.066*"class" + 0.051*"solution" + 0.046*"work" + 0.040*"return" + 0.039*"language" + 0.035*"attribute" + 0.033*"question" + 0.031*"method" + 0.030*"access" + 0.028*"case"
INFO: topic #3 (0.188): 0.051*"namespace" + 0.042*"int" + 0.035*"integer" + 0.032*"setattr" + 0.032*"print" + 0.031*"line" + 0.030*"member" + 0.026*"thing" + 0.026*"property" + 0.026*"field"
INFO: topic #4 (1.027): 0.159*"object" + 0.151*"function" + 0.098*"value" + 0.086*"variable" + 0.042*"parameter" + 0.036*"change" + 0.033*"instance" + 0.033*"type" + 0.020*"pass" + 0.016*"result"
INFO: topic diff=0.303055, rho=0.248452
DEBUG: bound: at document #0
INFO: -5.253 per-word bound, 38.1 perplexity estimate based on a held-out corpus of 5 documents with 167 words
INFO: PROGRESS: pass 3, at document #30/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.9676793, 0.11094293, 0.528192, 0.19294526, 1.1856401]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.968): 0.213*"reference" + 0.064*"name" + 0.062*"list" + 0.052*"string" + 0.048*"argument" + 0.046*"way" + 0.035*"example" + 0.030*"assignment" + 0.028*"method" + 0.027*"var"
INFO: topic #1 (0.111): 0.089*"effect" + 0.047*"update" + 0.036*"point" + 0.033*"reading" + 0.032*"thread" + 0.023*"time" + 0.023*"idea" + 0.022*"simulate" + 0.022*"process" + 0.020*"hand"
INFO: topic #2 (0.528): 0.084*"class" + 0.055*"method" + 0.047*"work" + 0.042*"return" + 0.042*"language" + 0.040*"solution" + 0.038*"attribute" + 0.037*"question" + 0.025*"problem" + 0.023*"access"
INFO: topic #3 (0.193): 0.073*"thing" + 0.044*"namespace" + 0.035*"int" + 0.030*"integer" + 0.028*"setattr" + 0.027*"print" + 0.027*"line" + 0.026*"member" + 0.022*"property" + 0.022*"field"
INFO: topic #4 (1.186): 0.178*"object" + 0.129*"function" + 0.106*"value" + 0.068*"variable" + 0.067*"change" + 0.050*"parameter" + 0.032*"instance" + 0.023*"type" + 0.019*"call" + 0.017*"copy"
INFO: topic diff=0.334587, rho=0.248452
DEBUG: bound: at document #0
INFO: -6.481 per-word bound, 89.3 perplexity estimate based on a held-out corpus of 5 documents with 85 words
INFO: PROGRESS: pass 3, at document #35/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.99446046, 0.11343415, 0.55621475, 0.18878993, 1.3317549]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.994): 0.219*"reference" + 0.057*"name" + 0.055*"list" + 0.048*"argument" + 0.047*"way" + 0.046*"string" + 0.037*"example" + 0.032*"assignment" + 0.025*"method" + 0.024*"var"
INFO: topic #1 (0.113): 0.062*"effect" + 0.043*"definition" + 0.033*"update" + 0.025*"point" + 0.023*"reading" + 0.023*"thread" + 0.021*"user" + 0.018*"extent" + 0.018*"borderline" + 0.018*"vote"
INFO: topic #2 (0.556): 0.090*"language" + 0.066*"class" + 0.044*"method" + 0.037*"work" + 0.033*"return" + 0.031*"solution" + 0.030*"attribute" + 0.029*"question" + 0.026*"post" + 0.020*"problem"
INFO: topic #3 (0.189): 0.063*"thing" + 0.038*"namespace" + 0.031*"int" + 0.026*"integer" + 0.025*"c" + 0.024*"setattr" + 0.024*"print" + 0.024*"line" + 0.023*"member" + 0.020*"property"
INFO: topic #4 (1.332): 0.177*"object" + 0.117*"function" + 0.117*"value" + 0.061*"variable" + 0.052*"change" + 0.048*"parameter" + 0.040*"answer" + 0.024*"instance" + 0.019*"pass" + 0.019*"call"
INFO: topic diff=0.289790, rho=0.248452
DEBUG: bound: at document #0
INFO: -5.830 per-word bound, 56.9 perplexity estimate based on a held-out corpus of 5 documents with 178 words
INFO: PROGRESS: pass 3, at document #40/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.05708, 0.12589408, 0.51776105, 0.18718894, 1.2953364]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.057): 0.219*"reference" + 0.057*"list" + 0.049*"name" + 0.043*"string" + 0.037*"example" + 0.034*"argument" + 0.034*"assignment" + 0.033*"way" + 0.032*"target" + 0.027*"element"
INFO: topic #1 (0.126): 0.076*"point" + 0.067*"update" + 0.045*"effect" + 0.033*"user" + 0.032*"definition" + 0.025*"wrap" + 0.024*"support" + 0.017*"reading" + 0.017*"thread" + 0.013*"fine"
INFO: topic #2 (0.518): 0.087*"language" + 0.055*"class" + 0.044*"method" + 0.043*"work" + 0.040*"case" + 0.027*"return" + 0.026*"solution" + 0.025*"attribute" + 0.024*"question" + 0.024*"show"
INFO: topic #3 (0.187): 0.079*"integer" + 0.049*"database" + 0.049*"entry" + 0.046*"print" + 0.038*"namespace" + 0.036*"thing" + 0.018*"int" + 0.015*"math" + 0.015*"clarifie" + 0.015*"map"
INFO: topic #4 (1.295): 0.203*"object" + 0.155*"value" + 0.093*"function" + 0.061*"variable" + 0.042*"change" + 0.037*"answer" + 0.034*"parameter" + 0.030*"type" + 0.018*"instance" + 0.017*"call"
INFO: topic diff=0.425597, rho=0.248452
DEBUG: bound: at document #0
INFO: -6.535 per-word bound, 92.7 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 3, at document #45/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0449699, 0.11998679, 0.58718216, 0.17444961, 1.3723147]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.045): 0.217*"reference" + 0.048*"list" + 0.041*"name" + 0.040*"argument" + 0.037*"example" + 0.036*"string" + 0.033*"way" + 0.029*"assignment" + 0.028*"memory" + 0.027*"target"
INFO: topic #1 (0.120): 0.067*"point" + 0.060*"update" + 0.040*"effect" + 0.030*"user" + 0.028*"definition" + 0.023*"wrap" + 0.022*"support" + 0.015*"reading" + 0.015*"thread" + 0.012*"fine"
INFO: topic #2 (0.587): 0.057*"language" + 0.051*"return" + 0.048*"case" + 0.043*"array" + 0.036*"class" + 0.032*"my_fun" + 0.029*"method" + 0.028*"work" + 0.022*"problem" + 0.020*"operator"
INFO: topic #3 (0.174): 0.071*"integer" + 0.044*"database" + 0.044*"entry" + 0.041*"print" + 0.034*"namespace" + 0.032*"thing" + 0.016*"int" + 0.014*"math" + 0.014*"clarifie" + 0.014*"map"
INFO: topic #4 (1.372): 0.195*"object" + 0.155*"value" + 0.102*"function" + 0.051*"variable" + 0.048*"parameter" + 0.045*"change" + 0.036*"answer" + 0.025*"type" + 0.020*"instance" + 0.019*"call"
INFO: topic diff=0.271752, rho=0.248452
DEBUG: bound: at document #0
INFO: -6.488 per-word bound, 89.8 perplexity estimate based on a held-out corpus of 5 documents with 98 words
INFO: PROGRESS: pass 3, at document #50/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.1124736, 0.12169592, 0.637238, 0.16443887, 1.4736861]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.112): 0.193*"reference" + 0.062*"list" + 0.047*"string" + 0.045*"name" + 0.039*"way" + 0.038*"argument" + 0.036*"example" + 0.029*"assignment" + 0.029*"code" + 0.022*"memory"
INFO: topic #1 (0.122): 0.055*"point" + 0.049*"update" + 0.041*"support" + 0.033*"effect" + 0.027*"reason" + 0.025*"user" + 0.023*"definition" + 0.019*"wrap" + 0.013*"reading" + 0.013*"thread"
INFO: topic #2 (0.637): 0.069*"return" + 0.050*"class" + 0.045*"language" + 0.030*"case" + 0.030*"context" + 0.028*"perl" + 0.027*"array" + 0.020*"my_fun" + 0.020*"method" + 0.019*"show"
INFO: topic #3 (0.164): 0.063*"integer" + 0.039*"database" + 0.039*"entry" + 0.037*"print" + 0.031*"namespace" + 0.029*"thing" + 0.015*"int" + 0.013*"math" + 0.013*"clarifie" + 0.013*"map"
INFO: topic #4 (1.474): 0.167*"object" + 0.155*"value" + 0.118*"function" + 0.057*"variable" + 0.049*"parameter" + 0.041*"change" + 0.029*"answer" + 0.025*"type" + 0.025*"call" + 0.018*"pass"
INFO: topic diff=0.305877, rho=0.248452
DEBUG: bound: at document #0
INFO: -6.204 per-word bound, 73.7 perplexity estimate based on a held-out corpus of 5 documents with 80 words
INFO: PROGRESS: pass 3, at document #55/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.08622, 0.12235087, 0.63283247, 0.16406083, 1.536238]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.086): 0.173*"reference" + 0.054*"list" + 0.053*"argument" + 0.047*"way" + 0.046*"name" + 0.045*"code" + 0.040*"string" + 0.031*"example" + 0.025*"assignment" + 0.019*"memory"
INFO: topic #1 (0.122): 0.045*"definition" + 0.044*"point" + 0.039*"update" + 0.033*"idea" + 0.033*"support" + 0.027*"effect" + 0.025*"dll" + 0.021*"reason" + 0.020*"user" + 0.015*"wrap"
INFO: topic #2 (0.633): 0.116*"return" + 0.041*"class" + 0.037*"language" + 0.025*"case" + 0.024*"context" + 0.024*"practice" + 0.023*"perl" + 0.022*"array" + 0.022*"problem" + 0.021*"situation"
INFO: topic #3 (0.164): 0.048*"ctype" + 0.047*"integer" + 0.029*"entry" + 0.029*"database" + 0.027*"print" + 0.026*"input" + 0.023*"namespace" + 0.023*"pointer" + 0.022*"thing" + 0.019*"byref"
INFO: topic #4 (1.536): 0.154*"value" + 0.128*"object" + 0.126*"function" + 0.053*"parameter" + 0.043*"variable" + 0.040*"type" + 0.037*"change" + 0.029*"pass" + 0.028*"call" + 0.022*"answer"
INFO: topic diff=0.224703, rho=0.248452
DEBUG: bound: at document #0
INFO: -5.666 per-word bound, 50.8 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 3, at document #60/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.8780855, 0.11417599, 0.5781286, 0.17984435, 1.5907056]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.878): 0.161*"reference" + 0.057*"way" + 0.055*"argument" + 0.048*"list" + 0.041*"name" + 0.040*"code" + 0.036*"string" + 0.027*"example" + 0.025*"store" + 0.022*"assignment"
INFO: topic #1 (0.114): 0.038*"definition" + 0.038*"point" + 0.034*"update" + 0.029*"idea" + 0.028*"support" + 0.023*"effect" + 0.022*"dll" + 0.019*"reason" + 0.017*"user" + 0.014*"wrap"
INFO: topic #2 (0.578): 0.132*"return" + 0.055*"case" + 0.035*"class" + 0.032*"language" + 0.024*"work" + 0.021*"context" + 0.021*"practice" + 0.020*"perl" + 0.019*"array" + 0.018*"problem"
INFO: topic #3 (0.180): 0.085*"command" + 0.064*"input" + 0.059*"integer" + 0.054*"line" + 0.051*"script" + 0.032*"print" + 0.027*"ctype" + 0.017*"condition" + 0.017*"screen" + 0.017*"calculation"
INFO: topic #4 (1.591): 0.153*"function" + 0.144*"value" + 0.127*"object" + 0.065*"variable" + 0.040*"parameter" + 0.029*"change" + 0.028*"arg" + 0.027*"type" + 0.024*"pass" + 0.021*"instance"
INFO: topic diff=0.280819, rho=0.248452
DEBUG: bound: at document #0
INFO: -7.547 per-word bound, 187.0 perplexity estimate based on a held-out corpus of 1 documents with 12 words
INFO: PROGRESS: pass 3, at document #61/61
INFO: optimized alpha [0.8147073, 0.1066327, 0.54175556, 0.22150439, 1.140356]
DEBUG: updating topics
INFO: merging changes from 1 documents into a model of 61 documents
INFO: topic #0 (0.815): 0.136*"reference" + 0.090*"argument" + 0.048*"way" + 0.048*"issue" + 0.041*"list" + 0.039*"output" + 0.034*"name" + 0.034*"code" + 0.030*"string" + 0.023*"example"
INFO: topic #1 (0.107): 0.032*"definition" + 0.032*"point" + 0.028*"update" + 0.024*"idea" + 0.024*"support" + 0.020*"effect" + 0.018*"dll" + 0.016*"reason" + 0.015*"user" + 0.012*"wrap"
INFO: topic #2 (0.542): 0.114*"return" + 0.068*"solution" + 0.047*"case" + 0.030*"class" + 0.027*"language" + 0.021*"work" + 0.018*"output" + 0.018*"context" + 0.018*"practice" + 0.017*"perl"
INFO: topic #3 (0.222): 0.087*"line" + 0.059*"dict.hpp" + 0.059*"dict.i" + 0.059*"window" + 0.059*"look" + 0.059*"test" + 0.059*"os" + 0.045*"command" + 0.034*"input" + 0.032*"integer"
INFO: topic #4 (1.140): 0.142*"function" + 0.134*"value" + 0.118*"object" + 0.061*"variable" + 0.043*"result" + 0.037*"parameter" + 0.028*"output" + 0.027*"change" + 0.026*"arg" + 0.025*"type"
INFO: topic diff=0.223601, rho=0.248452
DEBUG: bound: at document #0
INFO: -6.209 per-word bound, 74.0 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 4, at document #5/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.742427, 0.100729406, 0.42134222, 0.19718558, 0.9766734]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.742): 0.133*"reference" + 0.078*"argument" + 0.044*"list" + 0.041*"way" + 0.037*"assignment" + 0.033*"issue" + 0.031*"name" + 0.031*"code" + 0.029*"string" + 0.027*"output"
INFO: topic #1 (0.101): 0.027*"definition" + 0.027*"point" + 0.024*"update" + 0.021*"idea" + 0.020*"support" + 0.017*"effect" + 0.016*"dll" + 0.014*"reason" + 0.013*"user" + 0.010*"wrap"
INFO: topic #2 (0.421): 0.105*"return" + 0.063*"solution" + 0.044*"case" + 0.028*"class" + 0.025*"language" + 0.019*"work" + 0.017*"output" + 0.017*"context" + 0.017*"practice" + 0.016*"perl"
INFO: topic #3 (0.197): 0.081*"line" + 0.055*"dict.hpp" + 0.055*"dict.i" + 0.055*"window" + 0.055*"look" + 0.055*"test" + 0.055*"os" + 0.042*"command" + 0.032*"input" + 0.030*"integer"
INFO: topic #4 (0.977): 0.127*"function" + 0.105*"value" + 0.098*"object" + 0.056*"variable" + 0.052*"instance" + 0.035*"type" + 0.033*"parameter" + 0.032*"result" + 0.029*"answer" + 0.029*"c++"
INFO: topic diff=0.241642, rho=0.241121
DEBUG: bound: at document #0
INFO: -6.665 per-word bound, 101.5 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 4, at document #10/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.64811254, 0.09448477, 0.47349644, 0.1864649, 0.8832736]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.648): 0.149*"reference" + 0.076*"argument" + 0.070*"way" + 0.038*"list" + 0.032*"assignment" + 0.029*"issue" + 0.027*"name" + 0.027*"code" + 0.025*"string" + 0.023*"output"
INFO: topic #1 (0.094): 0.023*"definition" + 0.022*"point" + 0.020*"update" + 0.017*"idea" + 0.017*"support" + 0.014*"effect" + 0.013*"dll" + 0.012*"reason" + 0.011*"user" + 0.009*"wrap"
INFO: topic #2 (0.473): 0.062*"solution" + 0.054*"return" + 0.028*"language" + 0.028*"case" + 0.026*"work" + 0.025*"method" + 0.022*"need" + 0.021*"class" + 0.019*"side" + 0.018*"dataclasse"
INFO: topic #3 (0.186): 0.068*"line" + 0.047*"dict.i" + 0.047*"dict.hpp" + 0.047*"window" + 0.047*"look" + 0.047*"test" + 0.047*"os" + 0.040*"integer" + 0.036*"command" + 0.027*"input"
INFO: topic #4 (0.883): 0.114*"function" + 0.108*"value" + 0.091*"object" + 0.077*"instance" + 0.057*"variable" + 0.044*"parameter" + 0.040*"type" + 0.032*"change" + 0.029*"answer" + 0.026*"result"
INFO: topic diff=0.326268, rho=0.241121
DEBUG: bound: at document #0
INFO: -5.320 per-word bound, 39.9 perplexity estimate based on a held-out corpus of 5 documents with 187 words
INFO: PROGRESS: pass 4, at document #15/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7003169, 0.10066879, 0.48991868, 0.16638312, 0.9561922]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.700): 0.228*"reference" + 0.080*"way" + 0.052*"argument" + 0.042*"name" + 0.037*"assignment" + 0.034*"code" + 0.030*"example" + 0.026*"list" + 0.025*"string" + 0.021*"documentation"
INFO: topic #1 (0.101): 0.044*"idea" + 0.043*"effect" + 0.039*"hand" + 0.028*"point" + 0.026*"support" + 0.023*"reason" + 0.022*"wrap" + 0.021*"reading" + 0.021*"time" + 0.019*"bar"
INFO: topic #2 (0.490): 0.058*"return" + 0.046*"solution" + 0.042*"access" + 0.041*"class" + 0.034*"attribute" + 0.031*"side" + 0.030*"language" + 0.029*"case" + 0.028*"work" + 0.025*"need"
INFO: topic #3 (0.166): 0.062*"line" + 0.043*"dict.i" + 0.043*"dict.hpp" + 0.043*"window" + 0.043*"look" + 0.043*"test" + 0.043*"os" + 0.037*"integer" + 0.033*"command" + 0.025*"input"
INFO: topic #4 (0.956): 0.148*"function" + 0.122*"object" + 0.098*"value" + 0.086*"variable" + 0.047*"instance" + 0.046*"parameter" + 0.039*"type" + 0.022*"change" + 0.022*"c++" + 0.021*"answer"
INFO: topic diff=0.455063, rho=0.241121
DEBUG: bound: at document #0
INFO: -5.948 per-word bound, 61.7 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 4, at document #20/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.74916077, 0.10597167, 0.47478014, 0.1748042, 0.927636]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.749): 0.187*"reference" + 0.104*"argument" + 0.063*"name" + 0.053*"way" + 0.038*"string" + 0.032*"assignment" + 0.030*"code" + 0.027*"example" + 0.024*"list" + 0.023*"var"
INFO: topic #1 (0.106): 0.077*"effect" + 0.037*"time" + 0.037*"idea" + 0.032*"hand" + 0.023*"point" + 0.021*"support" + 0.020*"reason" + 0.019*"wrap" + 0.018*"reading" + 0.016*"rule"
INFO: topic #2 (0.475): 0.055*"class" + 0.050*"return" + 0.049*"solution" + 0.043*"work" + 0.036*"access" + 0.035*"language" + 0.035*"case" + 0.029*"attribute" + 0.027*"side" + 0.022*"need"
INFO: topic #3 (0.175): 0.067*"namespace" + 0.042*"line" + 0.041*"print" + 0.033*"field" + 0.033*"property" + 0.029*"test" + 0.029*"os" + 0.029*"look" + 0.029*"dict.i" + 0.029*"dict.hpp"
INFO: topic #4 (0.928): 0.169*"object" + 0.140*"function" + 0.094*"value" + 0.080*"variable" + 0.039*"instance" + 0.038*"parameter" + 0.032*"type" + 0.023*"change" + 0.021*"pass" + 0.018*"c++"
INFO: topic diff=0.245957, rho=0.241121
DEBUG: bound: at document #0
INFO: -5.804 per-word bound, 55.9 perplexity estimate based on a held-out corpus of 5 documents with 122 words
INFO: PROGRESS: pass 4, at document #25/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.826292, 0.10111707, 0.47978526, 0.19185588, 1.0142118]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.826): 0.148*"reference" + 0.102*"name" + 0.069*"argument" + 0.059*"list" + 0.043*"string" + 0.042*"way" + 0.039*"assignment" + 0.028*"var" + 0.026*"code" + 0.024*"example"
INFO: topic #1 (0.101): 0.067*"effect" + 0.033*"time" + 0.033*"idea" + 0.029*"hand" + 0.021*"point" + 0.019*"support" + 0.018*"reason" + 0.017*"wrap" + 0.016*"reading" + 0.015*"rule"
INFO: topic #2 (0.480): 0.065*"class" + 0.051*"solution" + 0.046*"work" + 0.041*"return" + 0.039*"language" + 0.034*"attribute" + 0.033*"question" + 0.030*"access" + 0.029*"case" + 0.028*"method"
INFO: topic #3 (0.192): 0.050*"namespace" + 0.040*"int" + 0.035*"integer" + 0.032*"setattr" + 0.032*"line" + 0.031*"print" + 0.030*"member" + 0.025*"field" + 0.025*"property" + 0.025*"thing"
INFO: topic #4 (1.014): 0.159*"object" + 0.151*"function" + 0.099*"value" + 0.088*"variable" + 0.042*"parameter" + 0.035*"change" + 0.034*"instance" + 0.033*"type" + 0.021*"pass" + 0.016*"result"
INFO: topic diff=0.280305, rho=0.241121
DEBUG: bound: at document #0
INFO: -5.222 per-word bound, 37.3 perplexity estimate based on a held-out corpus of 5 documents with 167 words
INFO: PROGRESS: pass 4, at document #30/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.9486819, 0.10833386, 0.5116147, 0.19573832, 1.1656828]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.949): 0.209*"reference" + 0.063*"name" + 0.060*"list" + 0.051*"string" + 0.047*"argument" + 0.045*"way" + 0.035*"method" + 0.034*"example" + 0.029*"assignment" + 0.027*"var"
INFO: topic #1 (0.108): 0.089*"effect" + 0.046*"update" + 0.035*"point" + 0.032*"reading" + 0.030*"thread" + 0.023*"time" + 0.023*"idea" + 0.022*"simulate" + 0.022*"process" + 0.020*"hand"
INFO: topic #2 (0.512): 0.085*"class" + 0.047*"work" + 0.044*"method" + 0.043*"return" + 0.042*"language" + 0.040*"solution" + 0.038*"attribute" + 0.037*"question" + 0.026*"problem" + 0.024*"access"
INFO: topic #3 (0.196): 0.067*"thing" + 0.044*"namespace" + 0.035*"int" + 0.030*"integer" + 0.028*"setattr" + 0.027*"line" + 0.027*"print" + 0.026*"member" + 0.022*"property" + 0.022*"field"
INFO: topic #4 (1.166): 0.178*"object" + 0.130*"function" + 0.106*"value" + 0.069*"variable" + 0.066*"change" + 0.050*"parameter" + 0.032*"instance" + 0.023*"type" + 0.020*"call" + 0.017*"copy"
INFO: topic diff=0.308000, rho=0.241121
DEBUG: bound: at document #0
INFO: -6.437 per-word bound, 86.7 perplexity estimate based on a held-out corpus of 5 documents with 85 words
INFO: PROGRESS: pass 4, at document #35/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.9739607, 0.110714726, 0.53847563, 0.1912089, 1.3043435]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.974): 0.215*"reference" + 0.056*"name" + 0.054*"list" + 0.048*"argument" + 0.046*"way" + 0.046*"string" + 0.037*"example" + 0.032*"assignment" + 0.031*"method" + 0.024*"var"
INFO: topic #1 (0.111): 0.062*"effect" + 0.043*"definition" + 0.032*"update" + 0.025*"point" + 0.023*"reading" + 0.021*"thread" + 0.021*"user" + 0.018*"bolt" + 0.018*"borderline" + 0.018*"extent"
INFO: topic #2 (0.538): 0.089*"language" + 0.067*"class" + 0.037*"work" + 0.035*"method" + 0.034*"return" + 0.032*"solution" + 0.030*"attribute" + 0.029*"question" + 0.026*"post" + 0.020*"problem"
INFO: topic #3 (0.191): 0.059*"thing" + 0.038*"namespace" + 0.031*"int" + 0.026*"integer" + 0.024*"setattr" + 0.024*"line" + 0.024*"c" + 0.024*"print" + 0.023*"member" + 0.019*"property"
INFO: topic #4 (1.304): 0.177*"object" + 0.119*"function" + 0.117*"value" + 0.063*"variable" + 0.052*"change" + 0.048*"parameter" + 0.040*"answer" + 0.025*"instance" + 0.020*"call" + 0.020*"pass"
INFO: topic diff=0.270151, rho=0.241121
DEBUG: bound: at document #0
INFO: -5.784 per-word bound, 55.1 perplexity estimate based on a held-out corpus of 5 documents with 178 words
INFO: PROGRESS: pass 4, at document #40/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0358225, 0.122554496, 0.50396794, 0.18941551, 1.2685597]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.036): 0.215*"reference" + 0.056*"list" + 0.048*"name" + 0.042*"string" + 0.036*"example" + 0.034*"argument" + 0.033*"assignment" + 0.033*"target" + 0.033*"way" + 0.030*"method"
INFO: topic #1 (0.123): 0.075*"point" + 0.066*"update" + 0.046*"effect" + 0.033*"user" + 0.032*"definition" + 0.025*"wrap" + 0.024*"support" + 0.017*"reading" + 0.016*"thread" + 0.013*"vote"
INFO: topic #2 (0.504): 0.086*"language" + 0.055*"class" + 0.043*"work" + 0.040*"case" + 0.036*"method" + 0.028*"return" + 0.027*"solution" + 0.025*"attribute" + 0.024*"question" + 0.023*"show"
INFO: topic #3 (0.189): 0.077*"integer" + 0.048*"database" + 0.048*"entry" + 0.045*"print" + 0.037*"namespace" + 0.034*"thing" + 0.018*"int" + 0.015*"math" + 0.015*"style" + 0.015*"connection"
INFO: topic #4 (1.269): 0.204*"object" + 0.156*"value" + 0.095*"function" + 0.062*"variable" + 0.042*"change" + 0.038*"answer" + 0.035*"parameter" + 0.030*"type" + 0.019*"call" + 0.018*"instance"
INFO: topic diff=0.393980, rho=0.241121
DEBUG: bound: at document #0
INFO: -6.466 per-word bound, 88.4 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 4, at document #45/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0229563, 0.117042355, 0.5694543, 0.1766085, 1.3441226]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.023): 0.214*"reference" + 0.048*"list" + 0.041*"name" + 0.039*"argument" + 0.036*"example" + 0.036*"string" + 0.033*"way" + 0.029*"assignment" + 0.028*"target" + 0.027*"memory"
INFO: topic #1 (0.117): 0.066*"point" + 0.059*"update" + 0.041*"effect" + 0.030*"user" + 0.028*"definition" + 0.023*"wrap" + 0.022*"support" + 0.016*"reading" + 0.014*"thread" + 0.012*"vote"
INFO: topic #2 (0.569): 0.057*"language" + 0.051*"return" + 0.048*"case" + 0.044*"array" + 0.037*"class" + 0.033*"my_fun" + 0.029*"work" + 0.024*"method" + 0.022*"problem" + 0.021*"operator"
INFO: topic #3 (0.177): 0.070*"integer" + 0.043*"database" + 0.043*"entry" + 0.041*"print" + 0.034*"namespace" + 0.031*"thing" + 0.016*"int" + 0.014*"math" + 0.014*"style" + 0.014*"connection"
INFO: topic #4 (1.344): 0.196*"object" + 0.155*"value" + 0.104*"function" + 0.053*"variable" + 0.048*"parameter" + 0.045*"change" + 0.037*"answer" + 0.025*"type" + 0.020*"call" + 0.020*"instance"
INFO: topic diff=0.253485, rho=0.241121
DEBUG: bound: at document #0
INFO: -6.442 per-word bound, 87.0 perplexity estimate based on a held-out corpus of 5 documents with 98 words
INFO: PROGRESS: pass 4, at document #50/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0889517, 0.11866875, 0.6171335, 0.16654636, 1.4406326]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.089): 0.191*"reference" + 0.061*"list" + 0.046*"string" + 0.045*"name" + 0.038*"way" + 0.038*"argument" + 0.035*"example" + 0.029*"assignment" + 0.029*"code" + 0.025*"method"
INFO: topic #1 (0.119): 0.055*"point" + 0.049*"update" + 0.041*"support" + 0.034*"effect" + 0.026*"reason" + 0.025*"user" + 0.024*"definition" + 0.019*"wrap" + 0.013*"reading" + 0.012*"thread"
INFO: topic #2 (0.617): 0.068*"return" + 0.050*"class" + 0.045*"language" + 0.031*"case" + 0.029*"context" + 0.028*"array" + 0.028*"perl" + 0.021*"my_fun" + 0.019*"show" + 0.018*"work"
INFO: topic #3 (0.167): 0.062*"integer" + 0.039*"database" + 0.039*"entry" + 0.036*"print" + 0.031*"namespace" + 0.028*"thing" + 0.015*"int" + 0.013*"math" + 0.013*"style" + 0.013*"connection"
INFO: topic #4 (1.441): 0.170*"object" + 0.156*"value" + 0.119*"function" + 0.058*"variable" + 0.049*"parameter" + 0.042*"change" + 0.030*"answer" + 0.026*"call" + 0.026*"type" + 0.019*"pass"
INFO: topic diff=0.283326, rho=0.241121
DEBUG: bound: at document #0
INFO: -6.172 per-word bound, 72.1 perplexity estimate based on a held-out corpus of 5 documents with 80 words
INFO: PROGRESS: pass 4, at document #55/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0639353, 0.119340286, 0.61202157, 0.16599058, 1.4991233]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.064): 0.172*"reference" + 0.053*"list" + 0.052*"argument" + 0.046*"way" + 0.045*"name" + 0.044*"code" + 0.040*"string" + 0.031*"example" + 0.025*"assignment" + 0.022*"method"
INFO: topic #1 (0.119): 0.044*"definition" + 0.044*"point" + 0.039*"update" + 0.033*"idea" + 0.033*"support" + 0.028*"effect" + 0.025*"dll" + 0.021*"reason" + 0.020*"user" + 0.016*"wrap"
INFO: topic #2 (0.612): 0.114*"return" + 0.041*"class" + 0.037*"language" + 0.025*"case" + 0.024*"context" + 0.024*"practice" + 0.023*"array" + 0.023*"perl" + 0.021*"problem" + 0.021*"situation"
INFO: topic #3 (0.166): 0.046*"integer" + 0.046*"ctype" + 0.029*"entry" + 0.029*"database" + 0.027*"print" + 0.027*"pointer" + 0.025*"input" + 0.023*"namespace" + 0.021*"thing" + 0.019*"byref"
INFO: topic #4 (1.499): 0.155*"value" + 0.130*"object" + 0.127*"function" + 0.053*"parameter" + 0.045*"variable" + 0.040*"type" + 0.037*"change" + 0.030*"call" + 0.030*"pass" + 0.023*"answer"
INFO: topic diff=0.208495, rho=0.241121
DEBUG: bound: at document #0
INFO: -5.612 per-word bound, 48.9 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 4, at document #60/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.8674965, 0.11175498, 0.56273454, 0.18108349, 1.5577137]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.867): 0.161*"reference" + 0.056*"way" + 0.054*"argument" + 0.048*"list" + 0.041*"name" + 0.039*"code" + 0.036*"string" + 0.027*"example" + 0.025*"store" + 0.023*"assignment"
INFO: topic #1 (0.112): 0.038*"definition" + 0.038*"point" + 0.034*"update" + 0.029*"idea" + 0.028*"support" + 0.024*"effect" + 0.022*"dll" + 0.018*"reason" + 0.018*"user" + 0.014*"wrap"
INFO: topic #2 (0.563): 0.130*"return" + 0.054*"case" + 0.036*"class" + 0.032*"language" + 0.024*"work" + 0.021*"context" + 0.020*"practice" + 0.020*"array" + 0.020*"perl" + 0.018*"problem"
INFO: topic #3 (0.181): 0.083*"command" + 0.063*"input" + 0.059*"integer" + 0.053*"line" + 0.050*"script" + 0.032*"print" + 0.027*"ctype" + 0.017*"database" + 0.017*"entry" + 0.017*"condition"
INFO: topic #4 (1.558): 0.152*"function" + 0.145*"value" + 0.128*"object" + 0.066*"variable" + 0.040*"parameter" + 0.030*"change" + 0.028*"arg" + 0.027*"type" + 0.025*"pass" + 0.021*"instance"
INFO: topic diff=0.261319, rho=0.241121
DEBUG: bound: at document #0
INFO: -7.420 per-word bound, 171.2 perplexity estimate based on a held-out corpus of 1 documents with 12 words
INFO: PROGRESS: pass 4, at document #61/61
INFO: optimized alpha [0.8103584, 0.104738444, 0.52722526, 0.22181967, 1.1384012]
DEBUG: updating topics
INFO: merging changes from 1 documents into a model of 61 documents
INFO: topic #0 (0.810): 0.137*"reference" + 0.088*"argument" + 0.048*"way" + 0.046*"issue" + 0.041*"output" + 0.041*"list" + 0.035*"name" + 0.034*"code" + 0.030*"string" + 0.023*"example"
INFO: topic #1 (0.105): 0.032*"definition" + 0.032*"point" + 0.029*"update" + 0.024*"idea" + 0.024*"support" + 0.021*"effect" + 0.019*"dll" + 0.016*"reason" + 0.015*"user" + 0.012*"wrap"
INFO: topic #2 (0.527): 0.114*"return" + 0.066*"solution" + 0.047*"case" + 0.031*"class" + 0.028*"language" + 0.021*"work" + 0.018*"context" + 0.018*"practice" + 0.017*"array" + 0.017*"perl"
INFO: topic #3 (0.222): 0.086*"line" + 0.059*"dict.hpp" + 0.059*"test" + 0.059*"os" + 0.059*"look" + 0.059*"dict.i" + 0.059*"window" + 0.045*"command" + 0.034*"input" + 0.032*"integer"
INFO: topic #4 (1.138): 0.142*"function" + 0.135*"value" + 0.119*"object" + 0.061*"variable" + 0.042*"result" + 0.038*"parameter" + 0.030*"output" + 0.028*"change" + 0.026*"arg" + 0.025*"type"
INFO: topic diff=0.210869, rho=0.241121
DEBUG: bound: at document #0
INFO: -6.175 per-word bound, 72.2 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 5, at document #5/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7413189, 0.09921135, 0.41545603, 0.19816567, 0.98202044]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.741): 0.134*"reference" + 0.077*"argument" + 0.044*"list" + 0.041*"way" + 0.036*"assignment" + 0.033*"issue" + 0.032*"name" + 0.031*"code" + 0.029*"output" + 0.029*"string"
INFO: topic #1 (0.099): 0.027*"definition" + 0.027*"point" + 0.024*"update" + 0.021*"idea" + 0.021*"support" + 0.018*"effect" + 0.016*"dll" + 0.014*"reason" + 0.013*"user" + 0.010*"wrap"
INFO: topic #2 (0.415): 0.105*"return" + 0.061*"solution" + 0.044*"case" + 0.029*"class" + 0.026*"language" + 0.020*"work" + 0.017*"context" + 0.017*"practice" + 0.016*"array" + 0.016*"perl"
INFO: topic #3 (0.198): 0.080*"line" + 0.055*"dict.hpp" + 0.055*"test" + 0.055*"os" + 0.055*"look" + 0.055*"dict.i" + 0.055*"window" + 0.042*"command" + 0.032*"input" + 0.030*"integer"
INFO: topic #4 (0.982): 0.127*"function" + 0.106*"value" + 0.100*"object" + 0.056*"variable" + 0.051*"instance" + 0.035*"type" + 0.033*"parameter" + 0.031*"result" + 0.030*"answer" + 0.028*"c++"
INFO: topic diff=0.226570, rho=0.234404
DEBUG: bound: at document #0
INFO: -6.628 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 5, at document #10/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.6509315, 0.0933047, 0.465738, 0.18753427, 0.88796216]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.651): 0.149*"reference" + 0.075*"argument" + 0.069*"way" + 0.038*"list" + 0.031*"assignment" + 0.028*"issue" + 0.028*"name" + 0.027*"code" + 0.025*"output" + 0.025*"string"
INFO: topic #1 (0.093): 0.023*"definition" + 0.023*"point" + 0.020*"update" + 0.017*"idea" + 0.017*"support" + 0.015*"effect" + 0.014*"dll" + 0.012*"reason" + 0.011*"user" + 0.009*"wrap"
INFO: topic #2 (0.466): 0.061*"solution" + 0.055*"return" + 0.029*"language" + 0.028*"case" + 0.026*"work" + 0.022*"method" + 0.022*"need" + 0.022*"class" + 0.019*"side" + 0.018*"dataclasse"
INFO: topic #3 (0.188): 0.068*"line" + 0.047*"dict.hpp" + 0.047*"test" + 0.047*"os" + 0.047*"look" + 0.047*"dict.i" + 0.047*"window" + 0.040*"integer" + 0.036*"command" + 0.027*"input"
INFO: topic #4 (0.888): 0.115*"function" + 0.109*"value" + 0.093*"object" + 0.075*"instance" + 0.057*"variable" + 0.044*"parameter" + 0.039*"type" + 0.032*"change" + 0.030*"answer" + 0.026*"result"
INFO: topic diff=0.308160, rho=0.234404
DEBUG: bound: at document #0
INFO: -5.297 per-word bound, 39.3 perplexity estimate based on a held-out corpus of 5 documents with 187 words
INFO: PROGRESS: pass 5, at document #15/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.70140386, 0.09928206, 0.48206916, 0.1677633, 0.9575277]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.701): 0.225*"reference" + 0.078*"way" + 0.052*"argument" + 0.042*"name" + 0.037*"assignment" + 0.034*"code" + 0.030*"example" + 0.026*"list" + 0.025*"string" + 0.020*"documentation"
INFO: topic #1 (0.099): 0.044*"idea" + 0.043*"effect" + 0.038*"hand" + 0.028*"point" + 0.025*"support" + 0.023*"reason" + 0.022*"wrap" + 0.021*"reading" + 0.020*"time" + 0.019*"lot"
INFO: topic #2 (0.482): 0.058*"return" + 0.046*"solution" + 0.041*"class" + 0.041*"access" + 0.034*"attribute" + 0.030*"side" + 0.030*"language" + 0.030*"case" + 0.028*"work" + 0.025*"need"
INFO: topic #3 (0.168): 0.062*"line" + 0.043*"dict.hpp" + 0.043*"test" + 0.043*"os" + 0.043*"look" + 0.043*"dict.i" + 0.043*"window" + 0.037*"integer" + 0.033*"command" + 0.025*"input"
INFO: topic #4 (0.958): 0.148*"function" + 0.123*"object" + 0.099*"value" + 0.086*"variable" + 0.047*"instance" + 0.046*"parameter" + 0.039*"type" + 0.023*"change" + 0.022*"c++" + 0.021*"answer"
INFO: topic diff=0.430800, rho=0.234404
DEBUG: bound: at document #0
INFO: -5.916 per-word bound, 60.4 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 5, at document #20/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7490542, 0.104435496, 0.47131544, 0.17599787, 0.9303458]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.749): 0.186*"reference" + 0.102*"argument" + 0.062*"name" + 0.053*"way" + 0.037*"string" + 0.032*"assignment" + 0.030*"code" + 0.027*"example" + 0.025*"list" + 0.023*"var"
INFO: topic #1 (0.104): 0.075*"effect" + 0.037*"idea" + 0.036*"time" + 0.032*"hand" + 0.023*"point" + 0.021*"support" + 0.020*"reason" + 0.019*"wrap" + 0.018*"reading" + 0.016*"consideration"
INFO: topic #2 (0.471): 0.054*"class" + 0.050*"return" + 0.049*"solution" + 0.043*"work" + 0.036*"access" + 0.035*"language" + 0.035*"case" + 0.029*"attribute" + 0.026*"side" + 0.022*"need"
INFO: topic #3 (0.176): 0.066*"namespace" + 0.043*"line" + 0.040*"print" + 0.033*"field" + 0.033*"property" + 0.029*"test" + 0.029*"os" + 0.029*"look" + 0.029*"dict.i" + 0.029*"dict.hpp"
INFO: topic #4 (0.930): 0.168*"object" + 0.140*"function" + 0.095*"value" + 0.080*"variable" + 0.039*"instance" + 0.038*"parameter" + 0.032*"type" + 0.023*"change" + 0.021*"pass" + 0.018*"c++"
INFO: topic diff=0.231445, rho=0.234404
DEBUG: bound: at document #0
INFO: -5.781 per-word bound, 55.0 perplexity estimate based on a held-out corpus of 5 documents with 122 words
INFO: PROGRESS: pass 5, at document #25/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.82680804, 0.099857055, 0.47610438, 0.19260179, 1.0131509]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.827): 0.148*"reference" + 0.101*"name" + 0.069*"argument" + 0.058*"list" + 0.043*"string" + 0.042*"way" + 0.039*"assignment" + 0.027*"var" + 0.026*"code" + 0.024*"example"
INFO: topic #1 (0.100): 0.067*"effect" + 0.033*"idea" + 0.032*"time" + 0.029*"hand" + 0.021*"point" + 0.019*"support" + 0.018*"reason" + 0.017*"wrap" + 0.016*"reading" + 0.015*"consideration"
INFO: topic #2 (0.476): 0.065*"class" + 0.050*"solution" + 0.046*"work" + 0.042*"return" + 0.039*"language" + 0.034*"attribute" + 0.032*"question" + 0.029*"access" + 0.029*"case" + 0.025*"method"
INFO: topic #3 (0.193): 0.050*"namespace" + 0.039*"int" + 0.035*"integer" + 0.032*"line" + 0.031*"setattr" + 0.031*"print" + 0.029*"member" + 0.025*"field" + 0.025*"property" + 0.024*"thing"
INFO: topic #4 (1.013): 0.159*"object" + 0.151*"function" + 0.099*"value" + 0.088*"variable" + 0.042*"parameter" + 0.035*"change" + 0.034*"instance" + 0.033*"type" + 0.021*"pass" + 0.016*"result"
INFO: topic diff=0.262982, rho=0.234404
DEBUG: bound: at document #0
INFO: -5.190 per-word bound, 36.5 perplexity estimate based on a held-out corpus of 5 documents with 167 words
INFO: PROGRESS: pass 5, at document #30/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.9444003, 0.10670587, 0.5044353, 0.18807347, 1.153681]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.944): 0.204*"reference" + 0.062*"name" + 0.059*"list" + 0.050*"string" + 0.047*"argument" + 0.044*"way" + 0.041*"method" + 0.034*"example" + 0.029*"assignment" + 0.026*"var"
INFO: topic #1 (0.107): 0.088*"effect" + 0.045*"update" + 0.035*"point" + 0.032*"reading" + 0.028*"thread" + 0.023*"idea" + 0.023*"time" + 0.021*"process" + 0.021*"simulate" + 0.020*"hand"
INFO: topic #2 (0.504): 0.084*"class" + 0.047*"work" + 0.044*"return" + 0.042*"language" + 0.041*"solution" + 0.038*"attribute" + 0.037*"question" + 0.036*"method" + 0.026*"problem" + 0.024*"access"
INFO: topic #3 (0.188): 0.045*"thing" + 0.044*"namespace" + 0.035*"int" + 0.031*"integer" + 0.029*"line" + 0.028*"setattr" + 0.027*"print" + 0.026*"member" + 0.022*"property" + 0.022*"field"
INFO: topic #4 (1.154): 0.178*"object" + 0.131*"function" + 0.107*"value" + 0.070*"variable" + 0.066*"change" + 0.050*"parameter" + 0.032*"instance" + 0.024*"type" + 0.022*"call" + 0.017*"copy"
INFO: topic diff=0.288841, rho=0.234404
DEBUG: bound: at document #0
INFO: -6.401 per-word bound, 84.5 perplexity estimate based on a held-out corpus of 5 documents with 85 words
INFO: PROGRESS: pass 5, at document #35/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.9687768, 0.10900687, 0.53038204, 0.18416406, 1.2864873]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.969): 0.211*"reference" + 0.055*"name" + 0.053*"list" + 0.048*"argument" + 0.045*"way" + 0.045*"string" + 0.036*"method" + 0.036*"example" + 0.031*"assignment" + 0.024*"var"
INFO: topic #1 (0.109): 0.062*"effect" + 0.042*"definition" + 0.032*"update" + 0.025*"point" + 0.023*"reading" + 0.021*"user" + 0.020*"thread" + 0.018*"vote" + 0.018*"piece" + 0.018*"bolt"
INFO: topic #2 (0.530): 0.089*"language" + 0.067*"class" + 0.038*"work" + 0.035*"return" + 0.032*"solution" + 0.031*"attribute" + 0.029*"question" + 0.029*"method" + 0.026*"post" + 0.020*"problem"
INFO: topic #3 (0.184): 0.040*"thing" + 0.039*"namespace" + 0.031*"int" + 0.027*"integer" + 0.025*"line" + 0.025*"setattr" + 0.024*"print" + 0.024*"c" + 0.023*"member" + 0.020*"property"
INFO: topic #4 (1.286): 0.177*"object" + 0.120*"function" + 0.117*"value" + 0.063*"variable" + 0.052*"change" + 0.048*"parameter" + 0.040*"answer" + 0.025*"instance" + 0.021*"call" + 0.020*"pass"
INFO: topic diff=0.256308, rho=0.234404
DEBUG: bound: at document #0
INFO: -5.746 per-word bound, 53.7 perplexity estimate based on a held-out corpus of 5 documents with 178 words
INFO: PROGRESS: pass 5, at document #40/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0288873, 0.12035403, 0.49818933, 0.18280344, 1.2507384]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.029): 0.212*"reference" + 0.055*"list" + 0.048*"name" + 0.041*"string" + 0.036*"example" + 0.034*"argument" + 0.034*"method" + 0.033*"assignment" + 0.033*"way" + 0.032*"target"
INFO: topic #1 (0.120): 0.074*"point" + 0.064*"update" + 0.046*"effect" + 0.033*"user" + 0.031*"definition" + 0.025*"wrap" + 0.024*"support" + 0.017*"reading" + 0.015*"thread" + 0.014*"incorrect"
INFO: topic #2 (0.498): 0.085*"language" + 0.056*"class" + 0.043*"work" + 0.039*"case" + 0.029*"return" + 0.029*"method" + 0.027*"solution" + 0.025*"attribute" + 0.025*"question" + 0.023*"show"
INFO: topic #3 (0.183): 0.076*"integer" + 0.047*"entry" + 0.047*"database" + 0.044*"print" + 0.038*"namespace" + 0.023*"thing" + 0.018*"int" + 0.017*"pointer" + 0.015*"clarifie" + 0.015*"connection"
INFO: topic #4 (1.251): 0.205*"object" + 0.156*"value" + 0.097*"function" + 0.063*"variable" + 0.043*"change" + 0.038*"answer" + 0.036*"parameter" + 0.030*"type" + 0.020*"call" + 0.019*"instance"
INFO: topic diff=0.370610, rho=0.234404
DEBUG: bound: at document #0
INFO: -6.420 per-word bound, 85.6 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 5, at document #45/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0162581, 0.115147345, 0.5607188, 0.17109244, 1.3247114]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.016): 0.211*"reference" + 0.047*"list" + 0.041*"name" + 0.039*"argument" + 0.036*"example" + 0.035*"string" + 0.033*"way" + 0.029*"method" + 0.028*"assignment" + 0.028*"target"
INFO: topic #1 (0.115): 0.066*"point" + 0.057*"update" + 0.042*"effect" + 0.030*"user" + 0.028*"definition" + 0.023*"wrap" + 0.022*"support" + 0.016*"reading" + 0.014*"thread" + 0.012*"incorrect"
INFO: topic #2 (0.561): 0.058*"language" + 0.051*"return" + 0.048*"case" + 0.043*"array" + 0.038*"class" + 0.032*"my_fun" + 0.029*"work" + 0.023*"item" + 0.022*"problem" + 0.021*"operator"
INFO: topic #3 (0.171): 0.069*"integer" + 0.043*"entry" + 0.043*"database" + 0.040*"print" + 0.034*"namespace" + 0.021*"thing" + 0.017*"int" + 0.016*"pointer" + 0.014*"clarifie" + 0.014*"connection"
INFO: topic #4 (1.325): 0.196*"object" + 0.155*"value" + 0.105*"function" + 0.054*"variable" + 0.048*"parameter" + 0.045*"change" + 0.037*"answer" + 0.026*"type" + 0.021*"call" + 0.021*"instance"
INFO: topic diff=0.240229, rho=0.234404
DEBUG: bound: at document #0
INFO: -6.404 per-word bound, 84.7 perplexity estimate based on a held-out corpus of 5 documents with 98 words
INFO: PROGRESS: pass 5, at document #50/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0806106, 0.11672133, 0.6066286, 0.16183603, 1.4180342]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.081): 0.189*"reference" + 0.060*"list" + 0.045*"string" + 0.044*"name" + 0.038*"way" + 0.038*"argument" + 0.035*"example" + 0.029*"method" + 0.029*"assignment" + 0.028*"code"
INFO: topic #1 (0.117): 0.055*"point" + 0.048*"update" + 0.040*"support" + 0.035*"effect" + 0.025*"reason" + 0.025*"user" + 0.024*"definition" + 0.019*"wrap" + 0.013*"reading" + 0.012*"thread"
INFO: topic #2 (0.607): 0.068*"return" + 0.050*"class" + 0.046*"language" + 0.031*"case" + 0.029*"context" + 0.028*"array" + 0.027*"perl" + 0.021*"my_fun" + 0.019*"show" + 0.019*"work"
INFO: topic #3 (0.162): 0.062*"integer" + 0.039*"entry" + 0.039*"database" + 0.036*"print" + 0.031*"namespace" + 0.019*"thing" + 0.015*"int" + 0.014*"pointer" + 0.013*"clarifie" + 0.013*"connection"
INFO: topic #4 (1.418): 0.171*"object" + 0.157*"value" + 0.120*"function" + 0.059*"variable" + 0.049*"parameter" + 0.042*"change" + 0.030*"answer" + 0.027*"call" + 0.026*"type" + 0.019*"pass"
INFO: topic diff=0.266970, rho=0.234404
DEBUG: bound: at document #0
INFO: -6.146 per-word bound, 70.8 perplexity estimate based on a held-out corpus of 5 documents with 80 words
INFO: PROGRESS: pass 5, at document #55/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0549651, 0.11738119, 0.6008113, 0.16150814, 1.4715897]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.055): 0.171*"reference" + 0.053*"list" + 0.051*"argument" + 0.045*"way" + 0.045*"name" + 0.043*"code" + 0.039*"string" + 0.030*"example" + 0.025*"method" + 0.025*"assignment"
INFO: topic #1 (0.117): 0.044*"point" + 0.044*"definition" + 0.039*"update" + 0.033*"idea" + 0.032*"support" + 0.028*"effect" + 0.025*"dll" + 0.021*"reason" + 0.020*"user" + 0.016*"wrap"
INFO: topic #2 (0.601): 0.113*"return" + 0.042*"class" + 0.038*"language" + 0.025*"case" + 0.024*"context" + 0.023*"practice" + 0.023*"array" + 0.023*"perl" + 0.021*"problem" + 0.021*"situation"
INFO: topic #3 (0.162): 0.046*"integer" + 0.044*"ctype" + 0.034*"pointer" + 0.029*"entry" + 0.029*"database" + 0.027*"print" + 0.025*"input" + 0.023*"namespace" + 0.019*"byref" + 0.019*"set"
INFO: topic #4 (1.472): 0.156*"value" + 0.133*"object" + 0.128*"function" + 0.053*"parameter" + 0.046*"variable" + 0.040*"type" + 0.038*"change" + 0.031*"call" + 0.030*"pass" + 0.024*"answer"
INFO: topic diff=0.196592, rho=0.234404
DEBUG: bound: at document #0
INFO: -5.573 per-word bound, 47.6 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 5, at document #60/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.8643527, 0.11018714, 0.5540337, 0.17584762, 1.5289953]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.864): 0.161*"reference" + 0.055*"way" + 0.053*"argument" + 0.048*"list" + 0.041*"name" + 0.039*"code" + 0.036*"string" + 0.027*"example" + 0.024*"output" + 0.024*"store"
INFO: topic #1 (0.110): 0.038*"point" + 0.038*"definition" + 0.034*"update" + 0.028*"idea" + 0.028*"support" + 0.025*"effect" + 0.022*"dll" + 0.018*"reason" + 0.018*"user" + 0.014*"wrap"
INFO: topic #2 (0.554): 0.128*"return" + 0.054*"case" + 0.036*"class" + 0.033*"language" + 0.024*"work" + 0.021*"context" + 0.020*"practice" + 0.020*"array" + 0.020*"perl" + 0.019*"problem"
INFO: topic #3 (0.176): 0.081*"command" + 0.061*"input" + 0.059*"integer" + 0.052*"line" + 0.049*"script" + 0.032*"print" + 0.027*"ctype" + 0.021*"pointer" + 0.017*"database" + 0.017*"entry"
INFO: topic #4 (1.529): 0.152*"function" + 0.145*"value" + 0.130*"object" + 0.066*"variable" + 0.041*"parameter" + 0.030*"change" + 0.027*"type" + 0.027*"arg" + 0.025*"pass" + 0.021*"instance"
INFO: topic diff=0.246246, rho=0.234404
DEBUG: bound: at document #0
INFO: -7.356 per-word bound, 163.8 perplexity estimate based on a held-out corpus of 1 documents with 12 words
INFO: PROGRESS: pass 5, at document #61/61
INFO: optimized alpha [0.8096523, 0.103507005, 0.5178658, 0.21437383, 1.1291422]
DEBUG: updating topics
INFO: merging changes from 1 documents into a model of 61 documents
INFO: topic #0 (0.810): 0.138*"reference" + 0.086*"argument" + 0.047*"way" + 0.044*"issue" + 0.044*"output" + 0.041*"list" + 0.035*"name" + 0.033*"code" + 0.031*"string" + 0.024*"example"
INFO: topic #1 (0.104): 0.033*"point" + 0.032*"definition" + 0.029*"update" + 0.024*"idea" + 0.024*"support" + 0.021*"effect" + 0.019*"dll" + 0.016*"reason" + 0.016*"user" + 0.012*"wrap"
INFO: topic #2 (0.518): 0.113*"return" + 0.064*"solution" + 0.047*"case" + 0.032*"class" + 0.029*"language" + 0.021*"work" + 0.018*"context" + 0.018*"practice" + 0.018*"array" + 0.017*"perl"
INFO: topic #3 (0.214): 0.085*"line" + 0.058*"dict.hpp" + 0.058*"test" + 0.058*"os" + 0.058*"look" + 0.058*"dict.i" + 0.058*"window" + 0.045*"command" + 0.034*"input" + 0.032*"integer"
INFO: topic #4 (1.129): 0.142*"function" + 0.136*"value" + 0.121*"object" + 0.062*"variable" + 0.041*"result" + 0.038*"parameter" + 0.029*"output" + 0.028*"change" + 0.025*"type" + 0.025*"arg"
INFO: topic diff=0.202206, rho=0.234404
DEBUG: bound: at document #0
INFO: -6.144 per-word bound, 70.7 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 6, at document #5/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.742181, 0.098241456, 0.41196832, 0.19275074, 0.97895455]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.742): 0.134*"reference" + 0.075*"argument" + 0.043*"list" + 0.041*"way" + 0.035*"assignment" + 0.032*"name" + 0.032*"issue" + 0.032*"output" + 0.031*"code" + 0.029*"string"
INFO: topic #1 (0.098): 0.028*"point" + 0.028*"definition" + 0.024*"update" + 0.021*"idea" + 0.021*"support" + 0.018*"effect" + 0.016*"dll" + 0.014*"reason" + 0.014*"user" + 0.011*"wrap"
INFO: topic #2 (0.412): 0.105*"return" + 0.059*"solution" + 0.044*"case" + 0.030*"class" + 0.027*"language" + 0.020*"work" + 0.017*"context" + 0.017*"practice" + 0.017*"array" + 0.016*"perl"
INFO: topic #3 (0.193): 0.079*"line" + 0.054*"dict.hpp" + 0.054*"test" + 0.054*"os" + 0.054*"look" + 0.054*"dict.i" + 0.054*"window" + 0.042*"command" + 0.032*"input" + 0.030*"integer"
INFO: topic #4 (0.979): 0.128*"function" + 0.108*"value" + 0.102*"object" + 0.057*"variable" + 0.051*"instance" + 0.035*"type" + 0.034*"parameter" + 0.031*"result" + 0.030*"answer" + 0.028*"c++"
INFO: topic diff=0.215466, rho=0.228218
DEBUG: bound: at document #0
INFO: -6.599 per-word bound, 96.9 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 6, at document #10/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.65655196, 0.092601635, 0.46076053, 0.1831412, 0.8877449]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.657): 0.148*"reference" + 0.073*"argument" + 0.068*"way" + 0.038*"list" + 0.031*"assignment" + 0.028*"name" + 0.028*"issue" + 0.028*"output" + 0.027*"code" + 0.025*"string"
INFO: topic #1 (0.093): 0.024*"point" + 0.023*"definition" + 0.021*"update" + 0.018*"idea" + 0.018*"support" + 0.016*"effect" + 0.014*"dll" + 0.012*"reason" + 0.012*"user" + 0.009*"wrap"
INFO: topic #2 (0.461): 0.060*"solution" + 0.056*"return" + 0.029*"language" + 0.028*"case" + 0.026*"work" + 0.022*"need" + 0.022*"class" + 0.020*"method" + 0.018*"side" + 0.018*"dataclasse"
INFO: topic #3 (0.183): 0.068*"line" + 0.046*"dict.hpp" + 0.046*"test" + 0.046*"os" + 0.046*"look" + 0.046*"dict.i" + 0.046*"window" + 0.040*"integer" + 0.036*"command" + 0.027*"input"
INFO: topic #4 (0.888): 0.116*"function" + 0.110*"value" + 0.095*"object" + 0.074*"instance" + 0.058*"variable" + 0.044*"parameter" + 0.039*"type" + 0.033*"change" + 0.030*"answer" + 0.026*"result"
INFO: topic diff=0.293969, rho=0.228218
DEBUG: bound: at document #0
INFO: -5.276 per-word bound, 38.8 perplexity estimate based on a held-out corpus of 5 documents with 187 words
INFO: PROGRESS: pass 6, at document #15/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.705584, 0.09840478, 0.4767493, 0.16473639, 0.9549537]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.706): 0.222*"reference" + 0.077*"way" + 0.052*"argument" + 0.042*"name" + 0.036*"assignment" + 0.034*"code" + 0.029*"example" + 0.027*"list" + 0.025*"string" + 0.020*"issue"
INFO: topic #1 (0.098): 0.043*"idea" + 0.042*"effect" + 0.038*"hand" + 0.028*"point" + 0.025*"support" + 0.023*"reason" + 0.022*"wrap" + 0.021*"reading" + 0.020*"time" + 0.019*"bar"
INFO: topic #2 (0.477): 0.059*"return" + 0.046*"solution" + 0.041*"class" + 0.041*"access" + 0.033*"attribute" + 0.030*"language" + 0.030*"side" + 0.030*"case" + 0.028*"work" + 0.025*"need"
INFO: topic #3 (0.165): 0.062*"line" + 0.042*"dict.hpp" + 0.042*"test" + 0.042*"os" + 0.042*"look" + 0.042*"dict.i" + 0.042*"window" + 0.037*"integer" + 0.033*"command" + 0.025*"input"
INFO: topic #4 (0.955): 0.148*"function" + 0.123*"object" + 0.100*"value" + 0.086*"variable" + 0.047*"instance" + 0.046*"parameter" + 0.039*"type" + 0.023*"change" + 0.021*"c++" + 0.021*"answer"
INFO: topic diff=0.410757, rho=0.228218
DEBUG: bound: at document #0
INFO: -5.889 per-word bound, 59.2 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 6, at document #20/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7520163, 0.10342385, 0.46968862, 0.1727872, 0.929701]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.752): 0.185*"reference" + 0.101*"argument" + 0.061*"name" + 0.053*"way" + 0.037*"string" + 0.032*"assignment" + 0.030*"code" + 0.027*"example" + 0.025*"list" + 0.023*"var"
INFO: topic #1 (0.103): 0.074*"effect" + 0.036*"idea" + 0.036*"time" + 0.032*"hand" + 0.024*"point" + 0.021*"support" + 0.019*"reason" + 0.019*"wrap" + 0.018*"reading" + 0.016*"clutter"
INFO: topic #2 (0.470): 0.054*"class" + 0.051*"return" + 0.048*"solution" + 0.043*"work" + 0.036*"language" + 0.035*"access" + 0.035*"case" + 0.029*"attribute" + 0.026*"side" + 0.022*"need"
INFO: topic #3 (0.173): 0.064*"namespace" + 0.043*"line" + 0.040*"print" + 0.032*"field" + 0.032*"property" + 0.030*"test" + 0.030*"os" + 0.030*"look" + 0.030*"dict.i" + 0.030*"dict.hpp"
INFO: topic #4 (0.930): 0.167*"object" + 0.140*"function" + 0.096*"value" + 0.080*"variable" + 0.039*"instance" + 0.038*"parameter" + 0.032*"type" + 0.023*"change" + 0.021*"pass" + 0.018*"call"
INFO: topic diff=0.219224, rho=0.228218
DEBUG: bound: at document #0
INFO: -5.757 per-word bound, 54.1 perplexity estimate based on a held-out corpus of 5 documents with 122 words
INFO: PROGRESS: pass 6, at document #25/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.83093786, 0.09905875, 0.47411025, 0.18831603, 1.0097686]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.831): 0.148*"reference" + 0.098*"name" + 0.068*"argument" + 0.057*"list" + 0.042*"string" + 0.041*"way" + 0.038*"assignment" + 0.027*"var" + 0.026*"code" + 0.024*"example"
INFO: topic #1 (0.099): 0.066*"effect" + 0.033*"idea" + 0.032*"time" + 0.028*"hand" + 0.021*"point" + 0.019*"support" + 0.018*"reason" + 0.017*"wrap" + 0.016*"reading" + 0.015*"clutter"
INFO: topic #2 (0.474): 0.065*"class" + 0.050*"solution" + 0.045*"work" + 0.042*"return" + 0.039*"language" + 0.034*"attribute" + 0.032*"question" + 0.029*"access" + 0.029*"case" + 0.022*"method"
INFO: topic #3 (0.188): 0.050*"namespace" + 0.039*"int" + 0.035*"integer" + 0.033*"line" + 0.031*"setattr" + 0.031*"print" + 0.029*"member" + 0.025*"field" + 0.025*"property" + 0.023*"test"
INFO: topic #4 (1.010): 0.159*"object" + 0.151*"function" + 0.100*"value" + 0.088*"variable" + 0.042*"parameter" + 0.035*"change" + 0.034*"instance" + 0.034*"type" + 0.021*"pass" + 0.017*"result"
INFO: topic diff=0.246454, rho=0.228218
DEBUG: bound: at document #0
INFO: -5.124 per-word bound, 34.9 perplexity estimate based on a held-out corpus of 5 documents with 167 words
INFO: PROGRESS: pass 6, at document #30/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.942284, 0.105570585, 0.49895146, 0.17434523, 1.1389937]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.942): 0.200*"reference" + 0.061*"name" + 0.058*"list" + 0.049*"string" + 0.046*"argument" + 0.044*"method" + 0.044*"way" + 0.033*"example" + 0.028*"assignment" + 0.026*"var"
INFO: topic #1 (0.106): 0.087*"effect" + 0.044*"update" + 0.035*"point" + 0.032*"reading" + 0.026*"thread" + 0.023*"idea" + 0.023*"time" + 0.021*"simulate" + 0.021*"process" + 0.020*"hand"
INFO: topic #2 (0.499): 0.084*"class" + 0.047*"work" + 0.045*"return" + 0.043*"language" + 0.041*"solution" + 0.038*"attribute" + 0.037*"question" + 0.029*"method" + 0.026*"problem" + 0.024*"access"
INFO: topic #3 (0.174): 0.045*"namespace" + 0.036*"int" + 0.032*"integer" + 0.030*"line" + 0.029*"setattr" + 0.028*"print" + 0.026*"member" + 0.023*"field" + 0.023*"property" + 0.021*"test"
INFO: topic #4 (1.139): 0.178*"object" + 0.132*"function" + 0.108*"value" + 0.071*"variable" + 0.065*"change" + 0.050*"parameter" + 0.033*"instance" + 0.024*"type" + 0.022*"call" + 0.017*"copy"
INFO: topic diff=0.268599, rho=0.228218
DEBUG: bound: at document #0
INFO: -6.369 per-word bound, 82.7 perplexity estimate based on a held-out corpus of 5 documents with 85 words
INFO: PROGRESS: pass 6, at document #35/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.96590406, 0.107796825, 0.52402073, 0.17148204, 1.2666357]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.966): 0.206*"reference" + 0.055*"name" + 0.052*"list" + 0.047*"argument" + 0.045*"way" + 0.044*"string" + 0.039*"method" + 0.035*"example" + 0.031*"assignment" + 0.023*"var"
INFO: topic #1 (0.108): 0.062*"effect" + 0.041*"definition" + 0.032*"update" + 0.025*"point" + 0.023*"reading" + 0.021*"user" + 0.019*"thread" + 0.018*"extent" + 0.018*"incorrect" + 0.018*"vote"
INFO: topic #2 (0.524): 0.088*"language" + 0.067*"class" + 0.038*"work" + 0.036*"return" + 0.033*"solution" + 0.031*"attribute" + 0.029*"question" + 0.025*"post" + 0.023*"method" + 0.020*"problem"
INFO: topic #3 (0.171): 0.040*"namespace" + 0.031*"int" + 0.028*"integer" + 0.027*"line" + 0.025*"setattr" + 0.025*"print" + 0.024*"c" + 0.023*"member" + 0.020*"property" + 0.020*"field"
INFO: topic #4 (1.267): 0.177*"object" + 0.121*"function" + 0.118*"value" + 0.064*"variable" + 0.052*"change" + 0.048*"parameter" + 0.040*"answer" + 0.026*"instance" + 0.022*"call" + 0.020*"pass"
INFO: topic diff=0.243429, rho=0.228218
DEBUG: bound: at document #0
INFO: -5.715 per-word bound, 52.5 perplexity estimate based on a held-out corpus of 5 documents with 178 words
INFO: PROGRESS: pass 6, at document #40/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0235438, 0.118718676, 0.4932124, 0.17080696, 1.2316918]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.024): 0.209*"reference" + 0.055*"list" + 0.048*"name" + 0.041*"string" + 0.036*"method" + 0.035*"example" + 0.034*"argument" + 0.033*"way" + 0.033*"assignment" + 0.032*"target"
INFO: topic #1 (0.119): 0.073*"point" + 0.062*"update" + 0.047*"effect" + 0.033*"user" + 0.031*"definition" + 0.025*"wrap" + 0.024*"support" + 0.017*"reading" + 0.015*"thread" + 0.014*"incorrect"
INFO: topic #2 (0.493): 0.085*"language" + 0.056*"class" + 0.043*"work" + 0.039*"case" + 0.030*"return" + 0.027*"solution" + 0.026*"attribute" + 0.025*"question" + 0.024*"method" + 0.023*"show"
INFO: topic #3 (0.171): 0.076*"integer" + 0.047*"entry" + 0.047*"database" + 0.044*"print" + 0.038*"namespace" + 0.022*"pointer" + 0.018*"int" + 0.016*"line" + 0.015*"connection" + 0.015*"clarifie"
INFO: topic #4 (1.232): 0.205*"object" + 0.156*"value" + 0.099*"function" + 0.064*"variable" + 0.043*"change" + 0.038*"answer" + 0.036*"parameter" + 0.030*"type" + 0.020*"call" + 0.019*"instance"
INFO: topic diff=0.350975, rho=0.228218
DEBUG: bound: at document #0
INFO: -6.383 per-word bound, 83.5 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 6, at document #45/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.010987, 0.11374372, 0.5532558, 0.1607123, 1.3024246]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.011): 0.208*"reference" + 0.047*"list" + 0.041*"name" + 0.039*"argument" + 0.035*"example" + 0.035*"string" + 0.033*"way" + 0.031*"method" + 0.028*"assignment" + 0.027*"target"
INFO: topic #1 (0.114): 0.065*"point" + 0.056*"update" + 0.042*"effect" + 0.030*"user" + 0.028*"definition" + 0.022*"wrap" + 0.022*"support" + 0.016*"reading" + 0.013*"thread" + 0.013*"incorrect"
INFO: topic #2 (0.553): 0.058*"language" + 0.051*"return" + 0.047*"case" + 0.042*"array" + 0.038*"class" + 0.032*"my_fun" + 0.030*"work" + 0.024*"item" + 0.022*"problem" + 0.021*"operator"
INFO: topic #3 (0.161): 0.069*"integer" + 0.043*"entry" + 0.043*"database" + 0.041*"print" + 0.035*"namespace" + 0.020*"pointer" + 0.017*"int" + 0.014*"line" + 0.014*"connection" + 0.014*"clarifie"
INFO: topic #4 (1.302): 0.197*"object" + 0.155*"value" + 0.106*"function" + 0.055*"variable" + 0.048*"parameter" + 0.045*"change" + 0.037*"answer" + 0.026*"type" + 0.022*"call" + 0.021*"instance"
INFO: topic diff=0.228393, rho=0.228218
DEBUG: bound: at document #0
INFO: -6.370 per-word bound, 82.7 perplexity estimate based on a held-out corpus of 5 documents with 98 words
INFO: PROGRESS: pass 6, at document #50/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.072944, 0.11526344, 0.5974992, 0.15267253, 1.3930115]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.073): 0.187*"reference" + 0.060*"list" + 0.045*"string" + 0.044*"name" + 0.038*"way" + 0.038*"argument" + 0.034*"example" + 0.031*"method" + 0.028*"assignment" + 0.028*"code"
INFO: topic #1 (0.115): 0.055*"point" + 0.047*"update" + 0.039*"support" + 0.035*"effect" + 0.025*"user" + 0.025*"reason" + 0.024*"definition" + 0.019*"wrap" + 0.014*"reading" + 0.011*"thread"
INFO: topic #2 (0.597): 0.068*"return" + 0.051*"class" + 0.046*"language" + 0.031*"case" + 0.028*"context" + 0.028*"array" + 0.027*"perl" + 0.021*"my_fun" + 0.019*"work" + 0.019*"show"
INFO: topic #3 (0.153): 0.062*"integer" + 0.038*"entry" + 0.038*"database" + 0.036*"print" + 0.031*"namespace" + 0.018*"pointer" + 0.015*"int" + 0.013*"line" + 0.013*"connection" + 0.013*"clarifie"
INFO: topic #4 (1.393): 0.172*"object" + 0.157*"value" + 0.121*"function" + 0.059*"variable" + 0.050*"parameter" + 0.042*"change" + 0.030*"answer" + 0.027*"call" + 0.026*"type" + 0.019*"pass"
INFO: topic diff=0.253277, rho=0.228218
DEBUG: bound: at document #0
INFO: -6.127 per-word bound, 69.9 perplexity estimate based on a held-out corpus of 5 documents with 80 words
INFO: PROGRESS: pass 6, at document #55/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0473853, 0.115896724, 0.59162915, 0.15274686, 1.4415082]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.047): 0.170*"reference" + 0.052*"list" + 0.051*"argument" + 0.045*"way" + 0.045*"name" + 0.042*"code" + 0.039*"string" + 0.030*"example" + 0.027*"method" + 0.025*"assignment"
INFO: topic #1 (0.116): 0.045*"point" + 0.043*"definition" + 0.038*"update" + 0.032*"support" + 0.032*"idea" + 0.029*"effect" + 0.024*"dll" + 0.021*"user" + 0.020*"reason" + 0.016*"wrap"
INFO: topic #2 (0.592): 0.111*"return" + 0.042*"class" + 0.038*"language" + 0.026*"case" + 0.024*"context" + 0.023*"practice" + 0.023*"array" + 0.022*"perl" + 0.021*"problem" + 0.021*"situation"
INFO: topic #3 (0.153): 0.046*"integer" + 0.043*"ctype" + 0.042*"pointer" + 0.029*"entry" + 0.029*"database" + 0.027*"print" + 0.024*"input" + 0.023*"namespace" + 0.019*"byref" + 0.019*"set"
INFO: topic #4 (1.442): 0.157*"value" + 0.135*"object" + 0.128*"function" + 0.053*"parameter" + 0.047*"variable" + 0.040*"type" + 0.038*"change" + 0.031*"call" + 0.029*"pass" + 0.024*"answer"
INFO: topic diff=0.185853, rho=0.228218
DEBUG: bound: at document #0
INFO: -5.543 per-word bound, 46.6 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 6, at document #60/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.86121887, 0.10899326, 0.5466655, 0.16625974, 1.4962735]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.861): 0.161*"reference" + 0.054*"way" + 0.053*"argument" + 0.047*"list" + 0.040*"name" + 0.038*"code" + 0.035*"string" + 0.027*"example" + 0.026*"output" + 0.025*"method"
INFO: topic #1 (0.109): 0.039*"point" + 0.038*"definition" + 0.033*"update" + 0.028*"support" + 0.028*"idea" + 0.025*"effect" + 0.021*"dll" + 0.018*"user" + 0.018*"reason" + 0.014*"wrap"
INFO: topic #2 (0.547): 0.127*"return" + 0.053*"case" + 0.036*"class" + 0.033*"language" + 0.024*"work" + 0.020*"context" + 0.020*"practice" + 0.020*"array" + 0.020*"perl" + 0.019*"problem"
INFO: topic #3 (0.166): 0.079*"command" + 0.060*"input" + 0.058*"integer" + 0.052*"line" + 0.048*"script" + 0.032*"print" + 0.026*"ctype" + 0.026*"pointer" + 0.018*"database" + 0.018*"entry"
INFO: topic #4 (1.496): 0.152*"function" + 0.146*"value" + 0.131*"object" + 0.066*"variable" + 0.041*"parameter" + 0.030*"change" + 0.027*"type" + 0.027*"arg" + 0.025*"pass" + 0.021*"call"
INFO: topic diff=0.233816, rho=0.228218
DEBUG: bound: at document #0
INFO: -7.304 per-word bound, 158.0 perplexity estimate based on a held-out corpus of 1 documents with 12 words
INFO: PROGRESS: pass 6, at document #61/61
INFO: optimized alpha [0.8065022, 0.10253192, 0.50900006, 0.20180362, 1.1092554]
DEBUG: updating topics
INFO: merging changes from 1 documents into a model of 61 documents
INFO: topic #0 (0.807): 0.138*"reference" + 0.083*"argument" + 0.047*"output" + 0.047*"way" + 0.043*"issue" + 0.041*"list" + 0.035*"name" + 0.033*"code" + 0.031*"string" + 0.024*"example"
INFO: topic #1 (0.103): 0.033*"point" + 0.032*"definition" + 0.029*"update" + 0.024*"support" + 0.024*"idea" + 0.022*"effect" + 0.019*"dll" + 0.016*"user" + 0.016*"reason" + 0.012*"wrap"
INFO: topic #2 (0.509): 0.112*"return" + 0.060*"solution" + 0.047*"case" + 0.032*"class" + 0.030*"language" + 0.022*"work" + 0.018*"context" + 0.018*"practice" + 0.018*"array" + 0.017*"perl"
INFO: topic #3 (0.202): 0.083*"line" + 0.057*"test" + 0.057*"os" + 0.057*"look" + 0.057*"dict.i" + 0.057*"dict.hpp" + 0.057*"window" + 0.044*"command" + 0.034*"input" + 0.032*"integer"
INFO: topic #4 (1.109): 0.143*"function" + 0.137*"value" + 0.123*"object" + 0.062*"variable" + 0.041*"result" + 0.038*"parameter" + 0.029*"change" + 0.027*"output" + 0.026*"type" + 0.025*"arg"
INFO: topic diff=0.195047, rho=0.228218
DEBUG: bound: at document #0
INFO: -6.115 per-word bound, 69.3 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 7, at document #5/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7406836, 0.09747752, 0.4082947, 0.18295252, 0.96726847]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.741): 0.134*"reference" + 0.074*"argument" + 0.043*"list" + 0.041*"way" + 0.035*"assignment" + 0.034*"output" + 0.032*"name" + 0.031*"issue" + 0.031*"code" + 0.029*"string"
INFO: topic #1 (0.097): 0.028*"point" + 0.028*"definition" + 0.025*"update" + 0.021*"support" + 0.021*"idea" + 0.019*"effect" + 0.016*"dll" + 0.014*"user" + 0.014*"reason" + 0.011*"wrap"
INFO: topic #2 (0.408): 0.104*"return" + 0.056*"solution" + 0.044*"case" + 0.030*"class" + 0.028*"language" + 0.020*"work" + 0.017*"context" + 0.017*"practice" + 0.017*"array" + 0.016*"perl"
INFO: topic #3 (0.183): 0.078*"line" + 0.053*"test" + 0.053*"os" + 0.053*"look" + 0.053*"dict.i" + 0.053*"dict.hpp" + 0.053*"window" + 0.041*"command" + 0.031*"input" + 0.031*"integer"
INFO: topic #4 (0.967): 0.129*"function" + 0.109*"value" + 0.104*"object" + 0.057*"variable" + 0.050*"instance" + 0.035*"type" + 0.034*"parameter" + 0.031*"result" + 0.030*"answer" + 0.027*"c++"
INFO: topic diff=0.205525, rho=0.222497
DEBUG: bound: at document #0
INFO: -6.577 per-word bound, 95.5 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 7, at document #10/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.66802204, 0.09212385, 0.45657277, 0.17487887, 0.8851733]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.668): 0.147*"reference" + 0.072*"argument" + 0.066*"way" + 0.038*"list" + 0.030*"assignment" + 0.029*"output" + 0.028*"name" + 0.027*"issue" + 0.027*"code" + 0.025*"string"
INFO: topic #1 (0.092): 0.024*"point" + 0.023*"definition" + 0.021*"update" + 0.018*"support" + 0.018*"idea" + 0.016*"effect" + 0.014*"dll" + 0.012*"user" + 0.012*"reason" + 0.010*"wrap"
INFO: topic #2 (0.457): 0.059*"solution" + 0.057*"return" + 0.029*"language" + 0.029*"case" + 0.026*"work" + 0.022*"class" + 0.022*"need" + 0.018*"side" + 0.017*"dataclasse" + 0.017*"functionality"
INFO: topic #3 (0.175): 0.068*"line" + 0.046*"dict.i" + 0.046*"test" + 0.046*"os" + 0.046*"look" + 0.046*"window" + 0.046*"dict.hpp" + 0.041*"integer" + 0.036*"command" + 0.027*"input"
INFO: topic #4 (0.885): 0.117*"function" + 0.112*"value" + 0.096*"object" + 0.073*"instance" + 0.058*"variable" + 0.044*"parameter" + 0.039*"type" + 0.033*"change" + 0.030*"answer" + 0.026*"result"
INFO: topic diff=0.282964, rho=0.222497
DEBUG: bound: at document #0
INFO: -5.258 per-word bound, 38.3 perplexity estimate based on a held-out corpus of 5 documents with 187 words
INFO: PROGRESS: pass 7, at document #15/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7154397, 0.09777649, 0.47225374, 0.15847157, 0.9509556]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.715): 0.218*"reference" + 0.075*"way" + 0.051*"argument" + 0.041*"name" + 0.036*"assignment" + 0.033*"code" + 0.029*"example" + 0.027*"list" + 0.025*"string" + 0.022*"method"
INFO: topic #1 (0.098): 0.043*"idea" + 0.042*"effect" + 0.037*"hand" + 0.028*"point" + 0.025*"support" + 0.023*"reason" + 0.022*"wrap" + 0.020*"reading" + 0.020*"time" + 0.019*"insight"
INFO: topic #2 (0.472): 0.060*"return" + 0.045*"solution" + 0.041*"class" + 0.040*"access" + 0.033*"attribute" + 0.031*"language" + 0.030*"case" + 0.030*"side" + 0.028*"work" + 0.025*"need"
INFO: topic #3 (0.158): 0.062*"line" + 0.043*"dict.i" + 0.043*"test" + 0.043*"os" + 0.043*"look" + 0.043*"window" + 0.043*"dict.hpp" + 0.037*"integer" + 0.033*"command" + 0.025*"input"
INFO: topic #4 (0.951): 0.148*"function" + 0.124*"object" + 0.101*"value" + 0.085*"variable" + 0.047*"instance" + 0.046*"parameter" + 0.039*"type" + 0.023*"change" + 0.022*"answer" + 0.021*"c++"
INFO: topic diff=0.392977, rho=0.222497
DEBUG: bound: at document #0
INFO: -5.864 per-word bound, 58.3 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 7, at document #20/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.76014453, 0.10266454, 0.46735686, 0.16630414, 0.92720807]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.760): 0.184*"reference" + 0.099*"argument" + 0.060*"name" + 0.053*"way" + 0.037*"string" + 0.031*"assignment" + 0.030*"code" + 0.027*"example" + 0.025*"list" + 0.022*"var"
INFO: topic #1 (0.103): 0.073*"effect" + 0.036*"idea" + 0.035*"time" + 0.031*"hand" + 0.024*"point" + 0.021*"support" + 0.019*"reason" + 0.018*"wrap" + 0.018*"reading" + 0.016*"break"
INFO: topic #2 (0.467): 0.054*"class" + 0.052*"return" + 0.047*"solution" + 0.042*"work" + 0.036*"language" + 0.035*"case" + 0.035*"access" + 0.029*"attribute" + 0.026*"side" + 0.022*"need"
INFO: topic #3 (0.166): 0.063*"namespace" + 0.043*"line" + 0.040*"print" + 0.031*"field" + 0.031*"property" + 0.030*"test" + 0.030*"os" + 0.030*"look" + 0.030*"dict.i" + 0.030*"dict.hpp"
INFO: topic #4 (0.927): 0.167*"object" + 0.140*"function" + 0.097*"value" + 0.080*"variable" + 0.039*"instance" + 0.038*"parameter" + 0.032*"type" + 0.024*"change" + 0.021*"pass" + 0.018*"call"
INFO: topic diff=0.208768, rho=0.222497
DEBUG: bound: at document #0
INFO: -5.729 per-word bound, 53.0 perplexity estimate based on a held-out corpus of 5 documents with 122 words
INFO: PROGRESS: pass 7, at document #25/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.8408492, 0.098486625, 0.47159442, 0.1806955, 1.0057883]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.841): 0.147*"reference" + 0.096*"name" + 0.067*"argument" + 0.056*"list" + 0.042*"string" + 0.041*"way" + 0.038*"assignment" + 0.026*"var" + 0.026*"code" + 0.024*"example"
INFO: topic #1 (0.098): 0.065*"effect" + 0.032*"idea" + 0.032*"time" + 0.028*"hand" + 0.021*"point" + 0.019*"support" + 0.018*"reason" + 0.017*"wrap" + 0.016*"reading" + 0.014*"break"
INFO: topic #2 (0.472): 0.064*"class" + 0.048*"solution" + 0.045*"work" + 0.043*"return" + 0.039*"language" + 0.034*"attribute" + 0.032*"question" + 0.029*"case" + 0.029*"access" + 0.022*"side"
INFO: topic #3 (0.181): 0.049*"namespace" + 0.039*"int" + 0.035*"integer" + 0.034*"line" + 0.031*"print" + 0.031*"setattr" + 0.028*"member" + 0.025*"field" + 0.025*"property" + 0.023*"test"
INFO: topic #4 (1.006): 0.159*"object" + 0.151*"function" + 0.101*"value" + 0.087*"variable" + 0.042*"parameter" + 0.035*"change" + 0.035*"instance" + 0.034*"type" + 0.021*"pass" + 0.017*"result"
INFO: topic diff=0.231964, rho=0.222497
DEBUG: bound: at document #0
INFO: -5.090 per-word bound, 34.1 perplexity estimate based on a held-out corpus of 5 documents with 167 words
INFO: PROGRESS: pass 7, at document #30/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.95030224, 0.10481091, 0.49563718, 0.1680933, 1.1320958]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.950): 0.197*"reference" + 0.060*"name" + 0.057*"list" + 0.048*"string" + 0.046*"argument" + 0.046*"method" + 0.043*"way" + 0.032*"example" + 0.028*"assignment" + 0.025*"var"
INFO: topic #1 (0.105): 0.086*"effect" + 0.043*"update" + 0.035*"point" + 0.031*"reading" + 0.025*"thread" + 0.023*"idea" + 0.023*"time" + 0.021*"simulate" + 0.021*"process" + 0.020*"hand"
INFO: topic #2 (0.496): 0.084*"class" + 0.047*"work" + 0.046*"return" + 0.043*"language" + 0.040*"solution" + 0.038*"attribute" + 0.036*"question" + 0.025*"problem" + 0.024*"case" + 0.024*"access"
INFO: topic #3 (0.168): 0.045*"namespace" + 0.035*"int" + 0.032*"integer" + 0.031*"line" + 0.028*"print" + 0.028*"setattr" + 0.026*"member" + 0.023*"field" + 0.023*"property" + 0.022*"test"
INFO: topic #4 (1.132): 0.178*"object" + 0.133*"function" + 0.108*"value" + 0.071*"variable" + 0.065*"change" + 0.050*"parameter" + 0.033*"instance" + 0.024*"type" + 0.022*"call" + 0.017*"copy"
INFO: topic diff=0.254726, rho=0.222497
DEBUG: bound: at document #0
INFO: -6.342 per-word bound, 81.1 perplexity estimate based on a held-out corpus of 5 documents with 85 words
INFO: PROGRESS: pass 7, at document #35/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.9733379, 0.10698248, 0.52008796, 0.16567674, 1.2557286]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.973): 0.204*"reference" + 0.054*"name" + 0.051*"list" + 0.047*"argument" + 0.044*"way" + 0.043*"string" + 0.041*"method" + 0.035*"example" + 0.031*"assignment" + 0.023*"var"
INFO: topic #1 (0.107): 0.062*"effect" + 0.041*"definition" + 0.031*"update" + 0.025*"point" + 0.023*"reading" + 0.020*"user" + 0.018*"thread" + 0.018*"fine" + 0.018*"respect" + 0.018*"extent"
INFO: topic #2 (0.520): 0.087*"language" + 0.067*"class" + 0.038*"work" + 0.037*"return" + 0.032*"solution" + 0.031*"attribute" + 0.029*"question" + 0.025*"post" + 0.021*"problem" + 0.020*"case"
INFO: topic #3 (0.166): 0.040*"namespace" + 0.031*"int" + 0.028*"integer" + 0.028*"line" + 0.025*"print" + 0.025*"setattr" + 0.023*"member" + 0.023*"c" + 0.020*"property" + 0.020*"field"
INFO: topic #4 (1.256): 0.178*"object" + 0.122*"function" + 0.118*"value" + 0.064*"variable" + 0.052*"change" + 0.048*"parameter" + 0.039*"answer" + 0.026*"instance" + 0.022*"call" + 0.020*"pass"
INFO: topic diff=0.232543, rho=0.222497
DEBUG: bound: at document #0
INFO: -5.688 per-word bound, 51.6 perplexity estimate based on a held-out corpus of 5 documents with 178 words
INFO: PROGRESS: pass 7, at document #40/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0287848, 0.11755823, 0.490351, 0.1653019, 1.2221075]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.029): 0.207*"reference" + 0.054*"list" + 0.047*"name" + 0.041*"string" + 0.038*"method" + 0.035*"example" + 0.034*"argument" + 0.033*"way" + 0.032*"assignment" + 0.031*"target"
INFO: topic #1 (0.118): 0.072*"point" + 0.061*"update" + 0.047*"effect" + 0.033*"user" + 0.031*"definition" + 0.025*"wrap" + 0.024*"support" + 0.018*"reading" + 0.014*"thread" + 0.014*"incorrect"
INFO: topic #2 (0.490): 0.084*"language" + 0.056*"class" + 0.043*"work" + 0.039*"case" + 0.031*"return" + 0.027*"solution" + 0.026*"attribute" + 0.025*"question" + 0.023*"show" + 0.021*"post"
INFO: topic #3 (0.165): 0.075*"integer" + 0.046*"entry" + 0.046*"database" + 0.044*"print" + 0.038*"namespace" + 0.025*"pointer" + 0.018*"int" + 0.016*"line" + 0.015*"connection" + 0.015*"clarifie"
INFO: topic #4 (1.222): 0.205*"object" + 0.156*"value" + 0.100*"function" + 0.065*"variable" + 0.043*"change" + 0.038*"answer" + 0.036*"parameter" + 0.030*"type" + 0.020*"call" + 0.020*"instance"
INFO: topic diff=0.334058, rho=0.222497
DEBUG: bound: at document #0
INFO: -6.352 per-word bound, 81.7 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 7, at document #45/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0151666, 0.11277049, 0.548445, 0.15600166, 1.2887592]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.015): 0.207*"reference" + 0.047*"list" + 0.041*"name" + 0.039*"argument" + 0.035*"string" + 0.035*"example" + 0.033*"way" + 0.033*"method" + 0.028*"assignment" + 0.027*"target"
INFO: topic #1 (0.113): 0.065*"point" + 0.055*"update" + 0.042*"effect" + 0.029*"user" + 0.028*"definition" + 0.022*"wrap" + 0.022*"support" + 0.016*"reading" + 0.013*"thread" + 0.013*"incorrect"
INFO: topic #2 (0.548): 0.058*"language" + 0.051*"return" + 0.047*"case" + 0.042*"array" + 0.039*"class" + 0.031*"my_fun" + 0.030*"work" + 0.024*"item" + 0.022*"problem" + 0.021*"operator"
INFO: topic #3 (0.156): 0.068*"integer" + 0.042*"entry" + 0.042*"database" + 0.040*"print" + 0.035*"namespace" + 0.023*"pointer" + 0.017*"int" + 0.015*"line" + 0.014*"connection" + 0.014*"clarifie"
INFO: topic #4 (1.289): 0.197*"object" + 0.155*"value" + 0.107*"function" + 0.055*"variable" + 0.049*"parameter" + 0.046*"change" + 0.037*"answer" + 0.026*"type" + 0.022*"call" + 0.021*"instance"
INFO: topic diff=0.218174, rho=0.222497
DEBUG: bound: at document #0
INFO: -6.339 per-word bound, 81.0 perplexity estimate based on a held-out corpus of 5 documents with 98 words
INFO: PROGRESS: pass 7, at document #50/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0746266, 0.11424577, 0.5913121, 0.14857414, 1.3769633]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.075): 0.187*"reference" + 0.059*"list" + 0.044*"string" + 0.044*"name" + 0.038*"argument" + 0.038*"way" + 0.034*"example" + 0.032*"method" + 0.028*"assignment" + 0.027*"code"
INFO: topic #1 (0.114): 0.055*"point" + 0.046*"update" + 0.039*"support" + 0.036*"effect" + 0.025*"user" + 0.025*"reason" + 0.024*"definition" + 0.019*"wrap" + 0.014*"reading" + 0.011*"thread"
INFO: topic #2 (0.591): 0.067*"return" + 0.051*"class" + 0.046*"language" + 0.031*"case" + 0.028*"context" + 0.027*"array" + 0.026*"perl" + 0.021*"my_fun" + 0.020*"work" + 0.019*"show"
INFO: topic #3 (0.149): 0.062*"integer" + 0.038*"entry" + 0.038*"database" + 0.036*"print" + 0.031*"namespace" + 0.021*"pointer" + 0.015*"int" + 0.014*"line" + 0.013*"connection" + 0.013*"clarifie"
INFO: topic #4 (1.377): 0.173*"object" + 0.157*"value" + 0.121*"function" + 0.060*"variable" + 0.050*"parameter" + 0.043*"change" + 0.031*"answer" + 0.027*"call" + 0.026*"type" + 0.019*"pass"
INFO: topic diff=0.241577, rho=0.222497
DEBUG: bound: at document #0
INFO: -6.112 per-word bound, 69.2 perplexity estimate based on a held-out corpus of 5 documents with 80 words
INFO: PROGRESS: pass 7, at document #55/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.048974, 0.11486493, 0.5857763, 0.14882056, 1.4215397]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.049): 0.170*"reference" + 0.052*"list" + 0.050*"argument" + 0.045*"name" + 0.044*"way" + 0.041*"code" + 0.039*"string" + 0.030*"example" + 0.028*"method" + 0.025*"output"
INFO: topic #1 (0.115): 0.045*"point" + 0.043*"definition" + 0.038*"update" + 0.032*"support" + 0.032*"idea" + 0.030*"effect" + 0.024*"dll" + 0.021*"user" + 0.020*"reason" + 0.016*"wrap"
INFO: topic #2 (0.586): 0.110*"return" + 0.042*"class" + 0.039*"language" + 0.026*"case" + 0.023*"context" + 0.023*"array" + 0.023*"practice" + 0.022*"perl" + 0.021*"problem" + 0.020*"situation"
INFO: topic #3 (0.149): 0.047*"pointer" + 0.046*"integer" + 0.042*"ctype" + 0.029*"entry" + 0.029*"database" + 0.027*"print" + 0.024*"input" + 0.024*"namespace" + 0.019*"byref" + 0.019*"set"
INFO: topic #4 (1.422): 0.157*"value" + 0.137*"object" + 0.129*"function" + 0.053*"parameter" + 0.047*"variable" + 0.040*"type" + 0.038*"change" + 0.031*"call" + 0.029*"pass" + 0.024*"answer"
INFO: topic diff=0.176320, rho=0.222497
DEBUG: bound: at document #0
INFO: -5.519 per-word bound, 45.8 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 7, at document #60/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.864866, 0.10820306, 0.54226166, 0.16176468, 1.473883]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.865): 0.161*"reference" + 0.054*"way" + 0.052*"argument" + 0.047*"list" + 0.041*"name" + 0.037*"code" + 0.035*"string" + 0.028*"output" + 0.027*"example" + 0.026*"method"
INFO: topic #1 (0.108): 0.039*"point" + 0.037*"definition" + 0.033*"update" + 0.028*"support" + 0.028*"idea" + 0.026*"effect" + 0.021*"dll" + 0.018*"user" + 0.018*"reason" + 0.014*"wrap"
INFO: topic #2 (0.542): 0.125*"return" + 0.052*"case" + 0.037*"class" + 0.034*"language" + 0.024*"work" + 0.020*"context" + 0.020*"array" + 0.020*"practice" + 0.019*"perl" + 0.019*"problem"
INFO: topic #3 (0.162): 0.078*"command" + 0.059*"input" + 0.058*"integer" + 0.051*"line" + 0.047*"script" + 0.032*"print" + 0.029*"pointer" + 0.026*"ctype" + 0.018*"database" + 0.018*"entry"
INFO: topic #4 (1.474): 0.152*"function" + 0.146*"value" + 0.133*"object" + 0.066*"variable" + 0.041*"parameter" + 0.031*"change" + 0.028*"type" + 0.026*"arg" + 0.025*"pass" + 0.022*"call"
INFO: topic diff=0.223681, rho=0.222497
DEBUG: bound: at document #0
INFO: -7.252 per-word bound, 152.4 perplexity estimate based on a held-out corpus of 1 documents with 12 words
INFO: PROGRESS: pass 7, at document #61/61
INFO: optimized alpha [0.8070509, 0.10187703, 0.49853957, 0.19543272, 1.0916878]
DEBUG: updating topics
INFO: merging changes from 1 documents into a model of 61 documents
INFO: topic #0 (0.807): 0.139*"reference" + 0.082*"argument" + 0.049*"output" + 0.046*"way" + 0.041*"issue" + 0.041*"list" + 0.035*"name" + 0.032*"code" + 0.031*"string" + 0.024*"example"
INFO: topic #1 (0.102): 0.034*"point" + 0.032*"definition" + 0.029*"update" + 0.024*"support" + 0.024*"idea" + 0.023*"effect" + 0.018*"dll" + 0.016*"user" + 0.016*"reason" + 0.013*"wrap"
INFO: topic #2 (0.499): 0.112*"return" + 0.053*"solution" + 0.047*"case" + 0.033*"class" + 0.030*"language" + 0.022*"work" + 0.018*"context" + 0.018*"array" + 0.018*"practice" + 0.018*"perl"
INFO: topic #3 (0.195): 0.082*"line" + 0.056*"dict.i" + 0.056*"dict.hpp" + 0.056*"window" + 0.056*"look" + 0.056*"test" + 0.056*"os" + 0.044*"command" + 0.033*"input" + 0.033*"integer"
INFO: topic #4 (1.092): 0.143*"function" + 0.138*"value" + 0.125*"object" + 0.063*"variable" + 0.040*"result" + 0.039*"parameter" + 0.029*"change" + 0.026*"type" + 0.025*"arg" + 0.024*"output"
INFO: topic diff=0.190564, rho=0.222497
DEBUG: bound: at document #0
INFO: -6.087 per-word bound, 68.0 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 8, at document #5/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7424954, 0.09700131, 0.4034731, 0.17811143, 0.9575536]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.742): 0.135*"reference" + 0.073*"argument" + 0.043*"list" + 0.041*"way" + 0.036*"output" + 0.035*"assignment" + 0.032*"name" + 0.031*"code" + 0.030*"issue" + 0.029*"string"
INFO: topic #1 (0.097): 0.029*"point" + 0.028*"definition" + 0.025*"update" + 0.021*"support" + 0.021*"idea" + 0.020*"effect" + 0.016*"dll" + 0.014*"user" + 0.014*"reason" + 0.011*"wrap"
INFO: topic #2 (0.403): 0.104*"return" + 0.049*"solution" + 0.044*"case" + 0.031*"class" + 0.028*"language" + 0.021*"work" + 0.017*"context" + 0.017*"array" + 0.017*"practice" + 0.016*"perl"
INFO: topic #3 (0.178): 0.077*"line" + 0.052*"dict.i" + 0.052*"dict.hpp" + 0.052*"window" + 0.052*"look" + 0.052*"test" + 0.052*"os" + 0.041*"command" + 0.031*"input" + 0.031*"integer"
INFO: topic #4 (0.958): 0.129*"function" + 0.111*"value" + 0.105*"object" + 0.058*"variable" + 0.049*"instance" + 0.035*"parameter" + 0.035*"type" + 0.031*"result" + 0.030*"answer" + 0.027*"change"
INFO: topic diff=0.197337, rho=0.217186
DEBUG: bound: at document #0
INFO: -6.552 per-word bound, 93.9 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 8, at document #10/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.6746399, 0.091835976, 0.45046774, 0.17077677, 0.8805069]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.675): 0.147*"reference" + 0.071*"argument" + 0.065*"way" + 0.038*"list" + 0.031*"output" + 0.030*"assignment" + 0.028*"name" + 0.027*"method" + 0.027*"code" + 0.026*"issue"
INFO: topic #1 (0.092): 0.025*"point" + 0.024*"definition" + 0.021*"update" + 0.018*"support" + 0.018*"idea" + 0.017*"effect" + 0.014*"dll" + 0.012*"user" + 0.012*"reason" + 0.010*"wrap"
INFO: topic #2 (0.450): 0.058*"return" + 0.056*"solution" + 0.030*"language" + 0.029*"case" + 0.026*"work" + 0.023*"class" + 0.022*"need" + 0.018*"side" + 0.017*"dataclasse" + 0.017*"functionality"
INFO: topic #3 (0.171): 0.067*"line" + 0.046*"window" + 0.046*"test" + 0.046*"os" + 0.046*"look" + 0.046*"dict.i" + 0.046*"dict.hpp" + 0.041*"integer" + 0.036*"command" + 0.027*"input"
INFO: topic #4 (0.881): 0.118*"function" + 0.113*"value" + 0.098*"object" + 0.072*"instance" + 0.058*"variable" + 0.044*"parameter" + 0.039*"type" + 0.033*"change" + 0.030*"answer" + 0.026*"result"
INFO: topic diff=0.272436, rho=0.217186
DEBUG: bound: at document #0
INFO: -5.241 per-word bound, 37.8 perplexity estimate based on a held-out corpus of 5 documents with 187 words
INFO: PROGRESS: pass 8, at document #15/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7207815, 0.0973476, 0.46593362, 0.15547034, 0.944844]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.721): 0.215*"reference" + 0.074*"way" + 0.051*"argument" + 0.041*"name" + 0.035*"assignment" + 0.033*"code" + 0.029*"example" + 0.027*"list" + 0.025*"string" + 0.025*"method"
INFO: topic #1 (0.097): 0.042*"idea" + 0.042*"effect" + 0.037*"hand" + 0.028*"point" + 0.025*"support" + 0.022*"reason" + 0.021*"wrap" + 0.020*"reading" + 0.020*"time" + 0.018*"insight"
INFO: topic #2 (0.466): 0.060*"return" + 0.043*"solution" + 0.041*"class" + 0.040*"access" + 0.033*"attribute" + 0.031*"language" + 0.030*"case" + 0.030*"side" + 0.028*"work" + 0.025*"need"
INFO: topic #3 (0.155): 0.062*"line" + 0.042*"window" + 0.042*"test" + 0.042*"os" + 0.042*"look" + 0.042*"dict.i" + 0.042*"dict.hpp" + 0.037*"integer" + 0.033*"command" + 0.025*"input"
INFO: topic #4 (0.945): 0.148*"function" + 0.124*"object" + 0.102*"value" + 0.085*"variable" + 0.047*"instance" + 0.046*"parameter" + 0.039*"type" + 0.023*"change" + 0.022*"answer" + 0.021*"c++"
INFO: topic diff=0.377915, rho=0.217186
DEBUG: bound: at document #0
INFO: -5.840 per-word bound, 57.3 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 8, at document #20/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7638833, 0.10210706, 0.4620495, 0.16309655, 0.9223498]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.764): 0.183*"reference" + 0.098*"argument" + 0.060*"name" + 0.052*"way" + 0.036*"string" + 0.031*"assignment" + 0.029*"code" + 0.027*"example" + 0.025*"list" + 0.024*"method"
INFO: topic #1 (0.102): 0.072*"effect" + 0.036*"idea" + 0.035*"time" + 0.031*"hand" + 0.024*"point" + 0.021*"support" + 0.019*"reason" + 0.018*"wrap" + 0.017*"reading" + 0.016*"lot"
INFO: topic #2 (0.462): 0.054*"class" + 0.053*"return" + 0.043*"solution" + 0.042*"work" + 0.036*"language" + 0.035*"case" + 0.035*"access" + 0.029*"attribute" + 0.026*"side" + 0.022*"need"
INFO: topic #3 (0.163): 0.062*"namespace" + 0.043*"line" + 0.039*"print" + 0.031*"field" + 0.031*"property" + 0.030*"test" + 0.030*"os" + 0.030*"look" + 0.030*"dict.i" + 0.030*"dict.hpp"
INFO: topic #4 (0.922): 0.167*"object" + 0.140*"function" + 0.098*"value" + 0.080*"variable" + 0.039*"instance" + 0.038*"parameter" + 0.033*"type" + 0.024*"change" + 0.021*"pass" + 0.018*"answer"
INFO: topic diff=0.199941, rho=0.217186
DEBUG: bound: at document #0
INFO: -5.712 per-word bound, 52.4 perplexity estimate based on a held-out corpus of 5 documents with 122 words
INFO: PROGRESS: pass 8, at document #25/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.84699386, 0.09809876, 0.46653572, 0.17707719, 1.0003955]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.847): 0.147*"reference" + 0.095*"name" + 0.067*"argument" + 0.055*"list" + 0.041*"way" + 0.041*"string" + 0.038*"assignment" + 0.026*"var" + 0.026*"code" + 0.024*"method"
INFO: topic #1 (0.098): 0.065*"effect" + 0.032*"idea" + 0.031*"time" + 0.028*"hand" + 0.022*"point" + 0.019*"support" + 0.017*"reason" + 0.017*"wrap" + 0.016*"reading" + 0.014*"lot"
INFO: topic #2 (0.467): 0.064*"class" + 0.046*"solution" + 0.045*"work" + 0.044*"return" + 0.040*"language" + 0.034*"attribute" + 0.031*"question" + 0.030*"case" + 0.029*"access" + 0.022*"side"
INFO: topic #3 (0.177): 0.049*"namespace" + 0.038*"int" + 0.035*"integer" + 0.034*"line" + 0.031*"print" + 0.030*"setattr" + 0.028*"member" + 0.024*"field" + 0.024*"property" + 0.024*"test"
INFO: topic #4 (1.000): 0.159*"object" + 0.151*"function" + 0.101*"value" + 0.087*"variable" + 0.043*"parameter" + 0.035*"change" + 0.035*"instance" + 0.034*"type" + 0.021*"pass" + 0.017*"result"
INFO: topic diff=0.221768, rho=0.217186
DEBUG: bound: at document #0
INFO: -5.072 per-word bound, 33.6 perplexity estimate based on a held-out corpus of 5 documents with 167 words
INFO: PROGRESS: pass 8, at document #30/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.95421064, 0.10425268, 0.49001127, 0.16524586, 1.1237093]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.954): 0.196*"reference" + 0.060*"name" + 0.056*"list" + 0.047*"string" + 0.047*"method" + 0.046*"argument" + 0.043*"way" + 0.032*"example" + 0.028*"assignment" + 0.025*"var"
INFO: topic #1 (0.104): 0.085*"effect" + 0.042*"update" + 0.035*"point" + 0.031*"reading" + 0.024*"thread" + 0.024*"idea" + 0.023*"time" + 0.021*"simulate" + 0.021*"process" + 0.021*"hand"
INFO: topic #2 (0.490): 0.083*"class" + 0.047*"work" + 0.047*"return" + 0.043*"language" + 0.038*"solution" + 0.038*"attribute" + 0.036*"question" + 0.025*"problem" + 0.025*"case" + 0.024*"access"
INFO: topic #3 (0.165): 0.045*"namespace" + 0.035*"int" + 0.032*"integer" + 0.032*"line" + 0.028*"print" + 0.028*"setattr" + 0.026*"member" + 0.022*"field" + 0.022*"property" + 0.022*"test"
INFO: topic #4 (1.124): 0.178*"object" + 0.133*"function" + 0.109*"value" + 0.071*"variable" + 0.064*"change" + 0.050*"parameter" + 0.033*"instance" + 0.025*"type" + 0.022*"call" + 0.016*"copy"
INFO: topic diff=0.243970, rho=0.217186
DEBUG: bound: at document #0
INFO: -6.317 per-word bound, 79.7 perplexity estimate based on a held-out corpus of 5 documents with 85 words
INFO: PROGRESS: pass 8, at document #35/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.97798836, 0.106376946, 0.5140446, 0.16302404, 1.2439207]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.978): 0.202*"reference" + 0.054*"name" + 0.051*"list" + 0.047*"argument" + 0.044*"way" + 0.043*"string" + 0.043*"method" + 0.034*"example" + 0.030*"assignment" + 0.023*"var"
INFO: topic #1 (0.106): 0.062*"effect" + 0.040*"definition" + 0.031*"update" + 0.025*"point" + 0.023*"reading" + 0.020*"user" + 0.018*"extent" + 0.018*"borderline" + 0.018*"fine" + 0.018*"bolt"
INFO: topic #2 (0.514): 0.086*"language" + 0.067*"class" + 0.038*"work" + 0.038*"return" + 0.031*"solution" + 0.031*"attribute" + 0.029*"question" + 0.025*"post" + 0.021*"problem" + 0.020*"case"
INFO: topic #3 (0.163): 0.040*"namespace" + 0.031*"int" + 0.029*"integer" + 0.028*"line" + 0.025*"print" + 0.025*"setattr" + 0.023*"member" + 0.022*"c" + 0.020*"property" + 0.020*"field"
INFO: topic #4 (1.244): 0.178*"object" + 0.122*"function" + 0.118*"value" + 0.065*"variable" + 0.051*"change" + 0.048*"parameter" + 0.039*"answer" + 0.027*"instance" + 0.022*"call" + 0.020*"pass"
INFO: topic diff=0.223025, rho=0.217186
DEBUG: bound: at document #0
INFO: -5.666 per-word bound, 50.8 perplexity estimate based on a held-out corpus of 5 documents with 178 words
INFO: PROGRESS: pass 8, at document #40/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0318966, 0.11665298, 0.48579922, 0.16278428, 1.2125447]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.032): 0.205*"reference" + 0.054*"list" + 0.047*"name" + 0.040*"string" + 0.039*"method" + 0.035*"argument" + 0.035*"example" + 0.033*"way" + 0.032*"assignment" + 0.030*"target"
INFO: topic #1 (0.117): 0.071*"point" + 0.060*"update" + 0.047*"effect" + 0.032*"user" + 0.031*"definition" + 0.024*"wrap" + 0.024*"support" + 0.018*"reading" + 0.014*"incorrect" + 0.014*"piece"
INFO: topic #2 (0.486): 0.083*"language" + 0.057*"class" + 0.043*"work" + 0.039*"case" + 0.032*"return" + 0.026*"solution" + 0.026*"attribute" + 0.025*"question" + 0.023*"show" + 0.021*"post"
INFO: topic #3 (0.163): 0.074*"integer" + 0.045*"entry" + 0.045*"database" + 0.043*"print" + 0.038*"namespace" + 0.027*"pointer" + 0.018*"int" + 0.017*"line" + 0.015*"connection" + 0.015*"clarifie"
INFO: topic #4 (1.213): 0.204*"object" + 0.155*"value" + 0.101*"function" + 0.065*"variable" + 0.043*"change" + 0.038*"answer" + 0.037*"parameter" + 0.030*"type" + 0.020*"call" + 0.020*"instance"
INFO: topic diff=0.319470, rho=0.217186
DEBUG: bound: at document #0
INFO: -6.323 per-word bound, 80.1 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 8, at document #45/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0173862, 0.11201806, 0.5419783, 0.1539077, 1.2750747]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.017): 0.205*"reference" + 0.047*"list" + 0.041*"name" + 0.039*"argument" + 0.035*"string" + 0.035*"example" + 0.034*"method" + 0.033*"way" + 0.028*"assignment" + 0.026*"target"
INFO: topic #1 (0.112): 0.064*"point" + 0.054*"update" + 0.043*"effect" + 0.029*"user" + 0.028*"definition" + 0.022*"wrap" + 0.022*"support" + 0.016*"reading" + 0.013*"incorrect" + 0.013*"piece"
INFO: topic #2 (0.542): 0.058*"language" + 0.052*"return" + 0.047*"case" + 0.041*"array" + 0.039*"class" + 0.031*"my_fun" + 0.030*"work" + 0.024*"item" + 0.022*"problem" + 0.020*"operator"
INFO: topic #3 (0.154): 0.067*"integer" + 0.041*"entry" + 0.041*"database" + 0.040*"print" + 0.035*"namespace" + 0.025*"pointer" + 0.017*"int" + 0.015*"line" + 0.014*"connection" + 0.014*"clarifie"
INFO: topic #4 (1.275): 0.197*"object" + 0.155*"value" + 0.108*"function" + 0.056*"variable" + 0.049*"parameter" + 0.046*"change" + 0.037*"answer" + 0.026*"type" + 0.022*"call" + 0.022*"instance"
INFO: topic diff=0.209332, rho=0.217186
DEBUG: bound: at document #0
INFO: -6.311 per-word bound, 79.4 perplexity estimate based on a held-out corpus of 5 documents with 98 words
INFO: PROGRESS: pass 8, at document #50/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0745611, 0.11344818, 0.5835846, 0.14681646, 1.3610274]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.075): 0.186*"reference" + 0.058*"list" + 0.044*"name" + 0.044*"string" + 0.038*"argument" + 0.037*"way" + 0.034*"example" + 0.033*"method" + 0.028*"assignment" + 0.027*"code"
INFO: topic #1 (0.113): 0.054*"point" + 0.046*"update" + 0.038*"support" + 0.036*"effect" + 0.025*"user" + 0.024*"reason" + 0.024*"definition" + 0.019*"wrap" + 0.014*"reading" + 0.011*"borderline"
INFO: topic #2 (0.584): 0.067*"return" + 0.051*"class" + 0.047*"language" + 0.031*"case" + 0.027*"context" + 0.027*"array" + 0.026*"perl" + 0.020*"my_fun" + 0.020*"work" + 0.019*"show"
INFO: topic #3 (0.147): 0.061*"integer" + 0.037*"entry" + 0.037*"database" + 0.036*"print" + 0.031*"namespace" + 0.022*"pointer" + 0.016*"int" + 0.014*"line" + 0.013*"connection" + 0.013*"clarifie"
INFO: topic #4 (1.361): 0.174*"object" + 0.157*"value" + 0.122*"function" + 0.060*"variable" + 0.050*"parameter" + 0.043*"change" + 0.031*"answer" + 0.027*"call" + 0.027*"type" + 0.019*"pass"
INFO: topic diff=0.231469, rho=0.217186
DEBUG: bound: at document #0
INFO: -6.099 per-word bound, 68.5 perplexity estimate based on a held-out corpus of 5 documents with 80 words
INFO: PROGRESS: pass 8, at document #55/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0502038, 0.11406123, 0.57887846, 0.14713664, 1.4034011]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.050): 0.170*"reference" + 0.052*"list" + 0.050*"argument" + 0.045*"name" + 0.044*"way" + 0.041*"code" + 0.039*"string" + 0.030*"example" + 0.029*"method" + 0.027*"output"
INFO: topic #1 (0.114): 0.045*"point" + 0.042*"definition" + 0.038*"update" + 0.032*"support" + 0.031*"idea" + 0.030*"effect" + 0.024*"dll" + 0.021*"user" + 0.020*"reason" + 0.016*"wrap"
INFO: topic #2 (0.579): 0.109*"return" + 0.043*"class" + 0.039*"language" + 0.026*"case" + 0.023*"context" + 0.023*"array" + 0.022*"practice" + 0.022*"perl" + 0.021*"problem" + 0.020*"situation"
INFO: topic #3 (0.147): 0.048*"pointer" + 0.046*"integer" + 0.041*"ctype" + 0.028*"entry" + 0.028*"database" + 0.027*"print" + 0.024*"namespace" + 0.023*"input" + 0.019*"byref" + 0.019*"set"
INFO: topic #4 (1.403): 0.157*"value" + 0.139*"object" + 0.129*"function" + 0.053*"parameter" + 0.048*"variable" + 0.040*"type" + 0.039*"change" + 0.031*"call" + 0.029*"pass" + 0.024*"answer"
INFO: topic diff=0.167736, rho=0.217186
DEBUG: bound: at document #0
INFO: -5.497 per-word bound, 45.2 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 8, at document #60/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.86883503, 0.10761307, 0.53726053, 0.15965122, 1.4541401]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.869): 0.161*"reference" + 0.053*"way" + 0.052*"argument" + 0.047*"list" + 0.041*"name" + 0.037*"code" + 0.035*"string" + 0.030*"output" + 0.027*"example" + 0.027*"method"
INFO: topic #1 (0.108): 0.039*"point" + 0.037*"definition" + 0.033*"update" + 0.028*"support" + 0.028*"idea" + 0.027*"effect" + 0.021*"dll" + 0.018*"user" + 0.018*"reason" + 0.014*"wrap"
INFO: topic #2 (0.537): 0.124*"return" + 0.052*"case" + 0.037*"class" + 0.034*"language" + 0.025*"work" + 0.020*"context" + 0.020*"array" + 0.020*"practice" + 0.019*"perl" + 0.019*"problem"
INFO: topic #3 (0.160): 0.076*"command" + 0.058*"input" + 0.058*"integer" + 0.050*"line" + 0.046*"script" + 0.032*"print" + 0.030*"pointer" + 0.026*"ctype" + 0.018*"database" + 0.018*"entry"
INFO: topic #4 (1.454): 0.152*"function" + 0.147*"value" + 0.134*"object" + 0.067*"variable" + 0.042*"parameter" + 0.031*"change" + 0.028*"type" + 0.026*"arg" + 0.025*"pass" + 0.022*"call"
INFO: topic diff=0.214989, rho=0.217186
DEBUG: bound: at document #0
INFO: -7.179 per-word bound, 144.9 perplexity estimate based on a held-out corpus of 1 documents with 12 words
INFO: PROGRESS: pass 8, at document #61/61
INFO: optimized alpha [0.7964325, 0.10112839, 0.46162966, 0.19162007, 1.0515431]
DEBUG: updating topics
INFO: merging changes from 1 documents into a model of 61 documents
INFO: topic #0 (0.796): 0.139*"reference" + 0.080*"argument" + 0.052*"output" + 0.046*"way" + 0.041*"list" + 0.040*"issue" + 0.035*"name" + 0.032*"code" + 0.031*"string" + 0.024*"example"
INFO: topic #1 (0.101): 0.034*"point" + 0.032*"definition" + 0.029*"update" + 0.024*"support" + 0.024*"idea" + 0.023*"effect" + 0.018*"dll" + 0.016*"user" + 0.016*"reason" + 0.013*"wrap"
INFO: topic #2 (0.462): 0.114*"return" + 0.048*"case" + 0.034*"class" + 0.031*"language" + 0.031*"solution" + 0.023*"work" + 0.019*"context" + 0.019*"array" + 0.018*"practice" + 0.018*"perl"
INFO: topic #3 (0.192): 0.079*"line" + 0.054*"dict.hpp" + 0.054*"test" + 0.054*"os" + 0.054*"look" + 0.054*"dict.i" + 0.054*"window" + 0.042*"command" + 0.032*"solution" + 0.032*"input"
INFO: topic #4 (1.052): 0.143*"function" + 0.139*"value" + 0.126*"object" + 0.063*"variable" + 0.040*"result" + 0.039*"parameter" + 0.030*"change" + 0.026*"type" + 0.024*"arg" + 0.023*"pass"
INFO: topic diff=0.189439, rho=0.217186
DEBUG: bound: at document #0
INFO: -6.058 per-word bound, 66.6 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 9, at document #5/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7357899, 0.09643994, 0.38025883, 0.17534435, 0.9315435]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.736): 0.136*"reference" + 0.072*"argument" + 0.043*"list" + 0.041*"way" + 0.038*"output" + 0.034*"assignment" + 0.033*"name" + 0.030*"code" + 0.030*"issue" + 0.029*"string"
INFO: topic #1 (0.096): 0.029*"point" + 0.028*"definition" + 0.025*"update" + 0.021*"support" + 0.021*"idea" + 0.020*"effect" + 0.016*"dll" + 0.014*"user" + 0.014*"reason" + 0.011*"wrap"
INFO: topic #2 (0.380): 0.106*"return" + 0.045*"case" + 0.032*"class" + 0.029*"language" + 0.029*"solution" + 0.021*"work" + 0.018*"context" + 0.017*"array" + 0.017*"practice" + 0.017*"perl"
INFO: topic #3 (0.175): 0.074*"line" + 0.051*"dict.hpp" + 0.051*"test" + 0.051*"os" + 0.051*"look" + 0.051*"dict.i" + 0.051*"window" + 0.040*"command" + 0.031*"solution" + 0.030*"input"
INFO: topic #4 (0.932): 0.130*"function" + 0.112*"value" + 0.107*"object" + 0.058*"variable" + 0.049*"instance" + 0.035*"parameter" + 0.034*"type" + 0.031*"result" + 0.030*"answer" + 0.028*"change"
INFO: topic diff=0.190333, rho=0.212238
DEBUG: bound: at document #0
INFO: -6.540 per-word bound, 93.1 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 9, at document #10/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.6700736, 0.09138948, 0.42434433, 0.1683309, 0.85928655]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.670): 0.146*"reference" + 0.070*"argument" + 0.064*"way" + 0.038*"list" + 0.033*"output" + 0.030*"assignment" + 0.030*"method" + 0.028*"name" + 0.026*"code" + 0.026*"issue"
INFO: topic #1 (0.091): 0.025*"point" + 0.024*"definition" + 0.021*"update" + 0.018*"support" + 0.018*"idea" + 0.017*"effect" + 0.014*"dll" + 0.012*"user" + 0.012*"reason" + 0.010*"wrap"
INFO: topic #2 (0.424): 0.059*"return" + 0.046*"solution" + 0.030*"language" + 0.030*"case" + 0.026*"work" + 0.024*"class" + 0.022*"need" + 0.018*"side" + 0.017*"dataclasse" + 0.017*"functionality"
INFO: topic #3 (0.168): 0.066*"line" + 0.045*"window" + 0.045*"test" + 0.045*"os" + 0.045*"look" + 0.045*"dict.i" + 0.045*"dict.hpp" + 0.040*"integer" + 0.035*"command" + 0.027*"solution"
INFO: topic #4 (0.859): 0.118*"function" + 0.113*"value" + 0.100*"object" + 0.071*"instance" + 0.059*"variable" + 0.044*"parameter" + 0.039*"type" + 0.033*"change" + 0.030*"answer" + 0.026*"result"
INFO: topic diff=0.264186, rho=0.212238
DEBUG: bound: at document #0
INFO: -5.225 per-word bound, 37.4 perplexity estimate based on a held-out corpus of 5 documents with 187 words
INFO: PROGRESS: pass 9, at document #15/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7151461, 0.096740715, 0.4410906, 0.15370166, 0.92219573]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.715): 0.213*"reference" + 0.073*"way" + 0.051*"argument" + 0.041*"name" + 0.035*"assignment" + 0.033*"code" + 0.029*"example" + 0.028*"list" + 0.027*"method" + 0.025*"string"
INFO: topic #1 (0.097): 0.042*"idea" + 0.042*"effect" + 0.036*"hand" + 0.028*"point" + 0.025*"support" + 0.022*"reason" + 0.021*"wrap" + 0.020*"reading" + 0.020*"time" + 0.018*"insight"
INFO: topic #2 (0.441): 0.061*"return" + 0.042*"class" + 0.040*"access" + 0.036*"solution" + 0.033*"attribute" + 0.031*"language" + 0.031*"case" + 0.030*"side" + 0.028*"work" + 0.025*"need"
INFO: topic #3 (0.154): 0.060*"line" + 0.041*"window" + 0.041*"test" + 0.041*"os" + 0.041*"look" + 0.041*"dict.i" + 0.041*"dict.hpp" + 0.037*"integer" + 0.033*"command" + 0.025*"solution"
INFO: topic #4 (0.922): 0.147*"function" + 0.125*"object" + 0.102*"value" + 0.085*"variable" + 0.047*"instance" + 0.046*"parameter" + 0.039*"type" + 0.024*"change" + 0.022*"answer" + 0.021*"c++"
INFO: topic diff=0.364764, rho=0.212238
DEBUG: bound: at document #0
INFO: -5.816 per-word bound, 56.4 perplexity estimate based on a held-out corpus of 5 documents with 104 words
INFO: PROGRESS: pass 9, at document #20/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.75698143, 0.10136634, 0.4394947, 0.16112655, 0.90293616]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.757): 0.182*"reference" + 0.096*"argument" + 0.059*"name" + 0.052*"way" + 0.036*"string" + 0.031*"assignment" + 0.029*"code" + 0.027*"example" + 0.026*"list" + 0.026*"method"
INFO: topic #1 (0.101): 0.072*"effect" + 0.036*"idea" + 0.034*"time" + 0.031*"hand" + 0.024*"point" + 0.021*"support" + 0.019*"reason" + 0.018*"wrap" + 0.017*"reading" + 0.016*"lot"
INFO: topic #2 (0.439): 0.054*"class" + 0.054*"return" + 0.042*"work" + 0.036*"language" + 0.036*"case" + 0.035*"access" + 0.034*"solution" + 0.029*"attribute" + 0.026*"side" + 0.022*"need"
INFO: topic #3 (0.161): 0.060*"namespace" + 0.043*"line" + 0.038*"print" + 0.030*"field" + 0.030*"property" + 0.030*"test" + 0.030*"os" + 0.030*"look" + 0.030*"dict.i" + 0.030*"dict.hpp"
INFO: topic #4 (0.903): 0.166*"object" + 0.141*"function" + 0.099*"value" + 0.080*"variable" + 0.039*"instance" + 0.039*"parameter" + 0.033*"type" + 0.024*"change" + 0.021*"pass" + 0.018*"answer"
INFO: topic diff=0.191578, rho=0.212238
DEBUG: bound: at document #0
INFO: -5.702 per-word bound, 52.0 perplexity estimate based on a held-out corpus of 5 documents with 122 words
INFO: PROGRESS: pass 9, at document #25/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.84217143, 0.09751846, 0.44553024, 0.17480677, 0.9806523]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.842): 0.147*"reference" + 0.093*"name" + 0.067*"argument" + 0.055*"list" + 0.041*"way" + 0.041*"string" + 0.037*"assignment" + 0.026*"method" + 0.026*"code" + 0.025*"var"
INFO: topic #1 (0.098): 0.064*"effect" + 0.032*"idea" + 0.031*"time" + 0.028*"hand" + 0.022*"point" + 0.019*"support" + 0.017*"reason" + 0.017*"wrap" + 0.016*"reading" + 0.014*"lot"
INFO: topic #2 (0.446): 0.064*"class" + 0.045*"return" + 0.045*"work" + 0.040*"language" + 0.038*"solution" + 0.034*"attribute" + 0.031*"question" + 0.030*"case" + 0.029*"access" + 0.022*"side"
INFO: topic #3 (0.175): 0.048*"namespace" + 0.037*"int" + 0.034*"integer" + 0.034*"line" + 0.030*"print" + 0.029*"setattr" + 0.027*"member" + 0.024*"field" + 0.024*"property" + 0.024*"test"
INFO: topic #4 (0.981): 0.159*"object" + 0.151*"function" + 0.102*"value" + 0.087*"variable" + 0.043*"parameter" + 0.035*"change" + 0.035*"instance" + 0.034*"type" + 0.021*"pass" + 0.017*"result"
INFO: topic diff=0.213205, rho=0.212238
DEBUG: bound: at document #0
INFO: -5.057 per-word bound, 33.3 perplexity estimate based on a held-out corpus of 5 documents with 167 words
INFO: PROGRESS: pass 9, at document #30/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.94620836, 0.10348906, 0.46922272, 0.16347021, 1.1001173]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.946): 0.194*"reference" + 0.059*"name" + 0.056*"list" + 0.049*"method" + 0.047*"string" + 0.047*"argument" + 0.043*"way" + 0.032*"example" + 0.028*"assignment" + 0.025*"code"
INFO: topic #1 (0.103): 0.085*"effect" + 0.042*"update" + 0.035*"point" + 0.031*"reading" + 0.024*"idea" + 0.024*"thread" + 0.023*"time" + 0.021*"hand" + 0.020*"process" + 0.020*"simulate"
INFO: topic #2 (0.469): 0.083*"class" + 0.048*"return" + 0.048*"work" + 0.043*"language" + 0.038*"attribute" + 0.036*"question" + 0.032*"solution" + 0.025*"problem" + 0.025*"case" + 0.025*"access"
INFO: topic #3 (0.163): 0.044*"namespace" + 0.034*"int" + 0.032*"integer" + 0.032*"line" + 0.028*"print" + 0.027*"setattr" + 0.025*"member" + 0.022*"field" + 0.022*"property" + 0.022*"test"
INFO: topic #4 (1.100): 0.178*"object" + 0.134*"function" + 0.109*"value" + 0.072*"variable" + 0.064*"change" + 0.050*"parameter" + 0.033*"instance" + 0.025*"type" + 0.022*"call" + 0.016*"copy"
INFO: topic diff=0.234825, rho=0.212238
DEBUG: bound: at document #0
INFO: -6.294 per-word bound, 78.4 perplexity estimate based on a held-out corpus of 5 documents with 85 words
INFO: PROGRESS: pass 9, at document #35/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.96992666, 0.10553887, 0.49284506, 0.16127974, 1.2156634]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.970): 0.201*"reference" + 0.054*"name" + 0.051*"list" + 0.047*"argument" + 0.044*"method" + 0.044*"way" + 0.043*"string" + 0.034*"example" + 0.030*"assignment" + 0.023*"code"
INFO: topic #1 (0.106): 0.061*"effect" + 0.040*"definition" + 0.030*"update" + 0.025*"point" + 0.023*"reading" + 0.020*"user" + 0.018*"incorrect" + 0.018*"respect" + 0.018*"fine" + 0.018*"vote"
INFO: topic #2 (0.493): 0.086*"language" + 0.067*"class" + 0.039*"return" + 0.039*"work" + 0.031*"attribute" + 0.029*"question" + 0.026*"solution" + 0.025*"post" + 0.021*"problem" + 0.021*"case"
INFO: topic #3 (0.161): 0.039*"namespace" + 0.030*"int" + 0.029*"integer" + 0.028*"line" + 0.025*"print" + 0.024*"setattr" + 0.022*"member" + 0.021*"c" + 0.020*"property" + 0.020*"field"
INFO: topic #4 (1.216): 0.177*"object" + 0.123*"function" + 0.119*"value" + 0.065*"variable" + 0.051*"change" + 0.048*"parameter" + 0.039*"answer" + 0.027*"instance" + 0.022*"call" + 0.020*"pass"
INFO: topic diff=0.214440, rho=0.212238
DEBUG: bound: at document #0
INFO: -5.647 per-word bound, 50.1 perplexity estimate based on a held-out corpus of 5 documents with 178 words
INFO: PROGRESS: pass 9, at document #40/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0232096, 0.11552057, 0.46851167, 0.16111636, 1.1891596]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.023): 0.204*"reference" + 0.053*"list" + 0.047*"name" + 0.041*"method" + 0.040*"string" + 0.035*"argument" + 0.034*"example" + 0.033*"way" + 0.032*"assignment" + 0.030*"target"
INFO: topic #1 (0.116): 0.070*"point" + 0.059*"update" + 0.047*"effect" + 0.032*"user" + 0.031*"definition" + 0.024*"wrap" + 0.024*"support" + 0.018*"reading" + 0.014*"bolt" + 0.014*"piece"
INFO: topic #2 (0.469): 0.083*"language" + 0.057*"class" + 0.043*"work" + 0.039*"case" + 0.033*"return" + 0.026*"attribute" + 0.025*"question" + 0.023*"show" + 0.022*"solution" + 0.021*"post"
INFO: topic #3 (0.161): 0.072*"integer" + 0.044*"database" + 0.044*"entry" + 0.043*"print" + 0.037*"namespace" + 0.027*"pointer" + 0.018*"int" + 0.017*"line" + 0.015*"setattr" + 0.015*"connection"
INFO: topic #4 (1.189): 0.204*"object" + 0.155*"value" + 0.102*"function" + 0.065*"variable" + 0.043*"change" + 0.037*"answer" + 0.037*"parameter" + 0.031*"type" + 0.021*"instance" + 0.020*"call"
INFO: topic diff=0.306132, rho=0.212238
DEBUG: bound: at document #0
INFO: -6.297 per-word bound, 78.6 perplexity estimate based on a held-out corpus of 5 documents with 78 words
INFO: PROGRESS: pass 9, at document #45/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0075408, 0.1110069, 0.5219153, 0.15247776, 1.2469952]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.008): 0.204*"reference" + 0.046*"list" + 0.041*"name" + 0.039*"argument" + 0.035*"method" + 0.035*"string" + 0.034*"example" + 0.033*"way" + 0.028*"assignment" + 0.026*"target"
INFO: topic #1 (0.111): 0.063*"point" + 0.053*"update" + 0.043*"effect" + 0.029*"user" + 0.028*"definition" + 0.022*"wrap" + 0.022*"support" + 0.016*"reading" + 0.013*"bolt" + 0.013*"piece"
INFO: topic #2 (0.522): 0.058*"language" + 0.052*"return" + 0.047*"case" + 0.041*"array" + 0.040*"class" + 0.030*"work" + 0.030*"my_fun" + 0.024*"item" + 0.022*"problem" + 0.020*"operator"
INFO: topic #3 (0.152): 0.066*"integer" + 0.040*"database" + 0.040*"entry" + 0.039*"print" + 0.034*"namespace" + 0.025*"pointer" + 0.017*"int" + 0.016*"line" + 0.014*"setattr" + 0.014*"connection"
INFO: topic #4 (1.247): 0.197*"object" + 0.155*"value" + 0.109*"function" + 0.056*"variable" + 0.049*"parameter" + 0.046*"change" + 0.036*"answer" + 0.026*"type" + 0.022*"instance" + 0.022*"call"
INFO: topic diff=0.201692, rho=0.212238
DEBUG: bound: at document #0
INFO: -6.286 per-word bound, 78.0 perplexity estimate based on a held-out corpus of 5 documents with 98 words
INFO: PROGRESS: pass 9, at document #50/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0621574, 0.11237635, 0.5620497, 0.14560083, 1.3303668]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.062): 0.186*"reference" + 0.058*"list" + 0.044*"name" + 0.044*"string" + 0.038*"argument" + 0.037*"way" + 0.034*"method" + 0.034*"example" + 0.028*"assignment" + 0.027*"code"
INFO: topic #1 (0.112): 0.054*"point" + 0.045*"update" + 0.038*"support" + 0.037*"effect" + 0.025*"user" + 0.024*"definition" + 0.024*"reason" + 0.019*"wrap" + 0.014*"reading" + 0.011*"respect"
INFO: topic #2 (0.562): 0.067*"return" + 0.051*"class" + 0.047*"language" + 0.031*"case" + 0.027*"context" + 0.027*"array" + 0.026*"perl" + 0.020*"work" + 0.020*"my_fun" + 0.019*"show"
INFO: topic #3 (0.146): 0.060*"integer" + 0.037*"database" + 0.037*"entry" + 0.036*"print" + 0.031*"namespace" + 0.023*"pointer" + 0.016*"int" + 0.015*"line" + 0.013*"setattr" + 0.013*"connection"
INFO: topic #4 (1.330): 0.174*"object" + 0.156*"value" + 0.122*"function" + 0.061*"variable" + 0.050*"parameter" + 0.043*"change" + 0.031*"answer" + 0.027*"call" + 0.027*"type" + 0.019*"pass"
INFO: topic diff=0.222673, rho=0.212238
DEBUG: bound: at document #0
INFO: -6.087 per-word bound, 68.0 perplexity estimate based on a held-out corpus of 5 documents with 80 words
INFO: PROGRESS: pass 9, at document #55/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0413065, 0.11298819, 0.5597421, 0.14592603, 1.3728724]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (1.041): 0.170*"reference" + 0.051*"list" + 0.050*"argument" + 0.044*"name" + 0.044*"way" + 0.040*"code" + 0.039*"string" + 0.031*"method" + 0.030*"example" + 0.029*"output"
INFO: topic #1 (0.113): 0.045*"point" + 0.042*"definition" + 0.038*"update" + 0.031*"support" + 0.031*"idea" + 0.031*"effect" + 0.023*"dll" + 0.021*"user" + 0.020*"reason" + 0.016*"wrap"
INFO: topic #2 (0.560): 0.108*"return" + 0.043*"class" + 0.039*"language" + 0.026*"case" + 0.023*"context" + 0.023*"array" + 0.022*"practice" + 0.022*"perl" + 0.021*"problem" + 0.020*"situation"
INFO: topic #3 (0.146): 0.048*"pointer" + 0.046*"integer" + 0.040*"ctype" + 0.028*"database" + 0.028*"entry" + 0.027*"print" + 0.024*"namespace" + 0.023*"input" + 0.019*"pointer(instance" + 0.019*"byref"
INFO: topic #4 (1.373): 0.157*"value" + 0.140*"object" + 0.130*"function" + 0.053*"parameter" + 0.049*"variable" + 0.039*"type" + 0.039*"change" + 0.031*"call" + 0.029*"pass" + 0.025*"answer"
INFO: topic diff=0.160043, rho=0.212238
DEBUG: bound: at document #0
INFO: -5.477 per-word bound, 44.5 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 9, at document #60/61
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.86599255, 0.10676825, 0.52269536, 0.15805328, 1.4237121]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 61 documents
INFO: topic #0 (0.866): 0.161*"reference" + 0.052*"way" + 0.051*"argument" + 0.047*"list" + 0.041*"name" + 0.037*"code" + 0.035*"string" + 0.032*"output" + 0.028*"method" + 0.027*"example"
INFO: topic #1 (0.107): 0.039*"point" + 0.037*"definition" + 0.033*"update" + 0.028*"support" + 0.028*"idea" + 0.027*"effect" + 0.021*"dll" + 0.018*"user" + 0.018*"reason" + 0.014*"wrap"
INFO: topic #2 (0.523): 0.123*"return" + 0.052*"case" + 0.038*"class" + 0.035*"language" + 0.025*"work" + 0.020*"context" + 0.020*"array" + 0.020*"practice" + 0.019*"perl" + 0.019*"problem"
INFO: topic #3 (0.158): 0.075*"command" + 0.057*"integer" + 0.057*"input" + 0.050*"line" + 0.045*"script" + 0.032*"print" + 0.031*"pointer" + 0.026*"ctype" + 0.018*"database" + 0.018*"entry"
INFO: topic #4 (1.424): 0.152*"function" + 0.147*"value" + 0.135*"object" + 0.067*"variable" + 0.042*"parameter" + 0.032*"change" + 0.028*"type" + 0.025*"arg" + 0.025*"pass" + 0.022*"call"
INFO: topic diff=0.207211, rho=0.212238
DEBUG: bound: at document #0
INFO: -7.053 per-word bound, 132.8 perplexity estimate based on a held-out corpus of 1 documents with 12 words
INFO: PROGRESS: pass 9, at document #61/61
INFO: optimized alpha [0.77257663, 0.09996314, 0.40040657, 0.1880501, 0.9897691]
DEBUG: updating topics
INFO: merging changes from 1 documents into a model of 61 documents
INFO: topic #0 (0.773): 0.140*"reference" + 0.079*"argument" + 0.055*"output" + 0.046*"way" + 0.041*"list" + 0.039*"issue" + 0.035*"name" + 0.032*"code" + 0.031*"string" + 0.024*"method"
INFO: topic #1 (0.100): 0.034*"point" + 0.032*"definition" + 0.029*"update" + 0.024*"support" + 0.024*"idea" + 0.024*"effect" + 0.018*"dll" + 0.016*"user" + 0.016*"reason" + 0.013*"wrap"
INFO: topic #2 (0.400): 0.115*"return" + 0.048*"case" + 0.035*"class" + 0.033*"language" + 0.023*"work" + 0.019*"context" + 0.019*"array" + 0.019*"practice" + 0.018*"perl" + 0.018*"problem"
INFO: topic #3 (0.188): 0.077*"line" + 0.052*"dict.hpp" + 0.052*"test" + 0.052*"os" + 0.052*"look" + 0.052*"dict.i" + 0.052*"window" + 0.050*"solution" + 0.041*"command" + 0.032*"integer"
INFO: topic #4 (0.990): 0.144*"function" + 0.139*"value" + 0.128*"object" + 0.063*"variable" + 0.040*"parameter" + 0.039*"result" + 0.030*"change" + 0.026*"type" + 0.024*"arg" + 0.023*"pass"
INFO: topic diff=0.187380, rho=0.212238
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=323, num_topics=5, decay=0.5, chunksize=5> in 0.31s', 'datetime': '2023-05-09T14:36:18.890199', 'gensim': '4.3.1', 'python': '3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}
INFO: {'id': 986145, 'content': 'Arguments are passed by assignment. The rationale behind this is twofold: So: If you pass a mutable object into a method, the method gets a reference to that same object and you can mutate it to your heart\'s delight, but if you rebind the reference in the method, the outer scope will know nothing about it, and after you\'re done, the outer reference will still point at the original object.  If you pass an immutable object to a method, you still can\'t rebind the outer reference, and you can\'t even mutate the object. To make it even more clear, let\'s have some examples.  Let\'s try to modify the list that was passed to a method: Output: Since the parameter passed in is a reference to outer_list, not a copy of it, we can use the mutating list methods to change it and have the changes reflected in the outer scope. Now let\'s see what happens when we try to change the reference that was passed in as a parameter: Output: Since the the_list parameter was passed by value, assigning a new list to it had no effect that the code outside the method could see. The the_list was a copy of the outer_list reference, and we had the_list point to a new list, but there was no way to change where outer_list pointed. It\'s immutable, so there\'s nothing we can do to change the contents of the string Now, let\'s try to change the reference Output: Again, since the the_string parameter was passed by value, assigning a new string to it had no effect that the code outside the method could see. The the_string was a copy of the outer_string reference, and we had the_string point to a new string, but there was no way to change where outer_string pointed. I hope this clears things up a little. EDIT: It\'s been noted that this doesn\'t answer the question that @David originally asked, "Is there something I can do to pass the variable by actual reference?". Let\'s work on that. As @Andrea\'s answer shows, you could return the new value. This doesn\'t change the way things are passed in, but does let you get the information you want back out: If you really wanted to avoid using a return value, you could create a class to hold your value and pass it into the function or use an existing class, like a list: Although this seems a little cumbersome.', 'score': 0.8543395639947212}
INFO: {'id': 69913926, 'content': "Python always receives parameters by value, so assigning a new value to a parameter variable inside the body of a function won't affect the caller. If the value is mutable, then mutating it inside the body of the function will affect the caller, but strings are immutable (there's no method you can call on a string that will change its contents, only return a new string). In general, the way to approach the situation you describe is to simply return multiple values: If you need an immutable argument to be mutable, though, an easy workaround (that doesn't involve using global) is to wrap it in a mutable container, like a list:", 'score': 0.8442102086862264}
INFO: {'id': 12440140, 'content': "Technically, Python always uses pass by reference values. I am going to repeat my other answer to support my statement. Python always uses pass-by-reference values. There isn't any exception. Any variable assignment means copying the reference value. No exception. Any variable is the name bound to the reference value. Always. You can think about a reference value as the address of the target object. The address is automatically dereferenced when used. This way, working with the reference value, it seems you work directly with the target object. But there always is a reference in between, one step more to jump to the target. Here is the example that proves that Python uses passing by reference:  If the argument was passed by value, the outer lst could not be modified. The green are the target objects (the black is the value stored inside, the red is the object type), the yellow is the memory with the reference value inside -- drawn as the arrow. The blue solid arrow is the reference value that was passed to the function (via the dashed blue arrow path). The ugly dark yellow is the internal dictionary. (It actually could be drawn also as a green ellipse. The colour and the shape only says it is internal.) You can use the id() built-in function to learn what the reference value is (that is, the address of the target object). In compiled languages, a variable is a memory space that is able to capture the value of the type. In Python, a variable is a name (captured internally as a string) bound to the reference variable that holds the reference value to the target object. The name of the variable is the key in the internal dictionary, the value part of that dictionary item stores the reference value to the target. Reference values are hidden in Python. There isn't any explicit user type for storing the reference value. However, you can use a list element (or element in any other suitable container type) as the reference variable, because all containers do store the elements also as references to the target objects. In other words, elements are actually not contained inside the container -- only the references to elements are.", 'score': 0.8392266545842794}
INFO: {'id': 54315603, 'content': 'Pass-by-reference in Python is quite different from the concept of pass by reference in C++/Java. Java and C#: primitive types (including string) pass by value (copy). A reference type is passed by reference (address copy), so all changes made in the parameter in the called function are visible to the caller. C++: Both pass-by-reference or pass-by-value are allowed. If a parameter is passed by reference, you can either modify it or not depending upon whether the parameter was passed as const or not. However, const or not, the parameter maintains the reference to the object and reference cannot be assigned to point to a different object within the called function. Python:\nPython is pass-by-object-reference, of which it is often said: Object references are passed by value. (read here). Both the caller and the function refer to the same object, but the parameter in the function is a new variable which is just holding a copy of the object in the caller. Like C++, a parameter can be either modified or not in function. This depends upon the type of object passed. For example, an immutable object type cannot be modified in the called function whereas a mutable object can be either updated or re-initialized. A crucial difference between updating or reassigning/re-initializing the mutable variable is that updated value gets reflected back in the called function whereas the reinitialized value does not. The scope of any assignment of new object to a mutable variable is local to the function in the python. Examples provided by @blair-conrad are great to understand this.', 'score': 0.8338477263590626}
INFO: {'id': 8140747, 'content': "The problem comes from a misunderstanding of what variables are in Python. If you're used to most traditional languages, you have a mental model of what happens in the following sequence: You believe that a is a memory location that stores the value 1, then is updated to store the value 2. That's not how things work in Python. Rather, a starts as a reference to an object with the value 1, then gets reassigned as a reference to an object with the value 2. Those two objects may continue to coexist even though a doesn't refer to the first one anymore; in fact they may be shared by any number of other references within the program. When you call a function with a parameter, a new reference is created that refers to the object passed in. This is separate from the reference that was used in the function call, so there's no way to update that reference and make it refer to a new object. In your example: self.variable is a reference to the string object 'Original'. When you call Change you create a second reference var to the object. Inside the function you reassign the reference var to a different string object 'Changed', but the reference self.variable is separate and does not change. The only way around this is to pass a mutable object. Because both references refer to the same object, any changes to the object are reflected in both places.", 'score': 0.8336368543848752}
INFO: {'id': 25810863, 'content': 'There are a lot of insights in answers here, but I think an additional point is not clearly mentioned here explicitly.   Quoting from Python documentation What are the rules for local and global variables in Python? In Python, variables that are only referenced inside a function are implicitly global. If a variable is assigned a new value anywhere within the functions body, its assumed to be a local. If a variable is ever assigned a new value inside the function, the variable is implicitly local, and you need to explicitly declare it as global.\nThough a bit surprising at first, a moments consideration explains this. On one hand, requiring global for assigned variables provides a bar against unintended side-effects. On the other hand, if global was required for all global references, youd be using global all the time. Youd have to declare as global every reference to a built-in function or to a component of an imported module. This clutter would defeat the usefulness of the global declaration for identifying side-effects. Even when passing a mutable object to a function this still applies. And to me it clearly explains the reason for the difference in behavior between assigning to the object and operating on the object in the function. gives: The assignment to an global variable that is not declared global therefore creates a new local object and breaks the link to the original object.', 'score': 0.8301006924583365}
INFO: {'id': 53929523, 'content': 'In the first case, num refers to the integer object of value 1.  Passing it to a function assigns arg to also refer to the same integer object of value 1, but then arg is reassigned to a new integer object of value 10.  num is still referring to the original integer object of value 1. In the second case, test_obj as assigned the value of a new TestClass instance.  Passing it to a function assigns arg to the same TestClass instance.  The object itself is altered, and both arg and test_obj still refer to the same object, so even after the function returns, test_obj "sees" the change.', 'score': 0.8255092252230916}
INFO: {'id': 74505976, 'content': "Adding to Tark-Tolonen's answer: Please absolutely avoid altering the object reference of the output argument in your function, otherwise the output argument won't work. For instance, I wish to pass an ndarray into a function my_fun and modify it After calling my_fun, array a stills remains all zeros since the function np.ones_like returns a reference to another array full of ones and assigns it to out_arr instead of modifying the object reference passed by out_arr directly. Running this code you will find that two print(id()) gives different memory locations. Also, beware of the array operators from numpy, they usually returns a reference to another array if you write something like this Using the - and = operator might cause similar problems. To prevent having out_arr's memory location altered, you can use the numpy functions that does the exactly same operations but has a out parameter built in. The proceeding code should be rewritten as And the memory location of out_arr remains the same before and after calling my_fun while its values gets modified successfully.", 'score': 0.8230527973968156}
INFO: {'id': 39054982, 'content': 'While pass by reference is nothing that fits well into Python and should be rarely used, there are some workarounds that actually can work to get the object currently assigned to a local variable or even reassign a local variable from inside of a called function. The basic idea is to have a function that can do that access and can be passed as object into other functions or stored in a class. One way is to use global (for global variables) or nonlocal (for local variables in a function) in a wrapper function. The same idea works for reading and deleting a variable. For just reading, there is even a shorter way of just using lambda: x which returns a callable that when called returns the current value of x. This is somewhat like "call by name" used in languages in the distant past. Passing 3 wrappers to access a variable is a bit unwieldy so those can be wrapped into a class that has a proxy attribute: Pythons "reflection" support makes it possible to get a object that is capable of reassigning a name/variable in a given scope without defining functions explicitly in that scope: Here the ByRef class wraps a dictionary access. So attribute access to wrapped is translated to a item access in the passed dictionary. By passing the result of the builtin locals and the name of a local variable, this ends up accessing a local variable. The Python documentation as of 3.5 advises that changing the dictionary might not work, but it seems to work for me.', 'score': 0.8225852623917012}
INFO: {'id': 70007855, 'content': "A simple answer: In Python, like C++, when you create an object instance and pass it as a parameter, no copies of the instance itself get made, so you are referencing the same instance from outside and inside the function and are able to modify the component datums of the same object instance, hence changes are visible to the outside. For basic types, Python and C++ also behave the same to each other, in that copies of the instances are now made, so the outside sees/modifies a different instance than the inside of the function. Hence changes from the inside are not visible on the outside. Here comes the real difference between Python and C++: C++ has the concept of address pointers, and C++ allows you to pass pointers instead, which bypasses the copying of basic types, so that the inside of the function can affect the same instances as those outside, so that the changes are also visible to the outside. This has no equivalent in Python, so is not possible without workarounds (such as creating wrapper types). Such pointers can be useful in Python, but it's not as necessary as it is in C++, because in C++, you can only return a single entity, whereas in Python you can return multiple values separated by commas (i.e., a tuple). So in Python, if you have variables a,b, and c, and want a function to modify them persistently (relative to the outside), you would do this: Such syntax is not easily possible in C++, thus in C++ you would do this instead:", 'score': 0.8198566327714055}
INFO: {'id': 62970753, 'content': "I am new to Python, started yesterday (though I have been programming for 45 years). I came here because I was writing a function where I wanted to have two so-called out-parameters. If it would have been only one out-parameter, I wouldn't get hung up right now on checking how reference/value works in Python. I would just have used the return value of the function instead. But since I needed two such out-parameters I felt I needed to sort it out. In this post I am going to show how I solved my situation. Perhaps others coming here can find it valuable, even though it is not exactly an answer to the topic question. Experienced Python programmers of course already know about the solution I used, but it was new to me. From the answers here I could quickly see that Python works a bit like JavaScript in this regard, and that you need to use workarounds if you want the reference functionality. But then I found something neat in Python that I don't think I have seen in other languages before, namely that you can return more than one value from a function, in a simple comma-separated way, like this: and that you can handle that on the calling side similarly, like this That was good enough for me and I was satisfied. There isn't any need to use some workaround. In other languages you can of course also return many values, but then usually in the from of an object, and you need to adjust the calling side accordingly. The Python way of doing it was nice and simple. If you want to mimic by reference even more, you could do as follows: which gives this result", 'score': 0.8152480631073875}
INFO: {'id': 986339, 'content': "Think of stuff being passed by assignment instead of by reference/by value. That way, it is always clear, what is happening as long as you understand what happens during the normal assignment. So, when passing a list to a function/method, the list is assigned to the parameter name. Appending to the list will result in the list being modified. Reassigning the list inside the function will not change the original list, since: Since immutable types cannot be modified, they seem like being passed by value - passing an int into a function means assigning the int to the function's parameter. You can only ever reassign that, but it won't change the original variables value.", 'score': 0.8142101739000027}
INFO: {'id': 21700609, 'content': 'The key to understanding parameter passing is to stop thinking about "variables". There are names and objects in Python and together they\nappear like variables, but it is useful to always distinguish the three. That is all there is to it. Mutability is irrelevant to this question. Example: This binds the name a to an object of type integer that holds the value 1. This binds the name b to the same object that the name x is currently bound to.\nAfterward, the name b has nothing to do with the name x anymore. See sections 3.1 and 4.2 in the Python 3 language reference. In the code shown in the question, the statement self.Change(self.variable) binds the name var (in the scope of function Change) to the object that holds the value \'Original\' and the assignment var = \'Changed\' (in the body of function Change) assigns that same name again: to some other object (that happens to hold a string as well but could have been something else entirely). So if the thing you want to change is a mutable object, there is no problem, as everything is effectively passed by reference. If it is an immutable object (e.g. a bool, number, string), the way to go is to wrap it in a mutable object.\nThe quick-and-dirty solution for this is a one-element list (instead of self.variable, pass [self.variable] and in the function modify var[0]).\nThe more pythonic approach would be to introduce a trivial, one-attribute class. The function receives an instance of the class and manipulates the attribute.', 'score': 0.8133340053586561}
INFO: {'id': 12686527, 'content': "Here is the simple (I hope) explanation of the concept pass by object used in Python.\nWhenever you pass an object to the function, the object itself is passed (object in Python is actually what you'd call a value in other programming languages) not the reference to this object. In other words, when you call: The actual object - [0, 1] (which would be called a value in other programming languages) is being passed. So in fact the function change_me will try to do something like: which obviously will not change the object passed to the function. If the function looked like this: Then the call would result in: which obviously will change the object. This answer explains it well.", 'score': 0.81201359260112}
INFO: {'id': 4702301, 'content': "In addition, if you feel like reading some code, I think that pywin32 has a way to handle output parameters. In the Windows API it's common practice to rely heavily on output parameters, so I figure they must have dealt with it in some way.", 'score': 0.8118508681110802}
INFO: {'id': 38692659, 'content': 'You cannot do this without indicating to the function which return type is required, or masking the function name (see my comment).  Let me demonstrate why. In Perl we can do this, by testing the context of the call.  The first (single return value) would be scalar context, and the second in list context.  We could test using a function called wantarray (Google "python wantarray" - other search engines are available).  Perl, for this reason and many others, is unusual if not unique. Python doesn\'t work like that, even though introspection can be taken to extremes compared to other languages.  The form of an assignment is: where name is a typeless reference.  So: Even if, by some sneaky means, we inspected the byte-code, we would have no way of knowing what class of object mat is supposed to reference.  A list, a tuple, an int, a bird, a plane? The syntax you show: is a puzzle.  Although valid, it has no practical difference to: which of course is a tuple.  So, how can we tell if: should be a tuple, a list, or whatever class of object mat is supposed to reference.   After all that, in my opinion returning objects of different classes is a dubious practice, even in Perl.  There are a few exceptions, returning None under some circumstances for example.  Why dubious?  Because the code becomes difficult to read, modify, and support.  ', 'score': 0.8115797513194992}
INFO: {'id': 15697476, 'content': 'Effbot (aka Fredrik Lundh) has described Python\'s variable passing style as call-by-object:  http://effbot.org/zone/call-by-object.htm Objects are allocated on the heap and pointers to them can be passed around anywhere.   When you make an assignment such as x = 1000, a dictionary entry is created that maps the string "x" in the current namespace to a pointer to the integer object containing one thousand.    When you update "x" with x = 2000, a new integer object is created and the dictionary is updated to point at the new object.  The old one thousand object is unchanged (and may or may not be alive depending on whether anything else refers to the object). When you do a new assignment such as y = x, a new dictionary entry "y" is created that points to the same object as the entry for "x". Objects like strings and integers are immutable.  This simply means that there are no methods that can change the object after it has been created.  For example, once the integer object one-thousand is created, it will never change.  Math is done by creating new integer objects. Objects like lists are mutable.  This means that the contents of the object can be changed by anything pointing to the object.  For example, x = []; y = x; x.append(10); print y will print [10].  The empty list was created.  Both "x" and "y" point to the same list.  The append method mutates (updates) the list object (like adding a record to a database) and the result is visible to both "x" and "y" (just as a database update would be visible to every connection to that database). Hope that clarifies the issue for you. ', 'score': 0.8099540274792816}
INFO: {'id': 71049904, 'content': "Python assigns a unique identifier to each object and this identifier can be found by using Python's built-in id() function.\nIt is ready to verify that actual and formal arguments in a function call have the same id value, which indicates that the dummy argument and actual argument refer to the same object. Note that the actual argument and the corresponding dummy argument are two names referring to the same object. If you re-bind a dummy argument to a new value/object in the function scope, this does not effect the fact that the actual argument still points to the original object because actual argument and dummy argument are two names. The above two facts can be summarized as arguments are passed by assignment. i.e., If you re-bind dummy_argument to a new object in the function body, the actual_argument still refers to the original object. If you use dummy_argument[0] = some_thing, then this will also modify actual_argument[0]. Therefore the effect of pass by reference can be achieved by modifying the components/attributes of the object reference passed in. Of course, this requires that the object passed is a mutable object.", 'score': 0.8096588581584585}
INFO: {'id': 56069248, 'content': 'Since it seems to be nowhere mentioned an approach to simulate references as known from e.g. C++ is to use an "update" function and pass that instead of the actual variable (or rather, "name"): This is mostly useful for "out-only references" or in a situation with multiple threads / processes (by making the update function thread / multiprocessing safe). Obviously the above does not allow reading the value, only updating it.', 'score': 0.8094387169045839}
INFO: {'id': 49184305, 'content': 'Python is about to "output" variables (or parameters as you called them) in a few ways. If you would like the variables to be written to screen, you can use the print function. If you instead want this variable to be used for a different python script, you might want to consider writing a function. Functions can take variables as input and use them to do calculations, then return outputs. Lastly, you may want to consider placing your sys.argv commands inside of a conditions which only runs the commands if your script is run from the command line. This way the program will not be looking for command line arguments if someone used "import" on your script instead of running it from the command line.', 'score': 0.8055721286046956}
INFO: {'id': 3127336, 'content': '(edit - Blair has updated his enormously popular answer so that it is now accurate) I think it is important to note that the current post with the most votes (by Blair Conrad), while being correct with respect to its result, is misleading and is borderline incorrect based on its definitions.  While there are many languages (like C) that allow the user to either pass by reference or pass by value, Python is not one of them. David Cournapeau\'s answer points to the real answer and explains why the behavior in Blair Conrad\'s post seems to be correct while the definitions are not. To the extent that Python is pass by value, all languages are pass by value since some piece of data (be it a "value" or a "reference") must be sent. However, that does not mean that Python is pass by value in the sense that a C programmer would think of it. If you want the behavior, Blair Conrad\'s answer is fine.  But if you want to know the nuts and bolts of why Python is neither pass by value or pass by reference, read David Cournapeau\'s answer.', 'score': 0.803227040444612}
INFO: {'id': 54736439, 'content': "1) RETURN the output of function A. 2) When you call function A, store the result in another variable. The variable result will now contain the value of (num1+num2). We will pass this as an argument to function B. 3) When calling function B, in place of num3, pass the value stored in 'result'. The second argument can be any number.", 'score': 0.8000634808925653}
INFO: {'id': 4702442, 'content': "You can do that with mutable objects, but in most cases it does not make sense because you can return multiple values (or a dictionary if you want to change a function's return value without breaking existing calls to it). I can only think of one case where you might need it - that is threading, or more exactly, passing a value between threads.", 'score': 0.7967691202764233}
INFO: {'id': 986044, 'content': "In this case the variable titled var in the method Change is assigned a reference to self.variable, and you immediately assign a string to var. It's no longer pointing to self.variable. The following code snippet shows what would happen if you modify the data structure pointed to by var and self.variable, in this case a list: I'm sure someone else could clarify this further.", 'score': 0.7963394098536382}
INFO: {'id': 29293411, 'content': 'Pythons pass-by-assignment scheme isnt quite the same as C++s reference parameters option, but it turns out to be very similar to the argument-passing model of the C language (and others) in practice:', 'score': 0.7952005312848618}
INFO: {'id': 67891176, 'content': 'This might be an elegant object-oriented solution without this functionality in Python.  An even more elegant solution would be to have any class you make subclass from this.  Or you could name it "MasterClass".  But instead of having a single variable and a single Boolean, make them a collection of some kind.  I fixed the naming of your instance variables to comply with PEP\xa08.', 'score': 0.7950403667223637}
INFO: {'id': 54736346, 'content': "First, you need your functions to return values. Currently A() is just computing the value num1 + num2 and not doing anything with it. If you want it to pass back the answer, you have to add a return statement at the end of it: Next, if you want to pass the result of that function into function B, you'd do this: See, it works the same as calling a function anywhere else, except it's inside the parentheses and in the same place as you might otherwise put a variable.", 'score': 0.7934304427277598}
INFO: {'id': 54736424, 'content': 'what your looking for is the "return"\nbasically it allows your function to give an output that you could use later. for example: in general this is pretty basic and not very good code practice because i don\'t know what your trying to solve. further information might help writing a better use of code for your problem :)\ni wouldn\'t actually use this code other than to demonstrate the return in this situation \njust so you know, while defining a function doesn\'t actually do anything until you call it so the fact you gave it the same name does not bind the actual values in any way. i would recommend you read more about python basics regardless. good luck!', 'score': 0.7931098759106123}
INFO: {'id': 65786490, 'content': 'POINTER(ctypes-type) declares a pointer type and its parameter must be a ctypes type, so below was incorrect: When you create a ctype to hold the output parameter, simply create an instance of the type: Then pass it as a parameter by reference with: Also, wrapping input values is generally unncessary if you set .argtypes.  ctypes knows to wrap Python values as declared, so you can just pass them directly. Example: test.c test.py Output: You can create pointers directly with pointer(instance) as well, so below also works, but is less efficient than byref:', 'score': 0.7914198531840585}
INFO: {'id': 40345432, 'content': 'Given the way Python handles values and references to them, the only way you can reference an arbitrary instance attribute is by name: In real code you would, of course, add error checking on the dict lookup.', 'score': 0.7887790695657592}
INFO: {'id': 35260424, 'content': "Aside from all the great explanations on how this stuff works in Python, I don't see a simple suggestion for the problem. As you seem to do create objects and instances, the Pythonic way of handling instance variables and changing them is the following: In instance methods, you normally refer to self to access instance attributes. It is normal to set instance attributes in __init__ and read or change them in instance methods. That is also why you pass self as the first argument to def Change. Another solution would be to create a static method like this:", 'score': 0.7854630317859138}
INFO: {'id': 53929719, 'content': 'This happens because -  In first case, after passing a variable to a function test_func2(num), that value like will be caught in a local variable arg, whose scope is local to the function. After we return from function that variable is destroyed as the function has ended its execution. And when you pass object to the function test_func(test_obj), the arg in function will be a reference to the object it catches i.e., test_obj. That means after modifying arg.one = 10 you are actually modifying the original objects value i.e., test_obj.one = 10.', 'score': 0.7831926683811192}
INFO: {'id': 65785486, 'content': 'I modified your code a little to Change the definitions to match.  Following the ideas in the answer to Passing pointers to DLL function in Python , this may help', 'score': 0.7816477569033657}
INFO: {'id': 49183847, 'content': "If you have to put it in as an input, don't you have that information already? How are you calling the function if you don't know what your inputs are? Store the input as a variable before calling it, then use that variable wherever else you need it.", 'score': 0.7793145151271152}
INFO: {'id': 4702272, 'content': "You mean like passing by reference? For Python object the default is to pass by reference. However, I don't think you can change the reference in Python (otherwise it won't affect the original object). For example:", 'score': 0.7770357604616732}
INFO: {'id': 4702280, 'content': 'Python can return a tuple of multiple items: But you can also pass a mutable parameter, and return values via mutation of the object as well:', 'score': 0.7737200572180407}
INFO: {'id': 50157212, 'content': 'You can merely use an empty class as an instance to store reference objects because internally object attributes are stored in an instance dictionary. See the example.', 'score': 0.771616424802615}
INFO: {'id': 67988352, 'content': 'I solved a similar requirement as follows: To implement a member function that changes a variable, dont pass the variable itself, but pass a functools.partial that contains setattr referring to the variable.\nCalling the functools.partial inside change() will execute settatr and change the actual referenced variable. Note that setattr needs the name of the variable as string.', 'score': 0.7713827265021379}
INFO: {'id': 69913928, 'content': 'To manipulate an outside-function variable, you either have to return it, or use it as a global variable: return global', 'score': 0.7695006312021317}
INFO: {'id': 21684541, 'content': 'As you can state you need to have a mutable object, but let me suggest you to check over the global variables as they can help you or even solve this kind of issue! http://docs.python.org/3/faq/programming.html#what-are-the-rules-for-local-and-global-variables-in-python example:', 'score': 0.7590571514992134}
INFO: {'id': 25670170, 'content': 'I found the other answers rather long and complicated, so I created this simple diagram to explain the way Python treats variables and parameters.\n', 'score': 0.7563802918623611}
INFO: {'id': 46136730, 'content': 'Since your example happens to be object-oriented, you could make the following change to achieve a similar result:', 'score': 0.7552976542320325}
INFO: {'id': 986495, 'content': 'It is neither pass-by-value or pass-by-reference - it is call-by-object. See this, by Fredrik Lundh: Call By Object Here is a significant quote: "...variables [names] are not objects; they cannot be denoted by other variables or referred to by objects." In your example, when the Change method is called--a namespace is created for it; and var becomes a name, within that namespace, for the string object \'Original\'. That object then has a name in two namespaces. Next, var = \'Changed\' binds var to a new string object, and thus the method\'s namespace forgets about \'Original\'. Finally, that namespace is forgotten, and the string \'Changed\' along with it.', 'score': 0.7540096574588508}
INFO: {'id': 73945173, 'content': 'There are already many great answers (or let\'s say opinions) about this and I\'ve read them, but I want to mention a missing one. The one from Python\'s documentation in the FAQ section. I don\'t know the date of publishing this page, but this should be our true reference: Remember that arguments are passed by assignment in Python. Since\nassignment just creates references to objects, theres no alias\nbetween an argument name in the caller and callee, and so no\ncall-by-reference per se. If you have: and you call it like fn(a), you\'re doing exactly what you do in assignment. So this happens: An additional reference to SOMETHING is created. Variables are just symbols/names/references. They don\'t "hold" anything.', 'score': 0.7527383495068286}
INFO: {'id': 69642519, 'content': "Most of the time, the variable to be passed by reference is a class member.\nThe solution I suggest is to use a decorator to add both a field that is mutable and corresponding property. The field is a class wrapper around the variable. The @refproperty adds both self._myvar (mutable) and self.myvar property. It will print 6. Compare this to: In this case, it won't work. It will print 4. The code is the following:", 'score': 0.7436965341856191}
INFO: {'id': 38834546, 'content': "I used the following method to quickly convert some Fortran code to Python.  True, it's not pass by reference as the original question was posed, but it is a simple workaround in some cases.", 'score': 0.7429466104622516}
INFO: {'id': 68167731, 'content': 'Use dataclasses. Also, it allows you to apply type restrictions (aka "type hints"). I agree with folks that in most cases you\'d better consider not to use it. And yet, when we\'re talking about contexts, it\'s worth to know that way. You can design an explicit context class though. When prototyping, I prefer dataclasses, just because it\'s easy to serialize them back and forth.', 'score': 0.7303586520308569}
INFO: {'id': 47050775, 'content': "One issue is this line: Should be: The $result handling looks funny, but I didn't continue to debug.  I think a better solution is to use a multi-argument typemap.  Here's what I came up with to test it (Windows OS): dict.hpp dict.cpp dict.i Output:", 'score': 0.7287613185747115}
INFO: {'id': 36775894, 'content': "There is a little trick to pass an object by reference, even though the language doesn't make it possible. It works in Java too; it's the list with one item. ;-) It's an ugly hack, but it works. ;-P", 'score': 0.7240920481189712}
INFO: {'id': 55992875, 'content': 'Since dictionaries are passed by reference, you can use a dict variable to store any referenced values inside it.', 'score': 0.7232505167773113}
INFO: {'id': 66819159, 'content': "Most likely not the most reliable method but this works, keep in mind that you are overloading the built-in str function which is typically something you don't want to do:", 'score': 0.7141034467113603}
INFO: {'id': 38691125, 'content': 'There are two ways to do this. One is to accept an argument that determines the return value. The second, (and more interesting) is to return a generator. This will let you get only the first or get the first n return values.', 'score': 0.7118331324138809}
INFO: {'id': 72357404, 'content': 'I share another fun way for people to comprehend this topic over a handy tool - Python Tutor: Learn Python, JavaScript, C, C++, and Java programming by visualizing code based on the example of passing a mutable list from @Mark Ransom. Just play it around, and then you will figure it out. Passing a String  Passing a List ', 'score': 0.6850730216735129}
INFO: {'id': 4702267, 'content': 'Pass a list or something like that and put the return value in there.', 'score': 0.6399443259129718}
INFO: {'id': 65935869, 'content': 'Alternatively, you could use ctypes which would look something like this: As a is a c int and not a Python integer and apparently passed by reference. However, you have to be careful as strange things could happen, and it is therefore not advised.', 'score': 0.6316695498770297}
INFO: {'id': 66113656, 'content': 'As far as I have researched, the only convincing way I found by using "_" but this when you call the function, not inside it. As an example: mat, _= ReadBinFile(filename) if you want the "mat" _, title= ReadBinFile(filename) if you want the "title"', 'score': 0.5988550696504917}
INFO: {'id': 6963425, 'content': 'A simple trick I normally use is to just wrap it in a list: (Yeah I know this can be inconvenient, but sometimes it is simple enough to do this.)', 'score': 0.3803882284867998}
INFO: {'id': 75696407, 'content': 'My naive answer:', 'score': 0.35040480810213004}
INFO: {'id': 986335, 'content': 'You got some really good answers here.', 'score': 0.35040480810213004}
INFO: {'id': 73913746, 'content': 'It can be passed with []:', 'score': 0.0}
INFO: {'id': 71579032, 'content': '', 'score': 0.0}
