INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<258 unique tokens: ['way', 'argument', 'change', 'factor', 'function']...> from 52 documents (total 785 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<258 unique tokens: ['way', 'argument', 'change', 'factor', 'function']...> from 52 documents (total 785 corpus positions)", 'datetime': '2023-05-09T14:38:30.747169', 'gensim': '4.3.1', 'python': '3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 5 topics, 10 passes over the supplied corpus of 52 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.320 per-word bound, 159.8 perplexity estimate based on a held-out corpus of 5 documents with 76 words
INFO: PROGRESS: pass 0, at document #5/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.07225543, 0.1334548, 0.071767434, 0.28744495, 0.0717621]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.072): 0.006*"way" + 0.005*"string" + 0.004*"argument" + 0.004*"print" + 0.004*"statement" + 0.004*"\n" + 0.004*"syntaxerror" + 0.004*"output" + 0.004*"error" + 0.004*"str.join()/str.format"
INFO: topic #1 (0.133): 0.121*"argument" + 0.081*"string" + 0.081*"statement" + 0.081*"readability" + 0.041*"way" + 0.041*"output" + 0.041*"print" + 0.041*"speed" + 0.041*"function" + 0.041*"program"
INFO: topic #2 (0.072): 0.005*"way" + 0.004*"string" + 0.004*"\n" + 0.004*"print" + 0.004*"statement" + 0.004*"argument" + 0.004*"syntaxerror" + 0.004*"error" + 0.004*"output" + 0.004*"raise"
INFO: topic #3 (0.287): 0.148*"string" + 0.050*"option" + 0.050*"print" + 0.050*"\n" + 0.033*"result" + 0.033*"punctuation" + 0.033*"backslashe" + 0.033*"name" + 0.033*"syntaxerror" + 0.017*"course"
INFO: topic #4 (0.072): 0.005*"way" + 0.005*"string" + 0.004*"argument" + 0.004*"print" + 0.004*"\n" + 0.004*"statement" + 0.004*"syntaxerror" + 0.004*"output" + 0.004*"error" + 0.004*"raise"
INFO: topic diff=3.881221, rho=1.000000
DEBUG: bound: at document #0
INFO: -8.354 per-word bound, 327.2 perplexity estimate based on a held-out corpus of 5 documents with 193 words
INFO: PROGRESS: pass 0, at document #10/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0799121, 0.17468369, 0.06772559, 0.29784948, 0.08155664]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.080): 0.127*"idea" + 0.064*"code" + 0.064*"case" + 0.033*"comment" + 0.033*"other" + 0.033*"platform" + 0.033*"reading" + 0.033*"file" + 0.033*"f" + 0.033*"note"
INFO: topic #1 (0.175): 0.376*"argument" + 0.205*"function" + 0.047*"readability" + 0.033*"parameter" + 0.023*"string" + 0.015*"way" + 0.014*"statement" + 0.009*"pep" + 0.007*"output" + 0.007*"print"
INFO: topic #2 (0.068): 0.114*"proposal" + 0.076*"definition" + 0.076*"recap" + 0.039*"parameter" + 0.039*"case" + 0.039*"pep" + 0.039*"heh" + 0.039*"guidance" + 0.039*"question" + 0.039*"end"
INFO: topic #3 (0.298): 0.152*"string" + 0.138*"name" + 0.069*"\n" + 0.039*"way" + 0.030*"answer" + 0.030*"format" + 0.027*"list" + 0.027*"option" + 0.027*"print" + 0.020*"argument"
INFO: topic #4 (0.082): 0.258*"parameter" + 0.057*"pep" + 0.048*"syntax" + 0.029*"position" + 0.028*"example" + 0.028*"keyword" + 0.028*"notation" + 0.020*"clinic" + 0.020*"line" + 0.019*"code"
INFO: topic diff=1.779445, rho=0.707107
DEBUG: bound: at document #0
INFO: -11.456 per-word bound, 2809.8 perplexity estimate based on a held-out corpus of 5 documents with 43 words
INFO: PROGRESS: pass 0, at document #15/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.08909166, 0.12142554, 0.10192692, 0.23505765, 0.09990642]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.089): 0.069*"idea" + 0.062*"code" + 0.052*"file" + 0.039*"path" + 0.035*"case" + 0.018*"reading" + 0.018*"platform" + 0.018*"os.linesep" + 0.018*"note" + 0.018*"f"
INFO: topic #1 (0.121): 0.325*"argument" + 0.177*"function" + 0.041*"readability" + 0.029*"parameter" + 0.020*"string" + 0.014*"way" + 0.013*"statement" + 0.008*"pep" + 0.007*"output" + 0.007*"print"
INFO: topic #2 (0.102): 0.040*"path" + 0.037*"proposal" + 0.037*"event" + 0.037*"hope" + 0.037*"work" + 0.025*"choice" + 0.025*"thing" + 0.025*"definition" + 0.025*"recap" + 0.025*"pathlib"
INFO: topic #3 (0.235): 0.112*"string" + 0.102*"name" + 0.051*"\n" + 0.037*"output" + 0.036*"error" + 0.029*"way" + 0.023*"answer" + 0.023*"format" + 0.021*"list" + 0.020*"option"
INFO: topic #4 (0.100): 0.205*"parameter" + 0.046*"pep" + 0.040*"module" + 0.038*"syntax" + 0.031*"slash" + 0.024*"version" + 0.023*"client" + 0.023*"documentation" + 0.023*"position" + 0.023*"example"
INFO: topic diff=0.833769, rho=0.577350
DEBUG: bound: at document #0
INFO: -8.711 per-word bound, 419.1 perplexity estimate based on a held-out corpus of 5 documents with 23 words
INFO: PROGRESS: pass 0, at document #20/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.10250676, 0.12075658, 0.0928195, 0.24961807, 0.100973874]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.103): 0.095*"directory" + 0.088*"file" + 0.067*"example" + 0.062*"code" + 0.049*"path" + 0.048*"case" + 0.035*"idea" + 0.024*"split" + 0.024*"os.path" + 0.010*"note"
INFO: topic #1 (0.121): 0.252*"argument" + 0.138*"function" + 0.040*"self" + 0.033*"readability" + 0.023*"parameter" + 0.017*"string" + 0.011*"way" + 0.011*"statement" + 0.007*"pep" + 0.006*"library"
INFO: topic #2 (0.093): 0.034*"path" + 0.031*"proposal" + 0.031*"hope" + 0.031*"event" + 0.031*"work" + 0.022*"thing" + 0.022*"choice" + 0.021*"recap" + 0.021*"definition" + 0.021*"pathlib"
INFO: topic #3 (0.250): 0.118*"name" + 0.065*"string" + 0.064*"separator" + 0.060*"window" + 0.036*"path" + 0.031*"reference" + 0.031*"convert" + 0.030*"\n" + 0.022*"output" + 0.021*"error"
INFO: topic #4 (0.101): 0.177*"parameter" + 0.040*"pep" + 0.035*"module" + 0.034*"syntax" + 0.027*"slash" + 0.027*"library" + 0.022*"example" + 0.021*"version" + 0.021*"client" + 0.021*"documentation"
INFO: topic diff=0.421067, rho=0.500000
DEBUG: bound: at document #0
INFO: -6.598 per-word bound, 96.8 perplexity estimate based on a held-out corpus of 5 documents with 107 words
INFO: PROGRESS: pass 0, at document #25/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.12056625, 0.13468005, 0.083241485, 0.25552866, 0.11366145]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.121): 0.101*"case" + 0.082*"field" + 0.077*"example" + 0.077*"code" + 0.053*"directory" + 0.049*"file" + 0.028*"path" + 0.020*"idea" + 0.014*"os.path" + 0.014*"split"
INFO: topic #1 (0.135): 0.242*"argument" + 0.184*"function" + 0.036*"value" + 0.027*"default" + 0.026*"parameter" + 0.023*"form" + 0.018*"doc" + 0.018*"way" + 0.016*"future" + 0.013*"section"
INFO: topic #2 (0.083): 0.027*"path" + 0.025*"proposal" + 0.025*"hope" + 0.025*"event" + 0.025*"work" + 0.018*"choice" + 0.018*"thing" + 0.017*"recap" + 0.017*"definition" + 0.017*"pathlib"
INFO: topic #3 (0.256): 0.137*"name" + 0.074*"separator" + 0.045*"error" + 0.043*"string" + 0.040*"window" + 0.032*"link" + 0.024*"path" + 0.021*"convert" + 0.021*"reference" + 0.020*"\n"
INFO: topic #4 (0.114): 0.218*"parameter" + 0.056*"keyword" + 0.040*"call" + 0.037*"syntax" + 0.034*"documentation" + 0.028*"c" + 0.026*"example" + 0.026*"module" + 0.021*"value" + 0.021*"client"
INFO: topic diff=0.793951, rho=0.447214
DEBUG: bound: at document #0
INFO: -9.524 per-word bound, 736.2 perplexity estimate based on a held-out corpus of 5 documents with 20 words
INFO: PROGRESS: pass 0, at document #30/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13158947, 0.12124961, 0.085920915, 0.2636691, 0.12225357]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.132): 0.084*"code" + 0.072*"case" + 0.064*"file" + 0.059*"field" + 0.055*"example" + 0.038*"directory" + 0.030*"snippet" + 0.030*"understanding" + 0.030*"path" + 0.015*"idea"
INFO: topic #1 (0.121): 0.217*"argument" + 0.165*"function" + 0.033*"value" + 0.025*"default" + 0.024*"parameter" + 0.021*"form" + 0.017*"doc" + 0.017*"way" + 0.015*"future" + 0.012*"section"
INFO: topic #2 (0.086): 0.055*"path" + 0.047*"problem" + 0.041*"parent" + 0.024*"throw" + 0.024*"path(__file__).resolve().parent" + 0.024*"lash" + 0.024*"cross" + 0.024*"program" + 0.015*"proposal" + 0.015*"event"
INFO: topic #3 (0.264): 0.086*"name" + 0.086*"window" + 0.067*"path" + 0.058*"string" + 0.047*"separator" + 0.032*"strip" + 0.029*"error" + 0.021*"link" + 0.014*"reference" + 0.014*"convert"
INFO: topic #4 (0.122): 0.191*"parameter" + 0.049*"keyword" + 0.035*"call" + 0.033*"syntax" + 0.030*"documentation" + 0.025*"slash" + 0.025*"version" + 0.025*"c" + 0.023*"example" + 0.023*"module"
INFO: topic diff=0.353846, rho=0.408248
DEBUG: bound: at document #0
INFO: -8.367 per-word bound, 330.2 perplexity estimate based on a held-out corpus of 5 documents with 72 words
INFO: PROGRESS: pass 0, at document #35/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14918298, 0.104838274, 0.08453557, 0.30424586, 0.14744316]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.149): 0.081*"directory" + 0.063*"component" + 0.061*"path" + 0.043*"note" + 0.041*"code" + 0.035*"case" + 0.031*"file" + 0.030*"drive" + 0.030*"letter" + 0.029*"field"
INFO: topic #1 (0.105): 0.189*"argument" + 0.144*"function" + 0.029*"value" + 0.022*"default" + 0.021*"parameter" + 0.019*"form" + 0.015*"doc" + 0.015*"way" + 0.013*"future" + 0.011*"section"
INFO: topic #2 (0.085): 0.044*"cross" + 0.044*"program" + 0.040*"path" + 0.034*"problem" + 0.030*"parent" + 0.018*"lash" + 0.018*"path(__file__).resolve().parent" + 0.018*"throw" + 0.012*"ruin" + 0.012*"os.path.dirname(__file"
INFO: topic #3 (0.304): 0.123*"path" + 0.056*"string" + 0.053*"list" + 0.050*"window" + 0.046*"component" + 0.033*"name" + 0.031*"letter" + 0.031*"drive" + 0.022*"reference" + 0.018*"join"
INFO: topic #4 (0.147): 0.135*"parameter" + 0.081*"slash" + 0.048*"c" + 0.033*"foo" + 0.032*"version" + 0.031*"keyword" + 0.024*"component" + 0.022*"call" + 0.022*"doc" + 0.020*"syntax"
INFO: topic diff=0.606379, rho=0.377964
DEBUG: bound: at document #0
INFO: -9.466 per-word bound, 707.2 perplexity estimate based on a held-out corpus of 5 documents with 28 words
INFO: PROGRESS: pass 0, at document #40/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.157983, 0.11172534, 0.09170665, 0.26403996, 0.14022687]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.158): 0.083*"file" + 0.055*"directory" + 0.052*"path" + 0.043*"component" + 0.039*"example" + 0.029*"note" + 0.029*"application" + 0.028*"code" + 0.024*"case" + 0.021*"need"
INFO: topic #1 (0.112): 0.167*"argument" + 0.134*"function" + 0.032*"application" + 0.029*"behavior" + 0.022*"value" + 0.017*"default" + 0.016*"parameter" + 0.014*"form" + 0.012*"doc" + 0.012*"motivation"
INFO: topic #2 (0.092): 0.075*"extension" + 0.034*"new_sandbox" + 0.031*"folder" + 0.026*"issue" + 0.026*"foobar.jpg" + 0.026*"bite" + 0.026*"prevent" + 0.026*"append" + 0.026*"dot" + 0.025*"cross"
INFO: topic #3 (0.264): 0.114*"path" + 0.048*"name" + 0.047*"string" + 0.045*"list" + 0.042*"window" + 0.039*"component" + 0.026*"letter" + 0.026*"drive" + 0.019*"reference" + 0.016*"join"
INFO: topic #4 (0.140): 0.118*"parameter" + 0.092*"slash" + 0.043*"c" + 0.029*"foo" + 0.029*"version" + 0.027*"keyword" + 0.021*"component" + 0.020*"call" + 0.020*"doc" + 0.018*"syntax"
INFO: topic diff=0.353815, rho=0.353553
DEBUG: bound: at document #0
INFO: -7.567 per-word bound, 189.6 perplexity estimate based on a held-out corpus of 5 documents with 46 words
INFO: PROGRESS: pass 0, at document #45/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.18389884, 0.109707475, 0.08377247, 0.25855827, 0.14381027]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.184): 0.096*"file" + 0.057*"directory" + 0.047*"case" + 0.037*"example" + 0.037*"code" + 0.036*"path" + 0.029*"component" + 0.029*"root" + 0.021*"remove" + 0.020*"note"
INFO: topic #1 (0.110): 0.217*"argument" + 0.127*"function" + 0.033*"value" + 0.028*"self" + 0.019*"application" + 0.019*"end" + 0.018*"edit" + 0.018*"companion" + 0.018*"behavior" + 0.015*"parameter"
INFO: topic #2 (0.084): 0.062*"extension" + 0.028*"new_sandbox" + 0.026*"folder" + 0.022*"append" + 0.022*"prevent" + 0.022*"bite" + 0.022*"issue" + 0.022*"foobar.jpg" + 0.022*"dot" + 0.021*"cross"
INFO: topic #3 (0.259): 0.104*"string" + 0.073*"path" + 0.032*"escape" + 0.032*"tabulation" + 0.032*"sequence" + 0.031*"name" + 0.031*"reference" + 0.029*"list" + 0.027*"window" + 0.025*"component"
INFO: topic #4 (0.144): 0.104*"parameter" + 0.090*"slash" + 0.038*"keyword" + 0.035*"mark" + 0.034*"documentation" + 0.032*"c" + 0.022*"foo" + 0.021*"version" + 0.018*"example" + 0.016*"component"
INFO: topic diff=0.388444, rho=0.333333
DEBUG: bound: at document #0
INFO: -6.362 per-word bound, 82.2 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 0, at document #50/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.19735713, 0.10687384, 0.076886006, 0.29108635, 0.14666782]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.197): 0.106*"example" + 0.060*"file" + 0.051*"character" + 0.047*"case" + 0.036*"directory" + 0.023*"point" + 0.023*"code" + 0.022*"path" + 0.019*"tab" + 0.019*"space"
INFO: topic #1 (0.107): 0.208*"argument" + 0.192*"function" + 0.030*"end" + 0.023*"parameter" + 0.022*"value" + 0.019*"self" + 0.014*"help" + 0.013*"application" + 0.012*"companion" + 0.012*"edit"
INFO: topic #2 (0.077): 0.050*"extension" + 0.023*"new_sandbox" + 0.021*"folder" + 0.018*"issue" + 0.018*"bite" + 0.018*"dot" + 0.018*"append" + 0.018*"foobar.jpg" + 0.018*"prevent" + 0.017*"cross"
INFO: topic #3 (0.291): 0.174*"string" + 0.062*"list" + 0.053*"sequence" + 0.033*"escape" + 0.029*"path" + 0.026*"length" + 0.026*"return" + 0.026*"tab" + 0.024*"item" + 0.023*"reference"
INFO: topic #4 (0.147): 0.226*"parameter" + 0.081*"slash" + 0.051*"documentation" + 0.030*"slash(/" + 0.027*"example" + 0.021*"keyword" + 0.019*"mark" + 0.018*"position" + 0.017*"c" + 0.016*"one"
INFO: topic diff=0.554296, rho=0.316228
DEBUG: bound: at document #0
INFO: -6.497 per-word bound, 90.3 perplexity estimate based on a held-out corpus of 2 documents with 71 words
INFO: PROGRESS: pass 0, at document #52/52
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
INFO: optimized alpha [0.14885846, 0.13248152, 0.06915023, 0.28555885, 0.18311772]
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 52 documents
INFO: topic #0 (0.149): 0.096*"example" + 0.054*"file" + 0.046*"character" + 0.042*"case" + 0.032*"directory" + 0.021*"point" + 0.021*"code" + 0.020*"path" + 0.017*"tab" + 0.017*"space"
INFO: topic #1 (0.132): 0.276*"function" + 0.196*"argument" + 0.028*"help" + 0.026*"value" + 0.021*"parameter" + 0.013*"pep-570" + 0.013*"cpython" + 0.013*"define" + 0.013*"rest" + 0.012*"proposal"
INFO: topic #2 (0.069): 0.039*"extension" + 0.019*"new_sandbox" + 0.018*"folder" + 0.015*"issue" + 0.015*"bite" + 0.015*"dot" + 0.015*"append" + 0.015*"foobar.jpg" + 0.015*"prevent" + 0.014*"cross"
INFO: topic #3 (0.286): 0.142*"string" + 0.105*"list" + 0.044*"sequence" + 0.043*"name" + 0.036*"answer" + 0.027*"escape" + 0.024*"path" + 0.021*"length" + 0.021*"return" + 0.021*"tab"
INFO: topic #4 (0.183): 0.218*"parameter" + 0.119*"syntax" + 0.074*"pep" + 0.030*"notation" + 0.027*"implementation" + 0.022*"slash" + 0.022*"example" + 0.021*"help" + 0.020*"keyword" + 0.017*"call"
INFO: topic diff=0.677385, rho=0.301511
DEBUG: bound: at document #0
INFO: -7.748 per-word bound, 215.0 perplexity estimate based on a held-out corpus of 5 documents with 76 words
INFO: PROGRESS: pass 1, at document #5/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13821867, 0.13501033, 0.06907857, 0.33833963, 0.15499207]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.138): 0.083*"example" + 0.047*"file" + 0.040*"character" + 0.037*"case" + 0.028*"directory" + 0.027*"variable" + 0.019*"point" + 0.019*"code" + 0.018*"path" + 0.015*"tab"
INFO: topic #1 (0.135): 0.230*"function" + 0.203*"argument" + 0.023*"readability" + 0.023*"help" + 0.021*"value" + 0.018*"self" + 0.017*"statement" + 0.016*"parameter" + 0.010*"define" + 0.010*"cpython"
INFO: topic #2 (0.069): 0.039*"program" + 0.029*"extension" + 0.014*"new_sandbox" + 0.013*"folder" + 0.012*"prevent" + 0.012*"foobar.jpg" + 0.012*"bite" + 0.012*"dot" + 0.012*"issue" + 0.012*"append"
INFO: topic #3 (0.338): 0.155*"string" + 0.061*"list" + 0.037*"name" + 0.035*"print" + 0.026*"answer" + 0.024*"output" + 0.023*"\n" + 0.023*"option" + 0.022*"sequence" + 0.017*"way"
INFO: topic #4 (0.155): 0.210*"parameter" + 0.115*"syntax" + 0.071*"pep" + 0.029*"notation" + 0.026*"implementation" + 0.021*"slash" + 0.021*"example" + 0.020*"help" + 0.019*"keyword" + 0.017*"call"
INFO: topic diff=0.397081, rho=0.283981
DEBUG: bound: at document #0
INFO: -5.431 per-word bound, 43.1 perplexity estimate based on a held-out corpus of 5 documents with 193 words
INFO: PROGRESS: pass 1, at document #10/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14619064, 0.15325888, 0.068111695, 0.33735904, 0.1671838]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.146): 0.070*"idea" + 0.064*"case" + 0.058*"example" + 0.047*"character" + 0.043*"code" + 0.040*"file" + 0.026*"point" + 0.022*"note" + 0.021*"need" + 0.021*"field"
INFO: topic #1 (0.153): 0.309*"argument" + 0.234*"function" + 0.030*"readability" + 0.024*"proposal" + 0.016*"parameter" + 0.014*"end" + 0.013*"help" + 0.012*"value" + 0.010*"self" + 0.009*"statement"
INFO: topic #2 (0.068): 0.063*"recap" + 0.029*"guidance" + 0.029*"document" + 0.029*"question" + 0.029*"win" + 0.029*"heh" + 0.029*"order" + 0.024*"program" + 0.018*"extension" + 0.011*"section"
INFO: topic #3 (0.337): 0.161*"string" + 0.065*"name" + 0.055*"list" + 0.036*"\n" + 0.031*"way" + 0.030*"answer" + 0.029*"print" + 0.020*"output" + 0.019*"option" + 0.018*"format"
INFO: topic #4 (0.167): 0.238*"parameter" + 0.080*"syntax" + 0.069*"pep" + 0.029*"notation" + 0.025*"example" + 0.025*"definition" + 0.024*"keyword" + 0.020*"slash" + 0.017*"position" + 0.017*"implementation"
INFO: topic diff=0.614913, rho=0.283981
DEBUG: bound: at document #0
INFO: -9.497 per-word bound, 722.4 perplexity estimate based on a held-out corpus of 5 documents with 43 words
INFO: PROGRESS: pass 1, at document #15/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14895825, 0.13539848, 0.08576503, 0.29689768, 0.17827587]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.149): 0.056*"idea" + 0.051*"case" + 0.051*"file" + 0.048*"code" + 0.047*"example" + 0.038*"character" + 0.034*"path" + 0.030*"directory" + 0.021*"point" + 0.019*"command"
INFO: topic #1 (0.135): 0.291*"argument" + 0.220*"function" + 0.028*"readability" + 0.022*"proposal" + 0.015*"parameter" + 0.013*"end" + 0.012*"help" + 0.011*"value" + 0.010*"self" + 0.009*"statement"
INFO: topic #2 (0.086): 0.039*"hope" + 0.039*"event" + 0.039*"work" + 0.025*"recap" + 0.022*"folder" + 0.022*"problem" + 0.021*"parent" + 0.021*"thing" + 0.021*"choice" + 0.021*"pathlib"
INFO: topic #3 (0.297): 0.147*"string" + 0.060*"name" + 0.050*"list" + 0.033*"\n" + 0.029*"output" + 0.029*"way" + 0.027*"answer" + 0.026*"print" + 0.020*"error" + 0.019*"path"
INFO: topic #4 (0.178): 0.219*"parameter" + 0.074*"syntax" + 0.064*"pep" + 0.027*"notation" + 0.025*"slash" + 0.023*"example" + 0.023*"definition" + 0.022*"keyword" + 0.018*"module" + 0.017*"documentation"
INFO: topic diff=0.413086, rho=0.283981
DEBUG: bound: at document #0
INFO: -7.757 per-word bound, 216.4 perplexity estimate based on a held-out corpus of 5 documents with 23 words
INFO: PROGRESS: pass 1, at document #20/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1603799, 0.1351635, 0.082632266, 0.30622703, 0.1752363]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.160): 0.075*"directory" + 0.072*"file" + 0.068*"example" + 0.054*"case" + 0.052*"code" + 0.040*"path" + 0.039*"idea" + 0.027*"character" + 0.018*"split" + 0.018*"os.path"
INFO: topic #1 (0.135): 0.265*"argument" + 0.201*"function" + 0.026*"readability" + 0.023*"self" + 0.021*"proposal" + 0.014*"parameter" + 0.012*"end" + 0.011*"help" + 0.010*"value" + 0.009*"statement"
INFO: topic #2 (0.083): 0.035*"hope" + 0.035*"event" + 0.035*"work" + 0.023*"recap" + 0.020*"folder" + 0.020*"problem" + 0.019*"parent" + 0.019*"thing" + 0.019*"choice" + 0.019*"pathlib"
INFO: topic #3 (0.306): 0.121*"string" + 0.073*"name" + 0.041*"list" + 0.032*"separator" + 0.030*"path" + 0.029*"window" + 0.028*"\n" + 0.024*"output" + 0.024*"way" + 0.023*"answer"
INFO: topic #4 (0.175): 0.208*"parameter" + 0.070*"syntax" + 0.060*"pep" + 0.026*"notation" + 0.024*"slash" + 0.022*"example" + 0.022*"definition" + 0.021*"keyword" + 0.019*"library" + 0.018*"module"
INFO: topic diff=0.217411, rho=0.283981
DEBUG: bound: at document #0
INFO: -6.031 per-word bound, 65.4 perplexity estimate based on a held-out corpus of 5 documents with 107 words
INFO: PROGRESS: pass 1, at document #25/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1654924, 0.14559264, 0.07820198, 0.30529335, 0.18626393]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.165): 0.077*"example" + 0.071*"case" + 0.067*"code" + 0.062*"field" + 0.054*"directory" + 0.052*"file" + 0.029*"path" + 0.029*"idea" + 0.020*"character" + 0.017*"method"
INFO: topic #1 (0.146): 0.242*"argument" + 0.192*"function" + 0.037*"value" + 0.024*"default" + 0.023*"form" + 0.015*"future" + 0.015*"parameter" + 0.014*"case" + 0.013*"section" + 0.012*"readability"
INFO: topic #2 (0.078): 0.031*"hope" + 0.031*"event" + 0.031*"work" + 0.020*"recap" + 0.018*"folder" + 0.018*"problem" + 0.017*"parent" + 0.017*"thing" + 0.017*"choice" + 0.017*"pathlib"
INFO: topic #3 (0.305): 0.105*"string" + 0.073*"name" + 0.043*"separator" + 0.036*"list" + 0.029*"error" + 0.026*"path" + 0.025*"window" + 0.024*"\n" + 0.022*"way" + 0.021*"output"
INFO: topic #4 (0.186): 0.225*"parameter" + 0.060*"syntax" + 0.042*"keyword" + 0.039*"pep" + 0.030*"call" + 0.026*"documentation" + 0.025*"example" + 0.024*"notation" + 0.019*"c" + 0.019*"module"
INFO: topic diff=0.467585, rho=0.283981
DEBUG: bound: at document #0
INFO: -8.919 per-word bound, 484.1 perplexity estimate based on a held-out corpus of 5 documents with 20 words
INFO: PROGRESS: pass 1, at document #30/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1741701, 0.13603911, 0.08060269, 0.31002527, 0.19088404]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.174): 0.075*"code" + 0.062*"file" + 0.062*"example" + 0.058*"case" + 0.050*"field" + 0.044*"directory" + 0.032*"path" + 0.024*"idea" + 0.022*"understanding" + 0.022*"snippet"
INFO: topic #1 (0.136): 0.227*"argument" + 0.180*"function" + 0.035*"value" + 0.023*"default" + 0.022*"form" + 0.014*"future" + 0.014*"parameter" + 0.013*"case" + 0.013*"section" + 0.012*"readability"
INFO: topic #2 (0.081): 0.039*"problem" + 0.039*"parent" + 0.031*"program" + 0.029*"path" + 0.026*"cross" + 0.024*"path(__file__).resolve().parent" + 0.024*"lash" + 0.024*"throw" + 0.021*"hope" + 0.021*"event"
INFO: topic #3 (0.310): 0.102*"string" + 0.059*"name" + 0.055*"window" + 0.054*"path" + 0.035*"separator" + 0.029*"list" + 0.023*"error" + 0.020*"\n" + 0.019*"strip" + 0.018*"way"
INFO: topic #4 (0.191): 0.210*"parameter" + 0.056*"syntax" + 0.040*"keyword" + 0.036*"pep" + 0.028*"call" + 0.024*"documentation" + 0.024*"example" + 0.023*"slash" + 0.023*"notation" + 0.018*"c"
INFO: topic diff=0.225900, rho=0.283981
DEBUG: bound: at document #0
INFO: -7.270 per-word bound, 154.3 perplexity estimate based on a held-out corpus of 5 documents with 72 words
INFO: PROGRESS: pass 1, at document #35/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.19044457, 0.12198386, 0.08067777, 0.34126717, 0.21307556]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.190): 0.073*"component" + 0.071*"directory" + 0.065*"path" + 0.041*"code" + 0.035*"note" + 0.034*"file" + 0.034*"example" + 0.032*"case" + 0.031*"letter" + 0.031*"drive"
INFO: topic #1 (0.122): 0.208*"argument" + 0.166*"function" + 0.032*"value" + 0.021*"default" + 0.020*"form" + 0.013*"future" + 0.013*"parameter" + 0.013*"case" + 0.012*"section" + 0.011*"readability"
INFO: topic #2 (0.081): 0.052*"program" + 0.049*"cross" + 0.030*"problem" + 0.030*"parent" + 0.023*"path" + 0.019*"path(__file__).resolve().parent" + 0.019*"lash" + 0.019*"throw" + 0.017*"hope" + 0.017*"event"
INFO: topic #3 (0.341): 0.094*"path" + 0.083*"string" + 0.056*"list" + 0.043*"window" + 0.033*"name" + 0.029*"component" + 0.025*"drive" + 0.025*"letter" + 0.021*"reference" + 0.019*"separator"
INFO: topic #4 (0.213): 0.176*"parameter" + 0.061*"slash" + 0.044*"syntax" + 0.036*"c" + 0.031*"keyword" + 0.029*"pep" + 0.025*"version" + 0.024*"foo" + 0.022*"call" + 0.019*"documentation"
INFO: topic diff=0.417684, rho=0.283981
DEBUG: bound: at document #0
INFO: -8.565 per-word bound, 378.8 perplexity estimate based on a held-out corpus of 5 documents with 28 words
INFO: PROGRESS: pass 1, at document #40/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.19707349, 0.1277249, 0.08674584, 0.2979049, 0.19827977]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.197): 0.074*"file" + 0.061*"path" + 0.055*"component" + 0.053*"directory" + 0.042*"example" + 0.037*"application" + 0.031*"code" + 0.027*"note" + 0.024*"behaviour" + 0.024*"case"
INFO: topic #1 (0.128): 0.192*"argument" + 0.156*"function" + 0.027*"value" + 0.026*"behavior" + 0.018*"default" + 0.017*"form" + 0.014*"application" + 0.011*"future" + 0.011*"parameter" + 0.011*"case"
INFO: topic #2 (0.087): 0.074*"extension" + 0.032*"program" + 0.031*"folder" + 0.031*"cross" + 0.027*"new_sandbox" + 0.025*"append" + 0.025*"foobar.jpg" + 0.025*"issue" + 0.025*"bite" + 0.025*"dot"
INFO: topic #3 (0.298): 0.088*"path" + 0.074*"string" + 0.050*"list" + 0.045*"name" + 0.039*"window" + 0.026*"component" + 0.023*"letter" + 0.023*"drive" + 0.019*"reference" + 0.018*"separator"
INFO: topic #4 (0.198): 0.162*"parameter" + 0.070*"slash" + 0.041*"syntax" + 0.033*"c" + 0.029*"keyword" + 0.027*"pep" + 0.023*"version" + 0.022*"foo" + 0.021*"call" + 0.018*"documentation"
INFO: topic diff=0.260874, rho=0.283981
DEBUG: bound: at document #0
INFO: -6.415 per-word bound, 85.4 perplexity estimate based on a held-out corpus of 5 documents with 46 words
INFO: PROGRESS: pass 1, at document #45/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.2055702, 0.12482843, 0.08080453, 0.28414458, 0.19454932]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.206): 0.094*"file" + 0.060*"directory" + 0.048*"path" + 0.043*"component" + 0.039*"code" + 0.033*"example" + 0.030*"application" + 0.029*"root" + 0.021*"note" + 0.020*"variable"
INFO: topic #1 (0.125): 0.215*"argument" + 0.139*"function" + 0.043*"case" + 0.035*"value" + 0.024*"self" + 0.021*"end" + 0.018*"behavior" + 0.017*"edit" + 0.017*"companion" + 0.012*"default"
INFO: topic #2 (0.081): 0.064*"extension" + 0.028*"program" + 0.027*"folder" + 0.027*"cross" + 0.023*"new_sandbox" + 0.022*"append" + 0.022*"foobar.jpg" + 0.022*"issue" + 0.022*"bite" + 0.022*"dot"
INFO: topic #3 (0.284): 0.109*"string" + 0.059*"path" + 0.034*"sequence" + 0.033*"list" + 0.033*"escape" + 0.032*"tabulation" + 0.030*"name" + 0.028*"reference" + 0.026*"window" + 0.022*"way"
INFO: topic #4 (0.195): 0.146*"parameter" + 0.073*"slash" + 0.038*"keyword" + 0.033*"syntax" + 0.030*"documentation" + 0.030*"example" + 0.028*"mark" + 0.028*"c" + 0.022*"pep" + 0.019*"version"
INFO: topic diff=0.265042, rho=0.283981
DEBUG: bound: at document #0
INFO: -5.596 per-word bound, 48.4 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 1, at document #50/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.2169363, 0.1216792, 0.075547405, 0.33289045, 0.19427039]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.217): 0.106*"example" + 0.067*"file" + 0.043*"directory" + 0.035*"path" + 0.031*"case" + 0.031*"component" + 0.028*"code" + 0.026*"point" + 0.021*"application" + 0.021*"root"
INFO: topic #1 (0.122): 0.211*"argument" + 0.192*"function" + 0.033*"end" + 0.031*"case" + 0.026*"value" + 0.018*"self" + 0.013*"behavior" + 0.013*"companion" + 0.013*"edit" + 0.011*"parameter"
INFO: topic #2 (0.076): 0.054*"extension" + 0.024*"program" + 0.023*"folder" + 0.023*"cross" + 0.020*"new_sandbox" + 0.019*"append" + 0.019*"foobar.jpg" + 0.019*"issue" + 0.019*"bite" + 0.019*"dot"
INFO: topic #3 (0.333): 0.163*"string" + 0.057*"list" + 0.050*"sequence" + 0.036*"character" + 0.034*"tab" + 0.032*"escape" + 0.028*"length" + 0.028*"return" + 0.025*"path" + 0.024*"space"
INFO: topic #4 (0.194): 0.232*"parameter" + 0.071*"slash" + 0.045*"documentation" + 0.035*"example" + 0.029*"slash(/" + 0.023*"keyword" + 0.020*"syntax" + 0.017*"mark" + 0.017*"position" + 0.017*"c"
INFO: topic diff=0.398067, rho=0.283981
DEBUG: bound: at document #0
INFO: -5.392 per-word bound, 42.0 perplexity estimate based on a held-out corpus of 2 documents with 71 words
INFO: PROGRESS: pass 1, at document #52/52
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
INFO: optimized alpha [0.1618633, 0.14698131, 0.06851709, 0.2900061, 0.23721492]
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 52 documents
INFO: topic #0 (0.162): 0.095*"example" + 0.060*"file" + 0.038*"directory" + 0.031*"path" + 0.028*"case" + 0.028*"component" + 0.025*"code" + 0.024*"point" + 0.019*"application" + 0.019*"root"
INFO: topic #1 (0.147): 0.307*"function" + 0.225*"argument" + 0.034*"value" + 0.016*"end" + 0.016*"case" + 0.016*"help" + 0.013*"proposal" + 0.009*"parameter" + 0.009*"define" + 0.009*"rest"
INFO: topic #2 (0.069): 0.044*"extension" + 0.020*"program" + 0.020*"folder" + 0.019*"cross" + 0.017*"new_sandbox" + 0.016*"append" + 0.016*"foobar.jpg" + 0.016*"issue" + 0.016*"bite" + 0.016*"dot"
INFO: topic #3 (0.290): 0.145*"string" + 0.079*"list" + 0.045*"sequence" + 0.036*"answer" + 0.032*"character" + 0.030*"tab" + 0.029*"escape" + 0.026*"length" + 0.025*"return" + 0.023*"path"
INFO: topic #4 (0.237): 0.204*"parameter" + 0.109*"syntax" + 0.068*"pep" + 0.028*"notation" + 0.026*"implementation" + 0.025*"help" + 0.023*"example" + 0.020*"slash" + 0.019*"keyword" + 0.016*"name"
INFO: topic diff=0.494692, rho=0.283981
DEBUG: bound: at document #0
INFO: -7.056 per-word bound, 133.0 perplexity estimate based on a held-out corpus of 5 documents with 76 words
INFO: PROGRESS: pass 2, at document #5/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14913023, 0.1481743, 0.06841314, 0.34070912, 0.19333673]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.149): 0.082*"example" + 0.052*"file" + 0.036*"variable" + 0.033*"directory" + 0.027*"path" + 0.025*"case" + 0.024*"component" + 0.022*"code" + 0.021*"point" + 0.017*"application"
INFO: topic #1 (0.148): 0.250*"function" + 0.224*"argument" + 0.027*"readability" + 0.027*"value" + 0.019*"self" + 0.018*"statement" + 0.013*"end" + 0.012*"case" + 0.012*"help" + 0.011*"speed"
INFO: topic #2 (0.068): 0.052*"program" + 0.034*"extension" + 0.016*"folder" + 0.015*"cross" + 0.014*"new_sandbox" + 0.013*"bite" + 0.013*"dot" + 0.013*"foobar.jpg" + 0.013*"append" + 0.013*"prevent"
INFO: topic #3 (0.341): 0.157*"string" + 0.048*"list" + 0.036*"print" + 0.026*"answer" + 0.025*"output" + 0.024*"\n" + 0.024*"option" + 0.024*"name" + 0.023*"sequence" + 0.018*"way"
INFO: topic #4 (0.193): 0.198*"parameter" + 0.105*"syntax" + 0.066*"pep" + 0.027*"notation" + 0.026*"implementation" + 0.024*"help" + 0.022*"example" + 0.019*"slash" + 0.019*"keyword" + 0.016*"name"
INFO: topic diff=0.334330, rho=0.273179
DEBUG: bound: at document #0
INFO: -5.225 per-word bound, 37.4 perplexity estimate based on a held-out corpus of 5 documents with 193 words
INFO: PROGRESS: pass 2, at document #10/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14616647, 0.1649516, 0.067271456, 0.3093111, 0.20249015]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.146): 0.075*"idea" + 0.059*"example" + 0.047*"case" + 0.046*"code" + 0.044*"file" + 0.028*"point" + 0.024*"note" + 0.023*"field" + 0.022*"need" + 0.019*"character"
INFO: topic #1 (0.165): 0.325*"argument" + 0.246*"function" + 0.033*"readability" + 0.023*"proposal" + 0.016*"case" + 0.016*"end" + 0.015*"value" + 0.011*"self" + 0.010*"section" + 0.010*"statement"
INFO: topic #2 (0.067): 0.064*"recap" + 0.032*"program" + 0.030*"win" + 0.030*"heh" + 0.030*"guidance" + 0.030*"order" + 0.030*"question" + 0.030*"document" + 0.021*"extension" + 0.010*"folder"
INFO: topic #3 (0.309): 0.167*"string" + 0.041*"list" + 0.038*"\n" + 0.032*"way" + 0.031*"answer" + 0.030*"print" + 0.027*"name" + 0.026*"character" + 0.021*"output" + 0.020*"option"
INFO: topic #4 (0.202): 0.225*"parameter" + 0.076*"syntax" + 0.065*"pep" + 0.031*"name" + 0.027*"notation" + 0.025*"definition" + 0.025*"example" + 0.023*"keyword" + 0.019*"slash" + 0.018*"implementation"
INFO: topic diff=0.523990, rho=0.273179
DEBUG: bound: at document #0
INFO: -8.977 per-word bound, 504.1 perplexity estimate based on a held-out corpus of 5 documents with 43 words
INFO: PROGRESS: pass 2, at document #15/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14922032, 0.14558527, 0.084179185, 0.2780872, 0.21157591]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.149): 0.059*"idea" + 0.054*"file" + 0.051*"code" + 0.050*"path" + 0.047*"example" + 0.037*"case" + 0.033*"directory" + 0.023*"command" + 0.023*"point" + 0.019*"note"
INFO: topic #1 (0.146): 0.306*"argument" + 0.232*"function" + 0.031*"readability" + 0.022*"proposal" + 0.016*"case" + 0.016*"end" + 0.014*"value" + 0.010*"self" + 0.010*"section" + 0.010*"statement"
INFO: topic #2 (0.084): 0.039*"event" + 0.039*"hope" + 0.039*"work" + 0.027*"recap" + 0.023*"folder" + 0.022*"problem" + 0.021*"parent" + 0.020*"choice" + 0.020*"thing" + 0.020*"pathlib"
INFO: topic #3 (0.278): 0.154*"string" + 0.038*"list" + 0.035*"\n" + 0.030*"output" + 0.030*"way" + 0.028*"answer" + 0.028*"print" + 0.025*"name" + 0.024*"character" + 0.020*"error"
INFO: topic #4 (0.212): 0.210*"parameter" + 0.070*"syntax" + 0.061*"pep" + 0.029*"name" + 0.026*"notation" + 0.023*"definition" + 0.023*"example" + 0.023*"slash" + 0.021*"keyword" + 0.017*"module"
INFO: topic diff=0.357651, rho=0.273179
DEBUG: bound: at document #0
INFO: -7.624 per-word bound, 197.2 perplexity estimate based on a held-out corpus of 5 documents with 23 words
INFO: PROGRESS: pass 2, at document #20/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.15936446, 0.14391932, 0.080992594, 0.26889426, 0.2064987]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.159): 0.077*"directory" + 0.074*"file" + 0.067*"example" + 0.054*"code" + 0.053*"path" + 0.044*"case" + 0.042*"idea" + 0.019*"os.path" + 0.019*"split" + 0.016*"command"
INFO: topic #1 (0.144): 0.279*"argument" + 0.212*"function" + 0.028*"readability" + 0.024*"self" + 0.020*"proposal" + 0.015*"case" + 0.015*"end" + 0.013*"value" + 0.009*"section" + 0.009*"statement"
INFO: topic #2 (0.081): 0.035*"event" + 0.035*"hope" + 0.035*"work" + 0.024*"recap" + 0.021*"folder" + 0.020*"problem" + 0.019*"parent" + 0.018*"choice" + 0.018*"thing" + 0.018*"pathlib"
INFO: topic #3 (0.269): 0.130*"string" + 0.033*"separator" + 0.032*"list" + 0.030*"\n" + 0.030*"window" + 0.026*"output" + 0.026*"way" + 0.026*"path" + 0.024*"answer" + 0.024*"print"
INFO: topic #4 (0.206): 0.197*"parameter" + 0.066*"syntax" + 0.057*"pep" + 0.043*"name" + 0.024*"notation" + 0.023*"example" + 0.022*"definition" + 0.022*"slash" + 0.020*"keyword" + 0.018*"library"
INFO: topic diff=0.195715, rho=0.273179
DEBUG: bound: at document #0
INFO: -5.877 per-word bound, 58.8 perplexity estimate based on a held-out corpus of 5 documents with 107 words
INFO: PROGRESS: pass 2, at document #25/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.16401604, 0.15448125, 0.07692719, 0.26976615, 0.2171645]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.164): 0.075*"example" + 0.071*"code" + 0.064*"field" + 0.058*"directory" + 0.055*"file" + 0.048*"case" + 0.040*"path" + 0.031*"idea" + 0.021*"method" + 0.015*"os.path"
INFO: topic #1 (0.154): 0.239*"argument" + 0.190*"function" + 0.040*"value" + 0.027*"case" + 0.027*"default" + 0.027*"form" + 0.018*"future" + 0.014*"section" + 0.013*"readability" + 0.011*"self"
INFO: topic #2 (0.077): 0.031*"event" + 0.031*"hope" + 0.031*"work" + 0.021*"recap" + 0.018*"folder" + 0.017*"problem" + 0.017*"parent" + 0.016*"choice" + 0.016*"thing" + 0.016*"pathlib"
INFO: topic #3 (0.270): 0.115*"string" + 0.045*"separator" + 0.028*"list" + 0.028*"error" + 0.027*"\n" + 0.026*"window" + 0.024*"way" + 0.023*"output" + 0.023*"path" + 0.022*"answer"
INFO: topic #4 (0.217): 0.221*"parameter" + 0.059*"syntax" + 0.043*"name" + 0.041*"keyword" + 0.038*"pep" + 0.028*"call" + 0.027*"example" + 0.024*"documentation" + 0.023*"notation" + 0.018*"c"
INFO: topic diff=0.405690, rho=0.273179
DEBUG: bound: at document #0
INFO: -8.781 per-word bound, 440.0 perplexity estimate based on a held-out corpus of 5 documents with 20 words
INFO: PROGRESS: pass 2, at document #30/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17263183, 0.14403385, 0.07921843, 0.27559048, 0.21818812]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.173): 0.077*"code" + 0.065*"file" + 0.061*"example" + 0.052*"field" + 0.048*"path" + 0.047*"directory" + 0.039*"case" + 0.026*"idea" + 0.022*"snippet" + 0.022*"understanding"
INFO: topic #1 (0.144): 0.225*"argument" + 0.179*"function" + 0.038*"value" + 0.026*"case" + 0.026*"default" + 0.026*"form" + 0.017*"future" + 0.013*"section" + 0.013*"readability" + 0.010*"self"
INFO: topic #2 (0.079): 0.038*"problem" + 0.038*"parent" + 0.033*"program" + 0.028*"cross" + 0.025*"path(__file__).resolve().parent" + 0.025*"lash" + 0.025*"throw" + 0.022*"hope" + 0.022*"event" + 0.022*"work"
INFO: topic #3 (0.276): 0.111*"string" + 0.056*"window" + 0.049*"path" + 0.037*"separator" + 0.023*"list" + 0.023*"error" + 0.022*"\n" + 0.020*"way" + 0.019*"strip" + 0.019*"output"
INFO: topic #4 (0.218): 0.208*"parameter" + 0.055*"syntax" + 0.040*"name" + 0.039*"keyword" + 0.036*"pep" + 0.027*"call" + 0.025*"example" + 0.023*"documentation" + 0.022*"notation" + 0.020*"slash"
INFO: topic diff=0.203309, rho=0.273179
DEBUG: bound: at document #0
INFO: -7.080 per-word bound, 135.3 perplexity estimate based on a held-out corpus of 5 documents with 72 words
INFO: PROGRESS: pass 2, at document #35/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.18830374, 0.12847959, 0.07932307, 0.29900512, 0.2374214]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.188): 0.094*"path" + 0.092*"component" + 0.062*"directory" + 0.048*"letter" + 0.048*"drive" + 0.037*"code" + 0.031*"file" + 0.031*"note" + 0.029*"example" + 0.026*"idea"
INFO: topic #1 (0.128): 0.208*"argument" + 0.165*"function" + 0.035*"value" + 0.024*"case" + 0.024*"default" + 0.024*"form" + 0.016*"future" + 0.012*"section" + 0.012*"readability" + 0.010*"self"
INFO: topic #2 (0.079): 0.052*"program" + 0.048*"cross" + 0.029*"problem" + 0.029*"parent" + 0.020*"throw" + 0.020*"path(__file__).resolve().parent" + 0.020*"lash" + 0.019*"slash" + 0.018*"ruin" + 0.018*"os.environ['home"
INFO: topic #3 (0.299): 0.099*"string" + 0.071*"path" + 0.059*"list" + 0.050*"window" + 0.024*"reference" + 0.023*"separator" + 0.019*"item" + 0.019*"join" + 0.016*"os.path.sep" + 0.016*"conjunction"
INFO: topic #4 (0.237): 0.180*"parameter" + 0.053*"slash" + 0.045*"syntax" + 0.034*"c" + 0.033*"name" + 0.032*"keyword" + 0.030*"pep" + 0.024*"version" + 0.022*"foo" + 0.022*"call"
INFO: topic diff=0.370030, rho=0.273179
DEBUG: bound: at document #0
INFO: -8.428 per-word bound, 344.3 perplexity estimate based on a held-out corpus of 5 documents with 28 words
INFO: PROGRESS: pass 2, at document #40/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.194638, 0.133484, 0.08509384, 0.25164866, 0.23038816]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.195): 0.086*"path" + 0.071*"component" + 0.066*"file" + 0.048*"directory" + 0.042*"application" + 0.037*"letter" + 0.037*"drive" + 0.036*"example" + 0.029*"code" + 0.026*"behaviour"
INFO: topic #1 (0.133): 0.195*"argument" + 0.159*"function" + 0.030*"value" + 0.026*"behavior" + 0.021*"case" + 0.021*"default" + 0.021*"form" + 0.014*"future" + 0.011*"section" + 0.010*"readability"
INFO: topic #2 (0.085): 0.072*"extension" + 0.033*"program" + 0.031*"cross" + 0.030*"folder" + 0.025*"new_sandbox" + 0.025*"prevent" + 0.025*"issue" + 0.025*"dot" + 0.025*"foobar.jpg" + 0.025*"bite"
INFO: topic #3 (0.252): 0.090*"string" + 0.065*"path" + 0.054*"list" + 0.046*"window" + 0.022*"reference" + 0.021*"separator" + 0.017*"item" + 0.017*"join" + 0.015*"conjunction" + 0.015*"os.path.sep"
INFO: topic #4 (0.230): 0.165*"parameter" + 0.061*"slash" + 0.043*"name" + 0.042*"syntax" + 0.032*"c" + 0.029*"keyword" + 0.028*"pep" + 0.022*"version" + 0.021*"foo" + 0.020*"call"
INFO: topic diff=0.235544, rho=0.273179
DEBUG: bound: at document #0
INFO: -6.201 per-word bound, 73.6 perplexity estimate based on a held-out corpus of 5 documents with 46 words
INFO: PROGRESS: pass 2, at document #45/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.20136799, 0.13001186, 0.07955069, 0.24590111, 0.22170188]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.201): 0.086*"file" + 0.071*"path" + 0.058*"component" + 0.055*"directory" + 0.034*"application" + 0.034*"code" + 0.031*"letter" + 0.031*"drive" + 0.030*"example" + 0.026*"root"
INFO: topic #1 (0.130): 0.217*"argument" + 0.142*"function" + 0.048*"case" + 0.037*"value" + 0.023*"self" + 0.021*"end" + 0.018*"behavior" + 0.018*"edit" + 0.018*"companion" + 0.015*"default"
INFO: topic #2 (0.080): 0.063*"extension" + 0.029*"program" + 0.027*"cross" + 0.026*"folder" + 0.022*"new_sandbox" + 0.022*"prevent" + 0.022*"issue" + 0.022*"dot" + 0.022*"foobar.jpg" + 0.022*"bite"
INFO: topic #3 (0.246): 0.122*"string" + 0.041*"path" + 0.037*"sequence" + 0.036*"escape" + 0.034*"tabulation" + 0.034*"list" + 0.030*"reference" + 0.029*"window" + 0.024*"way" + 0.022*"character"
INFO: topic #4 (0.222): 0.150*"parameter" + 0.065*"slash" + 0.039*"keyword" + 0.036*"name" + 0.035*"syntax" + 0.031*"example" + 0.029*"documentation" + 0.027*"mark" + 0.026*"c" + 0.023*"pep"
INFO: topic diff=0.243905, rho=0.273179
DEBUG: bound: at document #0
INFO: -5.452 per-word bound, 43.8 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 2, at document #50/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.21036875, 0.12599613, 0.074492976, 0.288801, 0.21777679]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.210): 0.098*"example" + 0.065*"file" + 0.054*"path" + 0.044*"component" + 0.042*"directory" + 0.026*"application" + 0.026*"code" + 0.026*"case" + 0.025*"point" + 0.024*"drive"
INFO: topic #1 (0.126): 0.215*"argument" + 0.193*"function" + 0.036*"case" + 0.033*"end" + 0.028*"value" + 0.018*"self" + 0.014*"behavior" + 0.013*"edit" + 0.013*"companion" + 0.011*"default"
INFO: topic #2 (0.074): 0.054*"extension" + 0.025*"program" + 0.024*"cross" + 0.023*"folder" + 0.019*"new_sandbox" + 0.019*"prevent" + 0.019*"issue" + 0.019*"dot" + 0.019*"foobar.jpg" + 0.019*"bite"
INFO: topic #3 (0.289): 0.170*"string" + 0.052*"sequence" + 0.046*"character" + 0.043*"list" + 0.036*"tab" + 0.033*"escape" + 0.030*"length" + 0.029*"return" + 0.028*"space" + 0.023*"item"
INFO: topic #4 (0.218): 0.223*"parameter" + 0.064*"slash" + 0.042*"documentation" + 0.035*"example" + 0.034*"name" + 0.026*"slash(/" + 0.026*"list" + 0.024*"keyword" + 0.021*"syntax" + 0.017*"mark"
INFO: topic diff=0.365386, rho=0.273179
DEBUG: bound: at document #0
INFO: -5.184 per-word bound, 36.4 perplexity estimate based on a held-out corpus of 2 documents with 71 words
INFO: PROGRESS: pass 2, at document #52/52
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
INFO: optimized alpha [0.15842961, 0.14945138, 0.06766232, 0.22864848, 0.26083192]
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 52 documents
INFO: topic #0 (0.158): 0.089*"example" + 0.059*"file" + 0.049*"path" + 0.040*"component" + 0.038*"directory" + 0.024*"application" + 0.024*"code" + 0.024*"case" + 0.023*"point" + 0.022*"drive"
INFO: topic #1 (0.149): 0.324*"function" + 0.240*"argument" + 0.042*"value" + 0.020*"case" + 0.018*"end" + 0.010*"proposal" + 0.010*"self" + 0.008*"behavior" + 0.007*"companion" + 0.007*"edit"
INFO: topic #2 (0.068): 0.045*"extension" + 0.022*"program" + 0.020*"cross" + 0.020*"folder" + 0.017*"new_sandbox" + 0.016*"prevent" + 0.016*"issue" + 0.016*"dot" + 0.016*"foobar.jpg" + 0.016*"bite"
INFO: topic #3 (0.229): 0.157*"string" + 0.048*"sequence" + 0.042*"character" + 0.040*"list" + 0.035*"answer" + 0.033*"tab" + 0.031*"escape" + 0.028*"length" + 0.027*"return" + 0.026*"space"
INFO: topic #4 (0.261): 0.196*"parameter" + 0.102*"syntax" + 0.064*"pep" + 0.031*"list" + 0.028*"help" + 0.027*"notation" + 0.025*"implementation" + 0.022*"example" + 0.022*"name" + 0.019*"keyword"
INFO: topic diff=0.442234, rho=0.273179
DEBUG: bound: at document #0
INFO: -6.966 per-word bound, 125.0 perplexity estimate based on a held-out corpus of 5 documents with 76 words
INFO: PROGRESS: pass 3, at document #5/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14608209, 0.14978905, 0.0674228, 0.2710629, 0.22154972]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.146): 0.077*"example" + 0.051*"file" + 0.042*"path" + 0.035*"component" + 0.034*"variable" + 0.033*"directory" + 0.021*"application" + 0.021*"code" + 0.021*"case" + 0.020*"point"
INFO: topic #1 (0.150): 0.260*"function" + 0.234*"argument" + 0.032*"value" + 0.028*"readability" + 0.020*"self" + 0.018*"statement" + 0.015*"case" + 0.014*"end" + 0.012*"speed" + 0.012*"change"
INFO: topic #2 (0.067): 0.053*"program" + 0.035*"extension" + 0.016*"cross" + 0.016*"folder" + 0.014*"new_sandbox" + 0.013*"dot" + 0.013*"foobar.jpg" + 0.013*"issue" + 0.013*"append" + 0.013*"bite"
INFO: topic #3 (0.271): 0.165*"string" + 0.037*"print" + 0.028*"list" + 0.026*"output" + 0.025*"answer" + 0.025*"\n" + 0.025*"sequence" + 0.025*"option" + 0.022*"character" + 0.019*"way"
INFO: topic #4 (0.222): 0.189*"parameter" + 0.098*"syntax" + 0.062*"pep" + 0.030*"list" + 0.027*"help" + 0.026*"notation" + 0.025*"name" + 0.024*"implementation" + 0.022*"example" + 0.018*"keyword"
INFO: topic diff=0.311130, rho=0.263523
DEBUG: bound: at document #0
INFO: -5.183 per-word bound, 36.3 perplexity estimate based on a held-out corpus of 5 documents with 193 words
INFO: PROGRESS: pass 3, at document #10/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14398286, 0.16638158, 0.066503115, 0.26185435, 0.22926652]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.144): 0.073*"idea" + 0.058*"example" + 0.045*"code" + 0.045*"file" + 0.044*"case" + 0.028*"point" + 0.024*"note" + 0.023*"path" + 0.023*"field" + 0.022*"need"
INFO: topic #1 (0.166): 0.334*"argument" + 0.254*"function" + 0.034*"readability" + 0.019*"case" + 0.018*"value" + 0.017*"end" + 0.017*"proposal" + 0.011*"self" + 0.011*"section" + 0.010*"statement"
INFO: topic #2 (0.067): 0.063*"recap" + 0.033*"program" + 0.030*"document" + 0.030*"win" + 0.030*"heh" + 0.030*"question" + 0.030*"guidance" + 0.030*"order" + 0.023*"extension" + 0.011*"cross"
INFO: topic #3 (0.262): 0.174*"string" + 0.039*"\n" + 0.035*"character" + 0.033*"way" + 0.031*"print" + 0.030*"answer" + 0.024*"list" + 0.022*"output" + 0.021*"sequence" + 0.021*"option"
INFO: topic #4 (0.229): 0.219*"parameter" + 0.073*"syntax" + 0.062*"pep" + 0.038*"name" + 0.026*"notation" + 0.024*"example" + 0.024*"definition" + 0.022*"keyword" + 0.020*"list" + 0.018*"slash"
INFO: topic diff=0.482529, rho=0.263523
DEBUG: bound: at document #0
INFO: -8.811 per-word bound, 449.2 perplexity estimate based on a held-out corpus of 5 documents with 43 words
INFO: PROGRESS: pass 3, at document #15/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14732103, 0.14751351, 0.08267305, 0.24267331, 0.23517348]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.147): 0.066*"path" + 0.058*"idea" + 0.053*"file" + 0.051*"code" + 0.046*"example" + 0.035*"case" + 0.033*"directory" + 0.023*"command" + 0.022*"point" + 0.019*"note"
INFO: topic #1 (0.148): 0.314*"argument" + 0.239*"function" + 0.032*"readability" + 0.018*"case" + 0.017*"value" + 0.016*"end" + 0.016*"proposal" + 0.011*"self" + 0.010*"section" + 0.009*"statement"
INFO: topic #2 (0.083): 0.038*"hope" + 0.038*"event" + 0.038*"work" + 0.027*"recap" + 0.022*"folder" + 0.021*"problem" + 0.021*"parent" + 0.020*"thing" + 0.020*"choice" + 0.020*"pathlib"
INFO: topic #3 (0.243): 0.161*"string" + 0.036*"\n" + 0.032*"character" + 0.031*"output" + 0.031*"way" + 0.029*"print" + 0.028*"answer" + 0.022*"list" + 0.020*"error" + 0.020*"sequence"
INFO: topic #4 (0.235): 0.205*"parameter" + 0.068*"syntax" + 0.059*"pep" + 0.036*"name" + 0.025*"notation" + 0.023*"example" + 0.023*"definition" + 0.021*"keyword" + 0.020*"slash" + 0.019*"list"
INFO: topic diff=0.337400, rho=0.263523
DEBUG: bound: at document #0
INFO: -7.572 per-word bound, 190.3 perplexity estimate based on a held-out corpus of 5 documents with 23 words
INFO: PROGRESS: pass 3, at document #20/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.15700954, 0.14568585, 0.07967837, 0.23664822, 0.22769654]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.157): 0.075*"directory" + 0.073*"file" + 0.065*"example" + 0.065*"path" + 0.053*"code" + 0.042*"case" + 0.041*"idea" + 0.019*"split" + 0.019*"os.path" + 0.017*"command"
INFO: topic #1 (0.146): 0.287*"argument" + 0.219*"function" + 0.029*"readability" + 0.024*"self" + 0.017*"case" + 0.016*"value" + 0.015*"end" + 0.015*"proposal" + 0.010*"section" + 0.009*"statement"
INFO: topic #2 (0.080): 0.034*"hope" + 0.034*"event" + 0.034*"work" + 0.024*"recap" + 0.020*"folder" + 0.019*"problem" + 0.019*"parent" + 0.018*"thing" + 0.018*"choice" + 0.018*"pathlib"
INFO: topic #3 (0.237): 0.136*"string" + 0.033*"separator" + 0.031*"\n" + 0.030*"window" + 0.028*"character" + 0.027*"output" + 0.026*"way" + 0.025*"print" + 0.024*"answer" + 0.020*"reference"
INFO: topic #4 (0.228): 0.194*"parameter" + 0.065*"syntax" + 0.055*"pep" + 0.048*"name" + 0.024*"notation" + 0.023*"example" + 0.022*"definition" + 0.020*"keyword" + 0.019*"slash" + 0.018*"list"
INFO: topic diff=0.184364, rho=0.263523
DEBUG: bound: at document #0
INFO: -5.784 per-word bound, 55.1 perplexity estimate based on a held-out corpus of 5 documents with 107 words
INFO: PROGRESS: pass 3, at document #25/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.16141318, 0.15592681, 0.07586342, 0.2383752, 0.23746651]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.161): 0.074*"example" + 0.070*"code" + 0.063*"field" + 0.058*"directory" + 0.056*"file" + 0.050*"path" + 0.044*"case" + 0.032*"idea" + 0.021*"method" + 0.015*"os.path"
INFO: topic #1 (0.156): 0.240*"argument" + 0.190*"function" + 0.042*"value" + 0.029*"case" + 0.028*"default" + 0.028*"form" + 0.019*"future" + 0.014*"section" + 0.013*"readability" + 0.011*"self"
INFO: topic #2 (0.076): 0.030*"hope" + 0.030*"event" + 0.030*"work" + 0.022*"recap" + 0.018*"folder" + 0.017*"problem" + 0.017*"parent" + 0.016*"thing" + 0.016*"choice" + 0.016*"pathlib"
INFO: topic #3 (0.238): 0.121*"string" + 0.045*"separator" + 0.028*"\n" + 0.027*"window" + 0.025*"character" + 0.024*"way" + 0.024*"output" + 0.023*"error" + 0.022*"print" + 0.022*"answer"
INFO: topic #4 (0.237): 0.220*"parameter" + 0.058*"syntax" + 0.047*"name" + 0.040*"keyword" + 0.039*"pep" + 0.027*"call" + 0.027*"example" + 0.023*"documentation" + 0.023*"notation" + 0.018*"c"
INFO: topic diff=0.366180, rho=0.263523
DEBUG: bound: at document #0
INFO: -8.628 per-word bound, 395.7 perplexity estimate based on a held-out corpus of 5 documents with 20 words
INFO: PROGRESS: pass 3, at document #30/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.16922577, 0.14477539, 0.077870786, 0.24329916, 0.22445436]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.169): 0.076*"code" + 0.066*"path" + 0.064*"file" + 0.059*"example" + 0.051*"field" + 0.047*"directory" + 0.036*"case" + 0.026*"idea" + 0.021*"understanding" + 0.021*"snippet"
INFO: topic #1 (0.145): 0.226*"argument" + 0.180*"function" + 0.040*"value" + 0.028*"case" + 0.027*"default" + 0.027*"form" + 0.018*"future" + 0.013*"section" + 0.013*"readability" + 0.011*"self"
INFO: topic #2 (0.078): 0.036*"problem" + 0.036*"parent" + 0.033*"program" + 0.030*"slash" + 0.027*"cross" + 0.025*"throw" + 0.025*"path(__file__).resolve().parent" + 0.025*"lash" + 0.021*"hope" + 0.021*"event"
INFO: topic #3 (0.243): 0.117*"string" + 0.056*"window" + 0.041*"path" + 0.037*"separator" + 0.023*"\n" + 0.021*"character" + 0.020*"way" + 0.020*"output" + 0.019*"error" + 0.019*"strip"
INFO: topic #4 (0.224): 0.209*"parameter" + 0.055*"syntax" + 0.044*"name" + 0.038*"keyword" + 0.037*"pep" + 0.026*"call" + 0.026*"example" + 0.022*"documentation" + 0.022*"notation" + 0.017*"c"
INFO: topic diff=0.192249, rho=0.263523
DEBUG: bound: at document #0
INFO: -6.843 per-word bound, 114.8 perplexity estimate based on a held-out corpus of 5 documents with 72 words
INFO: PROGRESS: pass 3, at document #35/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1830253, 0.12875113, 0.08193893, 0.26224512, 0.2295546]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.183): 0.105*"path" + 0.092*"component" + 0.060*"directory" + 0.053*"letter" + 0.053*"drive" + 0.037*"code" + 0.031*"file" + 0.030*"note" + 0.029*"example" + 0.027*"reset"
INFO: topic #1 (0.129): 0.210*"argument" + 0.167*"function" + 0.038*"value" + 0.026*"case" + 0.025*"default" + 0.025*"form" + 0.017*"future" + 0.012*"section" + 0.012*"readability" + 0.010*"self"
INFO: topic #2 (0.082): 0.066*"slash" + 0.048*"program" + 0.044*"cross" + 0.027*"problem" + 0.027*"parent" + 0.021*"os.environ['home" + 0.021*"ruin" + 0.021*"os.path.dirname(__file" + 0.019*"path(__file__).resolve().parent" + 0.019*"throw"
INFO: topic #3 (0.262): 0.107*"string" + 0.060*"path" + 0.052*"window" + 0.052*"list" + 0.025*"reference" + 0.025*"separator" + 0.019*"item" + 0.019*"join" + 0.017*"conjunction" + 0.017*"os.path.sep"
INFO: topic #4 (0.230): 0.186*"parameter" + 0.047*"syntax" + 0.038*"name" + 0.034*"c" + 0.033*"keyword" + 0.032*"slash" + 0.031*"pep" + 0.023*"version" + 0.022*"call" + 0.022*"example"
INFO: topic diff=0.326338, rho=0.263523
DEBUG: bound: at document #0
INFO: -8.330 per-word bound, 321.7 perplexity estimate based on a held-out corpus of 5 documents with 28 words
INFO: PROGRESS: pass 3, at document #40/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.18863037, 0.13308996, 0.09171437, 0.22441103, 0.21190323]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.189): 0.095*"path" + 0.072*"component" + 0.064*"file" + 0.047*"directory" + 0.042*"application" + 0.041*"letter" + 0.041*"drive" + 0.036*"example" + 0.029*"code" + 0.025*"behaviour"
INFO: topic #1 (0.133): 0.198*"argument" + 0.161*"function" + 0.033*"value" + 0.026*"behavior" + 0.023*"case" + 0.022*"default" + 0.022*"form" + 0.015*"future" + 0.011*"section" + 0.011*"readability"
INFO: topic #2 (0.092): 0.066*"extension" + 0.064*"slash" + 0.032*"program" + 0.029*"cross" + 0.028*"folder" + 0.023*"new_sandbox" + 0.023*"append" + 0.023*"prevent" + 0.023*"dot" + 0.023*"bite"
INFO: topic #3 (0.224): 0.097*"string" + 0.055*"path" + 0.047*"window" + 0.047*"list" + 0.023*"reference" + 0.023*"separator" + 0.018*"item" + 0.018*"join" + 0.016*"conjunction" + 0.016*"os.path.sep"
INFO: topic #4 (0.212): 0.173*"parameter" + 0.047*"name" + 0.044*"syntax" + 0.031*"c" + 0.030*"keyword" + 0.030*"slash" + 0.029*"pep" + 0.022*"version" + 0.021*"call" + 0.021*"example"
INFO: topic diff=0.217499, rho=0.263523
DEBUG: bound: at document #0
INFO: -6.141 per-word bound, 70.6 perplexity estimate based on a held-out corpus of 5 documents with 46 words
INFO: PROGRESS: pass 3, at document #45/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.19481227, 0.12948267, 0.08537175, 0.22167434, 0.20587128]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.195): 0.083*"file" + 0.079*"path" + 0.060*"component" + 0.054*"directory" + 0.035*"application" + 0.034*"drive" + 0.034*"letter" + 0.033*"code" + 0.030*"example" + 0.025*"root"
INFO: topic #1 (0.129): 0.218*"argument" + 0.144*"function" + 0.048*"case" + 0.039*"value" + 0.023*"self" + 0.021*"end" + 0.018*"behavior" + 0.017*"companion" + 0.017*"edit" + 0.016*"default"
INFO: topic #2 (0.085): 0.058*"extension" + 0.057*"slash" + 0.028*"program" + 0.026*"cross" + 0.025*"folder" + 0.021*"new_sandbox" + 0.020*"append" + 0.020*"prevent" + 0.020*"dot" + 0.020*"bite"
INFO: topic #3 (0.222): 0.126*"string" + 0.037*"sequence" + 0.036*"escape" + 0.035*"path" + 0.034*"tabulation" + 0.031*"reference" + 0.030*"window" + 0.030*"list" + 0.024*"character" + 0.024*"way"
INFO: topic #4 (0.206): 0.158*"parameter" + 0.040*"name" + 0.039*"keyword" + 0.039*"slash" + 0.037*"syntax" + 0.031*"example" + 0.029*"documentation" + 0.027*"mark" + 0.026*"c" + 0.025*"pep"
INFO: topic diff=0.226338, rho=0.263523
DEBUG: bound: at document #0
INFO: -5.357 per-word bound, 41.0 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 3, at document #50/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.20134553, 0.12463955, 0.079301946, 0.24495238, 0.20171821]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.201): 0.095*"example" + 0.065*"file" + 0.061*"path" + 0.046*"component" + 0.042*"directory" + 0.027*"application" + 0.027*"letter" + 0.027*"drive" + 0.026*"code" + 0.025*"case"
INFO: topic #1 (0.125): 0.215*"argument" + 0.192*"function" + 0.037*"case" + 0.032*"end" + 0.030*"value" + 0.017*"self" + 0.014*"behavior" + 0.013*"companion" + 0.013*"edit" + 0.012*"default"
INFO: topic #2 (0.079): 0.051*"extension" + 0.049*"slash" + 0.025*"program" + 0.023*"cross" + 0.022*"folder" + 0.018*"new_sandbox" + 0.018*"append" + 0.018*"prevent" + 0.018*"dot" + 0.018*"bite"
INFO: topic #3 (0.245): 0.176*"string" + 0.054*"sequence" + 0.048*"character" + 0.037*"tab" + 0.034*"escape" + 0.030*"length" + 0.030*"return" + 0.029*"space" + 0.024*"item" + 0.023*"reference"
INFO: topic #4 (0.202): 0.218*"parameter" + 0.051*"list" + 0.046*"slash" + 0.040*"documentation" + 0.035*"name" + 0.034*"example" + 0.025*"slash(/" + 0.024*"keyword" + 0.022*"syntax" + 0.017*"help"
INFO: topic diff=0.344965, rho=0.263523
DEBUG: bound: at document #0
INFO: -5.080 per-word bound, 33.8 perplexity estimate based on a held-out corpus of 2 documents with 71 words
INFO: PROGRESS: pass 3, at document #52/52
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
INFO: optimized alpha [0.15480576, 0.14675657, 0.07177058, 0.20266671, 0.24125122]
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 52 documents
INFO: topic #0 (0.155): 0.086*"example" + 0.059*"file" + 0.056*"path" + 0.042*"component" + 0.039*"directory" + 0.025*"application" + 0.025*"letter" + 0.025*"drive" + 0.024*"code" + 0.023*"case"
INFO: topic #1 (0.147): 0.325*"function" + 0.244*"argument" + 0.046*"value" + 0.021*"case" + 0.018*"end" + 0.010*"self" + 0.008*"behavior" + 0.008*"edit" + 0.008*"companion" + 0.007*"default"
INFO: topic #2 (0.072): 0.043*"extension" + 0.042*"slash" + 0.021*"program" + 0.020*"cross" + 0.019*"folder" + 0.016*"new_sandbox" + 0.016*"append" + 0.016*"prevent" + 0.016*"dot" + 0.016*"bite"
INFO: topic #3 (0.203): 0.163*"string" + 0.050*"sequence" + 0.045*"character" + 0.034*"tab" + 0.032*"escape" + 0.029*"answer" + 0.028*"length" + 0.028*"return" + 0.027*"space" + 0.022*"item"
INFO: topic #4 (0.241): 0.194*"parameter" + 0.100*"syntax" + 0.063*"pep" + 0.039*"list" + 0.028*"help" + 0.026*"notation" + 0.025*"implementation" + 0.022*"name" + 0.022*"example" + 0.019*"keyword"
INFO: topic diff=0.411342, rho=0.263523
DEBUG: bound: at document #0
INFO: -6.904 per-word bound, 119.7 perplexity estimate based on a held-out corpus of 5 documents with 76 words
INFO: PROGRESS: pass 4, at document #5/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14316282, 0.14701481, 0.071176834, 0.24032669, 0.2107136]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.143): 0.075*"example" + 0.052*"file" + 0.049*"path" + 0.037*"component" + 0.034*"directory" + 0.033*"variable" + 0.022*"application" + 0.022*"letter" + 0.022*"drive" + 0.021*"code"
INFO: topic #1 (0.147): 0.261*"function" + 0.236*"argument" + 0.036*"value" + 0.028*"readability" + 0.020*"self" + 0.017*"statement" + 0.016*"case" + 0.014*"end" + 0.012*"speed" + 0.012*"change"
INFO: topic #2 (0.071): 0.050*"program" + 0.035*"extension" + 0.034*"slash" + 0.016*"cross" + 0.016*"folder" + 0.013*"new_sandbox" + 0.013*"issue" + 0.013*"bite" + 0.013*"dot" + 0.013*"foobar.jpg"
INFO: topic #3 (0.240): 0.170*"string" + 0.038*"print" + 0.026*"output" + 0.026*"sequence" + 0.026*"\n" + 0.025*"option" + 0.023*"character" + 0.023*"answer" + 0.019*"way" + 0.019*"list"
INFO: topic #4 (0.211): 0.186*"parameter" + 0.095*"syntax" + 0.060*"pep" + 0.037*"list" + 0.031*"name" + 0.027*"help" + 0.025*"notation" + 0.024*"implementation" + 0.021*"example" + 0.018*"keyword"
INFO: topic diff=0.297461, rho=0.254824
DEBUG: bound: at document #0
INFO: -5.160 per-word bound, 35.8 perplexity estimate based on a held-out corpus of 5 documents with 193 words
INFO: PROGRESS: pass 4, at document #10/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14136872, 0.1628126, 0.06996071, 0.23778202, 0.21902013]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.141): 0.071*"idea" + 0.058*"example" + 0.045*"file" + 0.044*"code" + 0.042*"case" + 0.027*"point" + 0.027*"path" + 0.024*"note" + 0.022*"field" + 0.021*"need"
INFO: topic #1 (0.163): 0.337*"argument" + 0.258*"function" + 0.034*"readability" + 0.020*"value" + 0.019*"case" + 0.017*"end" + 0.011*"self" + 0.011*"section" + 0.010*"statement" + 0.009*"proposal"
INFO: topic #2 (0.070): 0.060*"recap" + 0.033*"program" + 0.029*"order" + 0.029*"document" + 0.029*"guidance" + 0.029*"heh" + 0.029*"win" + 0.029*"question" + 0.023*"extension" + 0.022*"slash"
INFO: topic #3 (0.238): 0.178*"string" + 0.039*"\n" + 0.037*"character" + 0.033*"way" + 0.032*"print" + 0.028*"answer" + 0.022*"output" + 0.022*"sequence" + 0.021*"option" + 0.020*"format"
INFO: topic #4 (0.219): 0.215*"parameter" + 0.072*"syntax" + 0.061*"pep" + 0.041*"name" + 0.026*"notation" + 0.024*"list" + 0.024*"example" + 0.024*"definition" + 0.022*"keyword" + 0.017*"implementation"
INFO: topic diff=0.451153, rho=0.254824
DEBUG: bound: at document #0
INFO: -8.677 per-word bound, 409.2 perplexity estimate based on a held-out corpus of 5 documents with 43 words
INFO: PROGRESS: pass 4, at document #15/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14460118, 0.14504547, 0.08628729, 0.2225212, 0.22382043]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.145): 0.071*"path" + 0.057*"idea" + 0.053*"file" + 0.051*"code" + 0.046*"example" + 0.034*"case" + 0.033*"directory" + 0.023*"command" + 0.022*"point" + 0.019*"note"
INFO: topic #1 (0.145): 0.317*"argument" + 0.243*"function" + 0.032*"readability" + 0.019*"value" + 0.018*"case" + 0.017*"end" + 0.011*"self" + 0.010*"section" + 0.009*"statement" + 0.009*"proposal"
INFO: topic #2 (0.086): 0.036*"event" + 0.036*"hope" + 0.036*"work" + 0.027*"recap" + 0.026*"slash" + 0.022*"folder" + 0.021*"problem" + 0.020*"parent" + 0.019*"choice" + 0.019*"thing"
INFO: topic #3 (0.223): 0.165*"string" + 0.037*"\n" + 0.034*"character" + 0.032*"output" + 0.031*"way" + 0.030*"print" + 0.026*"answer" + 0.020*"sequence" + 0.020*"option" + 0.019*"format"
INFO: topic #4 (0.224): 0.203*"parameter" + 0.068*"syntax" + 0.058*"pep" + 0.039*"name" + 0.025*"notation" + 0.023*"list" + 0.023*"example" + 0.022*"definition" + 0.021*"keyword" + 0.016*"implementation"
INFO: topic diff=0.323526, rho=0.254824
DEBUG: bound: at document #0
INFO: -7.532 per-word bound, 185.1 perplexity estimate based on a held-out corpus of 5 documents with 23 words
INFO: PROGRESS: pass 4, at document #20/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.15377943, 0.14331672, 0.083084345, 0.21809947, 0.21741776]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.154): 0.074*"directory" + 0.072*"file" + 0.068*"path" + 0.065*"example" + 0.053*"code" + 0.041*"idea" + 0.041*"case" + 0.018*"os.path" + 0.018*"split" + 0.017*"command"
INFO: topic #1 (0.143): 0.290*"argument" + 0.222*"function" + 0.030*"readability" + 0.024*"self" + 0.018*"value" + 0.018*"case" + 0.015*"end" + 0.010*"section" + 0.009*"statement" + 0.008*"proposal"
INFO: topic #2 (0.083): 0.033*"event" + 0.033*"hope" + 0.033*"work" + 0.024*"recap" + 0.024*"slash" + 0.020*"folder" + 0.019*"problem" + 0.019*"parent" + 0.017*"choice" + 0.017*"thing"
INFO: topic #3 (0.218): 0.141*"string" + 0.033*"separator" + 0.031*"\n" + 0.030*"window" + 0.029*"character" + 0.027*"output" + 0.027*"way" + 0.025*"print" + 0.023*"answer" + 0.020*"reference"
INFO: topic #4 (0.217): 0.192*"parameter" + 0.064*"syntax" + 0.055*"pep" + 0.050*"name" + 0.023*"notation" + 0.022*"example" + 0.022*"list" + 0.021*"definition" + 0.020*"keyword" + 0.017*"library"
INFO: topic diff=0.176382, rho=0.254824
DEBUG: bound: at document #0
INFO: -5.702 per-word bound, 52.0 perplexity estimate based on a held-out corpus of 5 documents with 107 words
INFO: PROGRESS: pass 4, at document #25/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.15733536, 0.15247872, 0.07883958, 0.21174212, 0.2254836]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.157): 0.073*"example" + 0.070*"code" + 0.062*"field" + 0.058*"directory" + 0.056*"file" + 0.053*"path" + 0.043*"case" + 0.032*"idea" + 0.021*"method" + 0.015*"os.path"
INFO: topic #1 (0.152): 0.240*"argument" + 0.191*"function" + 0.044*"value" + 0.029*"case" + 0.028*"default" + 0.028*"form" + 0.019*"future" + 0.014*"readability" + 0.013*"section" + 0.011*"self"
INFO: topic #2 (0.079): 0.030*"event" + 0.030*"hope" + 0.030*"work" + 0.022*"recap" + 0.022*"slash" + 0.018*"folder" + 0.017*"problem" + 0.017*"parent" + 0.016*"choice" + 0.016*"thing"
INFO: topic #3 (0.212): 0.126*"string" + 0.045*"separator" + 0.028*"\n" + 0.027*"window" + 0.027*"character" + 0.025*"output" + 0.024*"way" + 0.023*"print" + 0.020*"answer" + 0.019*"reference"
INFO: topic #4 (0.225): 0.218*"parameter" + 0.058*"syntax" + 0.048*"name" + 0.040*"keyword" + 0.039*"pep" + 0.027*"example" + 0.027*"call" + 0.023*"notation" + 0.023*"documentation" + 0.017*"c"
INFO: topic diff=0.336397, rho=0.254824
DEBUG: bound: at document #0
INFO: -8.528 per-word bound, 369.1 perplexity estimate based on a held-out corpus of 5 documents with 20 words
INFO: PROGRESS: pass 4, at document #30/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.16470712, 0.14184599, 0.080688655, 0.21725975, 0.21380645]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.165): 0.075*"code" + 0.072*"path" + 0.064*"file" + 0.059*"example" + 0.050*"field" + 0.047*"directory" + 0.035*"case" + 0.026*"idea" + 0.021*"understanding" + 0.021*"snippet"
INFO: topic #1 (0.142): 0.227*"argument" + 0.181*"function" + 0.041*"value" + 0.028*"case" + 0.027*"default" + 0.027*"form" + 0.018*"future" + 0.013*"readability" + 0.013*"section" + 0.011*"self"
INFO: topic #2 (0.081): 0.039*"slash" + 0.035*"problem" + 0.035*"parent" + 0.032*"program" + 0.026*"cross" + 0.024*"lash" + 0.024*"throw" + 0.024*"path(__file__).resolve().parent" + 0.021*"event" + 0.021*"hope"
INFO: topic #3 (0.217): 0.121*"string" + 0.056*"window" + 0.038*"path" + 0.037*"separator" + 0.024*"\n" + 0.022*"character" + 0.021*"output" + 0.020*"way" + 0.019*"print" + 0.019*"strip"
INFO: topic #4 (0.214): 0.208*"parameter" + 0.056*"syntax" + 0.046*"name" + 0.038*"keyword" + 0.037*"pep" + 0.026*"example" + 0.026*"call" + 0.022*"notation" + 0.022*"documentation" + 0.016*"c"
INFO: topic diff=0.180229, rho=0.254824
DEBUG: bound: at document #0
INFO: -6.753 per-word bound, 107.9 perplexity estimate based on a held-out corpus of 5 documents with 72 words
INFO: PROGRESS: pass 4, at document #35/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17745541, 0.12663035, 0.0845314, 0.23565179, 0.21935019]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.177): 0.108*"path" + 0.091*"component" + 0.060*"directory" + 0.052*"letter" + 0.052*"drive" + 0.037*"code" + 0.032*"file" + 0.030*"note" + 0.029*"example" + 0.026*"reset"
INFO: topic #1 (0.127): 0.211*"argument" + 0.168*"function" + 0.039*"value" + 0.026*"case" + 0.025*"default" + 0.025*"form" + 0.017*"future" + 0.013*"readability" + 0.012*"section" + 0.010*"self"
INFO: topic #2 (0.085): 0.072*"slash" + 0.046*"program" + 0.042*"cross" + 0.026*"problem" + 0.026*"parent" + 0.023*"ruin" + 0.023*"os.environ['home" + 0.023*"os.path.dirname(__file" + 0.018*"path(__file__).resolve().parent" + 0.018*"throw"
INFO: topic #3 (0.236): 0.110*"string" + 0.058*"path" + 0.052*"window" + 0.044*"list" + 0.025*"separator" + 0.025*"reference" + 0.020*"item" + 0.019*"join" + 0.017*"conjunction" + 0.017*"os.path.sep"
INFO: topic #4 (0.219): 0.186*"parameter" + 0.047*"syntax" + 0.039*"name" + 0.032*"c" + 0.032*"keyword" + 0.032*"pep" + 0.027*"slash" + 0.022*"version" + 0.022*"example" + 0.022*"call"
INFO: topic diff=0.305518, rho=0.254824
DEBUG: bound: at document #0
INFO: -8.238 per-word bound, 301.8 perplexity estimate based on a held-out corpus of 5 documents with 28 words
INFO: PROGRESS: pass 4, at document #40/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.18294388, 0.1307941, 0.09414463, 0.20530829, 0.20372888]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.183): 0.097*"path" + 0.071*"component" + 0.064*"file" + 0.047*"directory" + 0.041*"application" + 0.041*"drive" + 0.041*"letter" + 0.036*"example" + 0.029*"code" + 0.024*"behaviour"
INFO: topic #1 (0.131): 0.200*"argument" + 0.163*"function" + 0.034*"value" + 0.025*"behavior" + 0.023*"case" + 0.022*"default" + 0.022*"form" + 0.015*"future" + 0.011*"readability" + 0.011*"section"
INFO: topic #2 (0.094): 0.068*"slash" + 0.064*"extension" + 0.031*"program" + 0.028*"cross" + 0.027*"folder" + 0.022*"new_sandbox" + 0.022*"append" + 0.022*"prevent" + 0.022*"issue" + 0.022*"bite"
INFO: topic #3 (0.205): 0.101*"string" + 0.053*"path" + 0.048*"window" + 0.040*"list" + 0.023*"separator" + 0.023*"reference" + 0.018*"item" + 0.018*"join" + 0.015*"os.path.sep" + 0.015*"conjunction"
INFO: topic #4 (0.204): 0.174*"parameter" + 0.048*"name" + 0.044*"syntax" + 0.030*"c" + 0.030*"keyword" + 0.030*"pep" + 0.026*"slash" + 0.021*"version" + 0.021*"example" + 0.021*"call"
INFO: topic diff=0.203947, rho=0.254824
DEBUG: bound: at document #0
INFO: -6.099 per-word bound, 68.6 perplexity estimate based on a held-out corpus of 5 documents with 46 words
INFO: PROGRESS: pass 4, at document #45/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.18905565, 0.12730339, 0.0875649, 0.2042846, 0.19849071]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.189): 0.082*"file" + 0.081*"path" + 0.059*"component" + 0.054*"directory" + 0.034*"application" + 0.034*"drive" + 0.034*"letter" + 0.034*"code" + 0.030*"example" + 0.024*"root"
INFO: topic #1 (0.127): 0.219*"argument" + 0.146*"function" + 0.048*"case" + 0.040*"value" + 0.022*"self" + 0.020*"end" + 0.018*"behavior" + 0.017*"edit" + 0.017*"companion" + 0.016*"default"
INFO: topic #2 (0.088): 0.060*"slash" + 0.057*"extension" + 0.028*"program" + 0.026*"cross" + 0.024*"folder" + 0.020*"new_sandbox" + 0.020*"append" + 0.020*"prevent" + 0.020*"issue" + 0.020*"bite"
INFO: topic #3 (0.204): 0.127*"string" + 0.037*"sequence" + 0.035*"escape" + 0.034*"path" + 0.034*"tabulation" + 0.031*"window" + 0.031*"reference" + 0.026*"list" + 0.025*"character" + 0.024*"way"
INFO: topic #4 (0.198): 0.160*"parameter" + 0.041*"name" + 0.039*"keyword" + 0.038*"syntax" + 0.035*"slash" + 0.031*"example" + 0.028*"documentation" + 0.026*"mark" + 0.026*"c" + 0.025*"pep"
INFO: topic diff=0.211414, rho=0.254824
DEBUG: bound: at document #0
INFO: -5.292 per-word bound, 39.2 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 4, at document #50/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.19522718, 0.122597575, 0.08126785, 0.22587623, 0.19477814]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.195): 0.093*"example" + 0.065*"file" + 0.064*"path" + 0.047*"component" + 0.043*"directory" + 0.027*"application" + 0.027*"letter" + 0.027*"drive" + 0.027*"code" + 0.024*"case"
INFO: topic #1 (0.123): 0.217*"argument" + 0.193*"function" + 0.037*"case" + 0.032*"end" + 0.031*"value" + 0.017*"self" + 0.014*"behavior" + 0.013*"companion" + 0.013*"edit" + 0.013*"default"
INFO: topic #2 (0.081): 0.053*"slash" + 0.050*"extension" + 0.025*"program" + 0.023*"cross" + 0.022*"folder" + 0.018*"new_sandbox" + 0.018*"append" + 0.018*"prevent" + 0.018*"issue" + 0.018*"bite"
INFO: topic #3 (0.226): 0.175*"string" + 0.053*"sequence" + 0.048*"character" + 0.036*"tab" + 0.034*"escape" + 0.030*"length" + 0.029*"return" + 0.029*"space" + 0.024*"item" + 0.023*"reference"
INFO: topic #4 (0.195): 0.216*"parameter" + 0.052*"list" + 0.043*"slash" + 0.039*"documentation" + 0.036*"name" + 0.034*"example" + 0.024*"slash(/" + 0.024*"keyword" + 0.023*"syntax" + 0.018*"help"
INFO: topic diff=0.323519, rho=0.254824
DEBUG: bound: at document #0
INFO: -5.007 per-word bound, 32.2 perplexity estimate based on a held-out corpus of 2 documents with 71 words
INFO: PROGRESS: pass 4, at document #52/52
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
INFO: optimized alpha [0.15025052, 0.14273015, 0.07316451, 0.16837041, 0.22978708]
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 52 documents
INFO: topic #0 (0.150): 0.085*"example" + 0.059*"file" + 0.058*"path" + 0.043*"component" + 0.039*"directory" + 0.025*"application" + 0.025*"letter" + 0.025*"drive" + 0.025*"code" + 0.023*"case"
INFO: topic #1 (0.143): 0.323*"function" + 0.245*"argument" + 0.048*"value" + 0.021*"case" + 0.018*"end" + 0.010*"self" + 0.008*"behavior" + 0.008*"companion" + 0.008*"edit" + 0.007*"default"
INFO: topic #2 (0.073): 0.045*"slash" + 0.042*"extension" + 0.021*"program" + 0.020*"cross" + 0.019*"folder" + 0.016*"new_sandbox" + 0.016*"append" + 0.016*"prevent" + 0.016*"issue" + 0.016*"bite"
INFO: topic #3 (0.168): 0.166*"string" + 0.050*"sequence" + 0.045*"character" + 0.035*"tab" + 0.032*"escape" + 0.029*"length" + 0.028*"return" + 0.028*"space" + 0.023*"item" + 0.022*"reference"
INFO: topic #4 (0.230): 0.192*"parameter" + 0.098*"syntax" + 0.061*"pep" + 0.039*"list" + 0.028*"help" + 0.026*"notation" + 0.024*"implementation" + 0.023*"name" + 0.022*"example" + 0.019*"keyword"
INFO: topic diff=0.392409, rho=0.254824
DEBUG: bound: at document #0
INFO: -6.855 per-word bound, 115.8 perplexity estimate based on a held-out corpus of 5 documents with 76 words
INFO: PROGRESS: pass 5, at document #5/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13895713, 0.14258486, 0.072279446, 0.19982544, 0.2020351]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.139): 0.075*"example" + 0.052*"file" + 0.051*"path" + 0.038*"component" + 0.035*"directory" + 0.032*"variable" + 0.022*"application" + 0.022*"letter" + 0.022*"drive" + 0.022*"code"
INFO: topic #1 (0.143): 0.261*"function" + 0.237*"argument" + 0.037*"value" + 0.027*"readability" + 0.020*"self" + 0.017*"case" + 0.016*"statement" + 0.014*"end" + 0.013*"speed" + 0.013*"change"
INFO: topic #2 (0.072): 0.049*"program" + 0.037*"slash" + 0.035*"extension" + 0.016*"cross" + 0.016*"folder" + 0.013*"new_sandbox" + 0.013*"append" + 0.013*"prevent" + 0.013*"issue" + 0.013*"dot"
INFO: topic #3 (0.200): 0.172*"string" + 0.038*"print" + 0.027*"output" + 0.026*"sequence" + 0.026*"\n" + 0.025*"option" + 0.024*"character" + 0.019*"way" + 0.018*"list" + 0.018*"tab"
INFO: topic #4 (0.202): 0.184*"parameter" + 0.093*"syntax" + 0.059*"pep" + 0.037*"list" + 0.032*"name" + 0.027*"help" + 0.025*"notation" + 0.023*"implementation" + 0.021*"example" + 0.018*"keyword"
INFO: topic diff=0.285488, rho=0.246932
DEBUG: bound: at document #0
INFO: -5.141 per-word bound, 35.3 perplexity estimate based on a held-out corpus of 5 documents with 193 words
INFO: PROGRESS: pass 5, at document #10/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13751312, 0.15755703, 0.0709584, 0.20403092, 0.21040842]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.138): 0.069*"idea" + 0.058*"example" + 0.045*"file" + 0.044*"code" + 0.042*"case" + 0.029*"path" + 0.027*"point" + 0.023*"note" + 0.022*"field" + 0.022*"component"
INFO: topic #1 (0.158): 0.338*"argument" + 0.259*"function" + 0.034*"readability" + 0.021*"value" + 0.020*"case" + 0.017*"end" + 0.012*"self" + 0.011*"section" + 0.009*"statement" + 0.007*"speed"
INFO: topic #2 (0.071): 0.059*"recap" + 0.032*"program" + 0.029*"win" + 0.029*"order" + 0.029*"document" + 0.029*"guidance" + 0.029*"heh" + 0.029*"question" + 0.025*"slash" + 0.023*"extension"
INFO: topic #3 (0.204): 0.180*"string" + 0.039*"\n" + 0.037*"character" + 0.033*"way" + 0.032*"print" + 0.023*"output" + 0.022*"sequence" + 0.021*"option" + 0.020*"format" + 0.020*"answer"
INFO: topic #4 (0.210): 0.213*"parameter" + 0.071*"syntax" + 0.060*"pep" + 0.042*"name" + 0.026*"notation" + 0.024*"list" + 0.024*"example" + 0.023*"definition" + 0.022*"keyword" + 0.018*"proposal"
INFO: topic diff=0.428290, rho=0.246932
DEBUG: bound: at document #0
INFO: -8.579 per-word bound, 382.5 perplexity estimate based on a held-out corpus of 5 documents with 43 words
INFO: PROGRESS: pass 5, at document #15/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1402199, 0.14060526, 0.08682451, 0.18664943, 0.21512303]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.140): 0.072*"path" + 0.056*"idea" + 0.053*"file" + 0.050*"code" + 0.047*"example" + 0.034*"case" + 0.033*"directory" + 0.022*"command" + 0.022*"point" + 0.019*"note"
INFO: topic #1 (0.141): 0.319*"argument" + 0.245*"function" + 0.032*"readability" + 0.020*"value" + 0.019*"case" + 0.017*"end" + 0.011*"self" + 0.010*"section" + 0.009*"statement" + 0.007*"speed"
INFO: topic #2 (0.087): 0.036*"hope" + 0.036*"event" + 0.036*"work" + 0.027*"slash" + 0.026*"recap" + 0.022*"folder" + 0.020*"problem" + 0.020*"parent" + 0.019*"thing" + 0.019*"choice"
INFO: topic #3 (0.187): 0.168*"string" + 0.037*"\n" + 0.035*"character" + 0.032*"output" + 0.031*"way" + 0.030*"print" + 0.021*"sequence" + 0.020*"option" + 0.019*"format" + 0.019*"answer"
INFO: topic #4 (0.215): 0.201*"parameter" + 0.067*"syntax" + 0.057*"pep" + 0.040*"name" + 0.024*"notation" + 0.023*"list" + 0.022*"example" + 0.022*"definition" + 0.021*"keyword" + 0.017*"proposal"
INFO: topic diff=0.311891, rho=0.246932
DEBUG: bound: at document #0
INFO: -7.495 per-word bound, 180.3 perplexity estimate based on a held-out corpus of 5 documents with 23 words
INFO: PROGRESS: pass 5, at document #20/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14875431, 0.13898627, 0.083585985, 0.18462975, 0.20917869]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.149): 0.072*"directory" + 0.071*"file" + 0.069*"path" + 0.065*"example" + 0.053*"code" + 0.041*"idea" + 0.040*"case" + 0.018*"split" + 0.018*"os.path" + 0.016*"command"
INFO: topic #1 (0.139): 0.292*"argument" + 0.225*"function" + 0.030*"readability" + 0.024*"self" + 0.019*"value" + 0.018*"case" + 0.016*"end" + 0.010*"section" + 0.008*"statement" + 0.007*"speed"
INFO: topic #2 (0.084): 0.033*"hope" + 0.033*"event" + 0.033*"work" + 0.025*"slash" + 0.024*"recap" + 0.020*"folder" + 0.019*"problem" + 0.019*"parent" + 0.017*"thing" + 0.017*"choice"
INFO: topic #3 (0.185): 0.144*"string" + 0.033*"separator" + 0.032*"\n" + 0.030*"character" + 0.030*"window" + 0.027*"output" + 0.027*"way" + 0.026*"print" + 0.021*"reference" + 0.019*"path"
INFO: topic #4 (0.209): 0.191*"parameter" + 0.064*"syntax" + 0.054*"pep" + 0.050*"name" + 0.023*"notation" + 0.022*"example" + 0.022*"list" + 0.021*"definition" + 0.020*"keyword" + 0.016*"proposal"
INFO: topic diff=0.169755, rho=0.246932
DEBUG: bound: at document #0
INFO: -5.656 per-word bound, 50.4 perplexity estimate based on a held-out corpus of 5 documents with 107 words
INFO: PROGRESS: pass 5, at document #25/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.15221365, 0.1475708, 0.07935294, 0.18227924, 0.21679787]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.152): 0.072*"example" + 0.069*"code" + 0.060*"field" + 0.057*"directory" + 0.057*"file" + 0.055*"path" + 0.042*"case" + 0.033*"idea" + 0.021*"method" + 0.014*"os.path"
INFO: topic #1 (0.148): 0.242*"argument" + 0.193*"function" + 0.044*"value" + 0.030*"case" + 0.028*"default" + 0.028*"form" + 0.018*"future" + 0.014*"readability" + 0.013*"section" + 0.011*"self"
INFO: topic #2 (0.079): 0.029*"hope" + 0.029*"event" + 0.029*"work" + 0.022*"slash" + 0.022*"recap" + 0.018*"folder" + 0.017*"problem" + 0.017*"parent" + 0.016*"thing" + 0.016*"choice"
INFO: topic #3 (0.182): 0.130*"string" + 0.044*"separator" + 0.029*"\n" + 0.027*"character" + 0.027*"window" + 0.025*"output" + 0.025*"way" + 0.024*"print" + 0.019*"reference" + 0.017*"path"
INFO: topic #4 (0.217): 0.216*"parameter" + 0.058*"syntax" + 0.048*"name" + 0.039*"pep" + 0.039*"keyword" + 0.027*"example" + 0.026*"call" + 0.023*"notation" + 0.022*"documentation" + 0.017*"c"
INFO: topic diff=0.316612, rho=0.246932
DEBUG: bound: at document #0
INFO: -8.493 per-word bound, 360.2 perplexity estimate based on a held-out corpus of 5 documents with 20 words
INFO: PROGRESS: pass 5, at document #30/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.15899798, 0.13751921, 0.08102947, 0.18816738, 0.20587058]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.159): 0.074*"code" + 0.073*"path" + 0.064*"file" + 0.059*"example" + 0.049*"field" + 0.047*"directory" + 0.034*"case" + 0.027*"idea" + 0.020*"understanding" + 0.020*"snippet"
INFO: topic #1 (0.138): 0.229*"argument" + 0.183*"function" + 0.042*"value" + 0.028*"case" + 0.026*"default" + 0.026*"form" + 0.018*"future" + 0.014*"readability" + 0.013*"section" + 0.011*"self"
INFO: topic #2 (0.081): 0.038*"slash" + 0.035*"problem" + 0.035*"parent" + 0.031*"program" + 0.026*"cross" + 0.024*"lash" + 0.024*"throw" + 0.024*"path(__file__).resolve().parent" + 0.021*"event" + 0.021*"hope"
INFO: topic #3 (0.188): 0.124*"string" + 0.055*"window" + 0.037*"path" + 0.037*"separator" + 0.024*"\n" + 0.023*"character" + 0.021*"output" + 0.021*"way" + 0.020*"print" + 0.018*"strip"
INFO: topic #4 (0.206): 0.206*"parameter" + 0.056*"syntax" + 0.046*"name" + 0.037*"pep" + 0.037*"keyword" + 0.026*"example" + 0.025*"call" + 0.022*"notation" + 0.022*"documentation" + 0.016*"c"
INFO: topic diff=0.171975, rho=0.246932
DEBUG: bound: at document #0
INFO: -6.699 per-word bound, 103.9 perplexity estimate based on a held-out corpus of 5 documents with 72 words
INFO: PROGRESS: pass 5, at document #35/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17076482, 0.12324171, 0.08461587, 0.20580481, 0.2111074]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.171): 0.108*"path" + 0.089*"component" + 0.060*"directory" + 0.051*"letter" + 0.051*"drive" + 0.038*"code" + 0.032*"file" + 0.030*"example" + 0.029*"note" + 0.026*"reset"
INFO: topic #1 (0.123): 0.214*"argument" + 0.170*"function" + 0.039*"value" + 0.027*"case" + 0.025*"default" + 0.025*"form" + 0.017*"future" + 0.013*"readability" + 0.012*"section" + 0.010*"self"
INFO: topic #2 (0.085): 0.071*"slash" + 0.045*"program" + 0.041*"cross" + 0.026*"problem" + 0.026*"parent" + 0.023*"ruin" + 0.023*"os.environ['home" + 0.023*"os.path.dirname(__file" + 0.018*"lash" + 0.018*"throw"
INFO: topic #3 (0.206): 0.113*"string" + 0.057*"path" + 0.051*"window" + 0.042*"list" + 0.025*"separator" + 0.025*"reference" + 0.019*"item" + 0.019*"join" + 0.017*"\n" + 0.016*"conjunction"
INFO: topic #4 (0.211): 0.186*"parameter" + 0.048*"syntax" + 0.040*"name" + 0.032*"pep" + 0.032*"keyword" + 0.031*"c" + 0.026*"slash" + 0.022*"example" + 0.022*"version" + 0.022*"call"
INFO: topic diff=0.290642, rho=0.246932
DEBUG: bound: at document #0
INFO: -8.166 per-word bound, 287.2 perplexity estimate based on a held-out corpus of 5 documents with 28 words
INFO: PROGRESS: pass 5, at document #40/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17606655, 0.12724172, 0.09387183, 0.18264362, 0.19695377]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.176): 0.097*"path" + 0.070*"component" + 0.064*"file" + 0.047*"directory" + 0.041*"drive" + 0.041*"letter" + 0.040*"application" + 0.036*"example" + 0.030*"code" + 0.024*"behaviour"
INFO: topic #1 (0.127): 0.203*"argument" + 0.165*"function" + 0.035*"value" + 0.024*"behavior" + 0.024*"case" + 0.022*"default" + 0.022*"form" + 0.015*"future" + 0.012*"readability" + 0.011*"section"
INFO: topic #2 (0.094): 0.067*"slash" + 0.062*"extension" + 0.031*"program" + 0.028*"cross" + 0.027*"folder" + 0.022*"new_sandbox" + 0.021*"prevent" + 0.021*"append" + 0.021*"issue" + 0.021*"foobar.jpg"
INFO: topic #3 (0.183): 0.103*"string" + 0.052*"path" + 0.047*"window" + 0.039*"list" + 0.023*"separator" + 0.023*"reference" + 0.018*"item" + 0.018*"join" + 0.016*"\n" + 0.015*"os.path.sep"
INFO: topic #4 (0.197): 0.174*"parameter" + 0.048*"name" + 0.045*"syntax" + 0.030*"pep" + 0.030*"keyword" + 0.029*"c" + 0.025*"slash" + 0.021*"example" + 0.020*"version" + 0.020*"call"
INFO: topic diff=0.195031, rho=0.246932
DEBUG: bound: at document #0
INFO: -6.063 per-word bound, 66.9 perplexity estimate based on a held-out corpus of 5 documents with 46 words
INFO: PROGRESS: pass 5, at document #45/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.18192002, 0.12390806, 0.087369286, 0.18323272, 0.19215523]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.182): 0.082*"path" + 0.082*"file" + 0.059*"component" + 0.054*"directory" + 0.034*"drive" + 0.034*"letter" + 0.034*"code" + 0.034*"application" + 0.031*"example" + 0.024*"root"
INFO: topic #1 (0.124): 0.220*"argument" + 0.148*"function" + 0.047*"case" + 0.040*"value" + 0.022*"self" + 0.020*"end" + 0.018*"behavior" + 0.016*"edit" + 0.016*"companion" + 0.016*"default"
INFO: topic #2 (0.087): 0.060*"slash" + 0.056*"extension" + 0.028*"program" + 0.025*"cross" + 0.024*"folder" + 0.020*"new_sandbox" + 0.019*"prevent" + 0.019*"append" + 0.019*"issue" + 0.019*"foobar.jpg"
INFO: topic #3 (0.183): 0.128*"string" + 0.037*"sequence" + 0.035*"escape" + 0.034*"path" + 0.033*"tabulation" + 0.031*"window" + 0.030*"reference" + 0.026*"list" + 0.025*"character" + 0.024*"way"
INFO: topic #4 (0.192): 0.161*"parameter" + 0.041*"name" + 0.039*"syntax" + 0.038*"keyword" + 0.034*"slash" + 0.030*"example" + 0.027*"documentation" + 0.026*"pep" + 0.026*"mark" + 0.025*"c"
INFO: topic diff=0.200386, rho=0.246932
DEBUG: bound: at document #0
INFO: -5.260 per-word bound, 38.3 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 5, at document #50/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.18781702, 0.11941544, 0.081138626, 0.20321138, 0.18858069]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.188): 0.092*"example" + 0.065*"path" + 0.065*"file" + 0.047*"component" + 0.043*"directory" + 0.027*"letter" + 0.027*"drive" + 0.027*"code" + 0.027*"application" + 0.024*"case"
INFO: topic #1 (0.119): 0.219*"argument" + 0.193*"function" + 0.037*"case" + 0.031*"value" + 0.031*"end" + 0.017*"self" + 0.014*"behavior" + 0.013*"companion" + 0.013*"edit" + 0.013*"default"
INFO: topic #2 (0.081): 0.053*"slash" + 0.049*"extension" + 0.025*"program" + 0.023*"cross" + 0.021*"folder" + 0.018*"new_sandbox" + 0.017*"prevent" + 0.017*"append" + 0.017*"issue" + 0.017*"foobar.jpg"
INFO: topic #3 (0.203): 0.175*"string" + 0.053*"sequence" + 0.047*"character" + 0.036*"tab" + 0.034*"escape" + 0.030*"length" + 0.029*"return" + 0.029*"space" + 0.024*"item" + 0.023*"reference"
INFO: topic #4 (0.189): 0.214*"parameter" + 0.051*"list" + 0.042*"slash" + 0.038*"documentation" + 0.036*"name" + 0.033*"example" + 0.024*"syntax" + 0.024*"keyword" + 0.023*"slash(/" + 0.017*"help"
INFO: topic diff=0.308087, rho=0.246932
DEBUG: bound: at document #0
INFO: -4.942 per-word bound, 30.7 perplexity estimate based on a held-out corpus of 2 documents with 71 words
INFO: PROGRESS: pass 5, at document #52/52
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
INFO: optimized alpha [0.14711261, 0.13858898, 0.07326583, 0.1560628, 0.22172052]
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 52 documents
INFO: topic #0 (0.147): 0.084*"example" + 0.059*"path" + 0.059*"file" + 0.043*"component" + 0.039*"directory" + 0.025*"letter" + 0.025*"drive" + 0.025*"code" + 0.025*"application" + 0.022*"case"
INFO: topic #1 (0.139): 0.321*"function" + 0.246*"argument" + 0.048*"value" + 0.022*"case" + 0.018*"end" + 0.010*"self" + 0.008*"behavior" + 0.008*"companion" + 0.008*"edit" + 0.008*"default"
INFO: topic #2 (0.073): 0.045*"slash" + 0.042*"extension" + 0.022*"program" + 0.020*"cross" + 0.019*"folder" + 0.016*"new_sandbox" + 0.015*"prevent" + 0.015*"append" + 0.015*"issue" + 0.015*"foobar.jpg"
INFO: topic #3 (0.156): 0.165*"string" + 0.050*"sequence" + 0.045*"character" + 0.034*"tab" + 0.032*"escape" + 0.028*"length" + 0.028*"return" + 0.027*"space" + 0.023*"item" + 0.022*"reference"
INFO: topic #4 (0.222): 0.192*"parameter" + 0.097*"syntax" + 0.061*"pep" + 0.039*"list" + 0.028*"help" + 0.025*"notation" + 0.024*"implementation" + 0.023*"name" + 0.022*"example" + 0.019*"keyword"
INFO: topic diff=0.374610, rho=0.246932
DEBUG: bound: at document #0
INFO: -6.809 per-word bound, 112.1 perplexity estimate based on a held-out corpus of 5 documents with 76 words
INFO: PROGRESS: pass 6, at document #5/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13645461, 0.1385713, 0.07232068, 0.18480515, 0.19739048]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.136): 0.074*"example" + 0.053*"path" + 0.053*"file" + 0.038*"component" + 0.035*"directory" + 0.031*"variable" + 0.023*"letter" + 0.023*"drive" + 0.023*"code" + 0.022*"application"
INFO: topic #1 (0.139): 0.260*"function" + 0.238*"argument" + 0.037*"value" + 0.027*"readability" + 0.020*"self" + 0.017*"case" + 0.015*"statement" + 0.014*"end" + 0.012*"speed" + 0.012*"factor"
INFO: topic #2 (0.072): 0.048*"program" + 0.038*"slash" + 0.035*"extension" + 0.017*"cross" + 0.016*"folder" + 0.013*"new_sandbox" + 0.013*"append" + 0.013*"prevent" + 0.013*"issue" + 0.013*"dot"
INFO: topic #3 (0.185): 0.172*"string" + 0.037*"print" + 0.027*"output" + 0.027*"sequence" + 0.026*"\n" + 0.025*"option" + 0.024*"character" + 0.019*"way" + 0.018*"tab" + 0.018*"list"
INFO: topic #4 (0.197): 0.183*"parameter" + 0.093*"syntax" + 0.058*"pep" + 0.037*"list" + 0.033*"name" + 0.027*"help" + 0.024*"notation" + 0.023*"implementation" + 0.021*"example" + 0.018*"keyword"
INFO: topic diff=0.275295, rho=0.239732
DEBUG: bound: at document #0
INFO: -5.118 per-word bound, 34.7 perplexity estimate based on a held-out corpus of 5 documents with 193 words
INFO: PROGRESS: pass 6, at document #10/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13518357, 0.1528718, 0.070994824, 0.1906001, 0.20553622]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.135): 0.068*"idea" + 0.059*"example" + 0.046*"file" + 0.044*"code" + 0.041*"case" + 0.031*"path" + 0.027*"point" + 0.023*"note" + 0.023*"component" + 0.022*"field"
INFO: topic #1 (0.153): 0.337*"argument" + 0.260*"function" + 0.034*"readability" + 0.022*"value" + 0.020*"case" + 0.018*"end" + 0.012*"self" + 0.011*"section" + 0.009*"statement" + 0.007*"speed"
INFO: topic #2 (0.071): 0.057*"recap" + 0.032*"program" + 0.028*"win" + 0.028*"order" + 0.028*"document" + 0.028*"guidance" + 0.028*"heh" + 0.028*"question" + 0.025*"slash" + 0.024*"extension"
INFO: topic #3 (0.191): 0.180*"string" + 0.039*"\n" + 0.037*"character" + 0.033*"way" + 0.032*"print" + 0.023*"output" + 0.023*"sequence" + 0.021*"option" + 0.020*"length" + 0.020*"format"
INFO: topic #4 (0.206): 0.212*"parameter" + 0.071*"syntax" + 0.060*"pep" + 0.042*"name" + 0.025*"notation" + 0.025*"list" + 0.024*"example" + 0.023*"definition" + 0.022*"keyword" + 0.019*"proposal"
INFO: topic diff=0.408836, rho=0.239732
DEBUG: bound: at document #0
INFO: -8.487 per-word bound, 358.8 perplexity estimate based on a held-out corpus of 5 documents with 43 words
INFO: PROGRESS: pass 6, at document #15/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13775487, 0.13707127, 0.08635599, 0.17552735, 0.20884256]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.138): 0.072*"path" + 0.055*"idea" + 0.053*"file" + 0.050*"code" + 0.047*"example" + 0.033*"case" + 0.033*"directory" + 0.022*"point" + 0.022*"command" + 0.019*"note"
INFO: topic #1 (0.137): 0.319*"argument" + 0.246*"function" + 0.032*"readability" + 0.021*"value" + 0.019*"case" + 0.017*"end" + 0.011*"self" + 0.010*"section" + 0.009*"statement" + 0.007*"speed"
INFO: topic #2 (0.086): 0.035*"hope" + 0.035*"event" + 0.035*"work" + 0.027*"slash" + 0.026*"recap" + 0.021*"folder" + 0.020*"problem" + 0.020*"parent" + 0.018*"choice" + 0.018*"thing"
INFO: topic #3 (0.176): 0.168*"string" + 0.037*"\n" + 0.035*"character" + 0.032*"output" + 0.031*"way" + 0.030*"print" + 0.021*"sequence" + 0.020*"option" + 0.019*"length" + 0.019*"format"
INFO: topic #4 (0.209): 0.201*"parameter" + 0.067*"syntax" + 0.057*"pep" + 0.040*"name" + 0.024*"notation" + 0.023*"list" + 0.022*"example" + 0.022*"definition" + 0.021*"keyword" + 0.018*"proposal"
INFO: topic diff=0.301159, rho=0.239732
DEBUG: bound: at document #0
INFO: -7.468 per-word bound, 177.0 perplexity estimate based on a held-out corpus of 5 documents with 23 words
INFO: PROGRESS: pass 6, at document #20/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14586478, 0.13561966, 0.08319858, 0.17409629, 0.20339933]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.146): 0.071*"directory" + 0.071*"file" + 0.069*"path" + 0.065*"example" + 0.053*"code" + 0.041*"idea" + 0.040*"case" + 0.017*"os.path" + 0.017*"split" + 0.016*"point"
INFO: topic #1 (0.136): 0.293*"argument" + 0.226*"function" + 0.030*"readability" + 0.023*"self" + 0.020*"value" + 0.018*"case" + 0.016*"end" + 0.010*"section" + 0.008*"statement" + 0.007*"speed"
INFO: topic #2 (0.083): 0.032*"hope" + 0.032*"event" + 0.032*"work" + 0.025*"slash" + 0.024*"recap" + 0.020*"folder" + 0.018*"problem" + 0.018*"parent" + 0.017*"choice" + 0.017*"thing"
INFO: topic #3 (0.174): 0.145*"string" + 0.032*"separator" + 0.032*"\n" + 0.030*"character" + 0.029*"window" + 0.027*"output" + 0.027*"way" + 0.026*"print" + 0.020*"reference" + 0.019*"path"
INFO: topic #4 (0.203): 0.191*"parameter" + 0.064*"syntax" + 0.054*"pep" + 0.050*"name" + 0.023*"notation" + 0.022*"list" + 0.022*"example" + 0.021*"definition" + 0.020*"keyword" + 0.017*"proposal"
INFO: topic diff=0.163656, rho=0.239732
DEBUG: bound: at document #0
INFO: -5.627 per-word bound, 49.4 perplexity estimate based on a held-out corpus of 5 documents with 107 words
INFO: PROGRESS: pass 6, at document #25/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14921574, 0.14375784, 0.07908087, 0.17273827, 0.2106808]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.149): 0.072*"example" + 0.069*"code" + 0.059*"field" + 0.057*"directory" + 0.057*"file" + 0.055*"path" + 0.041*"case" + 0.033*"idea" + 0.021*"method" + 0.014*"os.path"
INFO: topic #1 (0.144): 0.243*"argument" + 0.194*"function" + 0.044*"value" + 0.030*"case" + 0.027*"default" + 0.027*"form" + 0.018*"future" + 0.014*"readability" + 0.013*"section" + 0.011*"self"
INFO: topic #2 (0.079): 0.029*"hope" + 0.029*"event" + 0.029*"work" + 0.023*"slash" + 0.022*"recap" + 0.018*"folder" + 0.017*"problem" + 0.017*"parent" + 0.015*"choice" + 0.015*"thing"
INFO: topic #3 (0.173): 0.131*"string" + 0.043*"separator" + 0.029*"\n" + 0.028*"character" + 0.027*"window" + 0.025*"output" + 0.024*"way" + 0.024*"print" + 0.019*"reference" + 0.017*"path"
INFO: topic #4 (0.211): 0.215*"parameter" + 0.059*"syntax" + 0.048*"name" + 0.040*"pep" + 0.038*"keyword" + 0.027*"example" + 0.026*"call" + 0.023*"notation" + 0.022*"documentation" + 0.016*"c"
INFO: topic diff=0.302119, rho=0.239732
DEBUG: bound: at document #0
INFO: -8.464 per-word bound, 353.2 perplexity estimate based on a held-out corpus of 5 documents with 20 words
INFO: PROGRESS: pass 6, at document #30/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.15564494, 0.13431771, 0.08065968, 0.17849816, 0.20054954]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.156): 0.074*"code" + 0.073*"path" + 0.064*"file" + 0.059*"example" + 0.048*"field" + 0.047*"directory" + 0.034*"case" + 0.027*"idea" + 0.020*"snippet" + 0.020*"understanding"
INFO: topic #1 (0.134): 0.231*"argument" + 0.184*"function" + 0.042*"value" + 0.028*"case" + 0.026*"default" + 0.026*"form" + 0.018*"future" + 0.014*"readability" + 0.013*"section" + 0.011*"self"
INFO: topic #2 (0.081): 0.038*"slash" + 0.034*"problem" + 0.034*"parent" + 0.031*"program" + 0.025*"cross" + 0.023*"path(__file__).resolve().parent" + 0.023*"throw" + 0.023*"lash" + 0.021*"event" + 0.021*"hope"
INFO: topic #3 (0.178): 0.126*"string" + 0.053*"window" + 0.037*"separator" + 0.036*"path" + 0.024*"\n" + 0.023*"character" + 0.021*"output" + 0.021*"way" + 0.020*"print" + 0.018*"strip"
INFO: topic #4 (0.201): 0.206*"parameter" + 0.056*"syntax" + 0.046*"name" + 0.038*"pep" + 0.037*"keyword" + 0.026*"example" + 0.025*"call" + 0.022*"notation" + 0.021*"documentation" + 0.016*"c"
INFO: topic diff=0.164805, rho=0.239732
DEBUG: bound: at document #0
INFO: -6.655 per-word bound, 100.8 perplexity estimate based on a held-out corpus of 5 documents with 72 words
INFO: PROGRESS: pass 6, at document #35/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.16682492, 0.12090592, 0.08408261, 0.19537167, 0.2057037]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.167): 0.107*"path" + 0.088*"component" + 0.060*"directory" + 0.051*"letter" + 0.051*"drive" + 0.038*"code" + 0.033*"file" + 0.030*"example" + 0.029*"note" + 0.026*"idea"
INFO: topic #1 (0.121): 0.216*"argument" + 0.172*"function" + 0.039*"value" + 0.027*"case" + 0.025*"default" + 0.025*"form" + 0.017*"future" + 0.013*"readability" + 0.012*"section" + 0.011*"self"
INFO: topic #2 (0.084): 0.069*"slash" + 0.045*"program" + 0.040*"cross" + 0.026*"problem" + 0.026*"parent" + 0.023*"ruin" + 0.023*"os.environ['home" + 0.023*"os.path.dirname(__file" + 0.018*"lash" + 0.018*"throw"
INFO: topic #3 (0.195): 0.114*"string" + 0.055*"path" + 0.051*"window" + 0.041*"list" + 0.025*"separator" + 0.025*"reference" + 0.019*"item" + 0.019*"join" + 0.017*"\n" + 0.016*"character"
INFO: topic #4 (0.206): 0.186*"parameter" + 0.049*"syntax" + 0.040*"name" + 0.033*"pep" + 0.032*"keyword" + 0.030*"c" + 0.026*"slash" + 0.022*"example" + 0.021*"call" + 0.021*"version"
INFO: topic diff=0.278229, rho=0.239732
DEBUG: bound: at document #0
INFO: -8.110 per-word bound, 276.4 perplexity estimate based on a held-out corpus of 5 documents with 28 words
INFO: PROGRESS: pass 6, at document #40/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17193337, 0.12476545, 0.092987455, 0.17476459, 0.19256368]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.172): 0.097*"path" + 0.070*"component" + 0.063*"file" + 0.048*"directory" + 0.040*"letter" + 0.040*"drive" + 0.040*"application" + 0.037*"example" + 0.030*"code" + 0.024*"behaviour"
INFO: topic #1 (0.125): 0.205*"argument" + 0.167*"function" + 0.035*"value" + 0.024*"case" + 0.024*"behavior" + 0.022*"default" + 0.022*"form" + 0.015*"future" + 0.012*"readability" + 0.011*"section"
INFO: topic #2 (0.093): 0.066*"slash" + 0.061*"extension" + 0.031*"program" + 0.028*"cross" + 0.026*"folder" + 0.021*"new_sandbox" + 0.021*"prevent" + 0.021*"append" + 0.021*"bite" + 0.021*"foobar.jpg"
INFO: topic #3 (0.175): 0.105*"string" + 0.051*"path" + 0.047*"window" + 0.038*"list" + 0.024*"separator" + 0.023*"reference" + 0.018*"item" + 0.017*"join" + 0.016*"\n" + 0.015*"character"
INFO: topic #4 (0.193): 0.175*"parameter" + 0.048*"name" + 0.046*"syntax" + 0.031*"pep" + 0.030*"keyword" + 0.029*"c" + 0.025*"slash" + 0.021*"example" + 0.020*"call" + 0.020*"version"
INFO: topic diff=0.187286, rho=0.239732
DEBUG: bound: at document #0
INFO: -6.034 per-word bound, 65.5 perplexity estimate based on a held-out corpus of 5 documents with 46 words
INFO: PROGRESS: pass 6, at document #45/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17773233, 0.12162367, 0.08671196, 0.17573419, 0.18813808]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.178): 0.082*"path" + 0.081*"file" + 0.059*"component" + 0.054*"directory" + 0.035*"code" + 0.034*"letter" + 0.034*"drive" + 0.034*"application" + 0.031*"example" + 0.024*"root"
INFO: topic #1 (0.122): 0.221*"argument" + 0.150*"function" + 0.046*"case" + 0.040*"value" + 0.022*"self" + 0.020*"end" + 0.017*"behavior" + 0.016*"default" + 0.016*"form" + 0.016*"edit"
INFO: topic #2 (0.087): 0.060*"slash" + 0.055*"extension" + 0.028*"program" + 0.025*"cross" + 0.024*"folder" + 0.019*"new_sandbox" + 0.019*"prevent" + 0.019*"append" + 0.019*"bite" + 0.019*"foobar.jpg"
INFO: topic #3 (0.176): 0.129*"string" + 0.036*"sequence" + 0.034*"escape" + 0.034*"path" + 0.032*"tabulation" + 0.031*"window" + 0.030*"reference" + 0.026*"list" + 0.025*"character" + 0.024*"way"
INFO: topic #4 (0.188): 0.162*"parameter" + 0.042*"name" + 0.040*"syntax" + 0.038*"keyword" + 0.033*"slash" + 0.030*"example" + 0.027*"pep" + 0.027*"documentation" + 0.025*"mark" + 0.025*"c"
INFO: topic diff=0.190957, rho=0.239732
DEBUG: bound: at document #0
INFO: -5.234 per-word bound, 37.6 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 6, at document #50/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.18351325, 0.11738324, 0.08068323, 0.19470455, 0.1848133]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.184): 0.091*"example" + 0.065*"path" + 0.064*"file" + 0.047*"component" + 0.043*"directory" + 0.028*"code" + 0.027*"letter" + 0.027*"drive" + 0.027*"application" + 0.024*"case"
INFO: topic #1 (0.117): 0.220*"argument" + 0.194*"function" + 0.037*"case" + 0.032*"value" + 0.031*"end" + 0.017*"self" + 0.014*"behavior" + 0.013*"default" + 0.013*"form" + 0.013*"edit"
INFO: topic #2 (0.081): 0.053*"slash" + 0.048*"extension" + 0.025*"program" + 0.023*"cross" + 0.021*"folder" + 0.017*"new_sandbox" + 0.017*"prevent" + 0.017*"append" + 0.017*"bite" + 0.017*"foobar.jpg"
INFO: topic #3 (0.195): 0.174*"string" + 0.052*"sequence" + 0.047*"character" + 0.036*"tab" + 0.033*"escape" + 0.030*"length" + 0.029*"return" + 0.029*"space" + 0.023*"item" + 0.023*"reference"
INFO: topic #4 (0.185): 0.213*"parameter" + 0.049*"list" + 0.041*"slash" + 0.037*"documentation" + 0.037*"name" + 0.033*"example" + 0.026*"syntax" + 0.024*"keyword" + 0.023*"slash(/" + 0.017*"pep"
INFO: topic diff=0.294890, rho=0.239732
DEBUG: bound: at document #0
INFO: -4.901 per-word bound, 29.9 perplexity estimate based on a held-out corpus of 2 documents with 71 words
INFO: PROGRESS: pass 6, at document #52/52
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
INFO: optimized alpha [0.14558403, 0.13579747, 0.07309842, 0.15231839, 0.2165153]
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 52 documents
INFO: topic #0 (0.146): 0.083*"example" + 0.060*"path" + 0.059*"file" + 0.043*"component" + 0.040*"directory" + 0.026*"code" + 0.025*"letter" + 0.025*"drive" + 0.025*"application" + 0.022*"case"
INFO: topic #1 (0.136): 0.318*"function" + 0.246*"argument" + 0.048*"value" + 0.022*"case" + 0.018*"end" + 0.010*"self" + 0.009*"behavior" + 0.008*"default" + 0.008*"form" + 0.008*"companion"
INFO: topic #2 (0.073): 0.046*"slash" + 0.042*"extension" + 0.022*"program" + 0.020*"cross" + 0.019*"folder" + 0.016*"new_sandbox" + 0.015*"prevent" + 0.015*"append" + 0.015*"bite" + 0.015*"foobar.jpg"
INFO: topic #3 (0.152): 0.165*"string" + 0.049*"sequence" + 0.045*"character" + 0.034*"tab" + 0.032*"escape" + 0.028*"length" + 0.027*"return" + 0.027*"space" + 0.022*"item" + 0.022*"reference"
INFO: topic #4 (0.217): 0.192*"parameter" + 0.096*"syntax" + 0.060*"pep" + 0.039*"list" + 0.028*"help" + 0.025*"notation" + 0.024*"implementation" + 0.023*"name" + 0.022*"example" + 0.019*"keyword"
INFO: topic diff=0.361710, rho=0.239732
DEBUG: bound: at document #0
INFO: -6.756 per-word bound, 108.1 perplexity estimate based on a held-out corpus of 5 documents with 76 words
INFO: PROGRESS: pass 7, at document #5/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13536757, 0.13591497, 0.072154514, 0.17968878, 0.19394328]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.135): 0.074*"example" + 0.054*"path" + 0.053*"file" + 0.039*"component" + 0.036*"directory" + 0.031*"variable" + 0.023*"code" + 0.023*"drive" + 0.023*"letter" + 0.023*"application"
INFO: topic #1 (0.136): 0.260*"function" + 0.238*"argument" + 0.038*"value" + 0.027*"readability" + 0.020*"self" + 0.017*"case" + 0.014*"end" + 0.014*"statement" + 0.012*"speed" + 0.012*"change"
INFO: topic #2 (0.072): 0.047*"program" + 0.038*"slash" + 0.035*"extension" + 0.017*"cross" + 0.016*"folder" + 0.013*"new_sandbox" + 0.013*"append" + 0.013*"prevent" + 0.013*"issue" + 0.013*"dot"
INFO: topic #3 (0.180): 0.171*"string" + 0.037*"print" + 0.027*"sequence" + 0.027*"output" + 0.025*"\n" + 0.024*"option" + 0.024*"character" + 0.019*"way" + 0.018*"tab" + 0.018*"list"
INFO: topic #4 (0.194): 0.184*"parameter" + 0.092*"syntax" + 0.058*"pep" + 0.037*"list" + 0.033*"name" + 0.027*"help" + 0.024*"notation" + 0.023*"implementation" + 0.021*"example" + 0.018*"keyword"
INFO: topic diff=0.265927, rho=0.233126
DEBUG: bound: at document #0
INFO: -5.096 per-word bound, 34.2 perplexity estimate based on a held-out corpus of 5 documents with 193 words
INFO: PROGRESS: pass 7, at document #10/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13416329, 0.149684, 0.070855305, 0.1857519, 0.20190038]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.134): 0.067*"idea" + 0.059*"example" + 0.046*"file" + 0.044*"code" + 0.040*"case" + 0.032*"path" + 0.027*"point" + 0.023*"component" + 0.023*"note" + 0.022*"field"
INFO: topic #1 (0.150): 0.336*"argument" + 0.260*"function" + 0.033*"readability" + 0.022*"value" + 0.020*"case" + 0.018*"end" + 0.012*"self" + 0.011*"section" + 0.009*"statement" + 0.007*"speed"
INFO: topic #2 (0.071): 0.056*"recap" + 0.032*"program" + 0.028*"win" + 0.028*"order" + 0.028*"document" + 0.028*"guidance" + 0.028*"heh" + 0.028*"question" + 0.026*"slash" + 0.024*"extension"
INFO: topic #3 (0.186): 0.179*"string" + 0.038*"\n" + 0.037*"character" + 0.032*"way" + 0.032*"print" + 0.023*"sequence" + 0.023*"output" + 0.021*"option" + 0.020*"length" + 0.020*"format"
INFO: topic #4 (0.202): 0.211*"parameter" + 0.071*"syntax" + 0.060*"pep" + 0.042*"name" + 0.025*"notation" + 0.025*"list" + 0.024*"example" + 0.023*"definition" + 0.022*"keyword" + 0.019*"proposal"
INFO: topic diff=0.392132, rho=0.233126
DEBUG: bound: at document #0
INFO: -8.395 per-word bound, 336.7 perplexity estimate based on a held-out corpus of 5 documents with 43 words
INFO: PROGRESS: pass 7, at document #15/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13617195, 0.1342288, 0.08561764, 0.17085697, 0.19642672]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.136): 0.072*"path" + 0.054*"idea" + 0.053*"file" + 0.051*"code" + 0.048*"example" + 0.033*"directory" + 0.033*"case" + 0.022*"point" + 0.022*"command" + 0.019*"component"
INFO: topic #1 (0.134): 0.318*"argument" + 0.246*"function" + 0.032*"readability" + 0.021*"value" + 0.019*"case" + 0.017*"end" + 0.011*"self" + 0.010*"section" + 0.008*"statement" + 0.007*"speed"
INFO: topic #2 (0.086): 0.034*"event" + 0.034*"hope" + 0.034*"work" + 0.028*"slash" + 0.026*"recap" + 0.021*"folder" + 0.020*"problem" + 0.019*"parent" + 0.018*"thing" + 0.018*"choice"
INFO: topic #3 (0.171): 0.168*"string" + 0.036*"\n" + 0.035*"character" + 0.031*"output" + 0.031*"way" + 0.030*"print" + 0.022*"sequence" + 0.020*"option" + 0.019*"length" + 0.019*"format"
INFO: topic #4 (0.196): 0.201*"parameter" + 0.068*"syntax" + 0.057*"pep" + 0.040*"name" + 0.024*"notation" + 0.024*"list" + 0.022*"example" + 0.022*"definition" + 0.021*"keyword" + 0.018*"proposal"
INFO: topic diff=0.292358, rho=0.233126
DEBUG: bound: at document #0
INFO: -7.444 per-word bound, 174.1 perplexity estimate based on a held-out corpus of 5 documents with 23 words
INFO: PROGRESS: pass 7, at document #20/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14393483, 0.13290888, 0.0825616, 0.16960195, 0.19204074]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.144): 0.070*"directory" + 0.070*"file" + 0.069*"path" + 0.064*"example" + 0.054*"code" + 0.041*"idea" + 0.039*"case" + 0.017*"os.path" + 0.017*"split" + 0.017*"point"
INFO: topic #1 (0.133): 0.294*"argument" + 0.227*"function" + 0.029*"readability" + 0.023*"self" + 0.020*"value" + 0.018*"case" + 0.016*"end" + 0.010*"section" + 0.008*"statement" + 0.007*"speed"
INFO: topic #2 (0.083): 0.031*"event" + 0.031*"hope" + 0.031*"work" + 0.026*"slash" + 0.024*"recap" + 0.019*"folder" + 0.018*"problem" + 0.018*"parent" + 0.016*"thing" + 0.016*"choice"
INFO: topic #3 (0.170): 0.146*"string" + 0.031*"\n" + 0.031*"separator" + 0.030*"character" + 0.029*"window" + 0.027*"output" + 0.027*"way" + 0.026*"print" + 0.020*"reference" + 0.019*"sequence"
INFO: topic #4 (0.192): 0.192*"parameter" + 0.065*"syntax" + 0.054*"pep" + 0.050*"name" + 0.023*"notation" + 0.023*"list" + 0.022*"example" + 0.021*"definition" + 0.020*"keyword" + 0.017*"proposal"
INFO: topic diff=0.158366, rho=0.233126
DEBUG: bound: at document #0
INFO: -5.607 per-word bound, 48.7 perplexity estimate based on a held-out corpus of 5 documents with 107 words
INFO: PROGRESS: pass 7, at document #25/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1471225, 0.1406309, 0.078565426, 0.1685108, 0.19909275]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.147): 0.071*"example" + 0.069*"code" + 0.058*"field" + 0.057*"directory" + 0.057*"file" + 0.055*"path" + 0.041*"case" + 0.033*"idea" + 0.020*"method" + 0.014*"os.path"
INFO: topic #1 (0.141): 0.244*"argument" + 0.195*"function" + 0.043*"value" + 0.030*"case" + 0.027*"default" + 0.027*"form" + 0.018*"future" + 0.015*"readability" + 0.013*"section" + 0.011*"self"
INFO: topic #2 (0.079): 0.028*"event" + 0.028*"hope" + 0.028*"work" + 0.023*"slash" + 0.022*"recap" + 0.018*"folder" + 0.017*"problem" + 0.017*"parent" + 0.015*"thing" + 0.015*"choice"
INFO: topic #3 (0.169): 0.132*"string" + 0.042*"separator" + 0.029*"\n" + 0.028*"character" + 0.026*"window" + 0.025*"output" + 0.024*"way" + 0.024*"print" + 0.019*"reference" + 0.017*"sequence"
INFO: topic #4 (0.199): 0.215*"parameter" + 0.059*"syntax" + 0.048*"name" + 0.040*"pep" + 0.038*"keyword" + 0.027*"example" + 0.025*"call" + 0.023*"notation" + 0.022*"documentation" + 0.017*"list"
INFO: topic diff=0.290550, rho=0.233126
DEBUG: bound: at document #0
INFO: -8.438 per-word bound, 346.9 perplexity estimate based on a held-out corpus of 5 documents with 20 words
INFO: PROGRESS: pass 7, at document #30/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.15326601, 0.13172008, 0.08006843, 0.17405763, 0.19050026]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.153): 0.074*"code" + 0.073*"path" + 0.064*"file" + 0.059*"example" + 0.048*"field" + 0.047*"directory" + 0.034*"case" + 0.027*"idea" + 0.019*"understanding" + 0.019*"snippet"
INFO: topic #1 (0.132): 0.232*"argument" + 0.185*"function" + 0.041*"value" + 0.028*"case" + 0.026*"default" + 0.026*"form" + 0.017*"future" + 0.014*"readability" + 0.013*"section" + 0.011*"self"
INFO: topic #2 (0.080): 0.038*"slash" + 0.033*"problem" + 0.033*"parent" + 0.030*"program" + 0.025*"cross" + 0.023*"lash" + 0.023*"path(__file__).resolve().parent" + 0.023*"throw" + 0.021*"event" + 0.021*"hope"
INFO: topic #3 (0.174): 0.127*"string" + 0.052*"window" + 0.036*"separator" + 0.036*"path" + 0.025*"\n" + 0.024*"character" + 0.021*"output" + 0.021*"way" + 0.020*"print" + 0.017*"strip"
INFO: topic #4 (0.191): 0.206*"parameter" + 0.057*"syntax" + 0.046*"name" + 0.038*"pep" + 0.036*"keyword" + 0.026*"example" + 0.024*"call" + 0.022*"notation" + 0.021*"documentation" + 0.016*"list"
INFO: topic diff=0.158360, rho=0.233126
DEBUG: bound: at document #0
INFO: -6.617 per-word bound, 98.1 perplexity estimate based on a held-out corpus of 5 documents with 72 words
INFO: PROGRESS: pass 7, at document #35/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.16395466, 0.11903232, 0.08335329, 0.19023907, 0.19603981]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.164): 0.106*"path" + 0.087*"component" + 0.060*"directory" + 0.050*"letter" + 0.050*"drive" + 0.039*"code" + 0.034*"file" + 0.031*"example" + 0.029*"note" + 0.026*"idea"
INFO: topic #1 (0.119): 0.218*"argument" + 0.174*"function" + 0.039*"value" + 0.027*"case" + 0.024*"default" + 0.024*"form" + 0.017*"future" + 0.013*"readability" + 0.012*"section" + 0.011*"self"
INFO: topic #2 (0.083): 0.068*"slash" + 0.044*"program" + 0.039*"cross" + 0.026*"problem" + 0.025*"parent" + 0.022*"os.path.dirname(__file" + 0.022*"ruin" + 0.022*"os.environ['home" + 0.018*"path(__file__).resolve().parent" + 0.018*"throw"
INFO: topic #3 (0.190): 0.115*"string" + 0.054*"path" + 0.050*"window" + 0.041*"list" + 0.025*"separator" + 0.024*"reference" + 0.019*"item" + 0.018*"join" + 0.017*"\n" + 0.017*"character"
INFO: topic #4 (0.196): 0.187*"parameter" + 0.049*"syntax" + 0.040*"name" + 0.034*"pep" + 0.032*"keyword" + 0.030*"c" + 0.025*"slash" + 0.022*"example" + 0.021*"call" + 0.021*"version"
INFO: topic diff=0.267571, rho=0.233126
DEBUG: bound: at document #0
INFO: -8.062 per-word bound, 267.3 perplexity estimate based on a held-out corpus of 5 documents with 28 words
INFO: PROGRESS: pass 7, at document #40/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.16885267, 0.12275089, 0.09192199, 0.1709714, 0.18451576]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.169): 0.097*"path" + 0.069*"component" + 0.063*"file" + 0.048*"directory" + 0.040*"letter" + 0.040*"drive" + 0.039*"application" + 0.037*"example" + 0.031*"code" + 0.023*"behaviour"
INFO: topic #1 (0.123): 0.207*"argument" + 0.169*"function" + 0.035*"value" + 0.024*"case" + 0.023*"behavior" + 0.022*"default" + 0.022*"form" + 0.015*"future" + 0.012*"readability" + 0.011*"section"
INFO: topic #2 (0.092): 0.066*"slash" + 0.059*"extension" + 0.031*"program" + 0.028*"cross" + 0.026*"folder" + 0.021*"new_sandbox" + 0.021*"foobar.jpg" + 0.021*"prevent" + 0.021*"append" + 0.021*"dot"
INFO: topic #3 (0.171): 0.106*"string" + 0.050*"path" + 0.046*"window" + 0.038*"list" + 0.024*"separator" + 0.023*"reference" + 0.018*"item" + 0.017*"join" + 0.016*"\n" + 0.016*"character"
INFO: topic #4 (0.185): 0.176*"parameter" + 0.048*"name" + 0.047*"syntax" + 0.032*"pep" + 0.030*"keyword" + 0.028*"c" + 0.024*"slash" + 0.021*"example" + 0.020*"call" + 0.020*"version"
INFO: topic diff=0.180558, rho=0.233126
DEBUG: bound: at document #0
INFO: -6.007 per-word bound, 64.3 perplexity estimate based on a held-out corpus of 5 documents with 46 words
INFO: PROGRESS: pass 7, at document #45/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17458096, 0.119767115, 0.08589156, 0.1719985, 0.18095407]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.175): 0.082*"path" + 0.080*"file" + 0.059*"component" + 0.054*"directory" + 0.036*"code" + 0.034*"letter" + 0.034*"drive" + 0.033*"application" + 0.031*"example" + 0.023*"root"
INFO: topic #1 (0.120): 0.222*"argument" + 0.152*"function" + 0.046*"case" + 0.040*"value" + 0.021*"self" + 0.019*"end" + 0.017*"behavior" + 0.016*"default" + 0.016*"form" + 0.016*"edit"
INFO: topic #2 (0.086): 0.059*"slash" + 0.054*"extension" + 0.028*"program" + 0.025*"cross" + 0.024*"folder" + 0.019*"new_sandbox" + 0.019*"foobar.jpg" + 0.019*"prevent" + 0.019*"append" + 0.019*"dot"
INFO: topic #3 (0.172): 0.129*"string" + 0.036*"sequence" + 0.034*"path" + 0.033*"escape" + 0.031*"window" + 0.031*"tabulation" + 0.030*"reference" + 0.026*"list" + 0.025*"character" + 0.024*"way"
INFO: topic #4 (0.181): 0.164*"parameter" + 0.042*"name" + 0.040*"syntax" + 0.037*"keyword" + 0.032*"slash" + 0.030*"example" + 0.028*"pep" + 0.026*"documentation" + 0.025*"mark" + 0.025*"c"
INFO: topic diff=0.182782, rho=0.233126
DEBUG: bound: at document #0
INFO: -5.212 per-word bound, 37.1 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 7, at document #50/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.18025653, 0.11575092, 0.080087714, 0.19015992, 0.17830248]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.180): 0.089*"example" + 0.066*"path" + 0.064*"file" + 0.047*"component" + 0.043*"directory" + 0.029*"code" + 0.027*"drive" + 0.027*"letter" + 0.027*"application" + 0.024*"case"
INFO: topic #1 (0.116): 0.221*"argument" + 0.194*"function" + 0.037*"case" + 0.032*"value" + 0.030*"end" + 0.017*"self" + 0.014*"behavior" + 0.013*"default" + 0.013*"form" + 0.013*"edit"
INFO: topic #2 (0.080): 0.052*"slash" + 0.047*"extension" + 0.025*"program" + 0.022*"cross" + 0.021*"folder" + 0.017*"new_sandbox" + 0.017*"foobar.jpg" + 0.017*"prevent" + 0.017*"append" + 0.017*"dot"
INFO: topic #3 (0.190): 0.173*"string" + 0.052*"sequence" + 0.047*"character" + 0.035*"tab" + 0.033*"escape" + 0.029*"length" + 0.028*"return" + 0.028*"space" + 0.023*"item" + 0.023*"reference"
INFO: topic #4 (0.178): 0.212*"parameter" + 0.048*"list" + 0.040*"slash" + 0.037*"name" + 0.036*"documentation" + 0.032*"example" + 0.027*"syntax" + 0.025*"keyword" + 0.022*"slash(/" + 0.018*"pep"
INFO: topic diff=0.283681, rho=0.233126
DEBUG: bound: at document #0
INFO: -4.866 per-word bound, 29.2 perplexity estimate based on a held-out corpus of 2 documents with 71 words
INFO: PROGRESS: pass 7, at document #52/52
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
INFO: optimized alpha [0.14433253, 0.13342142, 0.0727607, 0.15042791, 0.20825602]
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 52 documents
INFO: topic #0 (0.144): 0.082*"example" + 0.061*"path" + 0.059*"file" + 0.044*"component" + 0.040*"directory" + 0.027*"code" + 0.026*"drive" + 0.026*"letter" + 0.025*"application" + 0.022*"case"
INFO: topic #1 (0.133): 0.315*"function" + 0.246*"argument" + 0.048*"value" + 0.022*"case" + 0.018*"end" + 0.011*"self" + 0.009*"behavior" + 0.008*"default" + 0.008*"form" + 0.008*"companion"
INFO: topic #2 (0.073): 0.046*"slash" + 0.042*"extension" + 0.022*"program" + 0.020*"cross" + 0.019*"folder" + 0.015*"new_sandbox" + 0.015*"foobar.jpg" + 0.015*"prevent" + 0.015*"append" + 0.015*"dot"
INFO: topic #3 (0.150): 0.164*"string" + 0.049*"sequence" + 0.044*"character" + 0.034*"tab" + 0.032*"escape" + 0.028*"length" + 0.027*"return" + 0.027*"space" + 0.022*"item" + 0.022*"reference"
INFO: topic #4 (0.208): 0.192*"parameter" + 0.095*"syntax" + 0.060*"pep" + 0.038*"list" + 0.028*"help" + 0.025*"notation" + 0.024*"name" + 0.023*"implementation" + 0.022*"example" + 0.019*"keyword"
INFO: topic diff=0.350175, rho=0.233126
DEBUG: bound: at document #0
INFO: -6.705 per-word bound, 104.4 perplexity estimate based on a held-out corpus of 5 documents with 76 words
INFO: PROGRESS: pass 8, at document #5/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13449384, 0.13364856, 0.071835026, 0.1767585, 0.18763335]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.134): 0.074*"example" + 0.054*"path" + 0.053*"file" + 0.039*"component" + 0.036*"directory" + 0.030*"variable" + 0.024*"code" + 0.023*"drive" + 0.023*"letter" + 0.023*"application"
INFO: topic #1 (0.134): 0.259*"function" + 0.238*"argument" + 0.038*"value" + 0.026*"readability" + 0.020*"self" + 0.018*"case" + 0.015*"end" + 0.013*"statement" + 0.012*"change" + 0.012*"factor"
INFO: topic #2 (0.072): 0.046*"program" + 0.038*"slash" + 0.035*"extension" + 0.017*"cross" + 0.016*"folder" + 0.013*"new_sandbox" + 0.013*"foobar.jpg" + 0.013*"prevent" + 0.013*"issue" + 0.013*"bite"
INFO: topic #3 (0.177): 0.171*"string" + 0.037*"print" + 0.027*"sequence" + 0.026*"output" + 0.025*"\n" + 0.024*"character" + 0.024*"option" + 0.019*"way" + 0.018*"tab" + 0.018*"list"
INFO: topic #4 (0.188): 0.184*"parameter" + 0.091*"syntax" + 0.058*"pep" + 0.037*"list" + 0.033*"name" + 0.026*"help" + 0.024*"notation" + 0.023*"implementation" + 0.021*"example" + 0.019*"keyword"
INFO: topic diff=0.257621, rho=0.227038
DEBUG: bound: at document #0
INFO: -5.078 per-word bound, 33.8 perplexity estimate based on a held-out corpus of 5 documents with 193 words
INFO: PROGRESS: pass 8, at document #10/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1333188, 0.14691989, 0.07056868, 0.18280414, 0.19555229]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.133): 0.065*"idea" + 0.059*"example" + 0.047*"file" + 0.044*"code" + 0.040*"case" + 0.033*"path" + 0.026*"point" + 0.024*"component" + 0.023*"note" + 0.022*"field"
INFO: topic #1 (0.147): 0.335*"argument" + 0.260*"function" + 0.033*"readability" + 0.023*"value" + 0.020*"case" + 0.018*"end" + 0.012*"self" + 0.011*"section" + 0.008*"statement" + 0.008*"speed"
INFO: topic #2 (0.071): 0.055*"recap" + 0.032*"program" + 0.027*"win" + 0.027*"order" + 0.027*"document" + 0.027*"guidance" + 0.027*"heh" + 0.027*"question" + 0.027*"slash" + 0.024*"extension"
INFO: topic #3 (0.183): 0.179*"string" + 0.038*"\n" + 0.037*"character" + 0.032*"way" + 0.031*"print" + 0.023*"sequence" + 0.023*"output" + 0.021*"option" + 0.020*"length" + 0.020*"format"
INFO: topic #4 (0.196): 0.211*"parameter" + 0.071*"syntax" + 0.059*"pep" + 0.042*"name" + 0.025*"notation" + 0.025*"list" + 0.023*"example" + 0.023*"definition" + 0.022*"keyword" + 0.019*"proposal"
INFO: topic diff=0.377434, rho=0.227038
DEBUG: bound: at document #0
INFO: -8.307 per-word bound, 316.7 perplexity estimate based on a held-out corpus of 5 documents with 43 words
INFO: PROGRESS: pass 8, at document #15/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13521604, 0.13228732, 0.08486902, 0.16864249, 0.1906446]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.135): 0.071*"path" + 0.054*"idea" + 0.054*"file" + 0.051*"code" + 0.048*"example" + 0.033*"directory" + 0.033*"case" + 0.022*"point" + 0.021*"command" + 0.020*"component"
INFO: topic #1 (0.132): 0.318*"argument" + 0.247*"function" + 0.031*"readability" + 0.022*"value" + 0.019*"case" + 0.017*"end" + 0.012*"self" + 0.010*"section" + 0.008*"statement" + 0.007*"speed"
INFO: topic #2 (0.085): 0.034*"event" + 0.034*"hope" + 0.034*"work" + 0.028*"slash" + 0.026*"recap" + 0.021*"folder" + 0.019*"problem" + 0.019*"parent" + 0.017*"thing" + 0.017*"choice"
INFO: topic #3 (0.169): 0.168*"string" + 0.036*"\n" + 0.035*"character" + 0.031*"output" + 0.030*"way" + 0.030*"print" + 0.022*"sequence" + 0.020*"option" + 0.019*"length" + 0.019*"format"
INFO: topic #4 (0.191): 0.201*"parameter" + 0.068*"syntax" + 0.057*"pep" + 0.040*"name" + 0.024*"notation" + 0.024*"list" + 0.022*"example" + 0.022*"definition" + 0.021*"keyword" + 0.018*"proposal"
INFO: topic diff=0.282193, rho=0.227038
DEBUG: bound: at document #0
INFO: -7.421 per-word bound, 171.4 perplexity estimate based on a held-out corpus of 5 documents with 23 words
INFO: PROGRESS: pass 8, at document #20/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14270182, 0.131073, 0.08192368, 0.16747092, 0.18675412]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.143): 0.070*"file" + 0.070*"directory" + 0.069*"path" + 0.064*"example" + 0.053*"code" + 0.041*"idea" + 0.039*"case" + 0.017*"os.path" + 0.017*"split" + 0.017*"point"
INFO: topic #1 (0.131): 0.294*"argument" + 0.228*"function" + 0.029*"readability" + 0.023*"self" + 0.020*"value" + 0.019*"case" + 0.016*"end" + 0.010*"section" + 0.008*"statement" + 0.007*"speed"
INFO: topic #2 (0.082): 0.031*"event" + 0.031*"hope" + 0.031*"work" + 0.026*"slash" + 0.024*"recap" + 0.019*"folder" + 0.018*"problem" + 0.018*"parent" + 0.016*"thing" + 0.016*"choice"
INFO: topic #3 (0.167): 0.146*"string" + 0.031*"\n" + 0.031*"separator" + 0.030*"character" + 0.028*"window" + 0.027*"output" + 0.026*"way" + 0.026*"print" + 0.020*"reference" + 0.019*"sequence"
INFO: topic #4 (0.187): 0.192*"parameter" + 0.065*"syntax" + 0.054*"pep" + 0.050*"name" + 0.023*"notation" + 0.023*"list" + 0.022*"example" + 0.021*"definition" + 0.020*"keyword" + 0.017*"proposal"
INFO: topic diff=0.153472, rho=0.227038
DEBUG: bound: at document #0
INFO: -5.583 per-word bound, 47.9 perplexity estimate based on a held-out corpus of 5 documents with 107 words
INFO: PROGRESS: pass 8, at document #25/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14577349, 0.1384864, 0.078063264, 0.16649942, 0.19358207]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.146): 0.071*"example" + 0.068*"code" + 0.057*"file" + 0.057*"field" + 0.057*"directory" + 0.056*"path" + 0.040*"case" + 0.033*"idea" + 0.020*"method" + 0.014*"split"
INFO: topic #1 (0.138): 0.245*"argument" + 0.196*"function" + 0.043*"value" + 0.030*"case" + 0.027*"default" + 0.027*"form" + 0.018*"future" + 0.015*"readability" + 0.013*"section" + 0.012*"self"
INFO: topic #2 (0.078): 0.028*"event" + 0.028*"hope" + 0.028*"work" + 0.024*"slash" + 0.022*"recap" + 0.018*"folder" + 0.017*"problem" + 0.017*"parent" + 0.015*"thing" + 0.015*"choice"
INFO: topic #3 (0.166): 0.133*"string" + 0.041*"separator" + 0.029*"\n" + 0.028*"character" + 0.026*"window" + 0.025*"output" + 0.024*"way" + 0.024*"print" + 0.018*"reference" + 0.018*"sequence"
INFO: topic #4 (0.194): 0.215*"parameter" + 0.059*"syntax" + 0.048*"name" + 0.040*"pep" + 0.037*"keyword" + 0.026*"example" + 0.025*"call" + 0.023*"notation" + 0.022*"documentation" + 0.017*"list"
INFO: topic diff=0.279617, rho=0.227038
DEBUG: bound: at document #0
INFO: -8.411 per-word bound, 340.4 perplexity estimate based on a held-out corpus of 5 documents with 20 words
INFO: PROGRESS: pass 8, at document #30/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.15169774, 0.13000076, 0.07951095, 0.17185773, 0.18575875]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.152): 0.073*"code" + 0.073*"path" + 0.064*"file" + 0.059*"example" + 0.047*"field" + 0.047*"directory" + 0.033*"case" + 0.028*"idea" + 0.019*"snippet" + 0.019*"understanding"
INFO: topic #1 (0.130): 0.233*"argument" + 0.186*"function" + 0.041*"value" + 0.028*"case" + 0.026*"default" + 0.026*"form" + 0.017*"future" + 0.014*"readability" + 0.013*"section" + 0.011*"self"
INFO: topic #2 (0.080): 0.038*"slash" + 0.033*"problem" + 0.033*"parent" + 0.030*"program" + 0.024*"cross" + 0.022*"lash" + 0.022*"path(__file__).resolve().parent" + 0.022*"throw" + 0.021*"event" + 0.021*"hope"
INFO: topic #3 (0.172): 0.128*"string" + 0.051*"window" + 0.035*"separator" + 0.035*"path" + 0.025*"\n" + 0.024*"character" + 0.022*"output" + 0.021*"way" + 0.021*"print" + 0.016*"strip"
INFO: topic #4 (0.186): 0.206*"parameter" + 0.057*"syntax" + 0.046*"name" + 0.039*"pep" + 0.036*"keyword" + 0.026*"example" + 0.024*"call" + 0.022*"notation" + 0.021*"documentation" + 0.016*"list"
INFO: topic diff=0.152899, rho=0.227038
DEBUG: bound: at document #0
INFO: -6.581 per-word bound, 95.8 perplexity estimate based on a held-out corpus of 5 documents with 72 words
INFO: PROGRESS: pass 8, at document #35/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.16201064, 0.11788665, 0.08268896, 0.18749057, 0.19135128]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.162): 0.105*"path" + 0.085*"component" + 0.059*"directory" + 0.049*"letter" + 0.049*"drive" + 0.039*"code" + 0.034*"file" + 0.032*"example" + 0.028*"note" + 0.026*"idea"
INFO: topic #1 (0.118): 0.219*"argument" + 0.175*"function" + 0.039*"value" + 0.027*"case" + 0.024*"default" + 0.024*"form" + 0.016*"future" + 0.014*"readability" + 0.012*"section" + 0.011*"self"
INFO: topic #2 (0.083): 0.067*"slash" + 0.043*"program" + 0.039*"cross" + 0.025*"problem" + 0.025*"parent" + 0.022*"ruin" + 0.022*"os.environ['home" + 0.022*"os.path.dirname(__file" + 0.017*"lash" + 0.017*"path(__file__).resolve().parent"
INFO: topic #3 (0.187): 0.116*"string" + 0.053*"path" + 0.049*"window" + 0.040*"list" + 0.025*"separator" + 0.024*"reference" + 0.019*"item" + 0.018*"join" + 0.018*"\n" + 0.017*"character"
INFO: topic #4 (0.191): 0.188*"parameter" + 0.050*"syntax" + 0.040*"name" + 0.034*"pep" + 0.032*"keyword" + 0.029*"c" + 0.025*"slash" + 0.022*"example" + 0.021*"call" + 0.020*"version"
INFO: topic diff=0.258362, rho=0.227038
DEBUG: bound: at document #0
INFO: -8.017 per-word bound, 259.1 perplexity estimate based on a held-out corpus of 5 documents with 28 words
INFO: PROGRESS: pass 8, at document #40/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1667431, 0.12148567, 0.0909653, 0.16910619, 0.18068291]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.167): 0.096*"path" + 0.069*"component" + 0.063*"file" + 0.048*"directory" + 0.040*"letter" + 0.040*"drive" + 0.038*"application" + 0.037*"example" + 0.032*"code" + 0.023*"behaviour"
INFO: topic #1 (0.121): 0.209*"argument" + 0.170*"function" + 0.035*"value" + 0.024*"case" + 0.023*"behavior" + 0.022*"default" + 0.022*"form" + 0.015*"future" + 0.012*"readability" + 0.011*"section"
INFO: topic #2 (0.091): 0.065*"slash" + 0.058*"extension" + 0.030*"program" + 0.027*"cross" + 0.026*"folder" + 0.020*"new_sandbox" + 0.020*"foobar.jpg" + 0.020*"prevent" + 0.020*"append" + 0.020*"dot"
INFO: topic #3 (0.169): 0.108*"string" + 0.049*"path" + 0.045*"window" + 0.037*"list" + 0.024*"separator" + 0.023*"reference" + 0.017*"item" + 0.017*"join" + 0.017*"\n" + 0.016*"character"
INFO: topic #4 (0.181): 0.177*"parameter" + 0.048*"name" + 0.047*"syntax" + 0.032*"pep" + 0.030*"keyword" + 0.028*"c" + 0.024*"slash" + 0.021*"example" + 0.020*"call" + 0.019*"version"
INFO: topic diff=0.174779, rho=0.227038
DEBUG: bound: at document #0
INFO: -5.983 per-word bound, 63.2 perplexity estimate based on a held-out corpus of 5 documents with 46 words
INFO: PROGRESS: pass 8, at document #45/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17236212, 0.118628964, 0.08517573, 0.17012754, 0.17753437]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.172): 0.082*"path" + 0.079*"file" + 0.058*"component" + 0.054*"directory" + 0.036*"code" + 0.034*"letter" + 0.034*"drive" + 0.033*"application" + 0.032*"example" + 0.023*"root"
INFO: topic #1 (0.119): 0.223*"argument" + 0.153*"function" + 0.045*"case" + 0.040*"value" + 0.021*"self" + 0.019*"end" + 0.017*"behavior" + 0.016*"default" + 0.016*"form" + 0.015*"edit"
INFO: topic #2 (0.085): 0.059*"slash" + 0.053*"extension" + 0.028*"program" + 0.025*"cross" + 0.023*"folder" + 0.019*"new_sandbox" + 0.019*"foobar.jpg" + 0.019*"prevent" + 0.019*"append" + 0.019*"dot"
INFO: topic #3 (0.170): 0.129*"string" + 0.035*"sequence" + 0.034*"path" + 0.033*"escape" + 0.031*"window" + 0.030*"tabulation" + 0.029*"reference" + 0.026*"list" + 0.025*"character" + 0.024*"way"
INFO: topic #4 (0.178): 0.165*"parameter" + 0.042*"name" + 0.041*"syntax" + 0.037*"keyword" + 0.032*"slash" + 0.029*"example" + 0.028*"pep" + 0.026*"documentation" + 0.024*"c" + 0.024*"mark"
INFO: topic diff=0.175601, rho=0.227038
DEBUG: bound: at document #0
INFO: -5.191 per-word bound, 36.5 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 8, at document #50/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17796312, 0.114787556, 0.079588756, 0.187653, 0.17518951]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.178): 0.088*"example" + 0.066*"path" + 0.064*"file" + 0.047*"component" + 0.044*"directory" + 0.029*"code" + 0.028*"letter" + 0.028*"drive" + 0.027*"application" + 0.024*"case"
INFO: topic #1 (0.115): 0.221*"argument" + 0.194*"function" + 0.037*"case" + 0.032*"value" + 0.029*"end" + 0.017*"self" + 0.014*"behavior" + 0.013*"default" + 0.013*"form" + 0.012*"edit"
INFO: topic #2 (0.080): 0.052*"slash" + 0.047*"extension" + 0.025*"program" + 0.022*"cross" + 0.021*"folder" + 0.017*"new_sandbox" + 0.017*"foobar.jpg" + 0.017*"prevent" + 0.017*"append" + 0.017*"dot"
INFO: topic #3 (0.188): 0.173*"string" + 0.051*"sequence" + 0.046*"character" + 0.035*"tab" + 0.033*"escape" + 0.029*"length" + 0.028*"return" + 0.028*"space" + 0.023*"item" + 0.023*"reference"
INFO: topic #4 (0.175): 0.212*"parameter" + 0.047*"list" + 0.040*"slash" + 0.037*"name" + 0.036*"documentation" + 0.032*"example" + 0.028*"syntax" + 0.025*"keyword" + 0.022*"slash(/" + 0.019*"pep"
INFO: topic diff=0.273352, rho=0.227038
DEBUG: bound: at document #0
INFO: -4.836 per-word bound, 28.6 perplexity estimate based on a held-out corpus of 2 documents with 71 words
INFO: PROGRESS: pass 8, at document #52/52
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
INFO: optimized alpha [0.1436929, 0.1318724, 0.07251287, 0.14977111, 0.2039489]
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 52 documents
INFO: topic #0 (0.144): 0.082*"example" + 0.061*"path" + 0.059*"file" + 0.044*"component" + 0.040*"directory" + 0.027*"code" + 0.026*"letter" + 0.026*"drive" + 0.025*"application" + 0.022*"case"
INFO: topic #1 (0.132): 0.312*"function" + 0.246*"argument" + 0.047*"value" + 0.023*"case" + 0.018*"end" + 0.011*"self" + 0.009*"behavior" + 0.008*"default" + 0.008*"form" + 0.008*"companion"
INFO: topic #2 (0.073): 0.046*"slash" + 0.041*"extension" + 0.022*"program" + 0.020*"cross" + 0.019*"folder" + 0.015*"new_sandbox" + 0.015*"foobar.jpg" + 0.015*"prevent" + 0.015*"append" + 0.015*"dot"
INFO: topic #3 (0.150): 0.164*"string" + 0.049*"sequence" + 0.044*"character" + 0.033*"tab" + 0.031*"escape" + 0.028*"length" + 0.027*"return" + 0.027*"space" + 0.022*"item" + 0.022*"reference"
INFO: topic #4 (0.204): 0.192*"parameter" + 0.095*"syntax" + 0.060*"pep" + 0.038*"list" + 0.027*"help" + 0.025*"notation" + 0.024*"name" + 0.023*"implementation" + 0.022*"example" + 0.019*"keyword"
INFO: topic diff=0.339600, rho=0.227038
DEBUG: bound: at document #0
INFO: -6.659 per-word bound, 101.1 perplexity estimate based on a held-out corpus of 5 documents with 76 words
INFO: PROGRESS: pass 9, at document #5/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1341524, 0.13217816, 0.071612276, 0.17532995, 0.1845412]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.134): 0.073*"example" + 0.055*"path" + 0.053*"file" + 0.040*"component" + 0.036*"directory" + 0.029*"variable" + 0.025*"code" + 0.023*"drive" + 0.023*"letter" + 0.023*"application"
INFO: topic #1 (0.132): 0.258*"function" + 0.239*"argument" + 0.038*"value" + 0.026*"readability" + 0.020*"self" + 0.018*"case" + 0.015*"end" + 0.013*"statement" + 0.012*"change" + 0.012*"speed"
INFO: topic #2 (0.072): 0.046*"program" + 0.039*"slash" + 0.035*"extension" + 0.017*"cross" + 0.016*"folder" + 0.013*"new_sandbox" + 0.013*"foobar.jpg" + 0.013*"prevent" + 0.013*"issue" + 0.013*"bite"
INFO: topic #3 (0.175): 0.171*"string" + 0.036*"print" + 0.027*"sequence" + 0.026*"output" + 0.025*"\n" + 0.024*"character" + 0.024*"option" + 0.019*"tab" + 0.019*"list" + 0.019*"way"
INFO: topic #4 (0.185): 0.184*"parameter" + 0.091*"syntax" + 0.057*"pep" + 0.037*"list" + 0.033*"name" + 0.026*"help" + 0.024*"notation" + 0.022*"implementation" + 0.021*"example" + 0.019*"keyword"
INFO: topic diff=0.250048, rho=0.221404
DEBUG: bound: at document #0
INFO: -5.059 per-word bound, 33.3 perplexity estimate based on a held-out corpus of 5 documents with 193 words
INFO: PROGRESS: pass 9, at document #10/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13299008, 0.14503859, 0.070380636, 0.18127178, 0.19232818]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.133): 0.064*"idea" + 0.059*"example" + 0.047*"file" + 0.043*"code" + 0.039*"case" + 0.034*"path" + 0.026*"point" + 0.024*"component" + 0.023*"note" + 0.022*"directory"
INFO: topic #1 (0.145): 0.334*"argument" + 0.260*"function" + 0.033*"readability" + 0.023*"value" + 0.021*"case" + 0.018*"end" + 0.012*"self" + 0.011*"section" + 0.008*"statement" + 0.008*"speed"
INFO: topic #2 (0.070): 0.053*"recap" + 0.032*"program" + 0.027*"slash" + 0.027*"win" + 0.027*"order" + 0.027*"document" + 0.027*"guidance" + 0.027*"heh" + 0.027*"question" + 0.025*"extension"
INFO: topic #3 (0.181): 0.178*"string" + 0.037*"\n" + 0.037*"character" + 0.032*"way" + 0.031*"print" + 0.023*"sequence" + 0.023*"output" + 0.021*"option" + 0.020*"length" + 0.020*"format"
INFO: topic #4 (0.192): 0.210*"parameter" + 0.071*"syntax" + 0.059*"pep" + 0.041*"name" + 0.025*"notation" + 0.025*"list" + 0.023*"example" + 0.022*"definition" + 0.022*"keyword" + 0.018*"proposal"
INFO: topic diff=0.363860, rho=0.221404
DEBUG: bound: at document #0
INFO: -8.248 per-word bound, 303.9 perplexity estimate based on a held-out corpus of 5 documents with 43 words
INFO: PROGRESS: pass 9, at document #15/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13480873, 0.13107163, 0.08428263, 0.16765864, 0.18785866]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.135): 0.071*"path" + 0.054*"file" + 0.053*"idea" + 0.051*"code" + 0.049*"example" + 0.034*"directory" + 0.033*"case" + 0.022*"point" + 0.021*"command" + 0.020*"component"
INFO: topic #1 (0.131): 0.317*"argument" + 0.247*"function" + 0.031*"readability" + 0.022*"value" + 0.020*"case" + 0.017*"end" + 0.012*"self" + 0.010*"section" + 0.008*"statement" + 0.007*"speed"
INFO: topic #2 (0.084): 0.033*"event" + 0.033*"hope" + 0.033*"work" + 0.028*"slash" + 0.026*"recap" + 0.021*"folder" + 0.019*"problem" + 0.019*"parent" + 0.017*"thing" + 0.017*"choice"
INFO: topic #3 (0.168): 0.168*"string" + 0.035*"\n" + 0.035*"character" + 0.031*"output" + 0.030*"way" + 0.030*"print" + 0.022*"sequence" + 0.020*"option" + 0.019*"length" + 0.019*"format"
INFO: topic #4 (0.188): 0.201*"parameter" + 0.068*"syntax" + 0.057*"pep" + 0.040*"name" + 0.024*"notation" + 0.024*"list" + 0.022*"example" + 0.021*"definition" + 0.021*"keyword" + 0.018*"proposal"
INFO: topic diff=0.274044, rho=0.221404
DEBUG: bound: at document #0
INFO: -7.400 per-word bound, 168.9 perplexity estimate based on a held-out corpus of 5 documents with 23 words
INFO: PROGRESS: pass 9, at document #20/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14207344, 0.12993553, 0.081439294, 0.16653252, 0.18423474]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.142): 0.070*"file" + 0.069*"directory" + 0.069*"path" + 0.064*"example" + 0.053*"code" + 0.040*"idea" + 0.039*"case" + 0.017*"point" + 0.016*"os.path" + 0.016*"split"
INFO: topic #1 (0.130): 0.294*"argument" + 0.229*"function" + 0.029*"readability" + 0.023*"self" + 0.021*"value" + 0.019*"case" + 0.016*"end" + 0.010*"section" + 0.007*"statement" + 0.007*"speed"
INFO: topic #2 (0.081): 0.031*"event" + 0.031*"hope" + 0.031*"work" + 0.026*"slash" + 0.024*"recap" + 0.019*"folder" + 0.018*"problem" + 0.018*"parent" + 0.016*"thing" + 0.016*"choice"
INFO: topic #3 (0.167): 0.147*"string" + 0.031*"\n" + 0.030*"character" + 0.030*"separator" + 0.028*"window" + 0.027*"output" + 0.026*"way" + 0.026*"print" + 0.020*"reference" + 0.019*"sequence"
INFO: topic #4 (0.184): 0.192*"parameter" + 0.065*"syntax" + 0.054*"pep" + 0.049*"name" + 0.023*"notation" + 0.023*"list" + 0.022*"example" + 0.021*"definition" + 0.020*"keyword" + 0.017*"proposal"
INFO: topic diff=0.148946, rho=0.221404
DEBUG: bound: at document #0
INFO: -5.560 per-word bound, 47.2 perplexity estimate based on a held-out corpus of 5 documents with 107 words
INFO: PROGRESS: pass 9, at document #25/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14504863, 0.13710721, 0.07770417, 0.16561067, 0.19086549]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.145): 0.071*"example" + 0.068*"code" + 0.057*"file" + 0.056*"directory" + 0.056*"path" + 0.056*"field" + 0.040*"case" + 0.033*"idea" + 0.020*"method" + 0.014*"point"
INFO: topic #1 (0.137): 0.246*"argument" + 0.197*"function" + 0.043*"value" + 0.030*"case" + 0.026*"default" + 0.026*"form" + 0.018*"future" + 0.015*"readability" + 0.013*"section" + 0.012*"self"
INFO: topic #2 (0.078): 0.028*"event" + 0.028*"hope" + 0.028*"work" + 0.024*"slash" + 0.022*"recap" + 0.018*"folder" + 0.017*"problem" + 0.017*"parent" + 0.015*"thing" + 0.015*"choice"
INFO: topic #3 (0.166): 0.134*"string" + 0.041*"separator" + 0.029*"\n" + 0.028*"character" + 0.026*"window" + 0.025*"output" + 0.024*"way" + 0.024*"print" + 0.018*"reference" + 0.018*"sequence"
INFO: topic #4 (0.191): 0.214*"parameter" + 0.059*"syntax" + 0.048*"name" + 0.041*"pep" + 0.037*"keyword" + 0.026*"example" + 0.025*"call" + 0.023*"notation" + 0.022*"documentation" + 0.017*"list"
INFO: topic diff=0.269782, rho=0.221404
DEBUG: bound: at document #0
INFO: -8.386 per-word bound, 334.6 perplexity estimate based on a held-out corpus of 5 documents with 20 words
INFO: PROGRESS: pass 9, at document #30/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1507958, 0.12895946, 0.07910852, 0.17080759, 0.18348981]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.151): 0.073*"code" + 0.073*"path" + 0.064*"file" + 0.059*"example" + 0.047*"directory" + 0.047*"field" + 0.033*"case" + 0.028*"idea" + 0.019*"snippet" + 0.019*"understanding"
INFO: topic #1 (0.129): 0.234*"argument" + 0.187*"function" + 0.041*"value" + 0.028*"case" + 0.025*"default" + 0.025*"form" + 0.017*"future" + 0.014*"readability" + 0.013*"section" + 0.011*"self"
INFO: topic #2 (0.079): 0.038*"slash" + 0.032*"problem" + 0.032*"parent" + 0.030*"program" + 0.024*"cross" + 0.022*"lash" + 0.022*"path(__file__).resolve().parent" + 0.022*"throw" + 0.021*"event" + 0.021*"hope"
INFO: topic #3 (0.171): 0.129*"string" + 0.050*"window" + 0.035*"separator" + 0.034*"path" + 0.025*"\n" + 0.024*"character" + 0.022*"output" + 0.021*"way" + 0.021*"print" + 0.016*"strip"
INFO: topic #4 (0.183): 0.206*"parameter" + 0.057*"syntax" + 0.046*"name" + 0.039*"pep" + 0.036*"keyword" + 0.025*"example" + 0.024*"call" + 0.022*"notation" + 0.021*"documentation" + 0.017*"list"
INFO: topic diff=0.148176, rho=0.221404
DEBUG: bound: at document #0
INFO: -6.549 per-word bound, 93.7 perplexity estimate based on a held-out corpus of 5 documents with 72 words
INFO: PROGRESS: pass 9, at document #35/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.16080151, 0.117293514, 0.082197815, 0.18598373, 0.18901345]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.161): 0.105*"path" + 0.084*"component" + 0.059*"directory" + 0.049*"letter" + 0.049*"drive" + 0.040*"code" + 0.035*"file" + 0.032*"example" + 0.028*"note" + 0.026*"idea"
INFO: topic #1 (0.117): 0.220*"argument" + 0.177*"function" + 0.039*"value" + 0.027*"case" + 0.024*"default" + 0.024*"form" + 0.016*"future" + 0.014*"readability" + 0.012*"section" + 0.011*"self"
INFO: topic #2 (0.082): 0.066*"slash" + 0.043*"program" + 0.038*"cross" + 0.025*"problem" + 0.025*"parent" + 0.022*"ruin" + 0.022*"os.environ['home" + 0.022*"os.path.dirname(__file" + 0.017*"lash" + 0.017*"path(__file__).resolve().parent"
INFO: topic #3 (0.186): 0.117*"string" + 0.052*"path" + 0.048*"window" + 0.040*"list" + 0.025*"separator" + 0.024*"reference" + 0.018*"item" + 0.018*"\n" + 0.018*"join" + 0.018*"character"
INFO: topic #4 (0.189): 0.188*"parameter" + 0.050*"syntax" + 0.041*"name" + 0.035*"pep" + 0.031*"keyword" + 0.028*"c" + 0.025*"slash" + 0.023*"example" + 0.021*"call" + 0.020*"version"
INFO: topic diff=0.250067, rho=0.221404
DEBUG: bound: at document #0
INFO: -7.977 per-word bound, 251.9 perplexity estimate based on a held-out corpus of 5 documents with 28 words
INFO: PROGRESS: pass 9, at document #40/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.16539574, 0.12078702, 0.09022307, 0.16825156, 0.17885487]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.165): 0.096*"path" + 0.068*"component" + 0.063*"file" + 0.048*"directory" + 0.039*"letter" + 0.039*"drive" + 0.038*"application" + 0.038*"example" + 0.032*"code" + 0.023*"note"
INFO: topic #1 (0.121): 0.210*"argument" + 0.171*"function" + 0.035*"value" + 0.024*"case" + 0.022*"behavior" + 0.022*"default" + 0.022*"form" + 0.015*"future" + 0.013*"readability" + 0.011*"section"
INFO: topic #2 (0.090): 0.064*"slash" + 0.057*"extension" + 0.030*"program" + 0.027*"cross" + 0.025*"folder" + 0.020*"new_sandbox" + 0.020*"foobar.jpg" + 0.020*"prevent" + 0.020*"append" + 0.020*"dot"
INFO: topic #3 (0.168): 0.109*"string" + 0.048*"path" + 0.045*"window" + 0.037*"list" + 0.024*"separator" + 0.022*"reference" + 0.017*"item" + 0.017*"\n" + 0.017*"join" + 0.017*"character"
INFO: topic #4 (0.179): 0.178*"parameter" + 0.048*"syntax" + 0.048*"name" + 0.033*"pep" + 0.030*"keyword" + 0.027*"c" + 0.024*"slash" + 0.021*"example" + 0.020*"call" + 0.019*"version"
INFO: topic diff=0.169639, rho=0.221404
DEBUG: bound: at document #0
INFO: -5.961 per-word bound, 62.3 perplexity estimate based on a held-out corpus of 5 documents with 46 words
INFO: PROGRESS: pass 9, at document #45/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17090091, 0.11802738, 0.08464804, 0.16924506, 0.17592339]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.171): 0.082*"path" + 0.079*"file" + 0.058*"component" + 0.054*"directory" + 0.037*"code" + 0.034*"letter" + 0.034*"drive" + 0.032*"application" + 0.032*"example" + 0.023*"root"
INFO: topic #1 (0.118): 0.224*"argument" + 0.155*"function" + 0.045*"case" + 0.040*"value" + 0.021*"self" + 0.019*"end" + 0.017*"behavior" + 0.017*"default" + 0.016*"form" + 0.015*"companion"
INFO: topic #2 (0.085): 0.058*"slash" + 0.052*"extension" + 0.028*"program" + 0.025*"cross" + 0.023*"folder" + 0.019*"new_sandbox" + 0.018*"foobar.jpg" + 0.018*"prevent" + 0.018*"append" + 0.018*"dot"
INFO: topic #3 (0.169): 0.129*"string" + 0.035*"sequence" + 0.034*"path" + 0.032*"escape" + 0.031*"window" + 0.030*"tabulation" + 0.029*"reference" + 0.026*"list" + 0.025*"character" + 0.024*"way"
INFO: topic #4 (0.176): 0.167*"parameter" + 0.042*"syntax" + 0.042*"name" + 0.037*"keyword" + 0.031*"slash" + 0.029*"example" + 0.029*"pep" + 0.026*"documentation" + 0.024*"c" + 0.024*"mark"
INFO: topic diff=0.169216, rho=0.221404
DEBUG: bound: at document #0
INFO: -5.171 per-word bound, 36.0 perplexity estimate based on a held-out corpus of 5 documents with 106 words
INFO: PROGRESS: pass 9, at document #50/52
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1764293, 0.1143154, 0.07925156, 0.18624194, 0.17371812]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 52 documents
INFO: topic #0 (0.176): 0.087*"example" + 0.067*"path" + 0.064*"file" + 0.047*"component" + 0.044*"directory" + 0.030*"code" + 0.028*"letter" + 0.028*"drive" + 0.027*"application" + 0.024*"case"
INFO: topic #1 (0.114): 0.222*"argument" + 0.194*"function" + 0.036*"case" + 0.032*"value" + 0.029*"end" + 0.017*"self" + 0.014*"behavior" + 0.014*"default" + 0.014*"form" + 0.012*"companion"
INFO: topic #2 (0.079): 0.052*"slash" + 0.046*"extension" + 0.025*"program" + 0.022*"cross" + 0.021*"folder" + 0.017*"new_sandbox" + 0.017*"foobar.jpg" + 0.017*"prevent" + 0.017*"append" + 0.017*"dot"
INFO: topic #3 (0.186): 0.172*"string" + 0.051*"sequence" + 0.046*"character" + 0.035*"tab" + 0.033*"escape" + 0.029*"length" + 0.028*"return" + 0.028*"space" + 0.023*"item" + 0.023*"reference"
INFO: topic #4 (0.174): 0.211*"parameter" + 0.047*"list" + 0.039*"slash" + 0.037*"name" + 0.035*"documentation" + 0.032*"example" + 0.029*"syntax" + 0.025*"keyword" + 0.021*"slash(/" + 0.020*"pep"
INFO: topic diff=0.263886, rho=0.221404
DEBUG: bound: at document #0
INFO: -4.809 per-word bound, 28.0 perplexity estimate based on a held-out corpus of 2 documents with 71 words
INFO: PROGRESS: pass 9, at document #52/52
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
INFO: optimized alpha [0.14350298, 0.13091841, 0.07239682, 0.14975925, 0.2015768]
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 52 documents
INFO: topic #0 (0.144): 0.081*"example" + 0.062*"path" + 0.059*"file" + 0.044*"component" + 0.041*"directory" + 0.028*"code" + 0.026*"letter" + 0.026*"drive" + 0.025*"application" + 0.022*"case"
INFO: topic #1 (0.131): 0.310*"function" + 0.246*"argument" + 0.047*"value" + 0.023*"case" + 0.018*"end" + 0.011*"self" + 0.009*"behavior" + 0.009*"default" + 0.009*"form" + 0.008*"companion"
INFO: topic #2 (0.072): 0.046*"slash" + 0.041*"extension" + 0.022*"program" + 0.020*"cross" + 0.019*"folder" + 0.015*"new_sandbox" + 0.015*"foobar.jpg" + 0.015*"prevent" + 0.015*"append" + 0.015*"dot"
INFO: topic #3 (0.150): 0.164*"string" + 0.048*"sequence" + 0.044*"character" + 0.033*"tab" + 0.031*"escape" + 0.027*"length" + 0.026*"return" + 0.026*"space" + 0.022*"item" + 0.022*"reference"
INFO: topic #4 (0.202): 0.192*"parameter" + 0.094*"syntax" + 0.059*"pep" + 0.038*"list" + 0.027*"help" + 0.025*"notation" + 0.024*"name" + 0.023*"implementation" + 0.022*"example" + 0.020*"keyword"
INFO: topic diff=0.329858, rho=0.221404
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=258, num_topics=5, decay=0.5, chunksize=5> in 0.26s', 'datetime': '2023-05-09T14:38:31.010766', 'gensim': '4.3.1', 'python': '3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}
INFO: {'id': 63490955, 'content': 'There are three kinds of parameters in Python: When defining a function, a / is used to separate positional-only parameters (at least one) on the left and the rest on the right. If there is no / in the parameter list, there are no positional-only parameters. The syntax originated in the argument clinic, which is used to define functions for the CPython implementation. Its use appeared in help for such functions before it was added to the syntax of Python itself in PEP-570.', 'score': 0.7467572303736217}
INFO: {'id': 56514307, 'content': "The / as syntax was introduced in Python 3.8. The rationale for / in an argument list is given in PEP 570 -- Python Positional-Only Parameters: The new syntax will enable library authors to further control how their API can be called. It will allow designating which parameters must be called as positional-only, while preventing them from being called as keyword arguments. Previously, (informational) PEP 457 defined the syntax, but with a much more vague scope. This PEP takes the original proposal a step further by justifying the syntax and providing an implementation for the / syntax in function definitions. Similarities For all intents and purposes, if you understand help()'s / notation, then that's what is formally included as Python syntax in v3.8 via PEP 570. Differences PEP 570 -- Python Positional-Only Parameters PEP 457 -- Notation For Positional-Only Parameters There are already excellent answers on the meaning and usage of / in arguments. To save you the click through: A / means that all preceding parameters are positional-only parameters. Positional-only parameters before a / cannot be passed as name=value when calling the function. Python 3.8 What's New gives the following example: Valid function calls: Invalid function calls:", 'score': 0.7457630195273672}
INFO: {'id': 63490944, 'content': 'From Python documentation about help() : Note that if a slash(/) appears in the parameter list of a function, when invoking help(), it means that the parameters prior to the slash are positional-only. and from the FAQ entry on positional-only parameters : What does the slash(/) in the parameter list of a function mean? A slash in the argument list of a function denotes that the parameters prior to it are positional-only. Positional-only parameters are the ones without an externally-usable name. Upon calling a function that accepts positional-only parameters, arguments are mapped to parameters based solely on their position. For example, divmod() is a function that accepts positional-only parameters. Its documentation looks like this: The slash at the end of the parameter list means that both parameters are positional-only. Thus, calling divmod() with keyword arguments would lead to an error:', 'score': 0.7446534652609677}
INFO: {'id': 59661122, 'content': "As mentioned in the docs, the slash is for positional-only arguments, as the docs says: There is a new function parameter syntax / to indicate that some function parameters must be specified positionally and cannot be used as keyword arguments. This is the same notation shown by help() for C functions annotated with Larry Hastings Argument Clinic tool. And for the asterisk, it's mentioned here in the docs: For a parameter with a default value, the corresponding argument may be omitted from a call, in which case the parameters default value is substituted. If a parameter has a default value, all following parameters up until the * must also have a default value X this is a syntactic restriction that is not expressed by the grammar. So the ways to call this would be: And:", 'score': 0.7186319174864695}
INFO: {'id': 24735582, 'content': 'It signifies the end of the positional only parameters, parameters you cannot use as keyword parameters. Before Python 3.8, such parameters could only be specified in the C API. It means the key argument to __contains__ can only be passed in by position (range(5).__contains__(3)), not as a keyword argument (range(5).__contains__(key=3)), something you can do with positional arguments in pure-python functions. Also see the Argument Clinic documentation: To mark all parameters as positional-only in Argument Clinic, add a / on a line by itself after the last parameter, indented the same as the parameter lines. and the (very recent addition to) the Python FAQ: A slash in the argument list of a function denotes that the parameters prior to it are positional-only. Positional-only parameters are the ones without an externally-usable name. Upon calling a function that accepts positional-only parameters, arguments are mapped to parameters based solely on their position. The syntax is now part of the Python language specification, as of version 3.8, see PEP 570 V Python Positional-Only Parameters. Before PEP 570, the syntax was already reserved for possible future inclusion in Python, see PEP 457 - Syntax For Positional-Only Parameters.  Positional-only parameters can lead to cleaner and clearer APIs, make pure-Python implementations of otherwise C-only modules more consistent and easier to maintain, and because positional-only parameters require very little processing, they lead to faster Python code.', 'score': 0.7049440660601496}
INFO: {'id': 49961041, 'content': 'Try combo of split("/") and * for strings with existing joins.  How it works... split("/") turns existing path into list: [\'\', \'home\', \'build\', \'test\', \'sandboxes\', \'\'] * in front of the list breaks out each item of list its own parameter ', 'score': 0.7045593408276654}
INFO: {'id': 59642921, 'content': 'Forward Slash (/) indicates all arguments prior to it are positional only argument. Positional only arguments feature was added in python 3.8 after PEP 570 was accepted. Initially this notation was defined in PEP 457 - Notation for Notation For Positional-Only Parameters Parameters in function definition prior Foraward slash (/) are positional only and parameters followed by slash(/) can be of any kind as per syntax. Where arguments are mapped to positional only parameters solely based on their position upon calling a function. Passing positional-only parameters by keywords(name) is invalid. Let\'s take following example Here in the above function definition parameters a and b are positional-only, while x or y can be either positional or keyword. Following function calls are valid But, following function call is not valid which raises an exception TypeError since a, b are not passed as positional arguments instead passed as keyword TypeError: foo() got some positional-only arguments passed as keyword\narguments: \'a, b\' Many built in function in python accept positional only arguments where passing arguments by keyword doesn\'t make sense. For example built-in function len accepts only one positional(only) argument, Where calling len as len(obj="hello world")  impairs readability, check help(len). Positional only parameters make underlying c/library functions easy to maintain. It allows parameters names of positional only parameters to be changes in future without risk of breaking client code that uses API Last but not least, positional only parameters allow us to use their names to be used in variable length keyword arguments. Check following example Positional-only parameters syntax was officially added to python3.8. Checkout what\'s new python3.8 - positional only arguments PEP Related: PEP 570 -- Python Positional-Only Parameters', 'score': 0.6871968055023997}
INFO: {'id': 59661137, 'content': 'There is a new function parameter syntax / to indicate that some function parameters must be specified positionally and cannot be used as keyword arguments.[This is new in Python 3.8] Documentation specifies some of the use cases/benefits of positional-only parameters. It allows pure Python functions to fully emulate behaviors of\nexisting C coded functions. For example, the built-in pow()\nfunction does not accept keyword arguments: Another use case is to preclude keyword arguments when the parameter\nname is not helpful. For example, the builtin len() function has\nthe signature len(obj, /). This precludes awkward calls such as: A further benefit of marking a parameter as positional-only is that\nit allows the parameter name to be changed in the future without\nrisk of breaking client code. For example, in the statistics module,\nthe parameter name dist may be changed in the future. This was made\npossible with the following function specification: Where as * is used to force the caller to use named arguments. Django documentation contains a section which clearly explains a  usecase of named arguments. Form fields no longer accept optional arguments as positional\narguments To help prevent runtime errors due to incorrect ordering of\nform field arguments, optional arguments of built-in form fields are\nno longer accepted as positional arguments. For example: forms.IntegerField(25, 10) raises an exception and should be replaced\nwith: forms.IntegerField(max_value=25, min_value=10) Suppose we have a method called func, It must called with or ie, DEMO:', 'score': 0.685709860221925}
INFO: {'id': 44780467, 'content': 'You can\'t. Backslashes cannot appear inside the curly braces {}; doing so results in a SyntaxError:  This is specified in the PEP for f-strings: Backslashes may not appear inside the expression portions of f-strings, [...] One option is assinging \'\\n\' to a name and then .join on that inside the f-string; that is, without using a literal: Results in: Another option, as specified by @wim, is to use chr(10) to get \\n returned and then join there. f"Winners are:\\n{chr(10).join(names)}" Yet another, of course, is to \'\\n\'.join beforehand and then add the name accordingly: which results in the same output. This is one of the small differences between f-strings and str.format. In the latter, you can always use punctuation granted that a corresponding wacky dict is unpacked that contains those keys: (Please don\'t do this.) In the former, punctuation isn\'t allowed because you can\'t have identifiers that use them. Aside: I would definitely opt for print or format, as the other answers suggest as an alternative. The options I\'ve given only apply if you must for some reason use f-strings.  Just because something is new, doesn\'t mean you should try and do everything with it ;-)', 'score': 0.6794913623917471}
INFO: {'id': 44781006, 'content': "The other answers give ideas for how to put the newline character into a f-string field. However, I would argue that for the example the OP gave (which may or may not be indicative of OP's actual use case), none of these ideas should actually be used.  The entire point of using f-strings is increasing code readability. There is nothing you can do with f-strings that you cannot do with format. Consider carefully whether there is anything more readable about this (if you could do it):  ...or this: ...or this: vs. this:  The last way is at least as readable, if not more so.  In short: don't use a hammer when you need a screwdriver just because you have a shiny new one. Code is read much more often than it is written.  For other use cases, yes, it's possible the chr(10) idea or newline idea may be appropriate. But not for the one given. ", 'score': 0.6631029431358587}
INFO: {'id': 47363488, 'content': "As it wasn't mentioned in any answers, just in case you want to align and space your text, you can use the string format features. (above python 2.5) Of course \\t is actually a TAB token whereas the described method generates spaces. Example: Another Example, left aligned:", 'score': 0.6624765581963844}
INFO: {'id': 28243933, 'content': "As explained here, the / as an argument marks the end of arguments that are positional only (see here), i.e. arguments you can't use as keyword parameters. In the case of __eq__(self, value, /) the slash is at the end, which means that all arguments are marked as positional only while in the case of your __init__ only self, i.e. nothing, is positional only. Edit:\nThis was previously only used for built-in functions but since Python 3.8, you can use this in your own functions. The natural companion of / is * which allows to mark the beginning of keyword-only arguments. Example using both:\xa0", 'score': 0.6563589054743266}
INFO: {'id': 74845836, 'content': "You have this error because you use discord's client and not discord.ext's. Next up, slash won't be used (variable and event). Replace to this event: After this is done, update the Command Tree and it should appear no problem on Discord. Link here: https://discordpy.readthedocs.io/en/stable/interactions/api.html#commandtree Hope it helped. :D EDIT: try this, It's your code but I modified it (if it works well for me, it will work well for you): main.py: Now it should appear up to an hour after sync. Hope this helps more.\n(Little precision: if you use Pycord, the code will be different)", 'score': 0.654173933259666}
INFO: {'id': 44780840, 'content': "You don't need f-strings or other formatters to print a list of strings with a separator. Just use the sep keyword argument to print(): Output: That said, using str.join()/str.format() here would arguably be simpler and more readable than any f-string workaround:", 'score': 0.653531038037273}
INFO: {'id': 43390891, 'content': 'The Python reference manual includes several string literals that can be used in a string. These special sequences of characters are replaced by the intended meaning of the escape sequence.  Here is a table of some of the more useful escape sequences and a description of the output from them. Basic Example If i wanted to print some data points separated by a tab space I could print this string. Returns Example for Lists Here is another example where we are printing the items of list and we want to sperate the items by a TAB. Returns Raw Strings  Note that raw strings (a string which include a prefix "r"), string literals will be ignored. This allows these special sequences of characters to be included in strings without being changed. Returns Which maybe an undesired output String Lengths It should also be noted that string literals are only one character in length. Returns The raw string has a length of 9.', 'score': 0.6528897505377088}
INFO: {'id': 37556617, 'content': 'Note that a similar issue can bite you if you use os.path.join() to include an extension that already includes a dot, which is what happens automatically when you use os.path.splitext(). In this example: Even though extension might be .jpg you end up with a folder named "foobar" rather than a file called "foobar.jpg". To prevent this you need to append the extension separately:', 'score': 0.6523194098919298}
INFO: {'id': 62445955, 'content': 'Here are some more exotic Python 3 ways to get "hello" TAB "alex" (tested with Python 3.6.10): "hello\\N{TAB}alex" "hello\\N{tab}alex" "hello\\N{TaB}alex" "hello\\N{HT}alex" "hello\\N{CHARACTER TABULATION}alex" "hello\\N{HORIZONTAL TABULATION}alex" "hello\\x09alex" "hello\\u0009alex" "hello\\U00000009alex" Actually, instead of using an escape sequence, it is possible to insert tab symbol directly into the string literal. Here is the code with a tabulation character to copy and try: "hello alex" If the tab in the string above won\'t be lost anywhere during copying the string then "print(repr(< string from above >)" should print \'hello\\talex\'. See respective Python documentation for reference.', 'score': 0.6510651914205735}
INFO: {'id': 24296743, 'content': "To help understand why this surprising behavior isn't entirely terrible, consider an application which accepts a config file name as an argument: If the application is executed with: The config file /etc/myapp.conf/foo.conf will be used. But consider what happens if the application is called with: Then myapp should use the config file at /some/path/bar.conf (and not /etc/myapp.conf/some/path/bar.conf or similar). It may not be great, but I believe this is the motivation for the absolute path behaviour.", 'score': 0.6493080546214229}
INFO: {'id': 56212520, 'content': 'I asked this question myself. :) Found out that / was originally proposed by Guido in here. Alternative proposal: how about using \'/\' ? It\'s kind of the opposite\n  of \'*\' which means "keyword argument", and \'/\' is not a new character. Then his proposal won. Heh. If that\'s true, my \'/\' proposal wins: I think the very relevant document covering this is PEP 570.\nWhere recap section looks nice. Recap The use case will determine which parameters to use in the function definition: As guidance: Use positional-only if names do not matter or have no meaning, and there are only a few arguments which will always be passed in the same order.\n     Use keyword-only when names have meaning and the function definition is more understandable by being explicit with names. If the function ends with / This means all functional arguments are positional. ', 'score': 0.6485402602165715}
INFO: {'id': 44781133, 'content': "You can't use backslashes in f-strings as others have said, but you could step around this using os.linesep (although note this won't be \\n on all platforms, and is not recommended unless reading/writing binary files; see Rick's comments): Or perhaps in a less readable way, but guaranteed to be \\n, with chr():", 'score': 0.6454831858992759}
INFO: {'id': 69762290, 'content': "If (and only if!) readability is the top priority, and speed is truly not a factor, f-strings are very useful to make a simple function self documenting even if there are simpler ways to program it. Readability is maximized with f-strings when: (1) the statements that change the argument's state are clearly obvious, and (2) when the arguments are printed, the print statement is carefully formatted, and visually presented to make the arguments stand out: output:", 'score': 0.6417839061172648}
INFO: {'id': 1945930, 'content': 'The latter strings shouldn\'t start with a slash. If they start with a slash, then they\'re considered an "absolute path" and everything before them is discarded. Quoting the Python docs for os.path.join: If a component is an absolute path, all previous components are thrown away and joining continues from the absolute path component. Note on Windows, the behaviour in relation to drive letters, which seems to have changed compared to earlier Python versions: On Windows, the drive letter is not reset when an absolute path component (e.g., r\'\\foo\') is encountered. If a component contains a drive letter, all previous components are thrown away and the drive letter is reset. Note that since there is a current directory for each drive, os.path.join("c:", "foo") represents a path relative to the current directory on drive C: (c:foo), not c:\\foo.', 'score': 0.6361999020751771}
INFO: {'id': 74229426, 'content': 'Please refer following code snippet for understanding os.path.join(a, b) OR But, when OR', 'score': 0.6136252375008905}
INFO: {'id': 67751005, 'content': "If someone is looking for something like this: He/she wants to know the parent directory and then go to the sub-folders and maybe than to a specific file. If so, I use the following approach. path = os.path.pardir + os.sep + 'utils' + os.sep + 'properties.ini' print(f'The path to my global properties file is :: {path}') Output: ..\\utils\\properties.ini You can surely look at the whole documentation here : https://docs.python.org/3/library/os.html", 'score': 0.6119359946798087}
INFO: {'id': 16011123, 'content': "Don't build directory and file names your self, use python's included libraries.  In this case the relevant one is os.path. Especially join which creates a new pathname from a directory and a file name or directory and split that gets the filename from a full path. Your example would be ", 'score': 0.6061601161594938}
INFO: {'id': 68678495, 'content': 'The above statement will raise SyntaxError,\nBut to avoid the error, you can simply assign the string containing \\n to a variable and use it in f-string.', 'score': 0.5933281158743238}
INFO: {'id': 4488586, 'content': "It's usually \\t in command-line interfaces, which will convert the char \\t into the whitespace tab character. For example, hello\\talex -> hello--->alex.", 'score': 0.5904214517014125}
INFO: {'id': 73478978, 'content': 'OUTDATED Discord.py is no more updated. If you want to use a more recent version of the discord module, you have to install pycord https://guide.pycord.dev/installation To do this, first you have to uninstall the discord.py module using:\npip uninstall discord.py\nAnd then install pycord using:\npip install py-cord Your script will work like that:', 'score': 0.5892086589631541}
INFO: {'id': 1945935, 'content': 'Do not use forward slashes at the beginning of path components, except when refering to the root directory: see also: http://docs.python.org/library/os.path.html#os.path.join', 'score': 0.5855290193336553}
INFO: {'id': 1948595, 'content': "The idea of os.path.join() is to make your program cross-platform (linux/windows/etc). Even one slash ruins it. So it only makes sense when being used with some kind of a reference point like\nos.environ['HOME'] or os.path.dirname(__file__).", 'score': 0.5686945002785517}
INFO: {'id': 69469685, 'content': "The problem is your laptop maybe running Window. And Window annoyingly use back lash instead of forward slash'/'. To make your program cross-platform (linux/windows/etc).\nYou shouldn't provide any slashes (forward or backward) in your path if you want os.path.join to handle them properly. you should using: Or throw some Path(__file__).resolve().parent (path to parent of current file) or anything so that you don't use any slash inside os.path.join", 'score': 0.567626849219508}
INFO: {'id': 16011098, 'content': 'Use os.path.join().\nExample: os.path.join(pathfile,"output","log.txt"). In your code that would be: rootTree.write(os.path.join(pathfile,"output","log.txt"))', 'score': 0.5555650575455772}
INFO: {'id': 25559273, 'content': 'To make your function more portable, use it as such: or', 'score': 0.5512581139536912}
INFO: {'id': 65945746, 'content': 'Assume I have a variable named file that contains a file.\nThen I could use file.write("hello\\talex").', 'score': 0.5424752898646209}
INFO: {'id': 4488596, 'content': 'This is the code: The \\t inside the string is the escape sequence for the horizontal tabulation.', 'score': 0.5309646855647121}
INFO: {'id': 38923690, 'content': 'os.path.normpath(pathname) should also be mentioned as it converts / path separators into \\ separators on Windows. It also collapses redundant uplevel references... i.e., A/B and A/foo/../B and A/./B all become A/B.  And if you are Windows, these all become A\\B.', 'score': 0.5277656821915879}
INFO: {'id': 1945939, 'content': "It's because your '/new_sandbox/' begins with a / and thus is assumed to be relative to the root directory. Remove the leading /.", 'score': 0.5222999183722673}
INFO: {'id': 16011083, 'content': 'Use: to see how separator looks on a current OS.\nIn your code you can use:', 'score': 0.49945144214129283}
INFO: {'id': 14962135, 'content': 'os.path.join() can be used in conjunction with os.path.sep to create an absolute rather than relative path.', 'score': 0.4780050130793132}
INFO: {'id': 67585662, 'content': "I use pathlib for most things, so I like: pathlib.os.sep. Usually pathlib is the better choice if you don't need os!", 'score': 0.47517094706999685}
INFO: {'id': 4488585, 'content': 'You can use \\t in a string literal: "hello\\talex"', 'score': 0.4612066728750249}
INFO: {'id': 60416293, 'content': "I'd recommend to strip from the second and the following strings the string os.path.sep, preventing them to be interpreted as absolute paths:", 'score': 0.45768667589132683}
INFO: {'id': 16011039, 'content': 'Some useful links that will help you:', 'score': 0.4186470593086519}
INFO: {'id': 75404785, 'content': 'And remember not to use this strange way that also works:', 'score': 0.4067320969849613}
INFO: {'id': 57826848, 'content': 'a fuller version:', 'score': 0.33156694080398996}
INFO: {'id': 1946192, 'content': 'do it like this, without too the extra slashes', 'score': 0.09083652597805952}
INFO: {'id': 44189631, 'content': 'If you are fortunate enough to be running Python 3.4+, you can use pathlib: or, equivalently,', 'score': 0.0}
INFO: {'id': 50522959, 'content': 'You can use "os.sep "', 'score': 0.0}
INFO: {'id': 16011057, 'content': 'You can use os.sep:', 'score': 0.0}
INFO: {'id': 16011031, 'content': 'Do a import os and then use os.sep', 'score': 0.0}
INFO: {'id': 58588281, 'content': "you can strip the '/':", 'score': 0.0}
INFO: {'id': 1945936, 'content': 'Try with new_sandbox only', 'score': 0.0}
