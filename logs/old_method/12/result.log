INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<385 unique tokens: ['debugging', 'drawback', 'foo', 'method', 'name']...> from 78 documents (total 1533 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<385 unique tokens: ['debugging', 'drawback', 'foo', 'method', 'name']...> from 78 documents (total 1533 corpus positions)", 'datetime': '2023-05-09T14:37:44.187750', 'gensim': '4.3.1', 'python': '3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 5 topics, 10 passes over the supplied corpus of 78 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.137 per-word bound, 140.7 perplexity estimate based on a held-out corpus of 5 documents with 130 words
INFO: PROGRESS: pass 0, at document #5/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14589277, 0.18685071, 0.12898922, 0.07236567, 0.072524235]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.146): 0.137*"name" + 0.095*"function" + 0.074*"object" + 0.053*"code" + 0.053*"value" + 0.053*"thing" + 0.042*"memory" + 0.042*"language" + 0.032*"information" + 0.032*"variable"
INFO: topic #1 (0.187): 0.144*"list" + 0.143*"string" + 0.115*"variable" + 0.058*"name" + 0.029*"way" + 0.029*"function" + 0.029*"pandas" + 0.029*"builtin" + 0.029*"dataframe" + 0.029*"comment"
INFO: topic #2 (0.129): 0.134*"word" + 0.068*"name" + 0.068*"string" + 0.068*"debugging" + 0.068*"order" + 0.068*"foo" + 0.068*"snippet" + 0.068*"method" + 0.068*"drawback" + 0.001*"note"
INFO: topic #3 (0.072): 0.003*"string" + 0.003*"name" + 0.003*"return" + 0.003*"note" + 0.003*"kwargs" + 0.003*"word" + 0.003*"list" + 0.003*"variable" + 0.003*"function" + 0.003*"method"
INFO: topic #4 (0.073): 0.003*"string" + 0.003*"name" + 0.003*"word" + 0.003*"note" + 0.003*"variable" + 0.003*"list" + 0.003*"return" + 0.003*"kwargs" + 0.003*"drawback" + 0.003*"function"
INFO: topic diff=4.292840, rho=1.000000
DEBUG: bound: at document #0
INFO: -8.520 per-word bound, 367.0 perplexity estimate based on a held-out corpus of 5 documents with 191 words
INFO: PROGRESS: pass 0, at document #10/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.16722633, 0.14931113, 0.1448586, 0.09414549, 0.08002109]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.167): 0.136*"name" + 0.126*"function" + 0.090*"code" + 0.079*"value" + 0.071*"variable" + 0.042*"source" + 0.036*"information" + 0.032*"object" + 0.031*"case" + 0.027*"access"
INFO: topic #1 (0.149): 0.154*"list" + 0.132*"variable" + 0.096*"string" + 0.054*"note" + 0.050*"name" + 0.030*"function" + 0.016*"way" + 0.016*"pandas" + 0.016*"builtin" + 0.016*"dataframe"
INFO: topic #2 (0.145): 0.169*"foo" + 0.120*"name" + 0.093*"method" + 0.085*"word" + 0.024*"string" + 0.017*"debugging" + 0.017*"order" + 0.017*"snippet" + 0.017*"drawback" + 0.011*"scope"
INFO: topic #3 (0.094): 0.085*"frame" + 0.059*"varname" + 0.042*"need" + 0.042*"environment" + 0.042*"assignment" + 0.034*"package" + 0.034*"example" + 0.034*"scenario" + 0.026*"runtime" + 0.026*"wrapper"
INFO: topic #4 (0.080): 0.080*"answer" + 0.070*"scope" + 0.045*"version" + 0.045*"idilip" + 0.036*"frame" + 0.036*"person" + 0.036*"var" + 0.036*"stack" + 0.036*"retrieve_name" + 0.036*"bit"
INFO: topic diff=1.436593, rho=0.707107
DEBUG: bound: at document #0
INFO: -7.660 per-word bound, 202.2 perplexity estimate based on a held-out corpus of 5 documents with 45 words
INFO: PROGRESS: pass 0, at document #15/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.21100482, 0.15139389, 0.1039303, 0.098075725, 0.077624686]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.211): 0.142*"name" + 0.133*"value" + 0.085*"variable" + 0.081*"function" + 0.057*"code" + 0.035*"object" + 0.034*"case" + 0.031*"access" + 0.027*"source" + 0.024*"local"
INFO: topic #1 (0.151): 0.167*"variable" + 0.063*"string" + 0.059*"list" + 0.056*"input" + 0.056*"content" + 0.047*"name" + 0.035*"way" + 0.035*"return" + 0.028*"match" + 0.028*"none"
INFO: topic #2 (0.104): 0.124*"foo" + 0.089*"name" + 0.069*"method" + 0.063*"word" + 0.018*"string" + 0.013*"debugging" + 0.013*"order" + 0.013*"snippet" + 0.013*"drawback" + 0.009*"scope"
INFO: topic #3 (0.098): 0.076*"frame" + 0.053*"varname" + 0.038*"environment" + 0.038*"need" + 0.038*"assignment" + 0.037*"wrapper" + 0.037*"class" + 0.031*"scenario" + 0.031*"package" + 0.031*"example"
INFO: topic #4 (0.078): 0.086*"scope" + 0.067*"bit" + 0.045*"answer" + 0.026*"version" + 0.026*"idilip" + 0.021*"frame" + 0.021*"stack" + 0.021*"global" + 0.021*"example" + 0.021*"initialization"
INFO: topic diff=0.526754, rho=0.577350
DEBUG: bound: at document #0
INFO: -6.517 per-word bound, 91.6 perplexity estimate based on a held-out corpus of 5 documents with 37 words
INFO: PROGRESS: pass 0, at document #20/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.25536275, 0.17474012, 0.10080691, 0.09459458, 0.101827465]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.255): 0.162*"name" + 0.143*"value" + 0.101*"function" + 0.083*"variable" + 0.040*"code" + 0.025*"datum" + 0.024*"object" + 0.024*"case" + 0.022*"access" + 0.019*"source"
INFO: topic #1 (0.175): 0.160*"variable" + 0.095*"return" + 0.085*"list" + 0.074*"name" + 0.035*"string" + 0.032*"index" + 0.031*"input" + 0.031*"content" + 0.019*"module" + 0.019*"way"
INFO: topic #2 (0.101): 0.149*"method" + 0.074*"name" + 0.072*"foo" + 0.037*"word" + 0.024*"frame" + 0.013*"scope" + 0.011*"string" + 0.008*"debugging" + 0.008*"order" + 0.008*"snippet"
INFO: topic #3 (0.095): 0.066*"frame" + 0.046*"varname" + 0.033*"assignment" + 0.033*"need" + 0.033*"environment" + 0.032*"wrapper" + 0.032*"class" + 0.029*"work" + 0.027*"example" + 0.027*"scenario"
INFO: topic #4 (0.102): 0.104*"answer" + 0.076*"scope" + 0.049*"global" + 0.049*"var" + 0.034*"frame" + 0.033*"bit" + 0.030*"variation" + 0.030*"result" + 0.020*"index" + 0.013*"idilip"
INFO: topic diff=0.306110, rho=0.500000
DEBUG: bound: at document #0
INFO: -7.476 per-word bound, 178.0 perplexity estimate based on a held-out corpus of 5 documents with 69 words
INFO: PROGRESS: pass 0, at document #25/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.3320531, 0.17740817, 0.09931502, 0.120606184, 0.10905532]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.332): 0.173*"function" + 0.115*"name" + 0.091*"value" + 0.079*"variable" + 0.042*"object" + 0.038*"local" + 0.036*"code" + 0.019*"memory" + 0.018*"point" + 0.016*"location"
INFO: topic #1 (0.177): 0.131*"variable" + 0.078*"return" + 0.059*"string" + 0.049*"list" + 0.043*"name" + 0.036*"way" + 0.027*"function" + 0.027*"define" + 0.026*"write" + 0.019*"index"
INFO: topic #2 (0.099): 0.075*"method" + 0.048*"debugging" + 0.037*"name" + 0.036*"foo" + 0.028*"procedure" + 0.028*"type" + 0.019*"word" + 0.015*"string" + 0.015*"goal" + 0.015*"report"
INFO: topic #3 (0.121): 0.074*"example" + 0.065*"call" + 0.039*"need" + 0.039*"class" + 0.037*"frame" + 0.037*"work" + 0.028*"retrieve" + 0.026*"varname" + 0.024*"print" + 0.024*"effort"
INFO: topic #4 (0.109): 0.106*"var" + 0.066*"global" + 0.061*"answer" + 0.045*"scope" + 0.045*"inspect" + 0.033*"idea" + 0.033*"process" + 0.020*"frame" + 0.020*"bit" + 0.018*"variation"
INFO: topic diff=0.379311, rho=0.447214
DEBUG: bound: at document #0
INFO: -7.122 per-word bound, 139.3 perplexity estimate based on a held-out corpus of 5 documents with 89 words
INFO: PROGRESS: pass 0, at document #30/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.38708666, 0.19953418, 0.09727681, 0.14953762, 0.11595921]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.387): 0.139*"name" + 0.133*"function" + 0.092*"code" + 0.072*"variable" + 0.055*"value" + 0.052*"object" + 0.048*"source" + 0.029*"local" + 0.011*"mapping" + 0.011*"approach"
INFO: topic #1 (0.200): 0.080*"variable" + 0.080*"list" + 0.062*"name" + 0.060*"string" + 0.058*"module" + 0.038*"return" + 0.036*"way" + 0.023*"match" + 0.022*"reference" + 0.022*"namespace"
INFO: topic #2 (0.097): 0.051*"method" + 0.034*"constructor" + 0.034*"kind" + 0.034*"sorcery" + 0.033*"debugging" + 0.026*"name" + 0.025*"foo" + 0.020*"type" + 0.020*"procedure" + 0.013*"word"
INFO: topic #3 (0.150): 0.083*"example" + 0.063*"class" + 0.040*"call" + 0.037*"retrieve" + 0.029*"package" + 0.024*"need" + 0.023*"frame" + 0.023*"work" + 0.022*"course" + 0.022*"magic"
INFO: topic #4 (0.116): 0.077*"stack" + 0.077*"global" + 0.066*"var" + 0.038*"answer" + 0.028*"scope" + 0.028*"inspect" + 0.021*"python3" + 0.021*"process" + 0.021*"idea" + 0.013*"frame"
INFO: topic diff=0.469538, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.717 per-word bound, 52.6 perplexity estimate based on a held-out corpus of 5 documents with 114 words
INFO: PROGRESS: pass 0, at document #35/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.46769184, 0.22803089, 0.08822674, 0.16905302, 0.1031736]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.468): 0.229*"name" + 0.131*"object" + 0.104*"function" + 0.047*"variable" + 0.044*"code" + 0.041*"value" + 0.029*"local" + 0.023*"source" + 0.018*"reference" + 0.011*"program"
INFO: topic #1 (0.228): 0.141*"list" + 0.088*"name" + 0.069*"way" + 0.062*"string" + 0.042*"variable" + 0.040*"module" + 0.033*"namespace" + 0.031*"return" + 0.019*"define" + 0.018*"function"
INFO: topic #2 (0.088): 0.039*"method" + 0.026*"kind" + 0.026*"constructor" + 0.026*"sorcery" + 0.025*"debugging" + 0.020*"name" + 0.020*"foo" + 0.015*"type" + 0.015*"procedure" + 0.011*"word"
INFO: topic #3 (0.169): 0.098*"class" + 0.091*"example" + 0.032*"course" + 0.027*"assignment" + 0.026*"call" + 0.024*"retrieve" + 0.023*"instance" + 0.023*"kind" + 0.019*"package" + 0.019*"comprehension"
INFO: topic #4 (0.103): 0.061*"stack" + 0.061*"global" + 0.053*"var" + 0.031*"answer" + 0.023*"scope" + 0.023*"inspect" + 0.017*"python3" + 0.017*"idea" + 0.017*"process" + 0.011*"frame"
INFO: topic diff=0.476134, rho=0.377964
DEBUG: bound: at document #0
INFO: -8.063 per-word bound, 267.5 perplexity estimate based on a held-out corpus of 5 documents with 32 words
INFO: PROGRESS: pass 0, at document #40/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.44549534, 0.22249122, 0.094822824, 0.1744386, 0.118843794]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.445): 0.207*"name" + 0.127*"function" + 0.122*"object" + 0.040*"variable" + 0.038*"code" + 0.036*"value" + 0.028*"case" + 0.025*"local" + 0.020*"source" + 0.016*"reference"
INFO: topic #1 (0.222): 0.122*"list" + 0.076*"name" + 0.065*"module" + 0.060*"way" + 0.054*"string" + 0.037*"variable" + 0.029*"namespace" + 0.027*"return" + 0.017*"note" + 0.017*"define"
INFO: topic #2 (0.095): 0.058*"foo" + 0.047*"word" + 0.031*"loop" + 0.025*"method" + 0.017*"kind" + 0.017*"constructor" + 0.017*"sorcery" + 0.016*"globals().item" + 0.016*"each_item" + 0.016*"filter"
INFO: topic #3 (0.174): 0.117*"class" + 0.071*"example" + 0.046*"course" + 0.033*"work" + 0.024*"type" + 0.021*"assignment" + 0.021*"call" + 0.019*"retrieve" + 0.018*"instance" + 0.018*"kind"
INFO: topic #4 (0.119): 0.083*"answer" + 0.066*"global" + 0.039*"loop" + 0.037*"result" + 0.033*"stack" + 0.028*"var" + 0.028*"ex" + 0.028*"performance" + 0.020*"each_item" + 0.020*"filter"
INFO: topic diff=0.300484, rho=0.353553
DEBUG: bound: at document #0
INFO: -6.611 per-word bound, 97.8 perplexity estimate based on a held-out corpus of 5 documents with 133 words
INFO: PROGRESS: pass 0, at document #45/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.554987, 0.24293418, 0.107878506, 0.18749374, 0.12428932]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.555): 0.218*"name" + 0.144*"function" + 0.121*"object" + 0.058*"value" + 0.027*"variable" + 0.024*"attribute" + 0.021*"case" + 0.019*"code" + 0.017*"reference" + 0.017*"question"
INFO: topic #1 (0.243): 0.080*"list" + 0.075*"string" + 0.073*"name" + 0.047*"module" + 0.045*"way" + 0.043*"match" + 0.034*"note" + 0.027*"content" + 0.027*"return" + 0.026*"none"
INFO: topic #2 (0.108): 0.042*"method" + 0.037*"debugging" + 0.029*"order" + 0.028*"foo" + 0.023*"word" + 0.022*"story" + 0.022*"other" + 0.017*"fun" + 0.017*"page" + 0.017*"long"
INFO: topic #3 (0.187): 0.080*"class" + 0.071*"course" + 0.068*"example" + 0.032*"instance" + 0.027*"magic" + 0.026*"print" + 0.023*"work" + 0.018*"=" + 0.018*"frame" + 0.017*"type"
INFO: topic #4 (0.124): 0.072*"global" + 0.053*"answer" + 0.051*"stack" + 0.050*"result" + 0.025*"loop" + 0.019*"var" + 0.018*"performance" + 0.018*"ex" + 0.013*"filter" + 0.013*"each_item"
INFO: topic diff=0.675419, rho=0.333333
DEBUG: bound: at document #0
INFO: -6.270 per-word bound, 77.2 perplexity estimate based on a held-out corpus of 5 documents with 67 words
INFO: PROGRESS: pass 0, at document #50/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.659702, 0.28562677, 0.10725847, 0.19232595, 0.140239]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.660): 0.223*"name" + 0.159*"function" + 0.097*"object" + 0.050*"value" + 0.032*"variable" + 0.032*"attribute" + 0.021*"code" + 0.016*"local" + 0.016*"case" + 0.015*"argument"
INFO: topic #1 (0.286): 0.078*"string" + 0.070*"name" + 0.058*"module" + 0.058*"way" + 0.057*"list" + 0.044*"match" + 0.037*"note" + 0.032*"return" + 0.022*"function" + 0.020*"content"
INFO: topic #2 (0.107): 0.066*"method" + 0.030*"debugging" + 0.023*"order" + 0.022*"foo" + 0.018*"word" + 0.018*"story" + 0.018*"other" + 0.014*"fun" + 0.014*"guess" + 0.014*"basestring"
INFO: topic #3 (0.192): 0.122*"class" + 0.070*"example" + 0.053*"course" + 0.027*"need" + 0.024*"instance" + 0.020*"magic" + 0.019*"print" + 0.017*"work" + 0.014*"cmd" + 0.013*"="
INFO: topic #4 (0.140): 0.126*"global" + 0.061*"answer" + 0.033*"stack" + 0.032*"result" + 0.019*"contain" + 0.019*"bla" + 0.019*"my_list" + 0.017*"loop" + 0.015*"item" + 0.015*"cmd"
INFO: topic diff=0.293244, rho=0.316228
DEBUG: bound: at document #0
INFO: -6.782 per-word bound, 110.0 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 0, at document #55/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7437408, 0.3203322, 0.114740536, 0.21432857, 0.15661602]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.744): 0.212*"name" + 0.128*"object" + 0.125*"function" + 0.051*"value" + 0.031*"variable" + 0.030*"code" + 0.026*"case" + 0.024*"attribute" + 0.016*"reference" + 0.014*"search"
INFO: topic #1 (0.320): 0.063*"string" + 0.062*"match" + 0.062*"name" + 0.060*"way" + 0.060*"list" + 0.047*"module" + 0.044*"note" + 0.038*"return" + 0.018*"function" + 0.017*"search"
INFO: topic #2 (0.115): 0.109*"method" + 0.021*"debugging" + 0.016*"order" + 0.016*"foo" + 0.015*"track" + 0.013*"word" + 0.013*"story" + 0.013*"other" + 0.012*"goal" + 0.011*"player"
INFO: topic #3 (0.214): 0.136*"class" + 0.063*"instance" + 0.057*"example" + 0.044*"print" + 0.034*"environment" + 0.031*"course" + 0.023*"player" + 0.023*"iterator" + 0.023*"track" + 0.016*"property"
INFO: topic #4 (0.157): 0.115*"global" + 0.069*"answer" + 0.037*"loop" + 0.028*"scope" + 0.024*"stack" + 0.023*"result" + 0.014*"player" + 0.014*"atribute" + 0.014*"contain" + 0.014*"my_list"
INFO: topic diff=0.351189, rho=0.301511
DEBUG: bound: at document #0
INFO: -7.394 per-word bound, 168.2 perplexity estimate based on a held-out corpus of 5 documents with 183 words
INFO: PROGRESS: pass 0, at document #60/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.8112717, 0.30779102, 0.12853755, 0.24870525, 0.16004024]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.811): 0.188*"name" + 0.150*"object" + 0.110*"function" + 0.048*"code" + 0.034*"value" + 0.028*"source" + 0.022*"variable" + 0.020*"case" + 0.013*"attribute" + 0.013*"solution"
INFO: topic #1 (0.308): 0.082*"way" + 0.066*"string" + 0.057*"note" + 0.056*"list" + 0.051*"name" + 0.046*"module" + 0.044*"match" + 0.027*"return" + 0.022*"caller" + 0.017*"function"
INFO: topic #2 (0.129): 0.097*"method" + 0.026*"debugging" + 0.018*"loop" + 0.017*"constructor" + 0.016*"initialization" + 0.014*"frame" + 0.013*"production" + 0.013*"assignent" + 0.013*"rethink" + 0.013*"refactor"
INFO: topic #3 (0.249): 0.084*"class" + 0.047*"example" + 0.040*"instance" + 0.035*"frame" + 0.034*"call" + 0.029*"file" + 0.025*"work" + 0.024*"assignment" + 0.023*"=" + 0.023*"retrieve"
INFO: topic #4 (0.160): 0.076*"global" + 0.046*"answer" + 0.042*"scope" + 0.039*"stack" + 0.025*"inspect" + 0.025*"loop" + 0.018*"determine" + 0.018*"dimension" + 0.018*"lifetime" + 0.018*"self"
INFO: topic diff=0.909665, rho=0.288675
DEBUG: bound: at document #0
INFO: -6.822 per-word bound, 113.2 perplexity estimate based on a held-out corpus of 5 documents with 164 words
INFO: PROGRESS: pass 0, at document #65/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.9375157, 0.33244222, 0.13265845, 0.28052238, 0.16619448]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.938): 0.179*"name" + 0.161*"object" + 0.086*"function" + 0.050*"value" + 0.039*"variable" + 0.037*"code" + 0.027*"reference" + 0.017*"source" + 0.016*"attribute" + 0.016*"case"
INFO: topic #1 (0.332): 0.092*"way" + 0.060*"string" + 0.055*"list" + 0.045*"note" + 0.044*"name" + 0.043*"namespace" + 0.028*"module" + 0.027*"match" + 0.024*"reference" + 0.023*"integer"
INFO: topic #2 (0.133): 0.100*"method" + 0.022*"debugging" + 0.020*"parameter" + 0.015*"loop" + 0.014*"constructor" + 0.013*"initialization" + 0.013*"https://stackoverflow.com/a/49331683/7386061" + 0.012*"frame" + 0.011*"assignent" + 0.011*"production"
INFO: topic #3 (0.281): 0.101*"class" + 0.064*"example" + 0.039*"instance" + 0.037*"assignment" + 0.034*"print" + 0.028*"work" + 0.025*"frame" + 0.025*"call" + 0.021*"file" + 0.017*"="
INFO: topic #4 (0.166): 0.081*"var" + 0.049*"global" + 0.047*"scope" + 0.030*"answer" + 0.026*"design" + 0.025*"stack" + 0.017*"choice" + 0.017*"hash" + 0.016*"inspect" + 0.016*"loop"
INFO: topic diff=0.651044, rho=0.277350
DEBUG: bound: at document #0
INFO: -6.562 per-word bound, 94.5 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 0, at document #70/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.99683595, 0.348185, 0.1416264, 0.31666946, 0.15656447]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.997): 0.166*"object" + 0.166*"name" + 0.073*"function" + 0.051*"code" + 0.047*"value" + 0.036*"reference" + 0.034*"variable" + 0.018*"case" + 0.015*"solution" + 0.015*"source"
INFO: topic #1 (0.348): 0.086*"way" + 0.060*"string" + 0.045*"list" + 0.038*"name" + 0.037*"note" + 0.035*"namespace" + 0.034*"module" + 0.033*"reference" + 0.025*"return" + 0.024*"garbage"
INFO: topic #2 (0.142): 0.103*"method" + 0.039*"debugging" + 0.017*"parameter" + 0.013*"loop" + 0.012*"constructor" + 0.012*"version" + 0.011*"initialization" + 0.011*"https://stackoverflow.com/a/49331683/7386061" + 0.010*"frame" + 0.010*"situation"
INFO: topic #3 (0.317): 0.192*"class" + 0.062*"instance" + 0.052*"example" + 0.025*"assignment" + 0.023*"print" + 0.020*"retrieve" + 0.019*"work" + 0.017*"frame" + 0.017*"call" + 0.015*"type"
INFO: topic #4 (0.157): 0.072*"var" + 0.044*"global" + 0.042*"scope" + 0.027*"answer" + 0.023*"design" + 0.023*"stack" + 0.016*"choice" + 0.016*"hash" + 0.015*"inspect" + 0.015*"loop"
INFO: topic diff=0.332490, rho=0.267261
DEBUG: bound: at document #0
INFO: -6.428 per-word bound, 86.1 perplexity estimate based on a held-out corpus of 5 documents with 112 words
INFO: PROGRESS: pass 0, at document #75/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.1148058, 0.3886736, 0.13855866, 0.38457912, 0.1705254]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.115): 0.166*"object" + 0.164*"name" + 0.068*"function" + 0.047*"code" + 0.047*"variable" + 0.036*"reference" + 0.036*"value" + 0.023*"case" + 0.016*"source" + 0.012*"access"
INFO: topic #1 (0.389): 0.083*"way" + 0.056*"module" + 0.056*"namespace" + 0.053*"list" + 0.043*"string" + 0.038*"garbage" + 0.037*"note" + 0.032*"name" + 0.024*"reference" + 0.018*"return"
INFO: topic #2 (0.139): 0.088*"method" + 0.056*"debugging" + 0.015*"parameter" + 0.011*"loop" + 0.010*"constructor" + 0.010*"version" + 0.010*"initialization" + 0.009*"https://stackoverflow.com/a/49331683/7386061" + 0.009*"frame" + 0.009*"situation"
INFO: topic #3 (0.385): 0.150*"class" + 0.147*"instance" + 0.044*"example" + 0.041*"type" + 0.024*"print" + 0.019*"track" + 0.018*"assignment" + 0.014*"retrieve" + 0.014*"c" + 0.014*"work"
INFO: topic #4 (0.171): 0.055*"global" + 0.054*"var" + 0.042*"answer" + 0.041*"filter" + 0.031*"scope" + 0.018*"design" + 0.017*"stack" + 0.012*"hash" + 0.012*"choice" + 0.011*"inspect"
INFO: topic diff=0.416162, rho=0.258199
DEBUG: bound: at document #0
INFO: -6.984 per-word bound, 126.6 perplexity estimate based on a held-out corpus of 3 documents with 21 words
INFO: PROGRESS: pass 0, at document #78/78
DEBUG: performing inference on a chunk of 3 documents
DEBUG: 3/3 documents converged within 2000 iterations
INFO: optimized alpha [1.2087566, 0.38305154, 0.13270701, 0.46339828, 0.161906]
DEBUG: updating topics
INFO: merging changes from 3 documents into a model of 78 documents
INFO: topic #0 (1.209): 0.162*"name" + 0.156*"object" + 0.077*"function" + 0.051*"code" + 0.041*"variable" + 0.032*"reference" + 0.031*"value" + 0.020*"case" + 0.018*"attribute" + 0.015*"thing"
INFO: topic #1 (0.383): 0.096*"way" + 0.051*"module" + 0.051*"namespace" + 0.049*"list" + 0.039*"string" + 0.034*"garbage" + 0.034*"note" + 0.031*"name" + 0.022*"reference" + 0.016*"return"
INFO: topic #2 (0.133): 0.077*"method" + 0.050*"debugging" + 0.013*"parameter" + 0.010*"loop" + 0.009*"constructor" + 0.009*"version" + 0.009*"initialization" + 0.008*"https://stackoverflow.com/a/49331683/7386061" + 0.008*"frame" + 0.008*"situation"
INFO: topic #3 (0.463): 0.152*"class" + 0.136*"instance" + 0.049*"print" + 0.037*"example" + 0.034*"type" + 0.031*"part" + 0.016*"track" + 0.015*"assignment" + 0.012*"retrieve" + 0.011*"c"
INFO: topic #4 (0.162): 0.049*"global" + 0.048*"var" + 0.037*"answer" + 0.036*"filter" + 0.028*"scope" + 0.016*"design" + 0.015*"stack" + 0.011*"choice" + 0.011*"hash" + 0.010*"inspect"
INFO: topic diff=0.200044, rho=0.250000
DEBUG: bound: at document #0
INFO: -5.588 per-word bound, 48.1 perplexity estimate based on a held-out corpus of 5 documents with 130 words
INFO: PROGRESS: pass 1, at document #5/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.011164, 0.39725032, 0.1301091, 0.35491818, 0.14614084]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.011): 0.159*"name" + 0.123*"object" + 0.085*"function" + 0.051*"code" + 0.044*"variable" + 0.039*"value" + 0.029*"thing" + 0.023*"attribute" + 0.020*"case" + 0.020*"language"
INFO: topic #1 (0.397): 0.089*"string" + 0.083*"list" + 0.074*"way" + 0.034*"module" + 0.034*"namespace" + 0.033*"note" + 0.032*"variable" + 0.030*"name" + 0.028*"return" + 0.023*"garbage"
INFO: topic #2 (0.130): 0.078*"method" + 0.058*"debugging" + 0.048*"word" + 0.026*"order" + 0.026*"foo" + 0.022*"snippet" + 0.022*"drawback" + 0.010*"parameter" + 0.007*"loop" + 0.007*"constructor"
INFO: topic #3 (0.355): 0.145*"class" + 0.129*"instance" + 0.046*"print" + 0.035*"example" + 0.033*"type" + 0.030*"part" + 0.015*"track" + 0.014*"assignment" + 0.011*"retrieve" + 0.011*"c"
INFO: topic #4 (0.146): 0.042*"global" + 0.042*"var" + 0.033*"answer" + 0.032*"filter" + 0.024*"scope" + 0.014*"design" + 0.014*"stack" + 0.010*"choice" + 0.010*"hash" + 0.009*"inspect"
INFO: topic diff=0.353985, rho=0.238366
DEBUG: bound: at document #0
INFO: -7.039 per-word bound, 131.5 perplexity estimate based on a held-out corpus of 5 documents with 191 words
INFO: PROGRESS: pass 1, at document #10/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.9186507, 0.35348436, 0.14715904, 0.36688036, 0.16402085]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.919): 0.161*"name" + 0.097*"function" + 0.094*"object" + 0.063*"code" + 0.060*"variable" + 0.050*"value" + 0.025*"source" + 0.024*"case" + 0.023*"thing" + 0.018*"attribute"
INFO: topic #1 (0.353): 0.097*"list" + 0.086*"string" + 0.065*"way" + 0.041*"note" + 0.033*"variable" + 0.030*"module" + 0.030*"namespace" + 0.029*"name" + 0.025*"return" + 0.020*"garbage"
INFO: topic #2 (0.147): 0.091*"foo" + 0.086*"method" + 0.054*"word" + 0.037*"debugging" + 0.022*"version" + 0.019*"initialization" + 0.017*"order" + 0.014*"snippet" + 0.014*"drawback" + 0.013*"frame"
INFO: topic #3 (0.367): 0.077*"class" + 0.070*"instance" + 0.060*"frame" + 0.042*"example" + 0.037*"varname" + 0.033*"assignment" + 0.030*"need" + 0.030*"environment" + 0.025*"print" + 0.023*"part"
INFO: topic #4 (0.164): 0.077*"answer" + 0.054*"scope" + 0.044*"global" + 0.043*"var" + 0.028*"stack" + 0.025*"inspect" + 0.018*"filter" + 0.016*"bit" + 0.015*"idilip" + 0.015*"var_2"
INFO: topic diff=0.656572, rho=0.238366
DEBUG: bound: at document #0
INFO: -6.594 per-word bound, 96.6 perplexity estimate based on a held-out corpus of 5 documents with 45 words
INFO: PROGRESS: pass 1, at document #15/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.96611774, 0.35852596, 0.13796851, 0.3465146, 0.16214302]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (0.966): 0.161*"name" + 0.087*"object" + 0.085*"function" + 0.073*"variable" + 0.071*"value" + 0.055*"code" + 0.025*"case" + 0.022*"source" + 0.020*"thing" + 0.019*"access"
INFO: topic #1 (0.359): 0.076*"string" + 0.074*"list" + 0.061*"way" + 0.055*"variable" + 0.031*"return" + 0.031*"note" + 0.028*"name" + 0.026*"content" + 0.024*"input" + 0.023*"module"
INFO: topic #2 (0.138): 0.081*"foo" + 0.077*"method" + 0.049*"word" + 0.033*"debugging" + 0.020*"version" + 0.017*"initialization" + 0.015*"order" + 0.013*"snippet" + 0.013*"drawback" + 0.012*"frame"
INFO: topic #3 (0.347): 0.080*"class" + 0.067*"instance" + 0.057*"frame" + 0.040*"example" + 0.036*"varname" + 0.032*"assignment" + 0.028*"need" + 0.028*"environment" + 0.024*"print" + 0.022*"part"
INFO: topic #4 (0.162): 0.065*"scope" + 0.063*"answer" + 0.036*"global" + 0.036*"var" + 0.034*"bit" + 0.023*"stack" + 0.021*"inspect" + 0.015*"filter" + 0.013*"idilip" + 0.012*"defining"
INFO: topic diff=0.208463, rho=0.238366
DEBUG: bound: at document #0
INFO: -6.059 per-word bound, 66.7 perplexity estimate based on a held-out corpus of 5 documents with 37 words
INFO: PROGRESS: pass 1, at document #20/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.020428, 0.38282514, 0.13882366, 0.33423024, 0.185246]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.020): 0.172*"name" + 0.090*"function" + 0.080*"variable" + 0.080*"value" + 0.077*"object" + 0.049*"code" + 0.023*"case" + 0.019*"source" + 0.018*"thing" + 0.017*"access"
INFO: topic #1 (0.383): 0.084*"list" + 0.062*"string" + 0.061*"return" + 0.059*"variable" + 0.050*"way" + 0.031*"name" + 0.031*"module" + 0.031*"namespace" + 0.025*"note" + 0.024*"index"
INFO: topic #2 (0.139): 0.112*"method" + 0.067*"foo" + 0.040*"word" + 0.027*"debugging" + 0.020*"frame" + 0.017*"version" + 0.015*"initialization" + 0.013*"order" + 0.011*"snippet" + 0.011*"drawback"
INFO: topic #3 (0.334): 0.076*"class" + 0.063*"instance" + 0.058*"frame" + 0.038*"example" + 0.034*"varname" + 0.030*"assignment" + 0.027*"need" + 0.027*"environment" + 0.023*"print" + 0.021*"part"
INFO: topic #4 (0.185): 0.090*"answer" + 0.070*"scope" + 0.048*"global" + 0.048*"var" + 0.026*"bit" + 0.023*"result" + 0.018*"variation" + 0.017*"stack" + 0.016*"inspect" + 0.012*"filter"
INFO: topic diff=0.162699, rho=0.238366
DEBUG: bound: at document #0
INFO: -6.746 per-word bound, 107.4 perplexity estimate based on a held-out corpus of 5 documents with 69 words
INFO: PROGRESS: pass 1, at document #25/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.1108061, 0.3837091, 0.13897836, 0.370641, 0.19245528]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.111): 0.150*"name" + 0.121*"function" + 0.082*"variable" + 0.074*"object" + 0.070*"value" + 0.045*"code" + 0.021*"local" + 0.018*"case" + 0.016*"source" + 0.015*"memory"
INFO: topic #1 (0.384): 0.072*"string" + 0.066*"list" + 0.060*"return" + 0.057*"variable" + 0.051*"way" + 0.025*"name" + 0.024*"module" + 0.024*"namespace" + 0.020*"note" + 0.019*"index"
INFO: topic #2 (0.139): 0.091*"method" + 0.055*"foo" + 0.048*"debugging" + 0.033*"word" + 0.017*"frame" + 0.014*"version" + 0.012*"initialization" + 0.011*"order" + 0.009*"snippet" + 0.009*"drawback"
INFO: topic #3 (0.371): 0.069*"class" + 0.057*"example" + 0.050*"instance" + 0.046*"frame" + 0.034*"call" + 0.030*"need" + 0.027*"type" + 0.027*"varname" + 0.027*"print" + 0.024*"assignment"
INFO: topic #4 (0.192): 0.080*"var" + 0.069*"answer" + 0.059*"global" + 0.054*"scope" + 0.034*"inspect" + 0.021*"idea" + 0.021*"process" + 0.020*"bit" + 0.018*"result" + 0.014*"variation"
INFO: topic diff=0.276684, rho=0.238366
DEBUG: bound: at document #0
INFO: -6.550 per-word bound, 93.7 perplexity estimate based on a held-out corpus of 5 documents with 89 words
INFO: PROGRESS: pass 1, at document #30/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.1576813, 0.40731898, 0.13849054, 0.40409356, 0.1982116]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.158): 0.155*"name" + 0.112*"function" + 0.078*"variable" + 0.070*"code" + 0.068*"object" + 0.055*"value" + 0.032*"source" + 0.020*"local" + 0.014*"reference" + 0.013*"case"
INFO: topic #1 (0.407): 0.082*"list" + 0.071*"string" + 0.053*"module" + 0.048*"way" + 0.044*"variable" + 0.043*"return" + 0.029*"namespace" + 0.028*"name" + 0.023*"integer" + 0.020*"match"
INFO: topic #2 (0.138): 0.073*"method" + 0.045*"foo" + 0.039*"debugging" + 0.029*"constructor" + 0.027*"word" + 0.024*"sorcery" + 0.019*"kind" + 0.014*"frame" + 0.011*"version" + 0.010*"initialization"
INFO: topic #3 (0.404): 0.076*"class" + 0.066*"example" + 0.042*"instance" + 0.038*"frame" + 0.028*"call" + 0.027*"retrieve" + 0.025*"need" + 0.023*"package" + 0.023*"type" + 0.022*"varname"
INFO: topic #4 (0.198): 0.069*"global" + 0.064*"var" + 0.055*"stack" + 0.055*"answer" + 0.043*"scope" + 0.027*"inspect" + 0.017*"process" + 0.017*"idea" + 0.016*"bit" + 0.016*"python3"
INFO: topic diff=0.352903, rho=0.238366
DEBUG: bound: at document #0
INFO: -5.353 per-word bound, 40.9 perplexity estimate based on a held-out corpus of 5 documents with 114 words
INFO: PROGRESS: pass 1, at document #35/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.280883, 0.444424, 0.13067077, 0.41891876, 0.18262473]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.281): 0.215*"name" + 0.110*"object" + 0.100*"function" + 0.060*"variable" + 0.046*"code" + 0.046*"value" + 0.023*"local" + 0.022*"source" + 0.018*"reference" + 0.013*"case"
INFO: topic #1 (0.444): 0.128*"list" + 0.071*"string" + 0.069*"way" + 0.043*"module" + 0.037*"namespace" + 0.036*"return" + 0.035*"name" + 0.029*"variable" + 0.018*"index" + 0.018*"define"
INFO: topic #2 (0.131): 0.063*"method" + 0.038*"foo" + 0.033*"debugging" + 0.025*"constructor" + 0.023*"word" + 0.021*"sorcery" + 0.017*"kind" + 0.012*"frame" + 0.010*"version" + 0.009*"initialization"
INFO: topic #3 (0.419): 0.095*"class" + 0.076*"example" + 0.045*"instance" + 0.032*"frame" + 0.027*"assignment" + 0.023*"call" + 0.022*"retrieve" + 0.022*"course" + 0.021*"need" + 0.019*"package"
INFO: topic #4 (0.183): 0.061*"global" + 0.056*"var" + 0.049*"stack" + 0.049*"answer" + 0.038*"scope" + 0.024*"inspect" + 0.015*"process" + 0.015*"idea" + 0.015*"bit" + 0.014*"python3"
INFO: topic diff=0.350028, rho=0.238366
DEBUG: bound: at document #0
INFO: -7.504 per-word bound, 181.5 perplexity estimate based on a held-out corpus of 5 documents with 32 words
INFO: PROGRESS: pass 1, at document #40/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.1102664, 0.41982037, 0.13590245, 0.40651888, 0.20004949]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.110): 0.203*"name" + 0.114*"function" + 0.107*"object" + 0.056*"variable" + 0.042*"code" + 0.042*"value" + 0.023*"case" + 0.021*"local" + 0.020*"source" + 0.017*"reference"
INFO: topic #1 (0.420): 0.116*"list" + 0.064*"string" + 0.062*"way" + 0.061*"module" + 0.034*"namespace" + 0.033*"return" + 0.032*"name" + 0.027*"variable" + 0.019*"note" + 0.016*"index"
INFO: topic #2 (0.136): 0.061*"foo" + 0.050*"method" + 0.039*"word" + 0.027*"debugging" + 0.020*"constructor" + 0.017*"sorcery" + 0.013*"kind" + 0.010*"loop" + 0.010*"frame" + 0.008*"version"
INFO: topic #3 (0.407): 0.106*"class" + 0.066*"example" + 0.039*"instance" + 0.031*"course" + 0.029*"type" + 0.028*"frame" + 0.026*"work" + 0.024*"assignment" + 0.020*"call" + 0.019*"retrieve"
INFO: topic #4 (0.200): 0.076*"answer" + 0.062*"global" + 0.040*"loop" + 0.037*"var" + 0.032*"stack" + 0.031*"result" + 0.027*"filter" + 0.026*"scope" + 0.019*"each_item" + 0.019*"globals().item"
INFO: topic diff=0.191646, rho=0.238366
DEBUG: bound: at document #0
INFO: -6.237 per-word bound, 75.4 perplexity estimate based on a held-out corpus of 5 documents with 133 words
INFO: PROGRESS: pass 1, at document #45/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.2542772, 0.44095045, 0.14913528, 0.40237835, 0.20250244]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.254): 0.218*"name" + 0.131*"function" + 0.110*"object" + 0.055*"value" + 0.040*"variable" + 0.027*"code" + 0.020*"attribute" + 0.020*"case" + 0.018*"reference" + 0.014*"question"
INFO: topic #1 (0.441): 0.084*"list" + 0.077*"string" + 0.050*"way" + 0.049*"module" + 0.036*"match" + 0.032*"note" + 0.031*"name" + 0.031*"return" + 0.024*"content" + 0.022*"none"
INFO: topic #2 (0.149): 0.052*"method" + 0.038*"debugging" + 0.035*"foo" + 0.027*"order" + 0.023*"word" + 0.023*"story" + 0.019*"grab" + 0.019*"deal" + 0.019*"eval" + 0.019*"page"
INFO: topic #3 (0.402): 0.087*"class" + 0.067*"example" + 0.051*"course" + 0.045*"instance" + 0.028*"frame" + 0.026*"print" + 0.023*"type" + 0.021*"work" + 0.021*"magic" + 0.019*"assignment"
INFO: topic #4 (0.203): 0.071*"global" + 0.060*"answer" + 0.048*"stack" + 0.047*"result" + 0.031*"loop" + 0.029*"var" + 0.021*"filter" + 0.020*"scope" + 0.015*"each_item" + 0.015*"globals().item"
INFO: topic diff=0.512801, rho=0.238366
DEBUG: bound: at document #0
INFO: -6.012 per-word bound, 64.5 perplexity estimate based on a held-out corpus of 5 documents with 67 words
INFO: PROGRESS: pass 1, at document #50/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.3908583, 0.4865357, 0.14835343, 0.39753965, 0.22088121]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.391): 0.222*"name" + 0.143*"function" + 0.093*"object" + 0.049*"value" + 0.041*"variable" + 0.027*"code" + 0.026*"attribute" + 0.016*"case" + 0.016*"local" + 0.014*"reference"
INFO: topic #1 (0.487): 0.082*"string" + 0.068*"list" + 0.060*"way" + 0.060*"module" + 0.040*"match" + 0.036*"note" + 0.035*"return" + 0.030*"name" + 0.019*"content" + 0.018*"none"
INFO: topic #2 (0.148): 0.069*"method" + 0.032*"debugging" + 0.030*"foo" + 0.023*"order" + 0.019*"word" + 0.019*"story" + 0.017*"grab" + 0.017*"deal" + 0.017*"eval" + 0.017*"page"
INFO: topic #3 (0.398): 0.113*"class" + 0.069*"example" + 0.042*"course" + 0.037*"instance" + 0.026*"need" + 0.023*"frame" + 0.022*"print" + 0.020*"type" + 0.018*"work" + 0.017*"magic"
INFO: topic #4 (0.221): 0.116*"global" + 0.065*"answer" + 0.035*"stack" + 0.034*"result" + 0.023*"loop" + 0.021*"var" + 0.017*"my_list" + 0.017*"bla" + 0.016*"filter" + 0.015*"scope"
INFO: topic diff=0.230617, rho=0.238366
DEBUG: bound: at document #0
INFO: -6.349 per-word bound, 81.5 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 1, at document #55/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.4533726, 0.5139954, 0.15503043, 0.42688504, 0.23917425]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.453): 0.213*"name" + 0.120*"function" + 0.116*"object" + 0.050*"value" + 0.038*"variable" + 0.032*"code" + 0.023*"case" + 0.021*"attribute" + 0.016*"reference" + 0.014*"search"
INFO: topic #1 (0.514): 0.070*"string" + 0.069*"list" + 0.063*"way" + 0.057*"match" + 0.051*"module" + 0.042*"note" + 0.040*"return" + 0.027*"name" + 0.016*"content" + 0.015*"none"
INFO: topic #2 (0.155): 0.108*"method" + 0.026*"debugging" + 0.024*"foo" + 0.019*"order" + 0.016*"word" + 0.016*"story" + 0.014*"deal" + 0.014*"eval" + 0.014*"basestring" + 0.014*"long"
INFO: topic #3 (0.427): 0.123*"class" + 0.061*"instance" + 0.058*"example" + 0.039*"print" + 0.030*"environment" + 0.028*"course" + 0.028*"track" + 0.023*"player" + 0.023*"iterator" + 0.018*"need"
INFO: topic #4 (0.239): 0.110*"global" + 0.071*"answer" + 0.039*"loop" + 0.033*"scope" + 0.027*"stack" + 0.026*"result" + 0.017*"var" + 0.014*"atribute" + 0.013*"my_list" + 0.013*"bla"
INFO: topic diff=0.266648, rho=0.238366
DEBUG: bound: at document #0
INFO: -6.924 per-word bound, 121.4 perplexity estimate based on a held-out corpus of 5 documents with 183 words
INFO: PROGRESS: pass 1, at document #60/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.4323035, 0.4684769, 0.16969909, 0.46409163, 0.23774861]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.432): 0.195*"name" + 0.139*"object" + 0.110*"function" + 0.046*"code" + 0.036*"value" + 0.029*"variable" + 0.026*"source" + 0.019*"case" + 0.013*"line" + 0.013*"attribute"
INFO: topic #1 (0.468): 0.084*"way" + 0.074*"string" + 0.066*"list" + 0.056*"note" + 0.052*"module" + 0.044*"match" + 0.032*"return" + 0.024*"caller" + 0.024*"name" + 0.015*"def"
INFO: topic #2 (0.170): 0.092*"method" + 0.029*"initialization" + 0.027*"debugging" + 0.019*"constructor" + 0.017*"frame" + 0.017*"assignent" + 0.017*"production" + 0.016*"loop" + 0.014*"glance" + 0.014*"rethink"
INFO: topic #3 (0.464): 0.084*"class" + 0.049*"example" + 0.042*"instance" + 0.036*"frame" + 0.032*"file" + 0.031*"call" + 0.024*"work" + 0.023*"assignment" + 0.022*"retrieve" + 0.022*"="
INFO: topic #4 (0.238): 0.080*"global" + 0.052*"answer" + 0.045*"scope" + 0.040*"stack" + 0.029*"loop" + 0.026*"inspect" + 0.019*"result" + 0.019*"self" + 0.019*"determine" + 0.019*"dimension"
INFO: topic diff=0.710515, rho=0.238366
DEBUG: bound: at document #0
INFO: -6.369 per-word bound, 82.6 perplexity estimate based on a held-out corpus of 5 documents with 164 words
INFO: PROGRESS: pass 1, at document #65/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.5490147, 0.49193406, 0.17229562, 0.49010336, 0.24351276]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.549): 0.188*"name" + 0.153*"object" + 0.089*"function" + 0.049*"value" + 0.042*"variable" + 0.037*"code" + 0.026*"reference" + 0.017*"source" + 0.016*"case" + 0.016*"attribute"
INFO: topic #1 (0.492): 0.092*"way" + 0.065*"string" + 0.061*"list" + 0.046*"namespace" + 0.045*"note" + 0.033*"module" + 0.028*"match" + 0.026*"integer" + 0.021*"reference" + 0.020*"name"
INFO: topic #2 (0.172): 0.097*"method" + 0.026*"parameter" + 0.025*"initialization" + 0.023*"debugging" + 0.016*"constructor" + 0.015*"frame" + 0.015*"production" + 0.015*"assignent" + 0.014*"loop" + 0.013*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.490): 0.100*"class" + 0.064*"example" + 0.041*"instance" + 0.035*"assignment" + 0.033*"print" + 0.028*"frame" + 0.027*"work" + 0.025*"file" + 0.024*"call" + 0.017*"retrieve"
INFO: topic #4 (0.244): 0.076*"var" + 0.052*"global" + 0.046*"scope" + 0.036*"design" + 0.034*"answer" + 0.026*"stack" + 0.024*"choice" + 0.024*"hash" + 0.019*"loop" + 0.017*"inspect"
INFO: topic diff=0.519079, rho=0.238366
DEBUG: bound: at document #0
INFO: -6.239 per-word bound, 75.5 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 1, at document #70/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.5607207, 0.50731844, 0.18131626, 0.53679454, 0.22760384]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.561): 0.177*"name" + 0.160*"object" + 0.078*"function" + 0.050*"code" + 0.048*"value" + 0.037*"variable" + 0.034*"reference" + 0.018*"case" + 0.015*"source" + 0.014*"attribute"
INFO: topic #1 (0.507): 0.085*"way" + 0.064*"string" + 0.050*"list" + 0.038*"namespace" + 0.037*"module" + 0.037*"note" + 0.032*"garbage" + 0.031*"reference" + 0.027*"return" + 0.023*"match"
INFO: topic #2 (0.181): 0.101*"method" + 0.039*"debugging" + 0.022*"parameter" + 0.021*"initialization" + 0.019*"version" + 0.014*"constructor" + 0.013*"frame" + 0.013*"assignent" + 0.013*"production" + 0.012*"loop"
INFO: topic #3 (0.537): 0.181*"class" + 0.060*"instance" + 0.052*"example" + 0.025*"assignment" + 0.023*"print" + 0.020*"retrieve" + 0.020*"frame" + 0.019*"work" + 0.018*"c" + 0.017*"file"
INFO: topic #4 (0.228): 0.069*"var" + 0.047*"global" + 0.042*"scope" + 0.033*"design" + 0.030*"answer" + 0.024*"stack" + 0.022*"choice" + 0.022*"hash" + 0.017*"loop" + 0.015*"inspect"
INFO: topic diff=0.257923, rho=0.238366
DEBUG: bound: at document #0
INFO: -6.210 per-word bound, 74.1 perplexity estimate based on a held-out corpus of 5 documents with 112 words
INFO: PROGRESS: pass 1, at document #75/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6925092, 0.56725246, 0.17685136, 0.63517183, 0.24278627]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.693): 0.174*"name" + 0.162*"object" + 0.073*"function" + 0.049*"variable" + 0.047*"code" + 0.037*"value" + 0.035*"reference" + 0.023*"case" + 0.016*"source" + 0.012*"access"
INFO: topic #1 (0.567): 0.081*"way" + 0.056*"namespace" + 0.056*"module" + 0.055*"list" + 0.052*"garbage" + 0.046*"string" + 0.036*"note" + 0.023*"reference" + 0.021*"collection" + 0.019*"return"
INFO: topic #2 (0.177): 0.088*"method" + 0.056*"debugging" + 0.020*"parameter" + 0.019*"initialization" + 0.017*"version" + 0.013*"constructor" + 0.011*"frame" + 0.011*"assignent" + 0.011*"production" + 0.011*"loop"
INFO: topic #3 (0.635): 0.145*"class" + 0.141*"instance" + 0.045*"example" + 0.042*"type" + 0.024*"print" + 0.021*"track" + 0.018*"assignment" + 0.017*"c" + 0.014*"retrieve" + 0.014*"frame"
INFO: topic #4 (0.243): 0.058*"global" + 0.054*"var" + 0.045*"filter" + 0.045*"answer" + 0.033*"scope" + 0.026*"design" + 0.019*"stack" + 0.017*"hash" + 0.017*"choice" + 0.014*"loop"
INFO: topic diff=0.357737, rho=0.238366
DEBUG: bound: at document #0
INFO: -6.733 per-word bound, 106.4 perplexity estimate based on a held-out corpus of 3 documents with 21 words
INFO: PROGRESS: pass 1, at document #78/78
DEBUG: performing inference on a chunk of 3 documents
DEBUG: 3/3 documents converged within 2000 iterations
INFO: optimized alpha [1.8044546, 0.5510009, 0.17004807, 0.7472822, 0.23059565]
DEBUG: updating topics
INFO: merging changes from 3 documents into a model of 78 documents
INFO: topic #0 (1.804): 0.171*"name" + 0.152*"object" + 0.081*"function" + 0.050*"code" + 0.044*"variable" + 0.033*"value" + 0.031*"reference" + 0.020*"case" + 0.018*"attribute" + 0.016*"thing"
INFO: topic #1 (0.551): 0.094*"way" + 0.052*"namespace" + 0.051*"module" + 0.051*"list" + 0.048*"garbage" + 0.042*"string" + 0.033*"note" + 0.021*"reference" + 0.019*"collection" + 0.018*"return"
INFO: topic #2 (0.170): 0.077*"method" + 0.049*"debugging" + 0.018*"parameter" + 0.017*"initialization" + 0.015*"version" + 0.011*"constructor" + 0.010*"frame" + 0.010*"assignent" + 0.010*"production" + 0.010*"loop"
INFO: topic #3 (0.747): 0.148*"class" + 0.131*"instance" + 0.048*"print" + 0.038*"example" + 0.035*"type" + 0.031*"part" + 0.018*"track" + 0.015*"assignment" + 0.014*"c" + 0.012*"retrieve"
INFO: topic #4 (0.231): 0.051*"global" + 0.048*"var" + 0.040*"filter" + 0.040*"answer" + 0.029*"scope" + 0.023*"design" + 0.017*"stack" + 0.015*"choice" + 0.015*"hash" + 0.012*"loop"
INFO: topic diff=0.173679, rho=0.238366
DEBUG: bound: at document #0
INFO: -5.339 per-word bound, 40.5 perplexity estimate based on a held-out corpus of 5 documents with 130 words
INFO: PROGRESS: pass 2, at document #5/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.4279592, 0.5406417, 0.16430977, 0.5196205, 0.20141381]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.428): 0.165*"name" + 0.120*"object" + 0.088*"function" + 0.050*"code" + 0.047*"variable" + 0.039*"value" + 0.030*"thing" + 0.023*"attribute" + 0.020*"case" + 0.020*"language"
INFO: topic #1 (0.541): 0.091*"string" + 0.085*"list" + 0.074*"way" + 0.035*"namespace" + 0.035*"module" + 0.033*"note" + 0.033*"garbage" + 0.030*"return" + 0.024*"variable" + 0.015*"reference"
INFO: topic #2 (0.164): 0.078*"method" + 0.058*"debugging" + 0.048*"word" + 0.028*"foo" + 0.027*"order" + 0.023*"snippet" + 0.023*"drawback" + 0.013*"parameter" + 0.012*"initialization" + 0.011*"version"
INFO: topic #3 (0.520): 0.141*"class" + 0.125*"instance" + 0.046*"print" + 0.036*"example" + 0.033*"type" + 0.030*"part" + 0.017*"track" + 0.014*"assignment" + 0.014*"c" + 0.012*"retrieve"
INFO: topic #4 (0.201): 0.045*"global" + 0.042*"var" + 0.035*"filter" + 0.035*"answer" + 0.026*"scope" + 0.021*"design" + 0.015*"stack" + 0.014*"hash" + 0.014*"choice" + 0.011*"loop"
INFO: topic diff=0.309989, rho=0.231869
DEBUG: bound: at document #0
INFO: -6.661 per-word bound, 101.2 perplexity estimate based on a held-out corpus of 5 documents with 191 words
INFO: PROGRESS: pass 2, at document #10/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.2019677, 0.44955888, 0.18226092, 0.5137032, 0.2204614]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.202): 0.169*"name" + 0.100*"function" + 0.094*"object" + 0.063*"variable" + 0.063*"code" + 0.051*"value" + 0.025*"source" + 0.024*"case" + 0.023*"thing" + 0.018*"attribute"
INFO: topic #1 (0.450): 0.099*"list" + 0.089*"string" + 0.066*"way" + 0.041*"note" + 0.031*"namespace" + 0.031*"module" + 0.029*"garbage" + 0.027*"return" + 0.025*"variable" + 0.014*"name"
INFO: topic #2 (0.182): 0.093*"foo" + 0.089*"method" + 0.053*"word" + 0.038*"debugging" + 0.027*"initialization" + 0.026*"version" + 0.019*"frame" + 0.018*"order" + 0.015*"snippet" + 0.015*"drawback"
INFO: topic #3 (0.514): 0.075*"class" + 0.068*"instance" + 0.059*"frame" + 0.042*"example" + 0.038*"varname" + 0.033*"assignment" + 0.029*"need" + 0.029*"environment" + 0.024*"print" + 0.023*"part"
INFO: topic #4 (0.220): 0.077*"answer" + 0.054*"scope" + 0.045*"global" + 0.043*"var" + 0.028*"stack" + 0.025*"inspect" + 0.020*"filter" + 0.019*"bit" + 0.017*"defining" + 0.017*"warning"
INFO: topic diff=0.543626, rho=0.231869
DEBUG: bound: at document #0
INFO: -6.476 per-word bound, 89.0 perplexity estimate based on a held-out corpus of 5 documents with 45 words
INFO: PROGRESS: pass 2, at document #15/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.2627654, 0.4545872, 0.17056192, 0.47471964, 0.21647277]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.263): 0.168*"name" + 0.087*"function" + 0.086*"object" + 0.078*"variable" + 0.071*"value" + 0.055*"code" + 0.025*"case" + 0.022*"source" + 0.020*"thing" + 0.019*"access"
INFO: topic #1 (0.455): 0.080*"string" + 0.076*"list" + 0.062*"way" + 0.042*"variable" + 0.033*"return" + 0.032*"note" + 0.026*"content" + 0.024*"namespace" + 0.024*"module" + 0.024*"input"
INFO: topic #2 (0.171): 0.083*"foo" + 0.080*"method" + 0.047*"word" + 0.034*"debugging" + 0.024*"initialization" + 0.024*"version" + 0.017*"frame" + 0.016*"order" + 0.014*"snippet" + 0.014*"drawback"
INFO: topic #3 (0.475): 0.078*"class" + 0.065*"instance" + 0.057*"frame" + 0.040*"example" + 0.036*"varname" + 0.031*"assignment" + 0.028*"need" + 0.028*"environment" + 0.023*"print" + 0.022*"wrapper"
INFO: topic #4 (0.216): 0.065*"scope" + 0.063*"answer" + 0.037*"global" + 0.036*"bit" + 0.036*"var" + 0.023*"stack" + 0.021*"inspect" + 0.017*"filter" + 0.014*"defining" + 0.014*"var_2"
INFO: topic diff=0.180889, rho=0.231869
DEBUG: bound: at document #0
INFO: -5.966 per-word bound, 62.5 perplexity estimate based on a held-out corpus of 5 documents with 37 words
INFO: PROGRESS: pass 2, at document #20/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.3219008, 0.48039567, 0.17131808, 0.45022866, 0.24448025]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.322): 0.180*"name" + 0.092*"function" + 0.086*"variable" + 0.079*"value" + 0.077*"object" + 0.049*"code" + 0.023*"case" + 0.019*"source" + 0.018*"thing" + 0.017*"access"
INFO: topic #1 (0.480): 0.087*"list" + 0.065*"string" + 0.063*"return" + 0.051*"way" + 0.043*"variable" + 0.032*"namespace" + 0.032*"module" + 0.026*"note" + 0.025*"index" + 0.021*"content"
INFO: topic #2 (0.171): 0.113*"method" + 0.069*"foo" + 0.039*"word" + 0.028*"debugging" + 0.027*"frame" + 0.020*"initialization" + 0.020*"version" + 0.013*"order" + 0.012*"snippet" + 0.012*"drawback"
INFO: topic #3 (0.450): 0.074*"class" + 0.061*"instance" + 0.058*"frame" + 0.038*"example" + 0.034*"varname" + 0.030*"assignment" + 0.027*"need" + 0.026*"environment" + 0.022*"print" + 0.021*"wrapper"
INFO: topic #4 (0.244): 0.089*"answer" + 0.070*"scope" + 0.049*"global" + 0.048*"var" + 0.028*"bit" + 0.024*"result" + 0.019*"variation" + 0.018*"stack" + 0.016*"inspect" + 0.013*"filter"
INFO: topic diff=0.136781, rho=0.231869
DEBUG: bound: at document #0
INFO: -6.653 per-word bound, 100.6 perplexity estimate based on a held-out corpus of 5 documents with 69 words
INFO: PROGRESS: pass 2, at document #25/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.418232, 0.47788143, 0.17026068, 0.49128962, 0.25195232]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.418): 0.156*"name" + 0.123*"function" + 0.088*"variable" + 0.073*"object" + 0.069*"value" + 0.045*"code" + 0.021*"local" + 0.018*"case" + 0.016*"source" + 0.015*"thing"
INFO: topic #1 (0.478): 0.075*"string" + 0.068*"list" + 0.062*"return" + 0.052*"way" + 0.042*"variable" + 0.025*"namespace" + 0.025*"module" + 0.020*"note" + 0.020*"index" + 0.018*"define"
INFO: topic #2 (0.170): 0.095*"method" + 0.058*"foo" + 0.049*"debugging" + 0.033*"word" + 0.023*"frame" + 0.017*"initialization" + 0.017*"version" + 0.012*"order" + 0.010*"snippet" + 0.010*"drawback"
INFO: topic #3 (0.491): 0.067*"class" + 0.056*"example" + 0.049*"instance" + 0.046*"frame" + 0.032*"call" + 0.030*"need" + 0.028*"varname" + 0.027*"type" + 0.026*"print" + 0.024*"assignment"
INFO: topic #4 (0.252): 0.079*"var" + 0.069*"answer" + 0.059*"global" + 0.054*"scope" + 0.033*"inspect" + 0.022*"bit" + 0.021*"idea" + 0.021*"process" + 0.019*"result" + 0.015*"variation"
INFO: topic diff=0.235041, rho=0.231869
DEBUG: bound: at document #0
INFO: -6.440 per-word bound, 86.8 perplexity estimate based on a held-out corpus of 5 documents with 89 words
INFO: PROGRESS: pass 2, at document #30/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.4701344, 0.50131804, 0.16909437, 0.52434075, 0.25655833]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.470): 0.160*"name" + 0.112*"function" + 0.083*"variable" + 0.068*"code" + 0.068*"object" + 0.055*"value" + 0.032*"source" + 0.020*"local" + 0.013*"reference" + 0.013*"case"
INFO: topic #1 (0.501): 0.084*"list" + 0.074*"string" + 0.054*"module" + 0.050*"way" + 0.045*"return" + 0.032*"variable" + 0.030*"namespace" + 0.024*"integer" + 0.021*"match" + 0.015*"note"
INFO: topic #2 (0.169): 0.076*"method" + 0.047*"foo" + 0.040*"debugging" + 0.030*"constructor" + 0.027*"word" + 0.026*"sorcery" + 0.019*"kind" + 0.018*"frame" + 0.014*"initialization" + 0.014*"version"
INFO: topic #3 (0.524): 0.076*"class" + 0.066*"example" + 0.042*"instance" + 0.039*"frame" + 0.027*"call" + 0.026*"retrieve" + 0.025*"need" + 0.023*"varname" + 0.023*"type" + 0.023*"package"
INFO: topic #4 (0.257): 0.069*"global" + 0.064*"var" + 0.056*"answer" + 0.055*"stack" + 0.044*"scope" + 0.027*"inspect" + 0.018*"bit" + 0.017*"idea" + 0.017*"process" + 0.017*"python3"
INFO: topic diff=0.304448, rho=0.231869
DEBUG: bound: at document #0
INFO: -5.307 per-word bound, 39.6 perplexity estimate based on a held-out corpus of 5 documents with 114 words
INFO: PROGRESS: pass 2, at document #35/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6108601, 0.5436229, 0.15888028, 0.5335941, 0.23401357]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.611): 0.219*"name" + 0.107*"object" + 0.101*"function" + 0.064*"variable" + 0.045*"value" + 0.045*"code" + 0.022*"local" + 0.021*"source" + 0.018*"reference" + 0.013*"case"
INFO: topic #1 (0.544): 0.131*"list" + 0.073*"string" + 0.070*"way" + 0.044*"module" + 0.039*"namespace" + 0.038*"return" + 0.022*"variable" + 0.019*"index" + 0.018*"define" + 0.015*"integer"
INFO: topic #2 (0.159): 0.065*"method" + 0.040*"foo" + 0.034*"debugging" + 0.026*"constructor" + 0.023*"word" + 0.022*"sorcery" + 0.017*"kind" + 0.016*"frame" + 0.012*"initialization" + 0.012*"version"
INFO: topic #3 (0.534): 0.094*"class" + 0.075*"example" + 0.045*"instance" + 0.033*"frame" + 0.027*"assignment" + 0.023*"call" + 0.022*"retrieve" + 0.022*"course" + 0.021*"need" + 0.020*"varname"
INFO: topic #4 (0.234): 0.061*"global" + 0.056*"var" + 0.050*"answer" + 0.048*"stack" + 0.039*"scope" + 0.024*"inspect" + 0.016*"bit" + 0.015*"idea" + 0.015*"process" + 0.015*"python3"
INFO: topic diff=0.318556, rho=0.231869
DEBUG: bound: at document #0
INFO: -7.417 per-word bound, 170.9 perplexity estimate based on a held-out corpus of 5 documents with 32 words
INFO: PROGRESS: pass 2, at document #40/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.3913674, 0.5071066, 0.15702058, 0.51073694, 0.25446233]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.391): 0.207*"name" + 0.114*"function" + 0.104*"object" + 0.059*"variable" + 0.042*"value" + 0.042*"code" + 0.023*"case" + 0.021*"local" + 0.020*"source" + 0.016*"reference"
INFO: topic #1 (0.507): 0.119*"list" + 0.066*"string" + 0.064*"way" + 0.063*"module" + 0.035*"namespace" + 0.034*"return" + 0.020*"note" + 0.020*"variable" + 0.017*"index" + 0.017*"define"
INFO: topic #2 (0.157): 0.065*"foo" + 0.054*"method" + 0.028*"debugging" + 0.022*"constructor" + 0.019*"word" + 0.018*"sorcery" + 0.014*"kind" + 0.013*"frame" + 0.010*"initialization" + 0.010*"version"
INFO: topic #3 (0.511): 0.105*"class" + 0.066*"example" + 0.039*"instance" + 0.031*"course" + 0.029*"frame" + 0.029*"type" + 0.026*"work" + 0.024*"assignment" + 0.020*"call" + 0.019*"retrieve"
INFO: topic #4 (0.254): 0.075*"answer" + 0.061*"global" + 0.044*"loop" + 0.037*"var" + 0.032*"stack" + 0.030*"result" + 0.027*"filter" + 0.026*"scope" + 0.021*"globals().item" + 0.021*"each_item"
INFO: topic diff=0.178499, rho=0.231869
DEBUG: bound: at document #0
INFO: -6.168 per-word bound, 71.9 perplexity estimate based on a held-out corpus of 5 documents with 133 words
INFO: PROGRESS: pass 2, at document #45/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.5348654, 0.5268083, 0.17114651, 0.49270996, 0.2525676]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.535): 0.223*"name" + 0.131*"function" + 0.108*"object" + 0.054*"value" + 0.043*"variable" + 0.027*"code" + 0.020*"attribute" + 0.019*"case" + 0.017*"reference" + 0.013*"local"
INFO: topic #1 (0.527): 0.085*"list" + 0.079*"string" + 0.050*"way" + 0.050*"module" + 0.036*"match" + 0.032*"note" + 0.032*"return" + 0.024*"content" + 0.023*"namespace" + 0.022*"none"
INFO: topic #2 (0.171): 0.053*"method" + 0.039*"debugging" + 0.036*"foo" + 0.027*"order" + 0.025*"story" + 0.024*"frame" + 0.022*"eval" + 0.022*"page" + 0.022*"long" + 0.022*"guess"
INFO: topic #3 (0.493): 0.087*"class" + 0.067*"example" + 0.050*"course" + 0.045*"instance" + 0.027*"frame" + 0.026*"print" + 0.024*"type" + 0.021*"work" + 0.020*"magic" + 0.020*"assignment"
INFO: topic #4 (0.253): 0.071*"global" + 0.060*"answer" + 0.048*"stack" + 0.046*"result" + 0.036*"loop" + 0.030*"var" + 0.022*"filter" + 0.021*"scope" + 0.017*"globals().item" + 0.017*"each_item"
INFO: topic diff=0.465497, rho=0.231869
DEBUG: bound: at document #0
INFO: -5.972 per-word bound, 62.8 perplexity estimate based on a held-out corpus of 5 documents with 67 words
INFO: PROGRESS: pass 2, at document #50/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6961503, 0.57395154, 0.17002775, 0.48435926, 0.2733923]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.696): 0.226*"name" + 0.142*"function" + 0.092*"object" + 0.048*"value" + 0.043*"variable" + 0.027*"code" + 0.025*"attribute" + 0.016*"case" + 0.016*"local" + 0.014*"reference"
INFO: topic #1 (0.574): 0.083*"string" + 0.070*"list" + 0.061*"way" + 0.061*"module" + 0.040*"match" + 0.036*"note" + 0.036*"return" + 0.019*"content" + 0.018*"namespace" + 0.018*"none"
INFO: topic #2 (0.170): 0.070*"method" + 0.033*"debugging" + 0.031*"foo" + 0.023*"order" + 0.021*"story" + 0.021*"frame" + 0.019*"long" + 0.019*"grab" + 0.019*"deal" + 0.019*"page"
INFO: topic #3 (0.484): 0.112*"class" + 0.069*"example" + 0.042*"course" + 0.038*"instance" + 0.026*"need" + 0.023*"frame" + 0.022*"print" + 0.020*"type" + 0.018*"work" + 0.017*"magic"
INFO: topic #4 (0.273): 0.116*"global" + 0.066*"answer" + 0.035*"stack" + 0.034*"result" + 0.026*"loop" + 0.022*"var" + 0.017*"bla" + 0.017*"my_list" + 0.016*"filter" + 0.016*"scope"
INFO: topic diff=0.212646, rho=0.231869
DEBUG: bound: at document #0
INFO: -6.279 per-word bound, 77.7 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 2, at document #55/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7588241, 0.596161, 0.17676924, 0.52095926, 0.29339018]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.759): 0.217*"name" + 0.120*"function" + 0.114*"object" + 0.049*"value" + 0.040*"variable" + 0.032*"code" + 0.023*"case" + 0.020*"attribute" + 0.016*"search" + 0.016*"reference"
INFO: topic #1 (0.596): 0.072*"string" + 0.072*"list" + 0.064*"way" + 0.057*"match" + 0.052*"module" + 0.043*"note" + 0.042*"return" + 0.017*"content" + 0.016*"namespace" + 0.016*"none"
INFO: topic #2 (0.177): 0.110*"method" + 0.027*"debugging" + 0.025*"foo" + 0.019*"order" + 0.017*"story" + 0.017*"frame" + 0.015*"deal" + 0.015*"eval" + 0.015*"long" + 0.015*"grab"
INFO: topic #3 (0.521): 0.122*"class" + 0.060*"instance" + 0.058*"example" + 0.038*"print" + 0.030*"environment" + 0.028*"course" + 0.028*"track" + 0.025*"player" + 0.023*"iterator" + 0.018*"need"
INFO: topic #4 (0.293): 0.110*"global" + 0.072*"answer" + 0.042*"loop" + 0.033*"scope" + 0.027*"stack" + 0.027*"result" + 0.017*"var" + 0.014*"atribute" + 0.013*"bla" + 0.013*"my_list"
INFO: topic diff=0.244155, rho=0.231869
DEBUG: bound: at document #0
INFO: -6.857 per-word bound, 115.9 perplexity estimate based on a held-out corpus of 5 documents with 183 words
INFO: PROGRESS: pass 2, at document #60/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6926802, 0.5353244, 0.1925406, 0.55789536, 0.29848057]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.693): 0.200*"name" + 0.137*"object" + 0.112*"function" + 0.046*"code" + 0.036*"value" + 0.030*"variable" + 0.026*"source" + 0.019*"case" + 0.014*"line" + 0.013*"attribute"
INFO: topic #1 (0.535): 0.086*"way" + 0.077*"string" + 0.069*"list" + 0.057*"note" + 0.053*"module" + 0.045*"match" + 0.033*"return" + 0.026*"caller" + 0.014*"def" + 0.014*"content"
INFO: topic #2 (0.193): 0.091*"method" + 0.031*"initialization" + 0.026*"debugging" + 0.021*"frame" + 0.021*"assignent" + 0.021*"production" + 0.019*"constructor" + 0.014*"data" + 0.014*"pause" + 0.014*"recover"
INFO: topic #3 (0.558): 0.084*"class" + 0.049*"example" + 0.042*"instance" + 0.034*"frame" + 0.033*"file" + 0.030*"call" + 0.023*"work" + 0.023*"assignment" + 0.022*"retrieve" + 0.022*"="
INFO: topic #4 (0.298): 0.080*"global" + 0.052*"answer" + 0.048*"loop" + 0.044*"scope" + 0.040*"stack" + 0.025*"inspect" + 0.020*"result" + 0.019*"determine" + 0.019*"self" + 0.019*"init"
INFO: topic diff=0.670033, rho=0.231869
DEBUG: bound: at document #0
INFO: -6.297 per-word bound, 78.7 perplexity estimate based on a held-out corpus of 5 documents with 164 words
INFO: PROGRESS: pass 2, at document #65/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7894034, 0.5564618, 0.19386384, 0.57514143, 0.3026554]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.789): 0.193*"name" + 0.152*"object" + 0.091*"function" + 0.049*"value" + 0.044*"variable" + 0.038*"code" + 0.025*"reference" + 0.017*"source" + 0.016*"case" + 0.016*"attribute"
INFO: topic #1 (0.556): 0.092*"way" + 0.067*"string" + 0.062*"list" + 0.046*"namespace" + 0.046*"note" + 0.034*"module" + 0.029*"match" + 0.026*"integer" + 0.024*"reference" + 0.021*"return"
INFO: topic #2 (0.194): 0.095*"method" + 0.028*"parameter" + 0.027*"initialization" + 0.023*"debugging" + 0.019*"frame" + 0.018*"production" + 0.018*"assignent" + 0.016*"constructor" + 0.014*"https://stackoverflow.com/a/49331683/7386061" + 0.013*"refactor"
INFO: topic #3 (0.575): 0.101*"class" + 0.064*"example" + 0.042*"instance" + 0.035*"assignment" + 0.034*"print" + 0.027*"frame" + 0.027*"work" + 0.026*"file" + 0.024*"call" + 0.020*"c"
INFO: topic #4 (0.303): 0.072*"var" + 0.050*"global" + 0.044*"design" + 0.044*"scope" + 0.033*"answer" + 0.030*"loop" + 0.028*"hash" + 0.028*"choice" + 0.025*"stack" + 0.016*"inspect"
INFO: topic diff=0.487355, rho=0.231869
DEBUG: bound: at document #0
INFO: -6.165 per-word bound, 71.7 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 2, at document #70/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7665141, 0.5712528, 0.20267367, 0.6234328, 0.2799239]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.767): 0.183*"name" + 0.160*"object" + 0.081*"function" + 0.050*"code" + 0.048*"value" + 0.039*"variable" + 0.032*"reference" + 0.019*"case" + 0.015*"source" + 0.014*"attribute"
INFO: topic #1 (0.571): 0.085*"way" + 0.064*"string" + 0.051*"list" + 0.038*"garbage" + 0.038*"namespace" + 0.037*"module" + 0.037*"note" + 0.036*"reference" + 0.027*"return" + 0.023*"match"
INFO: topic #2 (0.203): 0.100*"method" + 0.038*"debugging" + 0.024*"parameter" + 0.023*"initialization" + 0.020*"version" + 0.016*"frame" + 0.016*"production" + 0.016*"assignent" + 0.014*"constructor" + 0.012*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.623): 0.180*"class" + 0.060*"instance" + 0.053*"example" + 0.025*"assignment" + 0.024*"print" + 0.021*"c" + 0.020*"retrieve" + 0.019*"frame" + 0.019*"work" + 0.019*"situation"
INFO: topic #4 (0.280): 0.066*"var" + 0.046*"global" + 0.040*"design" + 0.040*"scope" + 0.030*"answer" + 0.028*"loop" + 0.026*"hash" + 0.026*"choice" + 0.023*"stack" + 0.015*"inspect"
INFO: topic diff=0.237877, rho=0.231869
DEBUG: bound: at document #0
INFO: -6.173 per-word bound, 72.1 perplexity estimate based on a held-out corpus of 5 documents with 112 words
INFO: PROGRESS: pass 2, at document #75/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8979924, 0.64547, 0.19713537, 0.7310334, 0.2939932]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.898): 0.181*"name" + 0.163*"object" + 0.076*"function" + 0.051*"variable" + 0.048*"code" + 0.037*"value" + 0.033*"reference" + 0.023*"case" + 0.016*"source" + 0.012*"access"
INFO: topic #1 (0.645): 0.079*"way" + 0.063*"garbage" + 0.054*"namespace" + 0.054*"list" + 0.054*"module" + 0.045*"string" + 0.036*"note" + 0.027*"reference" + 0.022*"collection" + 0.019*"return"
INFO: topic #2 (0.197): 0.087*"method" + 0.054*"debugging" + 0.022*"parameter" + 0.021*"initialization" + 0.018*"version" + 0.014*"frame" + 0.014*"production" + 0.014*"assignent" + 0.013*"constructor" + 0.011*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.731): 0.145*"class" + 0.140*"instance" + 0.046*"example" + 0.042*"type" + 0.025*"print" + 0.021*"track" + 0.020*"c" + 0.018*"assignment" + 0.015*"retrieve" + 0.014*"frame"
INFO: topic #4 (0.294): 0.057*"global" + 0.053*"var" + 0.044*"answer" + 0.043*"filter" + 0.033*"design" + 0.032*"scope" + 0.022*"loop" + 0.021*"hash" + 0.021*"choice" + 0.019*"stack"
INFO: topic diff=0.335838, rho=0.231869
DEBUG: bound: at document #0
INFO: -6.693 per-word bound, 103.5 perplexity estimate based on a held-out corpus of 3 documents with 21 words
INFO: PROGRESS: pass 2, at document #78/78
DEBUG: performing inference on a chunk of 3 documents
DEBUG: 3/3 documents converged within 2000 iterations
INFO: optimized alpha [2.010925, 0.623404, 0.18959092, 0.8506714, 0.2784127]
DEBUG: updating topics
INFO: merging changes from 3 documents into a model of 78 documents
INFO: topic #0 (2.011): 0.177*"name" + 0.153*"object" + 0.084*"function" + 0.051*"code" + 0.045*"variable" + 0.033*"value" + 0.029*"reference" + 0.021*"case" + 0.018*"attribute" + 0.016*"thing"
INFO: topic #1 (0.623): 0.091*"way" + 0.058*"garbage" + 0.050*"namespace" + 0.050*"list" + 0.050*"module" + 0.042*"string" + 0.033*"note" + 0.025*"reference" + 0.021*"collection" + 0.018*"return"
INFO: topic #2 (0.190): 0.077*"method" + 0.048*"debugging" + 0.019*"parameter" + 0.018*"initialization" + 0.016*"version" + 0.013*"frame" + 0.013*"production" + 0.013*"assignent" + 0.011*"constructor" + 0.010*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.851): 0.149*"class" + 0.130*"instance" + 0.047*"print" + 0.038*"example" + 0.035*"type" + 0.031*"part" + 0.018*"track" + 0.017*"c" + 0.015*"assignment" + 0.012*"post"
INFO: topic #4 (0.278): 0.051*"global" + 0.047*"var" + 0.039*"answer" + 0.039*"filter" + 0.029*"design" + 0.029*"scope" + 0.020*"loop" + 0.019*"choice" + 0.019*"hash" + 0.017*"stack"
INFO: topic diff=0.163294, rho=0.231869
DEBUG: bound: at document #0
INFO: -5.327 per-word bound, 40.1 perplexity estimate based on a held-out corpus of 5 documents with 130 words
INFO: PROGRESS: pass 3, at document #5/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6311817, 0.60627496, 0.18257582, 0.5928006, 0.24001491]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.631): 0.169*"name" + 0.121*"object" + 0.089*"function" + 0.050*"code" + 0.050*"variable" + 0.040*"value" + 0.029*"thing" + 0.023*"attribute" + 0.020*"case" + 0.019*"language"
INFO: topic #1 (0.606): 0.091*"string" + 0.084*"list" + 0.073*"way" + 0.040*"garbage" + 0.035*"namespace" + 0.035*"module" + 0.033*"note" + 0.031*"return" + 0.018*"reference" + 0.016*"variable"
INFO: topic #2 (0.183): 0.079*"method" + 0.057*"debugging" + 0.036*"word" + 0.027*"foo" + 0.026*"order" + 0.022*"snippet" + 0.022*"drawback" + 0.014*"parameter" + 0.014*"initialization" + 0.012*"version"
INFO: topic #3 (0.593): 0.142*"class" + 0.124*"instance" + 0.045*"print" + 0.037*"example" + 0.033*"type" + 0.029*"part" + 0.017*"track" + 0.016*"c" + 0.015*"assignment" + 0.012*"post"
INFO: topic #4 (0.240): 0.045*"global" + 0.042*"var" + 0.035*"answer" + 0.034*"filter" + 0.026*"design" + 0.026*"scope" + 0.018*"loop" + 0.017*"hash" + 0.017*"choice" + 0.015*"stack"
INFO: topic diff=0.290579, rho=0.225877
DEBUG: bound: at document #0
INFO: -6.592 per-word bound, 96.4 perplexity estimate based on a held-out corpus of 5 documents with 191 words
INFO: PROGRESS: pass 3, at document #10/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.3435172, 0.49330294, 0.1999314, 0.5774629, 0.25855452]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.344): 0.172*"name" + 0.101*"function" + 0.095*"object" + 0.066*"variable" + 0.063*"code" + 0.051*"value" + 0.025*"source" + 0.024*"case" + 0.023*"thing" + 0.018*"attribute"
INFO: topic #1 (0.493): 0.098*"list" + 0.089*"string" + 0.066*"way" + 0.041*"note" + 0.036*"garbage" + 0.032*"namespace" + 0.032*"module" + 0.028*"return" + 0.017*"variable" + 0.016*"reference"
INFO: topic #2 (0.200): 0.094*"foo" + 0.092*"method" + 0.041*"word" + 0.039*"debugging" + 0.029*"initialization" + 0.027*"version" + 0.022*"frame" + 0.018*"order" + 0.015*"snippet" + 0.015*"drawback"
INFO: topic #3 (0.577): 0.075*"class" + 0.068*"instance" + 0.058*"frame" + 0.041*"example" + 0.037*"varname" + 0.032*"assignment" + 0.029*"need" + 0.029*"environment" + 0.024*"print" + 0.023*"part"
INFO: topic #4 (0.259): 0.075*"answer" + 0.052*"scope" + 0.044*"global" + 0.043*"var" + 0.027*"stack" + 0.024*"inspect" + 0.020*"filter" + 0.019*"bit" + 0.018*"var_2" + 0.018*"warning"
INFO: topic diff=0.504624, rho=0.225877
DEBUG: bound: at document #0
INFO: -6.465 per-word bound, 88.3 perplexity estimate based on a held-out corpus of 5 documents with 45 words
INFO: PROGRESS: pass 3, at document #15/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.4169183, 0.4983941, 0.18729325, 0.53261745, 0.25295258]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.417): 0.171*"name" + 0.088*"function" + 0.087*"object" + 0.082*"variable" + 0.070*"value" + 0.055*"code" + 0.025*"case" + 0.021*"source" + 0.020*"thing" + 0.018*"access"
INFO: topic #1 (0.498): 0.080*"string" + 0.077*"list" + 0.063*"way" + 0.033*"return" + 0.032*"note" + 0.029*"garbage" + 0.028*"variable" + 0.025*"content" + 0.025*"namespace" + 0.025*"module"
INFO: topic #2 (0.187): 0.084*"foo" + 0.082*"method" + 0.037*"word" + 0.035*"debugging" + 0.026*"initialization" + 0.025*"version" + 0.020*"frame" + 0.016*"order" + 0.014*"snippet" + 0.014*"drawback"
INFO: topic #3 (0.533): 0.078*"class" + 0.065*"instance" + 0.055*"frame" + 0.040*"example" + 0.036*"varname" + 0.031*"assignment" + 0.028*"need" + 0.027*"environment" + 0.023*"print" + 0.022*"wrapper"
INFO: topic #4 (0.253): 0.063*"scope" + 0.062*"answer" + 0.037*"global" + 0.036*"bit" + 0.036*"var" + 0.023*"stack" + 0.021*"inspect" + 0.017*"filter" + 0.015*"warning" + 0.015*"defining"
INFO: topic diff=0.169126, rho=0.225877
DEBUG: bound: at document #0
INFO: -5.944 per-word bound, 61.6 perplexity estimate based on a held-out corpus of 5 documents with 37 words
INFO: PROGRESS: pass 3, at document #20/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.479308, 0.523673, 0.18802778, 0.5023714, 0.28341728]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.479): 0.182*"name" + 0.093*"function" + 0.091*"variable" + 0.078*"object" + 0.078*"value" + 0.049*"code" + 0.022*"case" + 0.019*"source" + 0.018*"thing" + 0.016*"access"
INFO: topic #1 (0.524): 0.088*"list" + 0.066*"string" + 0.064*"return" + 0.052*"way" + 0.033*"namespace" + 0.033*"module" + 0.029*"variable" + 0.027*"note" + 0.025*"index" + 0.024*"garbage"
INFO: topic #2 (0.188): 0.115*"method" + 0.070*"foo" + 0.031*"frame" + 0.031*"word" + 0.029*"debugging" + 0.021*"initialization" + 0.020*"version" + 0.014*"order" + 0.012*"snippet" + 0.012*"drawback"
INFO: topic #3 (0.502): 0.074*"class" + 0.062*"instance" + 0.056*"frame" + 0.038*"example" + 0.034*"varname" + 0.029*"assignment" + 0.026*"need" + 0.026*"environment" + 0.022*"print" + 0.021*"wrapper"
INFO: topic #4 (0.283): 0.087*"answer" + 0.069*"scope" + 0.048*"global" + 0.047*"var" + 0.028*"bit" + 0.023*"result" + 0.019*"variation" + 0.018*"stack" + 0.016*"inspect" + 0.013*"filter"
INFO: topic diff=0.125917, rho=0.225877
DEBUG: bound: at document #0
INFO: -6.621 per-word bound, 98.5 perplexity estimate based on a held-out corpus of 5 documents with 69 words
INFO: PROGRESS: pass 3, at document #25/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.5750196, 0.519608, 0.18632679, 0.5445115, 0.2904295]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.575): 0.159*"name" + 0.123*"function" + 0.093*"variable" + 0.074*"object" + 0.069*"value" + 0.045*"code" + 0.020*"local" + 0.018*"case" + 0.016*"source" + 0.015*"thing"
INFO: topic #1 (0.520): 0.075*"string" + 0.069*"list" + 0.063*"return" + 0.053*"way" + 0.028*"variable" + 0.026*"namespace" + 0.026*"module" + 0.021*"note" + 0.020*"index" + 0.019*"garbage"
INFO: topic #2 (0.186): 0.097*"method" + 0.059*"foo" + 0.050*"debugging" + 0.026*"frame" + 0.026*"word" + 0.018*"initialization" + 0.018*"version" + 0.012*"order" + 0.010*"snippet" + 0.010*"drawback"
INFO: topic #3 (0.545): 0.068*"class" + 0.055*"example" + 0.050*"instance" + 0.045*"frame" + 0.032*"call" + 0.029*"need" + 0.027*"varname" + 0.027*"type" + 0.026*"print" + 0.024*"assignment"
INFO: topic #4 (0.290): 0.077*"var" + 0.069*"answer" + 0.058*"global" + 0.054*"scope" + 0.033*"inspect" + 0.022*"bit" + 0.020*"process" + 0.020*"idea" + 0.018*"result" + 0.015*"variation"
INFO: topic diff=0.217138, rho=0.225877
DEBUG: bound: at document #0
INFO: -6.390 per-word bound, 83.9 perplexity estimate based on a held-out corpus of 5 documents with 89 words
INFO: PROGRESS: pass 3, at document #30/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6258123, 0.54152125, 0.1847192, 0.57580423, 0.29347876]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.626): 0.163*"name" + 0.113*"function" + 0.086*"variable" + 0.068*"object" + 0.067*"code" + 0.054*"value" + 0.031*"source" + 0.020*"local" + 0.013*"case" + 0.012*"reference"
INFO: topic #1 (0.542): 0.085*"list" + 0.075*"string" + 0.054*"module" + 0.051*"way" + 0.046*"return" + 0.031*"namespace" + 0.024*"integer" + 0.022*"variable" + 0.021*"match" + 0.016*"reference"
INFO: topic #2 (0.185): 0.078*"method" + 0.048*"foo" + 0.040*"debugging" + 0.030*"constructor" + 0.026*"sorcery" + 0.021*"frame" + 0.021*"word" + 0.019*"kind" + 0.015*"initialization" + 0.014*"version"
INFO: topic #3 (0.576): 0.076*"class" + 0.065*"example" + 0.043*"instance" + 0.039*"frame" + 0.027*"call" + 0.026*"retrieve" + 0.025*"need" + 0.023*"varname" + 0.023*"type" + 0.023*"package"
INFO: topic #4 (0.293): 0.068*"global" + 0.063*"var" + 0.056*"answer" + 0.054*"stack" + 0.044*"scope" + 0.027*"inspect" + 0.018*"bit" + 0.017*"python3" + 0.017*"idea" + 0.017*"process"
INFO: topic diff=0.281257, rho=0.225877
DEBUG: bound: at document #0
INFO: -5.283 per-word bound, 38.9 perplexity estimate based on a held-out corpus of 5 documents with 114 words
INFO: PROGRESS: pass 3, at document #35/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7689594, 0.58561385, 0.17335229, 0.5816833, 0.26623687]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.769): 0.221*"name" + 0.106*"object" + 0.102*"function" + 0.067*"variable" + 0.045*"value" + 0.045*"code" + 0.022*"local" + 0.021*"source" + 0.017*"reference" + 0.013*"case"
INFO: topic #1 (0.586): 0.131*"list" + 0.074*"string" + 0.071*"way" + 0.044*"module" + 0.039*"return" + 0.039*"namespace" + 0.019*"index" + 0.018*"define" + 0.017*"element" + 0.016*"time"
INFO: topic #2 (0.173): 0.067*"method" + 0.041*"foo" + 0.035*"debugging" + 0.026*"constructor" + 0.022*"sorcery" + 0.019*"frame" + 0.019*"word" + 0.016*"kind" + 0.013*"initialization" + 0.013*"version"
INFO: topic #3 (0.582): 0.094*"class" + 0.075*"example" + 0.046*"instance" + 0.033*"frame" + 0.027*"assignment" + 0.023*"call" + 0.022*"retrieve" + 0.021*"course" + 0.021*"need" + 0.020*"varname"
INFO: topic #4 (0.266): 0.060*"global" + 0.056*"var" + 0.050*"answer" + 0.048*"stack" + 0.039*"scope" + 0.024*"inspect" + 0.016*"bit" + 0.016*"python3" + 0.015*"process" + 0.015*"idea"
INFO: topic diff=0.301483, rho=0.225877
DEBUG: bound: at document #0
INFO: -7.325 per-word bound, 160.4 perplexity estimate based on a held-out corpus of 5 documents with 32 words
INFO: PROGRESS: pass 3, at document #40/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.5299273, 0.5447641, 0.17088515, 0.5551755, 0.28788632]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.530): 0.209*"name" + 0.114*"function" + 0.103*"object" + 0.062*"variable" + 0.042*"value" + 0.042*"code" + 0.023*"case" + 0.020*"local" + 0.019*"source" + 0.016*"reference"
INFO: topic #1 (0.545): 0.119*"list" + 0.067*"string" + 0.064*"way" + 0.062*"module" + 0.035*"return" + 0.035*"namespace" + 0.020*"note" + 0.017*"index" + 0.017*"define" + 0.015*"element"
INFO: topic #2 (0.171): 0.065*"foo" + 0.055*"method" + 0.029*"debugging" + 0.022*"constructor" + 0.019*"sorcery" + 0.016*"frame" + 0.016*"word" + 0.014*"kind" + 0.011*"initialization" + 0.011*"version"
INFO: topic #3 (0.555): 0.105*"class" + 0.066*"example" + 0.040*"instance" + 0.030*"course" + 0.029*"frame" + 0.028*"type" + 0.025*"work" + 0.024*"assignment" + 0.020*"call" + 0.019*"retrieve"
INFO: topic #4 (0.288): 0.074*"answer" + 0.061*"global" + 0.044*"loop" + 0.037*"var" + 0.032*"stack" + 0.030*"result" + 0.026*"scope" + 0.026*"filter" + 0.021*"each_item" + 0.021*"globals().item"
INFO: topic diff=0.170980, rho=0.225877
DEBUG: bound: at document #0
INFO: -6.121 per-word bound, 69.6 perplexity estimate based on a held-out corpus of 5 documents with 133 words
INFO: PROGRESS: pass 3, at document #45/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6648797, 0.5632404, 0.1851906, 0.53072333, 0.2824984]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.665): 0.226*"name" + 0.133*"function" + 0.108*"object" + 0.054*"value" + 0.045*"variable" + 0.028*"code" + 0.019*"case" + 0.019*"attribute" + 0.016*"reference" + 0.014*"local"
INFO: topic #1 (0.563): 0.085*"list" + 0.078*"string" + 0.050*"way" + 0.049*"module" + 0.036*"match" + 0.032*"return" + 0.032*"note" + 0.023*"content" + 0.023*"namespace" + 0.022*"none"
INFO: topic #2 (0.185): 0.054*"method" + 0.039*"debugging" + 0.037*"foo" + 0.027*"order" + 0.026*"frame" + 0.025*"story" + 0.022*"guess" + 0.022*"traverse" + 0.022*"basestring" + 0.022*"grab"
INFO: topic #3 (0.531): 0.087*"class" + 0.067*"example" + 0.049*"course" + 0.045*"instance" + 0.027*"frame" + 0.026*"print" + 0.024*"type" + 0.021*"work" + 0.020*"assignment" + 0.020*"magic"
INFO: topic #4 (0.282): 0.071*"global" + 0.061*"answer" + 0.047*"stack" + 0.046*"result" + 0.036*"loop" + 0.031*"var" + 0.022*"scope" + 0.021*"filter" + 0.017*"globals().item" + 0.017*"each_item"
INFO: topic diff=0.436838, rho=0.225877
DEBUG: bound: at document #0
INFO: -5.950 per-word bound, 61.8 perplexity estimate based on a held-out corpus of 5 documents with 67 words
INFO: PROGRESS: pass 3, at document #50/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8359106, 0.609233, 0.18372908, 0.5215236, 0.30410555]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.836): 0.228*"name" + 0.143*"function" + 0.092*"object" + 0.048*"value" + 0.045*"variable" + 0.027*"code" + 0.025*"attribute" + 0.016*"case" + 0.016*"local" + 0.013*"reference"
INFO: topic #1 (0.609): 0.084*"string" + 0.071*"list" + 0.061*"way" + 0.061*"module" + 0.039*"match" + 0.036*"return" + 0.036*"note" + 0.019*"content" + 0.019*"namespace" + 0.018*"none"
INFO: topic #2 (0.184): 0.071*"method" + 0.033*"debugging" + 0.032*"foo" + 0.023*"order" + 0.023*"frame" + 0.022*"story" + 0.019*"eval" + 0.019*"grab" + 0.019*"guess" + 0.019*"basestring"
INFO: topic #3 (0.522): 0.112*"class" + 0.069*"example" + 0.041*"course" + 0.038*"instance" + 0.026*"need" + 0.023*"frame" + 0.022*"print" + 0.020*"type" + 0.018*"work" + 0.017*"assignment"
INFO: topic #4 (0.304): 0.115*"global" + 0.066*"answer" + 0.035*"stack" + 0.034*"result" + 0.027*"loop" + 0.023*"var" + 0.016*"scope" + 0.016*"filter" + 0.016*"bla" + 0.016*"my_list"
INFO: topic diff=0.202117, rho=0.225877
DEBUG: bound: at document #0
INFO: -6.242 per-word bound, 75.7 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 3, at document #55/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8965033, 0.6295054, 0.19038877, 0.562656, 0.32432753]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.897): 0.219*"name" + 0.121*"function" + 0.113*"object" + 0.049*"value" + 0.042*"variable" + 0.032*"code" + 0.022*"case" + 0.020*"attribute" + 0.017*"search" + 0.015*"reference"
INFO: topic #1 (0.630): 0.073*"string" + 0.073*"list" + 0.065*"way" + 0.057*"match" + 0.053*"module" + 0.043*"return" + 0.043*"note" + 0.017*"content" + 0.017*"namespace" + 0.016*"none"
INFO: topic #2 (0.190): 0.109*"method" + 0.027*"debugging" + 0.026*"foo" + 0.019*"order" + 0.019*"frame" + 0.018*"story" + 0.016*"deal" + 0.016*"long" + 0.016*"grab" + 0.016*"guess"
INFO: topic #3 (0.563): 0.121*"class" + 0.060*"instance" + 0.058*"example" + 0.038*"print" + 0.029*"environment" + 0.028*"course" + 0.027*"track" + 0.026*"player" + 0.023*"iterator" + 0.018*"need"
INFO: topic #4 (0.324): 0.110*"global" + 0.072*"answer" + 0.042*"loop" + 0.033*"scope" + 0.028*"stack" + 0.027*"result" + 0.018*"var" + 0.014*"atribute" + 0.013*"filter" + 0.013*"bla"
INFO: topic diff=0.230939, rho=0.225877
DEBUG: bound: at document #0
INFO: -6.803 per-word bound, 111.6 perplexity estimate based on a held-out corpus of 5 documents with 183 words
INFO: PROGRESS: pass 3, at document #60/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8015069, 0.5619869, 0.20646232, 0.596844, 0.32617533]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.802): 0.203*"name" + 0.137*"object" + 0.113*"function" + 0.046*"code" + 0.037*"value" + 0.032*"variable" + 0.025*"source" + 0.019*"case" + 0.014*"line" + 0.013*"attribute"
INFO: topic #1 (0.562): 0.086*"way" + 0.078*"string" + 0.070*"list" + 0.057*"note" + 0.054*"module" + 0.045*"match" + 0.034*"return" + 0.029*"caller" + 0.014*"content" + 0.013*"namespace"
INFO: topic #2 (0.206): 0.088*"method" + 0.030*"initialization" + 0.025*"debugging" + 0.023*"production" + 0.023*"assignent" + 0.023*"frame" + 0.018*"constructor" + 0.014*"parameter" + 0.014*"refactor" + 0.014*"data"
INFO: topic #3 (0.597): 0.085*"class" + 0.049*"example" + 0.042*"instance" + 0.033*"frame" + 0.033*"file" + 0.030*"call" + 0.023*"work" + 0.023*"assignment" + 0.022*"retrieve" + 0.021*"="
INFO: topic #4 (0.326): 0.081*"global" + 0.053*"answer" + 0.050*"loop" + 0.044*"scope" + 0.040*"stack" + 0.025*"inspect" + 0.020*"result" + 0.019*"self" + 0.019*"dimension" + 0.019*"init"
INFO: topic diff=0.633785, rho=0.225877
DEBUG: bound: at document #0
INFO: -6.233 per-word bound, 75.2 perplexity estimate based on a held-out corpus of 5 documents with 164 words
INFO: PROGRESS: pass 3, at document #65/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8823897, 0.5804313, 0.20669393, 0.6082223, 0.3289681]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.882): 0.196*"name" + 0.152*"object" + 0.094*"function" + 0.049*"value" + 0.045*"variable" + 0.038*"code" + 0.022*"reference" + 0.017*"source" + 0.016*"case" + 0.016*"attribute"
INFO: topic #1 (0.580): 0.092*"way" + 0.067*"string" + 0.063*"list" + 0.046*"namespace" + 0.045*"note" + 0.034*"module" + 0.032*"reference" + 0.029*"match" + 0.026*"integer" + 0.022*"return"
INFO: topic #2 (0.207): 0.093*"method" + 0.028*"parameter" + 0.026*"initialization" + 0.023*"debugging" + 0.021*"production" + 0.021*"assignent" + 0.020*"frame" + 0.016*"constructor" + 0.013*"https://stackoverflow.com/a/49331683/7386061" + 0.012*"base"
INFO: topic #3 (0.608): 0.102*"class" + 0.065*"example" + 0.042*"instance" + 0.035*"assignment" + 0.034*"print" + 0.027*"work" + 0.026*"frame" + 0.026*"file" + 0.024*"call" + 0.024*"c"
INFO: topic #4 (0.329): 0.071*"var" + 0.050*"global" + 0.046*"design" + 0.043*"scope" + 0.033*"answer" + 0.031*"loop" + 0.030*"hash" + 0.030*"choice" + 0.025*"stack" + 0.016*"inspect"
INFO: topic diff=0.461159, rho=0.225877
DEBUG: bound: at document #0
INFO: -6.115 per-word bound, 69.3 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 3, at document #70/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8395418, 0.59438354, 0.2150943, 0.6553588, 0.30307952]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.840): 0.188*"name" + 0.161*"object" + 0.084*"function" + 0.050*"code" + 0.048*"value" + 0.041*"variable" + 0.028*"reference" + 0.019*"case" + 0.015*"source" + 0.014*"attribute"
INFO: topic #1 (0.594): 0.084*"way" + 0.064*"string" + 0.051*"list" + 0.045*"reference" + 0.039*"garbage" + 0.037*"module" + 0.037*"namespace" + 0.037*"note" + 0.027*"return" + 0.023*"match"
INFO: topic #2 (0.215): 0.097*"method" + 0.037*"debugging" + 0.024*"parameter" + 0.023*"initialization" + 0.019*"version" + 0.018*"production" + 0.018*"assignent" + 0.018*"frame" + 0.014*"constructor" + 0.012*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.655): 0.178*"class" + 0.060*"instance" + 0.053*"example" + 0.025*"assignment" + 0.024*"c" + 0.024*"print" + 0.021*"situation" + 0.020*"retrieve" + 0.019*"work" + 0.019*"frame"
INFO: topic #4 (0.303): 0.065*"var" + 0.046*"global" + 0.042*"design" + 0.040*"scope" + 0.030*"answer" + 0.028*"loop" + 0.028*"choice" + 0.028*"hash" + 0.023*"stack" + 0.015*"inspect"
INFO: topic diff=0.225463, rho=0.225877
DEBUG: bound: at document #0
INFO: -6.142 per-word bound, 70.6 perplexity estimate based on a held-out corpus of 5 documents with 112 words
INFO: PROGRESS: pass 3, at document #75/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.965526, 0.6713382, 0.20873456, 0.76380146, 0.31575596]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.966): 0.185*"name" + 0.164*"object" + 0.078*"function" + 0.052*"variable" + 0.048*"code" + 0.038*"value" + 0.028*"reference" + 0.023*"case" + 0.016*"source" + 0.012*"access"
INFO: topic #1 (0.671): 0.078*"way" + 0.063*"garbage" + 0.054*"list" + 0.053*"module" + 0.053*"namespace" + 0.046*"string" + 0.036*"reference" + 0.035*"note" + 0.022*"collection" + 0.020*"return"
INFO: topic #2 (0.209): 0.086*"method" + 0.053*"debugging" + 0.022*"parameter" + 0.020*"initialization" + 0.017*"version" + 0.016*"production" + 0.016*"assignent" + 0.016*"frame" + 0.012*"constructor" + 0.011*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.764): 0.145*"class" + 0.138*"instance" + 0.046*"example" + 0.041*"type" + 0.025*"print" + 0.024*"c" + 0.021*"track" + 0.018*"assignment" + 0.016*"situation" + 0.015*"retrieve"
INFO: topic #4 (0.316): 0.057*"global" + 0.053*"var" + 0.044*"answer" + 0.042*"filter" + 0.035*"design" + 0.032*"scope" + 0.023*"loop" + 0.023*"hash" + 0.023*"choice" + 0.019*"stack"
INFO: topic diff=0.317693, rho=0.225877
DEBUG: bound: at document #0
INFO: -6.664 per-word bound, 101.4 perplexity estimate based on a held-out corpus of 3 documents with 21 words
INFO: PROGRESS: pass 3, at document #78/78
DEBUG: performing inference on a chunk of 3 documents
DEBUG: 3/3 documents converged within 2000 iterations
INFO: optimized alpha [2.075542, 0.64680725, 0.20069447, 0.8832485, 0.29875147]
DEBUG: updating topics
INFO: merging changes from 3 documents into a model of 78 documents
INFO: topic #0 (2.076): 0.181*"name" + 0.154*"object" + 0.086*"function" + 0.051*"code" + 0.047*"variable" + 0.034*"value" + 0.025*"reference" + 0.021*"case" + 0.018*"attribute" + 0.016*"thing"
INFO: topic #1 (0.647): 0.090*"way" + 0.059*"garbage" + 0.050*"list" + 0.050*"module" + 0.049*"namespace" + 0.042*"string" + 0.033*"reference" + 0.033*"note" + 0.020*"collection" + 0.018*"return"
INFO: topic #2 (0.201): 0.076*"method" + 0.047*"debugging" + 0.020*"parameter" + 0.018*"initialization" + 0.015*"version" + 0.015*"production" + 0.015*"assignent" + 0.014*"frame" + 0.011*"constructor" + 0.010*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.883): 0.148*"class" + 0.129*"instance" + 0.047*"print" + 0.039*"example" + 0.035*"type" + 0.030*"part" + 0.020*"c" + 0.018*"track" + 0.015*"assignment" + 0.013*"situation"
INFO: topic #4 (0.299): 0.051*"global" + 0.047*"var" + 0.039*"answer" + 0.038*"filter" + 0.031*"design" + 0.029*"scope" + 0.021*"loop" + 0.020*"choice" + 0.020*"hash" + 0.017*"stack"
INFO: topic diff=0.155740, rho=0.225877
DEBUG: bound: at document #0
INFO: -5.313 per-word bound, 39.7 perplexity estimate based on a held-out corpus of 5 documents with 130 words
INFO: PROGRESS: pass 4, at document #5/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7212073, 0.62989, 0.193073, 0.6246811, 0.25734648]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.721): 0.172*"name" + 0.122*"object" + 0.090*"function" + 0.053*"variable" + 0.050*"code" + 0.040*"value" + 0.029*"thing" + 0.023*"attribute" + 0.020*"case" + 0.019*"language"
INFO: topic #1 (0.630): 0.090*"string" + 0.083*"list" + 0.073*"way" + 0.042*"garbage" + 0.035*"module" + 0.035*"namespace" + 0.033*"note" + 0.032*"return" + 0.024*"reference" + 0.015*"collection"
INFO: topic #2 (0.193): 0.078*"method" + 0.057*"debugging" + 0.029*"word" + 0.027*"foo" + 0.026*"order" + 0.022*"drawback" + 0.022*"snippet" + 0.015*"parameter" + 0.014*"initialization" + 0.012*"version"
INFO: topic #3 (0.625): 0.142*"class" + 0.124*"instance" + 0.045*"print" + 0.037*"example" + 0.033*"type" + 0.029*"part" + 0.019*"c" + 0.017*"track" + 0.015*"assignment" + 0.013*"situation"
INFO: topic #4 (0.257): 0.045*"global" + 0.042*"var" + 0.035*"answer" + 0.034*"filter" + 0.028*"design" + 0.026*"scope" + 0.019*"loop" + 0.018*"hash" + 0.018*"choice" + 0.015*"stack"
INFO: topic diff=0.275985, rho=0.220326
DEBUG: bound: at document #0
INFO: -6.545 per-word bound, 93.4 perplexity estimate based on a held-out corpus of 5 documents with 191 words
INFO: PROGRESS: pass 4, at document #10/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.4103589, 0.51048404, 0.20964658, 0.6051555, 0.27511677]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.410): 0.174*"name" + 0.102*"function" + 0.096*"object" + 0.068*"variable" + 0.062*"code" + 0.050*"value" + 0.024*"source" + 0.024*"case" + 0.023*"thing" + 0.018*"attribute"
INFO: topic #1 (0.510): 0.097*"list" + 0.088*"string" + 0.066*"way" + 0.040*"note" + 0.038*"garbage" + 0.032*"module" + 0.032*"namespace" + 0.029*"return" + 0.021*"reference" + 0.013*"collection"
INFO: topic #2 (0.210): 0.093*"foo" + 0.092*"method" + 0.040*"debugging" + 0.033*"word" + 0.029*"initialization" + 0.027*"version" + 0.024*"frame" + 0.018*"order" + 0.015*"drawback" + 0.015*"snippet"
INFO: topic #3 (0.605): 0.076*"class" + 0.068*"instance" + 0.057*"frame" + 0.041*"example" + 0.037*"varname" + 0.032*"assignment" + 0.028*"need" + 0.028*"environment" + 0.024*"print" + 0.023*"part"
INFO: topic #4 (0.275): 0.074*"answer" + 0.051*"scope" + 0.044*"global" + 0.043*"var" + 0.027*"stack" + 0.024*"inspect" + 0.020*"filter" + 0.019*"bit" + 0.018*"var_1" + 0.018*"defining"
INFO: topic diff=0.477020, rho=0.220326
DEBUG: bound: at document #0
INFO: -6.456 per-word bound, 87.8 perplexity estimate based on a held-out corpus of 5 documents with 45 words
INFO: PROGRESS: pass 4, at document #15/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.4927899, 0.5155149, 0.19665809, 0.5592232, 0.26909426]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.493): 0.172*"name" + 0.089*"function" + 0.088*"object" + 0.085*"variable" + 0.069*"value" + 0.054*"code" + 0.025*"case" + 0.021*"source" + 0.020*"thing" + 0.018*"access"
INFO: topic #1 (0.516): 0.081*"string" + 0.077*"list" + 0.064*"way" + 0.034*"return" + 0.032*"note" + 0.030*"garbage" + 0.025*"module" + 0.025*"namespace" + 0.025*"content" + 0.023*"input"
INFO: topic #2 (0.197): 0.084*"foo" + 0.083*"method" + 0.036*"debugging" + 0.030*"word" + 0.026*"initialization" + 0.024*"version" + 0.022*"frame" + 0.016*"order" + 0.014*"drawback" + 0.014*"snippet"
INFO: topic #3 (0.559): 0.079*"class" + 0.065*"instance" + 0.054*"frame" + 0.040*"example" + 0.035*"varname" + 0.031*"assignment" + 0.027*"need" + 0.027*"environment" + 0.023*"print" + 0.022*"part"
INFO: topic #4 (0.269): 0.062*"scope" + 0.061*"answer" + 0.037*"global" + 0.036*"var" + 0.035*"bit" + 0.023*"stack" + 0.020*"inspect" + 0.017*"filter" + 0.015*"defining" + 0.015*"var_2"
INFO: topic diff=0.160347, rho=0.220326
DEBUG: bound: at document #0
INFO: -5.932 per-word bound, 61.1 perplexity estimate based on a held-out corpus of 5 documents with 37 words
INFO: PROGRESS: pass 4, at document #20/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.5565107, 0.5396868, 0.19731906, 0.5269082, 0.3001368]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.557): 0.183*"name" + 0.095*"variable" + 0.094*"function" + 0.079*"object" + 0.077*"value" + 0.049*"code" + 0.022*"case" + 0.019*"source" + 0.018*"thing" + 0.016*"access"
INFO: topic #1 (0.540): 0.088*"list" + 0.067*"string" + 0.064*"return" + 0.053*"way" + 0.033*"module" + 0.033*"namespace" + 0.027*"note" + 0.025*"garbage" + 0.025*"index" + 0.021*"content"
INFO: topic #2 (0.197): 0.115*"method" + 0.069*"foo" + 0.032*"frame" + 0.030*"debugging" + 0.025*"word" + 0.022*"initialization" + 0.021*"version" + 0.014*"order" + 0.012*"drawback" + 0.012*"snippet"
INFO: topic #3 (0.527): 0.075*"class" + 0.062*"instance" + 0.055*"frame" + 0.038*"example" + 0.034*"varname" + 0.029*"assignment" + 0.026*"need" + 0.026*"environment" + 0.022*"print" + 0.021*"part"
INFO: topic #4 (0.300): 0.086*"answer" + 0.068*"scope" + 0.048*"global" + 0.047*"var" + 0.027*"bit" + 0.023*"result" + 0.019*"variation" + 0.018*"stack" + 0.016*"inspect" + 0.013*"filter"
INFO: topic diff=0.118120, rho=0.220326
DEBUG: bound: at document #0
INFO: -6.599 per-word bound, 96.9 perplexity estimate based on a held-out corpus of 5 documents with 69 words
INFO: PROGRESS: pass 4, at document #25/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6504184, 0.5348984, 0.19525981, 0.56886226, 0.30681324]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.650): 0.161*"name" + 0.123*"function" + 0.097*"variable" + 0.075*"object" + 0.068*"value" + 0.045*"code" + 0.020*"local" + 0.018*"case" + 0.016*"source" + 0.015*"thing"
INFO: topic #1 (0.535): 0.076*"string" + 0.070*"list" + 0.063*"return" + 0.054*"way" + 0.026*"module" + 0.026*"namespace" + 0.022*"note" + 0.020*"garbage" + 0.020*"index" + 0.018*"define"
INFO: topic #2 (0.195): 0.097*"method" + 0.059*"foo" + 0.050*"debugging" + 0.028*"frame" + 0.022*"word" + 0.019*"initialization" + 0.018*"version" + 0.012*"order" + 0.010*"snippet" + 0.010*"drawback"
INFO: topic #3 (0.569): 0.069*"class" + 0.055*"example" + 0.050*"instance" + 0.045*"frame" + 0.031*"call" + 0.029*"need" + 0.027*"varname" + 0.027*"type" + 0.026*"print" + 0.024*"assignment"
INFO: topic #4 (0.307): 0.076*"var" + 0.068*"answer" + 0.058*"global" + 0.054*"scope" + 0.032*"inspect" + 0.022*"bit" + 0.020*"idea" + 0.020*"process" + 0.018*"result" + 0.015*"variation"
INFO: topic diff=0.204827, rho=0.220326
DEBUG: bound: at document #0
INFO: -6.354 per-word bound, 81.8 perplexity estimate based on a held-out corpus of 5 documents with 89 words
INFO: PROGRESS: pass 4, at document #30/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6967986, 0.55546045, 0.19330677, 0.59823215, 0.3088929]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.697): 0.164*"name" + 0.113*"function" + 0.089*"variable" + 0.069*"object" + 0.066*"code" + 0.054*"value" + 0.030*"source" + 0.019*"local" + 0.013*"case" + 0.011*"thing"
INFO: topic #1 (0.555): 0.085*"list" + 0.075*"string" + 0.054*"module" + 0.051*"way" + 0.046*"return" + 0.031*"namespace" + 0.024*"integer" + 0.021*"reference" + 0.021*"match" + 0.016*"note"
INFO: topic #2 (0.193): 0.079*"method" + 0.048*"foo" + 0.041*"debugging" + 0.030*"constructor" + 0.025*"sorcery" + 0.023*"frame" + 0.018*"kind" + 0.018*"word" + 0.015*"initialization" + 0.015*"version"
INFO: topic #3 (0.598): 0.077*"class" + 0.065*"example" + 0.043*"instance" + 0.038*"frame" + 0.027*"call" + 0.026*"retrieve" + 0.025*"need" + 0.024*"varname" + 0.023*"type" + 0.023*"package"
INFO: topic #4 (0.309): 0.067*"global" + 0.062*"var" + 0.056*"answer" + 0.053*"stack" + 0.044*"scope" + 0.027*"inspect" + 0.018*"bit" + 0.017*"python3" + 0.016*"process" + 0.016*"idea"
INFO: topic diff=0.265272, rho=0.220326
DEBUG: bound: at document #0
INFO: -5.264 per-word bound, 38.4 perplexity estimate based on a held-out corpus of 5 documents with 114 words
INFO: PROGRESS: pass 4, at document #35/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8384755, 0.60059047, 0.18139711, 0.60240585, 0.2800816]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.838): 0.222*"name" + 0.106*"object" + 0.103*"function" + 0.070*"variable" + 0.046*"value" + 0.045*"code" + 0.022*"local" + 0.021*"source" + 0.015*"reference" + 0.013*"case"
INFO: topic #1 (0.601): 0.130*"list" + 0.074*"string" + 0.071*"way" + 0.044*"module" + 0.039*"return" + 0.039*"namespace" + 0.019*"index" + 0.018*"define" + 0.017*"element" + 0.017*"time"
INFO: topic #2 (0.181): 0.068*"method" + 0.042*"foo" + 0.035*"debugging" + 0.026*"constructor" + 0.022*"sorcery" + 0.020*"frame" + 0.016*"kind" + 0.016*"word" + 0.014*"initialization" + 0.013*"version"
INFO: topic #3 (0.602): 0.094*"class" + 0.074*"example" + 0.047*"instance" + 0.033*"frame" + 0.027*"assignment" + 0.023*"call" + 0.022*"retrieve" + 0.021*"need" + 0.021*"course" + 0.020*"varname"
INFO: topic #4 (0.280): 0.060*"global" + 0.056*"var" + 0.050*"answer" + 0.047*"stack" + 0.039*"scope" + 0.024*"inspect" + 0.016*"bit" + 0.016*"python3" + 0.015*"idea" + 0.015*"process"
INFO: topic diff=0.288761, rho=0.220326
DEBUG: bound: at document #0
INFO: -7.295 per-word bound, 157.0 perplexity estimate based on a held-out corpus of 5 documents with 32 words
INFO: PROGRESS: pass 4, at document #40/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.5937527, 0.5587226, 0.17855877, 0.5745101, 0.30189732]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.594): 0.210*"name" + 0.115*"function" + 0.103*"object" + 0.064*"variable" + 0.042*"value" + 0.042*"code" + 0.022*"case" + 0.020*"local" + 0.019*"source" + 0.014*"reference"
INFO: topic #1 (0.559): 0.118*"list" + 0.068*"string" + 0.064*"way" + 0.062*"module" + 0.036*"return" + 0.035*"namespace" + 0.020*"note" + 0.017*"index" + 0.016*"define" + 0.016*"element"
INFO: topic #2 (0.179): 0.064*"foo" + 0.056*"method" + 0.029*"debugging" + 0.022*"constructor" + 0.019*"sorcery" + 0.017*"frame" + 0.014*"kind" + 0.013*"word" + 0.012*"initialization" + 0.011*"version"
INFO: topic #3 (0.575): 0.105*"class" + 0.065*"example" + 0.041*"instance" + 0.030*"course" + 0.029*"frame" + 0.028*"type" + 0.025*"work" + 0.024*"assignment" + 0.020*"call" + 0.019*"retrieve"
INFO: topic #4 (0.302): 0.074*"answer" + 0.061*"global" + 0.043*"loop" + 0.038*"var" + 0.032*"stack" + 0.029*"result" + 0.027*"scope" + 0.026*"filter" + 0.021*"globals().item" + 0.021*"each_item"
INFO: topic diff=0.165324, rho=0.220326
DEBUG: bound: at document #0
INFO: -6.086 per-word bound, 67.9 perplexity estimate based on a held-out corpus of 5 documents with 133 words
INFO: PROGRESS: pass 4, at document #45/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7188331, 0.576512, 0.19265914, 0.54698646, 0.29481107]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.719): 0.227*"name" + 0.133*"function" + 0.108*"object" + 0.054*"value" + 0.048*"variable" + 0.028*"code" + 0.019*"case" + 0.019*"attribute" + 0.014*"reference" + 0.014*"local"
INFO: topic #1 (0.577): 0.085*"list" + 0.078*"string" + 0.050*"way" + 0.049*"module" + 0.035*"match" + 0.032*"return" + 0.031*"note" + 0.023*"content" + 0.023*"test_function" + 0.023*"namespace"
INFO: topic #2 (0.193): 0.055*"method" + 0.039*"debugging" + 0.037*"foo" + 0.027*"frame" + 0.027*"order" + 0.025*"story" + 0.022*"basestring" + 0.022*"deal" + 0.022*"long" + 0.022*"traverse"
INFO: topic #3 (0.547): 0.088*"class" + 0.066*"example" + 0.048*"course" + 0.046*"instance" + 0.027*"frame" + 0.026*"print" + 0.024*"type" + 0.021*"work" + 0.020*"assignment" + 0.020*"magic"
INFO: topic #4 (0.295): 0.071*"global" + 0.061*"answer" + 0.047*"stack" + 0.045*"result" + 0.036*"loop" + 0.031*"var" + 0.022*"scope" + 0.021*"filter" + 0.017*"globals().item" + 0.017*"each_item"
INFO: topic diff=0.415724, rho=0.220326
DEBUG: bound: at document #0
INFO: -5.933 per-word bound, 61.1 perplexity estimate based on a held-out corpus of 5 documents with 67 words
INFO: PROGRESS: pass 4, at document #50/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8926286, 0.62003374, 0.1909691, 0.5375526, 0.31635386]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.893): 0.228*"name" + 0.143*"function" + 0.092*"object" + 0.048*"value" + 0.047*"variable" + 0.027*"code" + 0.024*"attribute" + 0.016*"case" + 0.016*"local" + 0.012*"argument"
INFO: topic #1 (0.620): 0.084*"string" + 0.071*"list" + 0.061*"way" + 0.060*"module" + 0.039*"match" + 0.037*"return" + 0.036*"note" + 0.019*"content" + 0.019*"test_function" + 0.019*"namespace"
INFO: topic #2 (0.191): 0.071*"method" + 0.033*"debugging" + 0.032*"foo" + 0.023*"frame" + 0.023*"order" + 0.022*"story" + 0.019*"page" + 0.019*"basestring" + 0.019*"grab" + 0.019*"traverse"
INFO: topic #3 (0.538): 0.111*"class" + 0.068*"example" + 0.040*"course" + 0.039*"instance" + 0.026*"need" + 0.023*"frame" + 0.022*"print" + 0.020*"type" + 0.018*"work" + 0.017*"assignment"
INFO: topic #4 (0.316): 0.114*"global" + 0.066*"answer" + 0.035*"stack" + 0.034*"result" + 0.027*"loop" + 0.024*"var" + 0.017*"scope" + 0.016*"filter" + 0.016*"my_list" + 0.016*"bla"
INFO: topic diff=0.193762, rho=0.220326
DEBUG: bound: at document #0
INFO: -6.216 per-word bound, 74.4 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 4, at document #55/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9518864, 0.6399373, 0.1974714, 0.581475, 0.33621585]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.952): 0.220*"name" + 0.122*"function" + 0.113*"object" + 0.049*"value" + 0.044*"variable" + 0.032*"code" + 0.022*"case" + 0.020*"attribute" + 0.016*"search" + 0.014*"source"
INFO: topic #1 (0.640): 0.073*"string" + 0.073*"list" + 0.065*"way" + 0.056*"match" + 0.053*"module" + 0.043*"return" + 0.042*"note" + 0.017*"content" + 0.017*"test_function" + 0.017*"namespace"
INFO: topic #2 (0.197): 0.108*"method" + 0.027*"debugging" + 0.027*"foo" + 0.019*"frame" + 0.019*"order" + 0.018*"story" + 0.016*"deal" + 0.016*"grab" + 0.016*"guess" + 0.016*"long"
INFO: topic #3 (0.581): 0.120*"class" + 0.059*"instance" + 0.058*"example" + 0.037*"print" + 0.029*"environment" + 0.028*"course" + 0.027*"player" + 0.027*"track" + 0.022*"iterator" + 0.018*"need"
INFO: topic #4 (0.336): 0.109*"global" + 0.072*"answer" + 0.042*"loop" + 0.033*"scope" + 0.028*"stack" + 0.027*"result" + 0.019*"var" + 0.014*"atribute" + 0.013*"filter" + 0.013*"bla"
INFO: topic diff=0.220846, rho=0.220326
DEBUG: bound: at document #0
INFO: -6.756 per-word bound, 108.1 perplexity estimate based on a held-out corpus of 5 documents with 183 words
INFO: PROGRESS: pass 4, at document #60/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.845352, 0.572065, 0.21349898, 0.6132008, 0.33641863]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.845): 0.205*"name" + 0.137*"object" + 0.115*"function" + 0.046*"code" + 0.037*"value" + 0.033*"variable" + 0.025*"source" + 0.019*"case" + 0.014*"line" + 0.014*"attribute"
INFO: topic #1 (0.572): 0.085*"way" + 0.078*"string" + 0.070*"list" + 0.056*"note" + 0.053*"module" + 0.045*"match" + 0.034*"return" + 0.034*"caller" + 0.014*"content" + 0.014*"test_function"
INFO: topic #2 (0.213): 0.085*"method" + 0.029*"initialization" + 0.025*"debugging" + 0.025*"assignent" + 0.025*"production" + 0.023*"frame" + 0.017*"constructor" + 0.014*"parameter" + 0.014*"data" + 0.014*"rethink"
INFO: topic #3 (0.613): 0.085*"class" + 0.050*"example" + 0.042*"instance" + 0.032*"frame" + 0.032*"file" + 0.030*"call" + 0.023*"work" + 0.023*"assignment" + 0.023*"c" + 0.022*"retrieve"
INFO: topic #4 (0.336): 0.081*"global" + 0.054*"answer" + 0.049*"loop" + 0.044*"scope" + 0.040*"stack" + 0.025*"inspect" + 0.020*"result" + 0.019*"dimension" + 0.019*"init" + 0.019*"determine"
INFO: topic diff=0.602720, rho=0.220326
DEBUG: bound: at document #0
INFO: -6.184 per-word bound, 72.7 perplexity estimate based on a held-out corpus of 5 documents with 164 words
INFO: PROGRESS: pass 4, at document #65/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9141631, 0.58846956, 0.21304442, 0.62115514, 0.33828673]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.914): 0.198*"name" + 0.152*"object" + 0.095*"function" + 0.050*"value" + 0.047*"variable" + 0.038*"code" + 0.018*"reference" + 0.017*"source" + 0.016*"case" + 0.016*"attribute"
INFO: topic #1 (0.588): 0.091*"way" + 0.067*"string" + 0.063*"list" + 0.045*"namespace" + 0.045*"note" + 0.040*"reference" + 0.034*"module" + 0.029*"match" + 0.025*"integer" + 0.022*"return"
INFO: topic #2 (0.213): 0.090*"method" + 0.028*"parameter" + 0.026*"initialization" + 0.022*"debugging" + 0.022*"assignent" + 0.022*"production" + 0.021*"frame" + 0.016*"constructor" + 0.013*"https://stackoverflow.com/a/49331683/7386061" + 0.012*"data"
INFO: topic #3 (0.621): 0.102*"class" + 0.065*"example" + 0.043*"instance" + 0.035*"assignment" + 0.034*"print" + 0.027*"work" + 0.026*"c" + 0.026*"frame" + 0.026*"file" + 0.024*"call"
INFO: topic #4 (0.338): 0.070*"var" + 0.051*"global" + 0.046*"design" + 0.043*"scope" + 0.033*"answer" + 0.031*"loop" + 0.030*"choice" + 0.030*"hash" + 0.025*"stack" + 0.016*"inspect"
INFO: topic diff=0.440851, rho=0.220326
DEBUG: bound: at document #0
INFO: -6.080 per-word bound, 67.6 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 4, at document #70/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8596001, 0.6019318, 0.22103186, 0.6664923, 0.3114576]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.860): 0.190*"name" + 0.161*"object" + 0.086*"function" + 0.050*"code" + 0.049*"value" + 0.042*"variable" + 0.022*"reference" + 0.019*"case" + 0.015*"source" + 0.015*"attribute"
INFO: topic #1 (0.602): 0.083*"way" + 0.064*"string" + 0.057*"reference" + 0.051*"list" + 0.038*"garbage" + 0.037*"module" + 0.037*"namespace" + 0.037*"note" + 0.027*"return" + 0.023*"match"
INFO: topic #2 (0.221): 0.095*"method" + 0.036*"debugging" + 0.024*"parameter" + 0.022*"initialization" + 0.019*"production" + 0.019*"assignent" + 0.018*"version" + 0.018*"frame" + 0.014*"constructor" + 0.012*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.666): 0.177*"class" + 0.060*"instance" + 0.053*"example" + 0.026*"c" + 0.025*"assignment" + 0.024*"print" + 0.022*"situation" + 0.020*"retrieve" + 0.019*"work" + 0.018*"frame"
INFO: topic #4 (0.311): 0.064*"var" + 0.046*"global" + 0.042*"design" + 0.039*"scope" + 0.031*"answer" + 0.028*"loop" + 0.028*"choice" + 0.028*"hash" + 0.023*"stack" + 0.015*"inspect"
INFO: topic diff=0.216407, rho=0.220326
DEBUG: bound: at document #0
INFO: -6.121 per-word bound, 69.6 perplexity estimate based on a held-out corpus of 5 documents with 112 words
INFO: PROGRESS: pass 4, at document #75/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9804872, 0.6791381, 0.2142889, 0.7735618, 0.3232208]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.980): 0.188*"name" + 0.164*"object" + 0.080*"function" + 0.054*"variable" + 0.048*"code" + 0.039*"value" + 0.023*"reference" + 0.023*"case" + 0.016*"source" + 0.012*"access"
INFO: topic #1 (0.679): 0.077*"way" + 0.061*"garbage" + 0.054*"list" + 0.053*"module" + 0.052*"namespace" + 0.046*"reference" + 0.046*"string" + 0.035*"note" + 0.021*"collection" + 0.020*"return"
INFO: topic #2 (0.214): 0.084*"method" + 0.051*"debugging" + 0.022*"parameter" + 0.020*"initialization" + 0.017*"production" + 0.017*"assignent" + 0.017*"version" + 0.016*"frame" + 0.012*"constructor" + 0.010*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.774): 0.145*"class" + 0.137*"instance" + 0.046*"example" + 0.041*"type" + 0.026*"c" + 0.025*"print" + 0.021*"track" + 0.018*"assignment" + 0.016*"situation" + 0.015*"retrieve"
INFO: topic #4 (0.323): 0.057*"global" + 0.052*"var" + 0.044*"answer" + 0.042*"filter" + 0.035*"design" + 0.032*"scope" + 0.023*"loop" + 0.023*"hash" + 0.023*"choice" + 0.019*"stack"
INFO: topic diff=0.303864, rho=0.220326
DEBUG: bound: at document #0
INFO: -6.641 per-word bound, 99.8 perplexity estimate based on a held-out corpus of 3 documents with 21 words
INFO: PROGRESS: pass 4, at document #78/78
DEBUG: performing inference on a chunk of 3 documents
DEBUG: 3/3 documents converged within 2000 iterations
INFO: optimized alpha [2.0881512, 0.65383154, 0.20606588, 0.8904526, 0.30590105]
DEBUG: updating topics
INFO: merging changes from 3 documents into a model of 78 documents
INFO: topic #0 (2.088): 0.183*"name" + 0.155*"object" + 0.087*"function" + 0.051*"code" + 0.048*"variable" + 0.035*"value" + 0.021*"reference" + 0.021*"case" + 0.018*"attribute" + 0.016*"thing"
INFO: topic #1 (0.654): 0.089*"way" + 0.057*"garbage" + 0.050*"list" + 0.049*"module" + 0.049*"namespace" + 0.043*"reference" + 0.043*"string" + 0.033*"note" + 0.020*"collection" + 0.018*"return"
INFO: topic #2 (0.206): 0.075*"method" + 0.046*"debugging" + 0.019*"parameter" + 0.018*"initialization" + 0.016*"production" + 0.016*"assignent" + 0.015*"version" + 0.015*"frame" + 0.011*"constructor" + 0.010*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.890): 0.148*"class" + 0.128*"instance" + 0.047*"print" + 0.039*"example" + 0.035*"type" + 0.030*"part" + 0.022*"c" + 0.018*"track" + 0.016*"assignment" + 0.014*"situation"
INFO: topic #4 (0.306): 0.051*"global" + 0.047*"var" + 0.039*"answer" + 0.037*"filter" + 0.032*"design" + 0.029*"scope" + 0.021*"loop" + 0.021*"choice" + 0.021*"hash" + 0.017*"stack"
INFO: topic diff=0.149247, rho=0.220326
DEBUG: bound: at document #0
INFO: -5.297 per-word bound, 39.3 perplexity estimate based on a held-out corpus of 5 documents with 130 words
INFO: PROGRESS: pass 5, at document #5/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7608778, 0.63838434, 0.1983014, 0.63935083, 0.26439804]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.761): 0.173*"name" + 0.122*"object" + 0.091*"function" + 0.054*"variable" + 0.050*"code" + 0.040*"value" + 0.028*"thing" + 0.022*"attribute" + 0.020*"case" + 0.019*"language"
INFO: topic #1 (0.638): 0.089*"string" + 0.082*"list" + 0.073*"way" + 0.041*"garbage" + 0.035*"module" + 0.035*"namespace" + 0.033*"note" + 0.032*"return" + 0.031*"reference" + 0.015*"collection"
INFO: topic #2 (0.198): 0.078*"method" + 0.056*"debugging" + 0.027*"foo" + 0.025*"order" + 0.023*"word" + 0.021*"snippet" + 0.021*"drawback" + 0.015*"parameter" + 0.014*"initialization" + 0.012*"production"
INFO: topic #3 (0.639): 0.141*"class" + 0.123*"instance" + 0.045*"print" + 0.038*"example" + 0.033*"type" + 0.029*"part" + 0.021*"c" + 0.017*"track" + 0.015*"assignment" + 0.013*"situation"
INFO: topic #4 (0.264): 0.045*"global" + 0.042*"var" + 0.035*"answer" + 0.033*"filter" + 0.028*"design" + 0.026*"scope" + 0.019*"loop" + 0.019*"choice" + 0.019*"hash" + 0.016*"stack"
INFO: topic diff=0.263714, rho=0.215166
DEBUG: bound: at document #0
INFO: -6.505 per-word bound, 90.8 perplexity estimate based on a held-out corpus of 5 documents with 191 words
INFO: PROGRESS: pass 5, at document #10/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.4440935, 0.5188127, 0.21419233, 0.61808604, 0.28161094]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.444): 0.175*"name" + 0.102*"function" + 0.097*"object" + 0.069*"variable" + 0.062*"code" + 0.050*"value" + 0.024*"source" + 0.024*"case" + 0.023*"thing" + 0.018*"attribute"
INFO: topic #1 (0.519): 0.096*"list" + 0.087*"string" + 0.066*"way" + 0.040*"note" + 0.037*"garbage" + 0.032*"module" + 0.032*"namespace" + 0.029*"return" + 0.028*"reference" + 0.013*"collection"
INFO: topic #2 (0.214): 0.092*"method" + 0.092*"foo" + 0.040*"debugging" + 0.029*"initialization" + 0.027*"word" + 0.027*"version" + 0.024*"frame" + 0.018*"order" + 0.015*"drawback" + 0.015*"snippet"
INFO: topic #3 (0.618): 0.077*"class" + 0.068*"instance" + 0.056*"frame" + 0.042*"example" + 0.036*"varname" + 0.032*"assignment" + 0.028*"need" + 0.028*"environment" + 0.024*"print" + 0.023*"part"
INFO: topic #4 (0.282): 0.073*"answer" + 0.051*"scope" + 0.045*"global" + 0.042*"var" + 0.027*"stack" + 0.024*"inspect" + 0.020*"filter" + 0.019*"bit" + 0.017*"defining" + 0.017*"warning"
INFO: topic diff=0.455254, rho=0.215166
DEBUG: bound: at document #0
INFO: -6.446 per-word bound, 87.2 perplexity estimate based on a held-out corpus of 5 documents with 45 words
INFO: PROGRESS: pass 5, at document #15/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.5320933, 0.5236413, 0.20125824, 0.57258064, 0.27567646]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.532): 0.173*"name" + 0.089*"function" + 0.089*"object" + 0.088*"variable" + 0.069*"value" + 0.054*"code" + 0.025*"case" + 0.021*"source" + 0.020*"thing" + 0.018*"access"
INFO: topic #1 (0.524): 0.081*"string" + 0.077*"list" + 0.064*"way" + 0.034*"return" + 0.032*"note" + 0.030*"garbage" + 0.026*"module" + 0.026*"namespace" + 0.025*"content" + 0.023*"reference"
INFO: topic #2 (0.201): 0.083*"method" + 0.083*"foo" + 0.036*"debugging" + 0.026*"initialization" + 0.025*"word" + 0.024*"version" + 0.022*"frame" + 0.016*"order" + 0.014*"drawback" + 0.014*"snippet"
INFO: topic #3 (0.573): 0.080*"class" + 0.066*"instance" + 0.054*"frame" + 0.040*"example" + 0.035*"varname" + 0.031*"assignment" + 0.027*"need" + 0.027*"environment" + 0.023*"print" + 0.022*"part"
INFO: topic #4 (0.276): 0.062*"scope" + 0.061*"answer" + 0.037*"global" + 0.036*"var" + 0.034*"bit" + 0.023*"stack" + 0.020*"inspect" + 0.017*"filter" + 0.015*"defining" + 0.015*"var_1"
INFO: topic diff=0.152917, rho=0.215166
DEBUG: bound: at document #0
INFO: -5.924 per-word bound, 60.7 perplexity estimate based on a held-out corpus of 5 documents with 37 words
INFO: PROGRESS: pass 5, at document #20/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.5954623, 0.54671556, 0.20186424, 0.53967863, 0.30653515]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.595): 0.183*"name" + 0.097*"variable" + 0.094*"function" + 0.080*"object" + 0.076*"value" + 0.049*"code" + 0.022*"case" + 0.019*"source" + 0.018*"thing" + 0.016*"access"
INFO: topic #1 (0.547): 0.088*"list" + 0.068*"string" + 0.063*"return" + 0.054*"way" + 0.033*"module" + 0.033*"namespace" + 0.027*"note" + 0.026*"garbage" + 0.024*"index" + 0.021*"content"
INFO: topic #2 (0.202): 0.114*"method" + 0.069*"foo" + 0.032*"frame" + 0.030*"debugging" + 0.022*"initialization" + 0.021*"word" + 0.021*"version" + 0.014*"order" + 0.012*"snippet" + 0.012*"drawback"
INFO: topic #3 (0.540): 0.076*"class" + 0.063*"instance" + 0.054*"frame" + 0.038*"example" + 0.033*"varname" + 0.029*"assignment" + 0.026*"need" + 0.026*"environment" + 0.022*"print" + 0.021*"part"
INFO: topic #4 (0.307): 0.085*"answer" + 0.067*"scope" + 0.048*"global" + 0.047*"var" + 0.027*"bit" + 0.022*"result" + 0.018*"variation" + 0.018*"stack" + 0.016*"inspect" + 0.013*"filter"
INFO: topic diff=0.112001, rho=0.215166
DEBUG: bound: at document #0
INFO: -6.581 per-word bound, 95.8 perplexity estimate based on a held-out corpus of 5 documents with 69 words
INFO: PROGRESS: pass 5, at document #25/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6871376, 0.54153395, 0.1996338, 0.5809581, 0.31300122]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.687): 0.161*"name" + 0.122*"function" + 0.100*"variable" + 0.076*"object" + 0.067*"value" + 0.045*"code" + 0.020*"local" + 0.018*"case" + 0.016*"source" + 0.015*"thing"
INFO: topic #1 (0.542): 0.076*"string" + 0.070*"list" + 0.063*"return" + 0.055*"way" + 0.027*"module" + 0.027*"namespace" + 0.022*"note" + 0.021*"garbage" + 0.020*"index" + 0.018*"define"
INFO: topic #2 (0.200): 0.097*"method" + 0.059*"foo" + 0.050*"debugging" + 0.028*"frame" + 0.019*"initialization" + 0.018*"word" + 0.018*"version" + 0.012*"order" + 0.010*"drawback" + 0.010*"snippet"
INFO: topic #3 (0.581): 0.070*"class" + 0.054*"example" + 0.051*"instance" + 0.044*"frame" + 0.031*"call" + 0.029*"need" + 0.027*"varname" + 0.026*"type" + 0.026*"print" + 0.024*"assignment"
INFO: topic #4 (0.313): 0.075*"var" + 0.068*"answer" + 0.057*"global" + 0.053*"scope" + 0.032*"inspect" + 0.022*"bit" + 0.019*"idea" + 0.019*"process" + 0.018*"result" + 0.015*"variation"
INFO: topic diff=0.195135, rho=0.215166
DEBUG: bound: at document #0
INFO: -6.323 per-word bound, 80.1 perplexity estimate based on a held-out corpus of 5 documents with 89 words
INFO: PROGRESS: pass 5, at document #30/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.728216, 0.56089395, 0.19747046, 0.6085383, 0.3145081]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.728): 0.165*"name" + 0.113*"function" + 0.092*"variable" + 0.070*"object" + 0.066*"code" + 0.054*"value" + 0.030*"source" + 0.019*"local" + 0.014*"case" + 0.011*"thing"
INFO: topic #1 (0.561): 0.085*"list" + 0.075*"string" + 0.053*"module" + 0.052*"way" + 0.046*"return" + 0.031*"namespace" + 0.027*"reference" + 0.024*"integer" + 0.021*"match" + 0.016*"note"
INFO: topic #2 (0.197): 0.079*"method" + 0.048*"foo" + 0.041*"debugging" + 0.029*"constructor" + 0.025*"sorcery" + 0.023*"frame" + 0.017*"kind" + 0.016*"initialization" + 0.015*"word" + 0.015*"version"
INFO: topic #3 (0.609): 0.077*"class" + 0.064*"example" + 0.044*"instance" + 0.038*"frame" + 0.027*"call" + 0.025*"retrieve" + 0.025*"need" + 0.024*"varname" + 0.023*"type" + 0.023*"print"
INFO: topic #4 (0.315): 0.067*"global" + 0.062*"var" + 0.056*"answer" + 0.052*"stack" + 0.044*"scope" + 0.026*"inspect" + 0.018*"bit" + 0.017*"python3" + 0.016*"idea" + 0.016*"process"
INFO: topic diff=0.252375, rho=0.215166
DEBUG: bound: at document #0
INFO: -5.249 per-word bound, 38.0 perplexity estimate based on a held-out corpus of 5 documents with 114 words
INFO: PROGRESS: pass 5, at document #35/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8681325, 0.60783625, 0.18547279, 0.6120028, 0.28564495]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.868): 0.221*"name" + 0.106*"object" + 0.103*"function" + 0.072*"variable" + 0.046*"value" + 0.046*"code" + 0.022*"local" + 0.021*"source" + 0.014*"case" + 0.013*"reference"
INFO: topic #1 (0.608): 0.128*"list" + 0.074*"string" + 0.070*"way" + 0.044*"module" + 0.039*"return" + 0.038*"namespace" + 0.019*"index" + 0.019*"reference" + 0.018*"define" + 0.017*"element"
INFO: topic #2 (0.185): 0.069*"method" + 0.042*"foo" + 0.035*"debugging" + 0.026*"constructor" + 0.022*"sorcery" + 0.020*"frame" + 0.016*"kind" + 0.014*"initialization" + 0.013*"word" + 0.013*"version"
INFO: topic #3 (0.612): 0.094*"class" + 0.074*"example" + 0.047*"instance" + 0.033*"frame" + 0.027*"assignment" + 0.023*"call" + 0.022*"retrieve" + 0.022*"need" + 0.021*"course" + 0.020*"varname"
INFO: topic #4 (0.286): 0.060*"global" + 0.055*"var" + 0.050*"answer" + 0.046*"stack" + 0.039*"scope" + 0.024*"inspect" + 0.016*"bit" + 0.016*"python3" + 0.015*"process" + 0.015*"idea"
INFO: topic diff=0.277751, rho=0.215166
DEBUG: bound: at document #0
INFO: -7.272 per-word bound, 154.5 perplexity estimate based on a held-out corpus of 5 documents with 32 words
INFO: PROGRESS: pass 5, at document #40/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.623421, 0.56570643, 0.18244025, 0.58355165, 0.3072484]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.623): 0.210*"name" + 0.115*"function" + 0.103*"object" + 0.067*"variable" + 0.043*"value" + 0.042*"code" + 0.022*"case" + 0.020*"local" + 0.020*"source" + 0.012*"reference"
INFO: topic #1 (0.566): 0.117*"list" + 0.068*"string" + 0.064*"way" + 0.061*"module" + 0.036*"return" + 0.035*"namespace" + 0.020*"note" + 0.017*"index" + 0.017*"reference" + 0.016*"define"
INFO: topic #2 (0.182): 0.064*"foo" + 0.057*"method" + 0.030*"debugging" + 0.022*"constructor" + 0.018*"sorcery" + 0.017*"frame" + 0.013*"kind" + 0.012*"initialization" + 0.011*"word" + 0.011*"version"
INFO: topic #3 (0.584): 0.104*"class" + 0.065*"example" + 0.042*"instance" + 0.029*"frame" + 0.029*"course" + 0.028*"type" + 0.025*"work" + 0.024*"assignment" + 0.020*"call" + 0.019*"retrieve"
INFO: topic #4 (0.307): 0.073*"answer" + 0.060*"global" + 0.043*"loop" + 0.038*"var" + 0.032*"stack" + 0.029*"result" + 0.027*"scope" + 0.025*"filter" + 0.020*"each_item" + 0.020*"globals().item"
INFO: topic diff=0.160406, rho=0.215166
DEBUG: bound: at document #0
INFO: -6.054 per-word bound, 66.5 perplexity estimate based on a held-out corpus of 5 documents with 133 words
INFO: PROGRESS: pass 5, at document #45/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.739256, 0.5829651, 0.19618039, 0.55430275, 0.29939985]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.739): 0.227*"name" + 0.133*"function" + 0.108*"object" + 0.054*"value" + 0.050*"variable" + 0.029*"code" + 0.019*"case" + 0.019*"attribute" + 0.014*"local" + 0.013*"source"
INFO: topic #1 (0.583): 0.085*"list" + 0.077*"string" + 0.050*"way" + 0.048*"module" + 0.034*"match" + 0.032*"return" + 0.031*"note" + 0.024*"test_function" + 0.023*"namespace" + 0.022*"content"
INFO: topic #2 (0.196): 0.055*"method" + 0.039*"debugging" + 0.038*"foo" + 0.027*"frame" + 0.027*"order" + 0.025*"story" + 0.022*"long" + 0.022*"traverse" + 0.022*"page" + 0.022*"grab"
INFO: topic #3 (0.554): 0.088*"class" + 0.066*"example" + 0.047*"course" + 0.047*"instance" + 0.027*"frame" + 0.026*"print" + 0.024*"type" + 0.021*"work" + 0.020*"assignment" + 0.019*"magic"
INFO: topic #4 (0.299): 0.070*"global" + 0.061*"answer" + 0.046*"stack" + 0.044*"result" + 0.035*"loop" + 0.032*"var" + 0.023*"scope" + 0.021*"filter" + 0.017*"globals().item" + 0.017*"each_item"
INFO: topic diff=0.397718, rho=0.215166
DEBUG: bound: at document #0
INFO: -5.917 per-word bound, 60.4 perplexity estimate based on a held-out corpus of 5 documents with 67 words
INFO: PROGRESS: pass 5, at document #50/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9121877, 0.6239214, 0.19436914, 0.54470557, 0.32052782]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.912): 0.228*"name" + 0.143*"function" + 0.092*"object" + 0.049*"variable" + 0.049*"value" + 0.028*"code" + 0.024*"attribute" + 0.016*"case" + 0.016*"local" + 0.012*"argument"
INFO: topic #1 (0.624): 0.083*"string" + 0.071*"list" + 0.061*"way" + 0.060*"module" + 0.038*"match" + 0.036*"return" + 0.035*"note" + 0.020*"test_function" + 0.019*"namespace" + 0.019*"content"
INFO: topic #2 (0.194): 0.071*"method" + 0.033*"debugging" + 0.033*"foo" + 0.024*"frame" + 0.023*"order" + 0.021*"story" + 0.019*"page" + 0.019*"traverse" + 0.019*"grab" + 0.019*"basestring"
INFO: topic #3 (0.545): 0.111*"class" + 0.068*"example" + 0.040*"course" + 0.039*"instance" + 0.026*"need" + 0.023*"frame" + 0.022*"print" + 0.020*"type" + 0.018*"work" + 0.017*"assignment"
INFO: topic #4 (0.321): 0.113*"global" + 0.066*"answer" + 0.035*"stack" + 0.034*"result" + 0.027*"loop" + 0.024*"var" + 0.017*"scope" + 0.016*"filter" + 0.016*"my_list" + 0.016*"bla"
INFO: topic diff=0.186170, rho=0.215166
DEBUG: bound: at document #0
INFO: -6.194 per-word bound, 73.2 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 5, at document #55/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9713595, 0.643934, 0.20071468, 0.5902381, 0.3398613]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.971): 0.220*"name" + 0.122*"function" + 0.112*"object" + 0.049*"value" + 0.045*"variable" + 0.032*"code" + 0.022*"case" + 0.020*"attribute" + 0.016*"search" + 0.014*"source"
INFO: topic #1 (0.644): 0.073*"list" + 0.073*"string" + 0.064*"way" + 0.055*"match" + 0.052*"module" + 0.042*"return" + 0.042*"note" + 0.019*"reference" + 0.018*"test_function" + 0.017*"namespace"
INFO: topic #2 (0.201): 0.108*"method" + 0.028*"debugging" + 0.027*"foo" + 0.020*"frame" + 0.019*"order" + 0.018*"story" + 0.016*"grab" + 0.016*"long" + 0.016*"page" + 0.016*"deal"
INFO: topic #3 (0.590): 0.119*"class" + 0.059*"instance" + 0.058*"example" + 0.037*"print" + 0.028*"environment" + 0.028*"course" + 0.027*"player" + 0.026*"track" + 0.022*"iterator" + 0.018*"need"
INFO: topic #4 (0.340): 0.109*"global" + 0.072*"answer" + 0.041*"loop" + 0.034*"scope" + 0.028*"stack" + 0.027*"result" + 0.019*"var" + 0.014*"atribute" + 0.013*"filter" + 0.013*"my_list"
INFO: topic diff=0.211953, rho=0.215166
DEBUG: bound: at document #0
INFO: -6.716 per-word bound, 105.1 perplexity estimate based on a held-out corpus of 5 documents with 183 words
INFO: PROGRESS: pass 5, at document #60/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8613445, 0.5776361, 0.21652195, 0.6198998, 0.339407]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.861): 0.206*"name" + 0.136*"object" + 0.115*"function" + 0.046*"code" + 0.038*"value" + 0.035*"variable" + 0.025*"source" + 0.019*"case" + 0.014*"attribute" + 0.014*"line"
INFO: topic #1 (0.578): 0.084*"way" + 0.077*"string" + 0.070*"list" + 0.055*"note" + 0.053*"module" + 0.044*"match" + 0.040*"caller" + 0.034*"return" + 0.015*"reference" + 0.015*"test_function"
INFO: topic #2 (0.217): 0.084*"method" + 0.028*"initialization" + 0.025*"assignent" + 0.025*"production" + 0.025*"debugging" + 0.023*"frame" + 0.017*"constructor" + 0.014*"parameter" + 0.013*"data" + 0.013*"rethink"
INFO: topic #3 (0.620): 0.086*"class" + 0.050*"example" + 0.043*"instance" + 0.032*"frame" + 0.032*"file" + 0.030*"call" + 0.024*"c" + 0.023*"work" + 0.023*"assignment" + 0.022*"retrieve"
INFO: topic #4 (0.339): 0.081*"global" + 0.054*"answer" + 0.049*"loop" + 0.044*"scope" + 0.040*"stack" + 0.025*"inspect" + 0.020*"result" + 0.019*"determine" + 0.019*"self" + 0.019*"dimension"
INFO: topic diff=0.575679, rho=0.215166
DEBUG: bound: at document #0
INFO: -6.144 per-word bound, 70.7 perplexity estimate based on a held-out corpus of 5 documents with 164 words
INFO: PROGRESS: pass 5, at document #65/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9213223, 0.59237623, 0.21570203, 0.6256119, 0.34070277]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.921): 0.199*"name" + 0.152*"object" + 0.096*"function" + 0.050*"value" + 0.048*"variable" + 0.038*"code" + 0.017*"source" + 0.017*"case" + 0.016*"attribute" + 0.015*"reference"
INFO: topic #1 (0.592): 0.089*"way" + 0.067*"string" + 0.063*"list" + 0.048*"reference" + 0.044*"note" + 0.044*"namespace" + 0.034*"module" + 0.029*"match" + 0.026*"caller" + 0.025*"integer"
INFO: topic #2 (0.216): 0.089*"method" + 0.027*"parameter" + 0.025*"initialization" + 0.022*"assignent" + 0.022*"production" + 0.022*"debugging" + 0.021*"frame" + 0.015*"constructor" + 0.013*"https://stackoverflow.com/a/49331683/7386061" + 0.012*"data"
INFO: topic #3 (0.626): 0.103*"class" + 0.065*"example" + 0.043*"instance" + 0.035*"assignment" + 0.034*"print" + 0.027*"c" + 0.027*"work" + 0.026*"frame" + 0.026*"file" + 0.024*"call"
INFO: topic #4 (0.341): 0.069*"var" + 0.051*"global" + 0.046*"design" + 0.043*"scope" + 0.034*"answer" + 0.031*"loop" + 0.030*"choice" + 0.030*"hash" + 0.025*"stack" + 0.016*"inspect"
INFO: topic diff=0.423162, rho=0.215166
DEBUG: bound: at document #0
INFO: -6.053 per-word bound, 66.4 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 5, at document #70/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8606544, 0.6054625, 0.22335038, 0.66924214, 0.31392315]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.861): 0.192*"name" + 0.161*"object" + 0.087*"function" + 0.050*"code" + 0.049*"value" + 0.043*"variable" + 0.019*"case" + 0.018*"reference" + 0.016*"source" + 0.015*"attribute"
INFO: topic #1 (0.605): 0.082*"way" + 0.066*"reference" + 0.063*"string" + 0.051*"list" + 0.037*"module" + 0.037*"garbage" + 0.036*"note" + 0.036*"namespace" + 0.027*"return" + 0.023*"match"
INFO: topic #2 (0.223): 0.094*"method" + 0.036*"debugging" + 0.024*"parameter" + 0.022*"initialization" + 0.020*"production" + 0.020*"assignent" + 0.018*"frame" + 0.018*"version" + 0.014*"constructor" + 0.011*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.669): 0.176*"class" + 0.060*"instance" + 0.054*"example" + 0.027*"c" + 0.025*"assignment" + 0.024*"print" + 0.022*"situation" + 0.020*"retrieve" + 0.019*"work" + 0.019*"frame"
INFO: topic #4 (0.314): 0.063*"var" + 0.047*"global" + 0.042*"design" + 0.039*"scope" + 0.031*"answer" + 0.028*"loop" + 0.028*"choice" + 0.028*"hash" + 0.023*"stack" + 0.015*"inspect"
INFO: topic diff=0.208299, rho=0.215166
DEBUG: bound: at document #0
INFO: -6.104 per-word bound, 68.8 perplexity estimate based on a held-out corpus of 5 documents with 112 words
INFO: PROGRESS: pass 5, at document #75/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9767512, 0.6823629, 0.21650878, 0.7739498, 0.32505503]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.977): 0.189*"name" + 0.165*"object" + 0.081*"function" + 0.055*"variable" + 0.048*"code" + 0.039*"value" + 0.023*"case" + 0.019*"reference" + 0.017*"source" + 0.012*"access"
INFO: topic #1 (0.682): 0.076*"way" + 0.060*"garbage" + 0.055*"reference" + 0.053*"list" + 0.052*"module" + 0.051*"namespace" + 0.046*"string" + 0.034*"note" + 0.021*"collection" + 0.020*"return"
INFO: topic #2 (0.217): 0.083*"method" + 0.050*"debugging" + 0.021*"parameter" + 0.020*"initialization" + 0.018*"production" + 0.018*"assignent" + 0.017*"frame" + 0.016*"version" + 0.012*"constructor" + 0.010*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.774): 0.145*"class" + 0.135*"instance" + 0.047*"example" + 0.041*"type" + 0.027*"c" + 0.025*"print" + 0.021*"track" + 0.019*"assignment" + 0.017*"situation" + 0.015*"retrieve"
INFO: topic #4 (0.325): 0.057*"global" + 0.052*"var" + 0.044*"answer" + 0.041*"filter" + 0.035*"design" + 0.033*"scope" + 0.024*"loop" + 0.023*"hash" + 0.023*"choice" + 0.019*"stack"
INFO: topic diff=0.291972, rho=0.215166
DEBUG: bound: at document #0
INFO: -6.621 per-word bound, 98.4 perplexity estimate based on a held-out corpus of 3 documents with 21 words
INFO: PROGRESS: pass 5, at document #78/78
DEBUG: performing inference on a chunk of 3 documents
DEBUG: 3/3 documents converged within 2000 iterations
INFO: optimized alpha [2.0822275, 0.6566936, 0.2082891, 0.8875163, 0.30785027]
DEBUG: updating topics
INFO: merging changes from 3 documents into a model of 78 documents
INFO: topic #0 (2.082): 0.185*"name" + 0.155*"object" + 0.088*"function" + 0.051*"code" + 0.049*"variable" + 0.035*"value" + 0.021*"case" + 0.018*"attribute" + 0.017*"reference" + 0.016*"thing"
INFO: topic #1 (0.657): 0.087*"way" + 0.056*"garbage" + 0.051*"reference" + 0.050*"list" + 0.048*"module" + 0.048*"namespace" + 0.043*"string" + 0.032*"note" + 0.020*"collection" + 0.019*"return"
INFO: topic #2 (0.208): 0.075*"method" + 0.045*"debugging" + 0.019*"parameter" + 0.018*"initialization" + 0.016*"production" + 0.016*"assignent" + 0.015*"frame" + 0.015*"version" + 0.011*"constructor" + 0.010*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.888): 0.148*"class" + 0.128*"instance" + 0.046*"print" + 0.040*"example" + 0.034*"type" + 0.030*"part" + 0.023*"c" + 0.018*"track" + 0.016*"assignment" + 0.014*"situation"
INFO: topic #4 (0.308): 0.051*"global" + 0.047*"var" + 0.040*"answer" + 0.037*"filter" + 0.032*"design" + 0.030*"scope" + 0.021*"loop" + 0.021*"choice" + 0.021*"hash" + 0.018*"stack"
INFO: topic diff=0.143772, rho=0.215166
DEBUG: bound: at document #0
INFO: -5.282 per-word bound, 38.9 perplexity estimate based on a held-out corpus of 5 documents with 130 words
INFO: PROGRESS: pass 6, at document #5/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7790954, 0.64262515, 0.20063375, 0.6462602, 0.2672673]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.779): 0.174*"name" + 0.123*"object" + 0.091*"function" + 0.056*"variable" + 0.050*"code" + 0.040*"value" + 0.028*"thing" + 0.022*"attribute" + 0.020*"case" + 0.019*"language"
INFO: topic #1 (0.643): 0.088*"string" + 0.082*"list" + 0.073*"way" + 0.041*"garbage" + 0.038*"reference" + 0.035*"module" + 0.035*"namespace" + 0.033*"note" + 0.031*"return" + 0.014*"collection"
INFO: topic #2 (0.201): 0.078*"method" + 0.055*"debugging" + 0.026*"foo" + 0.025*"order" + 0.021*"snippet" + 0.021*"drawback" + 0.019*"word" + 0.015*"parameter" + 0.014*"initialization" + 0.013*"production"
INFO: topic #3 (0.646): 0.142*"class" + 0.122*"instance" + 0.044*"print" + 0.038*"example" + 0.033*"type" + 0.028*"part" + 0.022*"c" + 0.017*"track" + 0.015*"assignment" + 0.014*"situation"
INFO: topic #4 (0.267): 0.046*"global" + 0.042*"var" + 0.036*"answer" + 0.033*"filter" + 0.028*"design" + 0.026*"scope" + 0.019*"loop" + 0.019*"hash" + 0.019*"choice" + 0.016*"stack"
INFO: topic diff=0.252841, rho=0.210352
DEBUG: bound: at document #0
INFO: -6.469 per-word bound, 88.6 perplexity estimate based on a held-out corpus of 5 documents with 191 words
INFO: PROGRESS: pass 6, at document #10/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.4634407, 0.52484524, 0.21594107, 0.62441874, 0.2840682]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.463): 0.175*"name" + 0.102*"function" + 0.098*"object" + 0.070*"variable" + 0.062*"code" + 0.050*"value" + 0.024*"source" + 0.024*"case" + 0.023*"thing" + 0.018*"attribute"
INFO: topic #1 (0.525): 0.094*"list" + 0.086*"string" + 0.066*"way" + 0.040*"note" + 0.037*"garbage" + 0.034*"reference" + 0.032*"module" + 0.032*"namespace" + 0.028*"return" + 0.015*"documentation"
INFO: topic #2 (0.216): 0.093*"method" + 0.091*"foo" + 0.040*"debugging" + 0.029*"initialization" + 0.027*"version" + 0.024*"frame" + 0.022*"word" + 0.018*"order" + 0.015*"drawback" + 0.015*"snippet"
INFO: topic #3 (0.624): 0.077*"class" + 0.069*"instance" + 0.056*"frame" + 0.042*"example" + 0.036*"varname" + 0.032*"assignment" + 0.028*"need" + 0.028*"environment" + 0.025*"print" + 0.023*"part"
INFO: topic #4 (0.284): 0.072*"answer" + 0.050*"scope" + 0.045*"global" + 0.042*"var" + 0.027*"stack" + 0.024*"inspect" + 0.020*"filter" + 0.018*"bit" + 0.017*"var_1" + 0.017*"warning"
INFO: topic diff=0.437690, rho=0.210352
DEBUG: bound: at document #0
INFO: -6.434 per-word bound, 86.5 perplexity estimate based on a held-out corpus of 5 documents with 45 words
INFO: PROGRESS: pass 6, at document #15/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.5535644, 0.5294123, 0.20324497, 0.57972085, 0.27831662]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.554): 0.173*"name" + 0.090*"object" + 0.089*"function" + 0.089*"variable" + 0.068*"value" + 0.054*"code" + 0.025*"case" + 0.021*"source" + 0.020*"thing" + 0.018*"access"
INFO: topic #1 (0.529): 0.080*"string" + 0.077*"list" + 0.064*"way" + 0.034*"return" + 0.032*"note" + 0.030*"garbage" + 0.028*"reference" + 0.026*"module" + 0.026*"namespace" + 0.024*"content"
INFO: topic #2 (0.203): 0.083*"method" + 0.082*"foo" + 0.036*"debugging" + 0.026*"initialization" + 0.024*"version" + 0.022*"frame" + 0.020*"word" + 0.016*"order" + 0.014*"drawback" + 0.014*"snippet"
INFO: topic #3 (0.580): 0.080*"class" + 0.066*"instance" + 0.053*"frame" + 0.040*"example" + 0.034*"varname" + 0.030*"assignment" + 0.027*"need" + 0.027*"environment" + 0.024*"print" + 0.022*"part"
INFO: topic #4 (0.278): 0.061*"scope" + 0.061*"answer" + 0.038*"global" + 0.036*"var" + 0.034*"bit" + 0.023*"stack" + 0.020*"inspect" + 0.017*"filter" + 0.015*"warning" + 0.015*"var_2"
INFO: topic diff=0.146459, rho=0.210352
DEBUG: bound: at document #0
INFO: -5.918 per-word bound, 60.5 perplexity estimate based on a held-out corpus of 5 documents with 37 words
INFO: PROGRESS: pass 6, at document #20/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6157932, 0.55158764, 0.2038248, 0.54687, 0.30871683]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.616): 0.184*"name" + 0.099*"variable" + 0.094*"function" + 0.081*"object" + 0.075*"value" + 0.049*"code" + 0.022*"case" + 0.019*"source" + 0.018*"thing" + 0.016*"access"
INFO: topic #1 (0.552): 0.087*"list" + 0.068*"string" + 0.062*"return" + 0.054*"way" + 0.034*"module" + 0.033*"namespace" + 0.028*"note" + 0.026*"garbage" + 0.024*"index" + 0.024*"reference"
INFO: topic #2 (0.204): 0.114*"method" + 0.068*"foo" + 0.032*"frame" + 0.030*"debugging" + 0.022*"initialization" + 0.020*"version" + 0.017*"word" + 0.014*"order" + 0.012*"snippet" + 0.012*"drawback"
INFO: topic #3 (0.547): 0.077*"class" + 0.063*"instance" + 0.054*"frame" + 0.038*"example" + 0.033*"varname" + 0.029*"assignment" + 0.026*"need" + 0.025*"environment" + 0.023*"print" + 0.021*"part"
INFO: topic #4 (0.309): 0.084*"answer" + 0.066*"scope" + 0.048*"global" + 0.046*"var" + 0.027*"bit" + 0.022*"result" + 0.018*"variation" + 0.018*"stack" + 0.016*"inspect" + 0.013*"filter"
INFO: topic diff=0.107113, rho=0.210352
DEBUG: bound: at document #0
INFO: -6.566 per-word bound, 94.7 perplexity estimate based on a held-out corpus of 5 documents with 69 words
INFO: PROGRESS: pass 6, at document #25/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7051191, 0.5461663, 0.20153017, 0.5872399, 0.31502426]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.705): 0.162*"name" + 0.121*"function" + 0.101*"variable" + 0.077*"object" + 0.067*"value" + 0.045*"code" + 0.020*"local" + 0.019*"case" + 0.016*"source" + 0.015*"thing"
INFO: topic #1 (0.546): 0.076*"string" + 0.070*"list" + 0.062*"return" + 0.055*"way" + 0.027*"module" + 0.027*"namespace" + 0.022*"note" + 0.021*"garbage" + 0.019*"index" + 0.019*"reference"
INFO: topic #2 (0.202): 0.097*"method" + 0.059*"foo" + 0.049*"debugging" + 0.028*"frame" + 0.019*"initialization" + 0.018*"version" + 0.015*"word" + 0.012*"order" + 0.010*"drawback" + 0.010*"snippet"
INFO: topic #3 (0.587): 0.070*"class" + 0.054*"example" + 0.052*"instance" + 0.044*"frame" + 0.030*"call" + 0.029*"need" + 0.027*"varname" + 0.026*"type" + 0.026*"print" + 0.024*"assignment"
INFO: topic #4 (0.315): 0.074*"var" + 0.068*"answer" + 0.057*"global" + 0.053*"scope" + 0.031*"inspect" + 0.022*"bit" + 0.019*"idea" + 0.019*"process" + 0.018*"result" + 0.015*"variation"
INFO: topic diff=0.186961, rho=0.210352
DEBUG: bound: at document #0
INFO: -6.296 per-word bound, 78.6 perplexity estimate based on a held-out corpus of 5 documents with 89 words
INFO: PROGRESS: pass 6, at document #30/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.742018, 0.56442976, 0.1992677, 0.61339134, 0.31619754]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.742): 0.165*"name" + 0.113*"function" + 0.093*"variable" + 0.071*"object" + 0.065*"code" + 0.054*"value" + 0.030*"source" + 0.019*"local" + 0.014*"case" + 0.011*"thing"
INFO: topic #1 (0.564): 0.085*"list" + 0.075*"string" + 0.053*"module" + 0.052*"way" + 0.046*"return" + 0.031*"reference" + 0.031*"namespace" + 0.023*"integer" + 0.021*"match" + 0.017*"note"
INFO: topic #2 (0.199): 0.080*"method" + 0.048*"foo" + 0.041*"debugging" + 0.029*"constructor" + 0.025*"sorcery" + 0.023*"frame" + 0.017*"kind" + 0.016*"initialization" + 0.015*"version" + 0.012*"word"
INFO: topic #3 (0.613): 0.078*"class" + 0.064*"example" + 0.045*"instance" + 0.038*"frame" + 0.026*"call" + 0.025*"retrieve" + 0.025*"need" + 0.024*"varname" + 0.023*"type" + 0.023*"print"
INFO: topic #4 (0.316): 0.067*"global" + 0.062*"var" + 0.056*"answer" + 0.051*"stack" + 0.044*"scope" + 0.026*"inspect" + 0.018*"bit" + 0.017*"python3" + 0.016*"idea" + 0.016*"process"
INFO: topic diff=0.241137, rho=0.210352
DEBUG: bound: at document #0
INFO: -5.235 per-word bound, 37.6 perplexity estimate based on a held-out corpus of 5 documents with 114 words
INFO: PROGRESS: pass 6, at document #35/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8817763, 0.6146099, 0.18744425, 0.6169908, 0.2879599]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.882): 0.220*"name" + 0.106*"object" + 0.103*"function" + 0.073*"variable" + 0.046*"value" + 0.046*"code" + 0.021*"local" + 0.021*"source" + 0.014*"case" + 0.011*"reference"
INFO: topic #1 (0.615): 0.127*"list" + 0.073*"string" + 0.070*"way" + 0.043*"module" + 0.039*"return" + 0.038*"namespace" + 0.023*"reference" + 0.018*"index" + 0.018*"define" + 0.017*"element"
INFO: topic #2 (0.187): 0.069*"method" + 0.042*"foo" + 0.036*"debugging" + 0.025*"constructor" + 0.022*"sorcery" + 0.020*"frame" + 0.015*"kind" + 0.014*"initialization" + 0.013*"version" + 0.011*"word"
INFO: topic #3 (0.617): 0.094*"class" + 0.073*"example" + 0.048*"instance" + 0.033*"frame" + 0.027*"assignment" + 0.023*"call" + 0.022*"retrieve" + 0.022*"need" + 0.021*"course" + 0.020*"varname"
INFO: topic #4 (0.288): 0.060*"global" + 0.055*"var" + 0.050*"answer" + 0.046*"stack" + 0.040*"scope" + 0.024*"inspect" + 0.016*"bit" + 0.016*"python3" + 0.015*"process" + 0.015*"idea"
INFO: topic diff=0.267587, rho=0.210352
DEBUG: bound: at document #0
INFO: -7.250 per-word bound, 152.2 perplexity estimate based on a held-out corpus of 5 documents with 32 words
INFO: PROGRESS: pass 6, at document #40/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6392834, 0.5720148, 0.1843329, 0.58835906, 0.30923176]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.639): 0.209*"name" + 0.115*"function" + 0.103*"object" + 0.068*"variable" + 0.043*"value" + 0.043*"code" + 0.022*"case" + 0.020*"local" + 0.020*"source" + 0.011*"reference"
INFO: topic #1 (0.572): 0.116*"list" + 0.067*"string" + 0.064*"way" + 0.060*"module" + 0.036*"return" + 0.035*"namespace" + 0.021*"reference" + 0.020*"note" + 0.017*"index" + 0.016*"define"
INFO: topic #2 (0.184): 0.064*"foo" + 0.058*"method" + 0.030*"debugging" + 0.021*"constructor" + 0.018*"sorcery" + 0.017*"frame" + 0.013*"kind" + 0.012*"initialization" + 0.011*"version" + 0.010*"word"
INFO: topic #3 (0.588): 0.104*"class" + 0.065*"example" + 0.043*"instance" + 0.030*"frame" + 0.029*"course" + 0.028*"type" + 0.025*"work" + 0.024*"assignment" + 0.020*"call" + 0.019*"retrieve"
INFO: topic #4 (0.309): 0.073*"answer" + 0.060*"global" + 0.042*"loop" + 0.038*"var" + 0.032*"stack" + 0.029*"result" + 0.028*"scope" + 0.025*"filter" + 0.020*"each_item" + 0.020*"globals().item"
INFO: topic diff=0.156116, rho=0.210352
DEBUG: bound: at document #0
INFO: -6.026 per-word bound, 65.2 perplexity estimate based on a held-out corpus of 5 documents with 133 words
INFO: PROGRESS: pass 6, at document #45/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7475814, 0.58877414, 0.19768819, 0.5582001, 0.30105773]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.748): 0.227*"name" + 0.133*"function" + 0.108*"object" + 0.055*"value" + 0.051*"variable" + 0.030*"code" + 0.020*"case" + 0.019*"attribute" + 0.014*"local" + 0.014*"source"
INFO: topic #1 (0.589): 0.084*"list" + 0.076*"string" + 0.050*"way" + 0.048*"module" + 0.034*"match" + 0.032*"return" + 0.030*"note" + 0.026*"reference" + 0.025*"test_function" + 0.023*"namespace"
INFO: topic #2 (0.198): 0.056*"method" + 0.039*"debugging" + 0.038*"foo" + 0.027*"frame" + 0.026*"order" + 0.024*"story" + 0.022*"page" + 0.022*"long" + 0.022*"eval" + 0.022*"deal"
INFO: topic #3 (0.558): 0.088*"class" + 0.066*"example" + 0.047*"instance" + 0.046*"course" + 0.027*"frame" + 0.026*"print" + 0.024*"type" + 0.021*"work" + 0.021*"assignment" + 0.019*"magic"
INFO: topic #4 (0.301): 0.070*"global" + 0.061*"answer" + 0.046*"stack" + 0.044*"result" + 0.035*"loop" + 0.032*"var" + 0.023*"scope" + 0.021*"filter" + 0.017*"each_item" + 0.017*"globals().item"
INFO: topic diff=0.381579, rho=0.210352
DEBUG: bound: at document #0
INFO: -5.902 per-word bound, 59.8 perplexity estimate based on a held-out corpus of 5 documents with 67 words
INFO: PROGRESS: pass 6, at document #50/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9176832, 0.62798893, 0.19583149, 0.54851204, 0.32164216]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.918): 0.228*"name" + 0.142*"function" + 0.093*"object" + 0.050*"variable" + 0.049*"value" + 0.028*"code" + 0.024*"attribute" + 0.016*"case" + 0.016*"local" + 0.012*"argument"
INFO: topic #1 (0.628): 0.082*"string" + 0.071*"list" + 0.061*"way" + 0.059*"module" + 0.038*"match" + 0.036*"return" + 0.035*"note" + 0.022*"reference" + 0.021*"test_function" + 0.019*"namespace"
INFO: topic #2 (0.196): 0.071*"method" + 0.033*"debugging" + 0.033*"foo" + 0.024*"frame" + 0.023*"order" + 0.021*"story" + 0.019*"grab" + 0.019*"deal" + 0.019*"basestring" + 0.019*"guess"
INFO: topic #3 (0.549): 0.110*"class" + 0.068*"example" + 0.040*"instance" + 0.039*"course" + 0.026*"need" + 0.023*"frame" + 0.022*"print" + 0.020*"type" + 0.018*"work" + 0.018*"assignment"
INFO: topic #4 (0.322): 0.112*"global" + 0.066*"answer" + 0.035*"stack" + 0.034*"result" + 0.027*"loop" + 0.025*"var" + 0.018*"scope" + 0.016*"filter" + 0.016*"bla" + 0.016*"my_list"
INFO: topic diff=0.179009, rho=0.210352
DEBUG: bound: at document #0
INFO: -6.174 per-word bound, 72.2 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 6, at document #55/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9772751, 0.6480229, 0.20203412, 0.5947565, 0.34041306]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.977): 0.220*"name" + 0.122*"function" + 0.112*"object" + 0.049*"value" + 0.046*"variable" + 0.032*"code" + 0.022*"case" + 0.020*"attribute" + 0.016*"search" + 0.014*"source"
INFO: topic #1 (0.648): 0.073*"list" + 0.073*"string" + 0.064*"way" + 0.054*"match" + 0.052*"module" + 0.042*"return" + 0.041*"note" + 0.023*"reference" + 0.019*"test_function" + 0.017*"namespace"
INFO: topic #2 (0.202): 0.107*"method" + 0.028*"debugging" + 0.028*"foo" + 0.020*"frame" + 0.019*"order" + 0.018*"story" + 0.016*"grab" + 0.016*"page" + 0.016*"traverse" + 0.016*"long"
INFO: topic #3 (0.595): 0.118*"class" + 0.059*"instance" + 0.058*"example" + 0.036*"print" + 0.028*"environment" + 0.028*"player" + 0.027*"course" + 0.026*"track" + 0.021*"iterator" + 0.018*"need"
INFO: topic #4 (0.340): 0.108*"global" + 0.072*"answer" + 0.041*"loop" + 0.034*"scope" + 0.028*"stack" + 0.027*"result" + 0.020*"var" + 0.014*"atribute" + 0.013*"filter" + 0.013*"my_list"
INFO: topic diff=0.204123, rho=0.210352
DEBUG: bound: at document #0
INFO: -6.679 per-word bound, 102.5 perplexity estimate based on a held-out corpus of 5 documents with 183 words
INFO: PROGRESS: pass 6, at document #60/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8655688, 0.5822825, 0.2175115, 0.62274444, 0.339633]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.866): 0.206*"name" + 0.136*"object" + 0.116*"function" + 0.046*"code" + 0.038*"value" + 0.036*"variable" + 0.025*"source" + 0.019*"case" + 0.014*"attribute" + 0.013*"line"
INFO: topic #1 (0.582): 0.083*"way" + 0.076*"string" + 0.070*"list" + 0.054*"note" + 0.052*"module" + 0.044*"match" + 0.042*"caller" + 0.034*"return" + 0.019*"reference" + 0.015*"test_function"
INFO: topic #2 (0.218): 0.083*"method" + 0.028*"initialization" + 0.025*"assignent" + 0.025*"production" + 0.025*"debugging" + 0.023*"frame" + 0.017*"constructor" + 0.014*"parameter" + 0.013*"data" + 0.013*"rethink"
INFO: topic #3 (0.623): 0.087*"class" + 0.050*"example" + 0.043*"instance" + 0.032*"frame" + 0.032*"file" + 0.030*"call" + 0.024*"c" + 0.023*"work" + 0.023*"assignment" + 0.022*"print"
INFO: topic #4 (0.340): 0.082*"global" + 0.054*"answer" + 0.049*"loop" + 0.044*"scope" + 0.040*"stack" + 0.025*"inspect" + 0.021*"result" + 0.019*"self" + 0.019*"dimension" + 0.019*"init"
INFO: topic diff=0.551690, rho=0.210352
DEBUG: bound: at document #0
INFO: -6.108 per-word bound, 69.0 perplexity estimate based on a held-out corpus of 5 documents with 164 words
INFO: PROGRESS: pass 6, at document #65/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9193218, 0.5955974, 0.21652043, 0.6268694, 0.3405444]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.919): 0.200*"name" + 0.152*"object" + 0.097*"function" + 0.050*"value" + 0.049*"variable" + 0.038*"code" + 0.017*"source" + 0.017*"case" + 0.016*"attribute" + 0.012*"reference"
INFO: topic #1 (0.596): 0.088*"way" + 0.066*"string" + 0.062*"list" + 0.054*"reference" + 0.044*"note" + 0.043*"namespace" + 0.034*"module" + 0.028*"match" + 0.027*"caller" + 0.024*"integer"
INFO: topic #2 (0.217): 0.088*"method" + 0.027*"parameter" + 0.025*"initialization" + 0.023*"assignent" + 0.023*"production" + 0.022*"debugging" + 0.021*"frame" + 0.015*"constructor" + 0.013*"https://stackoverflow.com/a/49331683/7386061" + 0.012*"data"
INFO: topic #3 (0.627): 0.103*"class" + 0.065*"example" + 0.043*"instance" + 0.035*"assignment" + 0.034*"print" + 0.027*"c" + 0.027*"work" + 0.026*"frame" + 0.026*"file" + 0.024*"call"
INFO: topic #4 (0.341): 0.069*"var" + 0.052*"global" + 0.045*"design" + 0.043*"scope" + 0.034*"answer" + 0.031*"loop" + 0.030*"hash" + 0.030*"choice" + 0.025*"stack" + 0.016*"inspect"
INFO: topic diff=0.407380, rho=0.210352
DEBUG: bound: at document #0
INFO: -6.030 per-word bound, 65.4 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 6, at document #70/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8560973, 0.6083149, 0.22390337, 0.6690555, 0.31421632]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.856): 0.193*"name" + 0.161*"object" + 0.088*"function" + 0.050*"code" + 0.049*"value" + 0.044*"variable" + 0.019*"case" + 0.016*"source" + 0.015*"attribute" + 0.014*"reference"
INFO: topic #1 (0.608): 0.081*"way" + 0.072*"reference" + 0.063*"string" + 0.051*"list" + 0.037*"module" + 0.036*"note" + 0.036*"garbage" + 0.036*"namespace" + 0.027*"return" + 0.023*"match"
INFO: topic #2 (0.224): 0.093*"method" + 0.035*"debugging" + 0.023*"parameter" + 0.022*"initialization" + 0.020*"production" + 0.020*"assignent" + 0.018*"frame" + 0.018*"version" + 0.013*"constructor" + 0.012*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.669): 0.175*"class" + 0.060*"instance" + 0.054*"example" + 0.027*"c" + 0.025*"assignment" + 0.024*"print" + 0.022*"situation" + 0.020*"retrieve" + 0.019*"work" + 0.019*"frame"
INFO: topic #4 (0.314): 0.063*"var" + 0.047*"global" + 0.042*"design" + 0.039*"scope" + 0.032*"answer" + 0.028*"loop" + 0.028*"choice" + 0.028*"hash" + 0.023*"stack" + 0.015*"inspect"
INFO: topic diff=0.200602, rho=0.210352
DEBUG: bound: at document #0
INFO: -6.089 per-word bound, 68.1 perplexity estimate based on a held-out corpus of 5 documents with 112 words
INFO: PROGRESS: pass 6, at document #75/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9677345, 0.68451834, 0.21710947, 0.77122754, 0.32485333]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.968): 0.190*"name" + 0.165*"object" + 0.082*"function" + 0.055*"variable" + 0.048*"code" + 0.040*"value" + 0.023*"case" + 0.017*"source" + 0.015*"reference" + 0.012*"access"
INFO: topic #1 (0.685): 0.075*"way" + 0.062*"reference" + 0.058*"garbage" + 0.053*"list" + 0.051*"module" + 0.050*"namespace" + 0.046*"string" + 0.034*"note" + 0.020*"collection" + 0.020*"return"
INFO: topic #2 (0.217): 0.083*"method" + 0.050*"debugging" + 0.021*"parameter" + 0.020*"initialization" + 0.018*"production" + 0.018*"assignent" + 0.017*"frame" + 0.016*"version" + 0.012*"constructor" + 0.011*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.771): 0.144*"class" + 0.134*"instance" + 0.047*"example" + 0.040*"type" + 0.027*"c" + 0.025*"print" + 0.021*"track" + 0.019*"assignment" + 0.017*"situation" + 0.015*"retrieve"
INFO: topic #4 (0.325): 0.057*"global" + 0.052*"var" + 0.044*"answer" + 0.040*"filter" + 0.035*"design" + 0.033*"scope" + 0.024*"loop" + 0.023*"hash" + 0.023*"choice" + 0.020*"stack"
INFO: topic diff=0.281178, rho=0.210352
DEBUG: bound: at document #0
INFO: -6.602 per-word bound, 97.1 perplexity estimate based on a held-out corpus of 3 documents with 21 words
INFO: PROGRESS: pass 6, at document #78/78
DEBUG: performing inference on a chunk of 3 documents
DEBUG: 3/3 documents converged within 2000 iterations
INFO: optimized alpha [2.070996, 0.658576, 0.20898531, 0.8814246, 0.30791247]
DEBUG: updating topics
INFO: merging changes from 3 documents into a model of 78 documents
INFO: topic #0 (2.071): 0.186*"name" + 0.155*"object" + 0.089*"function" + 0.051*"code" + 0.049*"variable" + 0.035*"value" + 0.021*"case" + 0.018*"attribute" + 0.016*"thing" + 0.015*"source"
INFO: topic #1 (0.659): 0.086*"way" + 0.058*"reference" + 0.055*"garbage" + 0.050*"list" + 0.048*"module" + 0.047*"namespace" + 0.043*"string" + 0.032*"note" + 0.019*"collection" + 0.019*"return"
INFO: topic #2 (0.209): 0.075*"method" + 0.045*"debugging" + 0.019*"parameter" + 0.018*"initialization" + 0.016*"production" + 0.016*"assignent" + 0.015*"frame" + 0.015*"version" + 0.011*"constructor" + 0.010*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.881): 0.148*"class" + 0.127*"instance" + 0.046*"print" + 0.040*"example" + 0.034*"type" + 0.029*"part" + 0.023*"c" + 0.018*"track" + 0.016*"assignment" + 0.014*"situation"
INFO: topic #4 (0.308): 0.052*"global" + 0.047*"var" + 0.040*"answer" + 0.037*"filter" + 0.032*"design" + 0.030*"scope" + 0.022*"loop" + 0.021*"choice" + 0.021*"hash" + 0.018*"stack"
INFO: topic diff=0.138947, rho=0.210352
DEBUG: bound: at document #0
INFO: -5.266 per-word bound, 38.5 perplexity estimate based on a held-out corpus of 5 documents with 130 words
INFO: PROGRESS: pass 7, at document #5/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7872438, 0.6455237, 0.20152292, 0.64972246, 0.26847678]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.787): 0.175*"name" + 0.123*"object" + 0.092*"function" + 0.056*"variable" + 0.050*"code" + 0.040*"value" + 0.028*"thing" + 0.022*"attribute" + 0.020*"case" + 0.018*"language"
INFO: topic #1 (0.646): 0.086*"string" + 0.081*"list" + 0.072*"way" + 0.043*"reference" + 0.041*"garbage" + 0.035*"module" + 0.035*"namespace" + 0.033*"note" + 0.031*"return" + 0.014*"collection"
INFO: topic #2 (0.202): 0.078*"method" + 0.055*"debugging" + 0.026*"foo" + 0.024*"order" + 0.020*"snippet" + 0.020*"drawback" + 0.015*"parameter" + 0.015*"word" + 0.014*"initialization" + 0.013*"production"
INFO: topic #3 (0.650): 0.141*"class" + 0.121*"instance" + 0.044*"print" + 0.039*"example" + 0.033*"type" + 0.028*"part" + 0.022*"c" + 0.017*"track" + 0.015*"assignment" + 0.014*"situation"
INFO: topic #4 (0.268): 0.046*"global" + 0.042*"var" + 0.036*"answer" + 0.033*"filter" + 0.028*"design" + 0.027*"scope" + 0.020*"loop" + 0.019*"choice" + 0.019*"hash" + 0.016*"stack"
INFO: topic diff=0.243001, rho=0.205847
DEBUG: bound: at document #0
INFO: -6.435 per-word bound, 86.5 perplexity estimate based on a held-out corpus of 5 documents with 191 words
INFO: PROGRESS: pass 7, at document #10/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.4757031, 0.52998036, 0.21632004, 0.62780964, 0.28493395]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.476): 0.176*"name" + 0.102*"function" + 0.099*"object" + 0.070*"variable" + 0.062*"code" + 0.050*"value" + 0.024*"source" + 0.024*"case" + 0.022*"thing" + 0.018*"attribute"
INFO: topic #1 (0.530): 0.093*"list" + 0.085*"string" + 0.066*"way" + 0.039*"note" + 0.039*"reference" + 0.037*"garbage" + 0.032*"module" + 0.032*"namespace" + 0.028*"return" + 0.017*"documentation"
INFO: topic #2 (0.216): 0.093*"method" + 0.089*"foo" + 0.040*"debugging" + 0.028*"initialization" + 0.026*"version" + 0.024*"frame" + 0.018*"order" + 0.017*"word" + 0.015*"drawback" + 0.015*"snippet"
INFO: topic #3 (0.628): 0.078*"class" + 0.069*"instance" + 0.055*"frame" + 0.042*"example" + 0.036*"varname" + 0.032*"assignment" + 0.028*"need" + 0.027*"environment" + 0.025*"print" + 0.022*"part"
INFO: topic #4 (0.285): 0.071*"answer" + 0.050*"scope" + 0.045*"global" + 0.043*"var" + 0.027*"stack" + 0.023*"inspect" + 0.020*"filter" + 0.018*"bit" + 0.017*"design" + 0.017*"var_2"
INFO: topic diff=0.421729, rho=0.205847
DEBUG: bound: at document #0
INFO: -6.419 per-word bound, 85.6 perplexity estimate based on a held-out corpus of 5 documents with 45 words
INFO: PROGRESS: pass 7, at document #15/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.5643696, 0.5342751, 0.20389977, 0.5837545, 0.27931607]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.564): 0.174*"name" + 0.091*"object" + 0.090*"function" + 0.089*"variable" + 0.068*"value" + 0.054*"code" + 0.025*"case" + 0.021*"source" + 0.020*"thing" + 0.018*"access"
INFO: topic #1 (0.534): 0.080*"string" + 0.076*"list" + 0.064*"way" + 0.034*"return" + 0.032*"note" + 0.032*"reference" + 0.030*"garbage" + 0.027*"module" + 0.026*"namespace" + 0.024*"content"
INFO: topic #2 (0.204): 0.084*"method" + 0.081*"foo" + 0.036*"debugging" + 0.026*"initialization" + 0.024*"version" + 0.022*"frame" + 0.016*"order" + 0.016*"word" + 0.014*"drawback" + 0.014*"snippet"
INFO: topic #3 (0.584): 0.081*"class" + 0.066*"instance" + 0.053*"frame" + 0.040*"example" + 0.034*"varname" + 0.030*"assignment" + 0.027*"need" + 0.026*"environment" + 0.024*"print" + 0.022*"part"
INFO: topic #4 (0.279): 0.060*"scope" + 0.060*"answer" + 0.038*"global" + 0.036*"var" + 0.033*"bit" + 0.023*"stack" + 0.020*"inspect" + 0.017*"filter" + 0.015*"design" + 0.015*"defining"
INFO: topic diff=0.140638, rho=0.205847
DEBUG: bound: at document #0
INFO: -5.914 per-word bound, 60.3 perplexity estimate based on a held-out corpus of 5 documents with 37 words
INFO: PROGRESS: pass 7, at document #20/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6249338, 0.555838, 0.20446678, 0.55120224, 0.3091575]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.625): 0.184*"name" + 0.098*"variable" + 0.094*"function" + 0.082*"object" + 0.074*"value" + 0.049*"code" + 0.022*"case" + 0.019*"source" + 0.018*"thing" + 0.016*"access"
INFO: topic #1 (0.556): 0.087*"list" + 0.068*"string" + 0.061*"return" + 0.054*"way" + 0.034*"module" + 0.033*"namespace" + 0.028*"note" + 0.027*"reference" + 0.026*"garbage" + 0.023*"index"
INFO: topic #2 (0.204): 0.113*"method" + 0.068*"foo" + 0.032*"frame" + 0.031*"debugging" + 0.022*"initialization" + 0.020*"version" + 0.014*"order" + 0.014*"word" + 0.012*"snippet" + 0.012*"drawback"
INFO: topic #3 (0.551): 0.077*"class" + 0.063*"instance" + 0.053*"frame" + 0.038*"example" + 0.033*"varname" + 0.029*"assignment" + 0.026*"need" + 0.025*"environment" + 0.023*"print" + 0.021*"part"
INFO: topic #4 (0.309): 0.083*"answer" + 0.066*"scope" + 0.048*"global" + 0.046*"var" + 0.027*"bit" + 0.022*"result" + 0.018*"stack" + 0.018*"variation" + 0.016*"inspect" + 0.014*"filter"
INFO: topic diff=0.102968, rho=0.205847
DEBUG: bound: at document #0
INFO: -6.551 per-word bound, 93.8 perplexity estimate based on a held-out corpus of 5 documents with 69 words
INFO: PROGRESS: pass 7, at document #25/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7120734, 0.5503427, 0.20216312, 0.59054744, 0.31532612]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.712): 0.163*"name" + 0.121*"function" + 0.101*"variable" + 0.078*"object" + 0.067*"value" + 0.045*"code" + 0.019*"local" + 0.019*"case" + 0.016*"source" + 0.015*"thing"
INFO: topic #1 (0.550): 0.076*"string" + 0.070*"list" + 0.061*"return" + 0.055*"way" + 0.027*"module" + 0.027*"namespace" + 0.022*"note" + 0.022*"reference" + 0.021*"garbage" + 0.019*"index"
INFO: topic #2 (0.202): 0.097*"method" + 0.058*"foo" + 0.049*"debugging" + 0.028*"frame" + 0.019*"initialization" + 0.018*"version" + 0.012*"order" + 0.012*"word" + 0.010*"drawback" + 0.010*"snippet"
INFO: topic #3 (0.591): 0.071*"class" + 0.054*"example" + 0.052*"instance" + 0.044*"frame" + 0.030*"call" + 0.029*"need" + 0.027*"varname" + 0.026*"print" + 0.026*"type" + 0.024*"assignment"
INFO: topic #4 (0.315): 0.074*"var" + 0.067*"answer" + 0.057*"global" + 0.053*"scope" + 0.031*"inspect" + 0.022*"bit" + 0.019*"idea" + 0.019*"process" + 0.018*"result" + 0.015*"stack"
INFO: topic diff=0.179726, rho=0.205847
DEBUG: bound: at document #0
INFO: -6.272 per-word bound, 77.3 perplexity estimate based on a held-out corpus of 5 documents with 89 words
INFO: PROGRESS: pass 7, at document #30/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7462196, 0.56765336, 0.19987006, 0.6156163, 0.3163049]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.746): 0.166*"name" + 0.113*"function" + 0.093*"variable" + 0.071*"object" + 0.065*"code" + 0.054*"value" + 0.030*"source" + 0.019*"local" + 0.014*"case" + 0.011*"thing"
INFO: topic #1 (0.568): 0.084*"list" + 0.074*"string" + 0.052*"way" + 0.052*"module" + 0.046*"return" + 0.034*"reference" + 0.031*"namespace" + 0.023*"integer" + 0.021*"match" + 0.017*"note"
INFO: topic #2 (0.200): 0.080*"method" + 0.048*"foo" + 0.041*"debugging" + 0.028*"constructor" + 0.024*"sorcery" + 0.023*"frame" + 0.016*"initialization" + 0.016*"kind" + 0.015*"version" + 0.010*"order"
INFO: topic #3 (0.616): 0.078*"class" + 0.063*"example" + 0.046*"instance" + 0.039*"frame" + 0.026*"call" + 0.025*"retrieve" + 0.025*"need" + 0.024*"varname" + 0.023*"print" + 0.023*"type"
INFO: topic #4 (0.316): 0.066*"global" + 0.061*"var" + 0.056*"answer" + 0.050*"stack" + 0.044*"scope" + 0.026*"inspect" + 0.018*"bit" + 0.017*"python3" + 0.016*"idea" + 0.016*"process"
INFO: topic diff=0.230853, rho=0.205847
DEBUG: bound: at document #0
INFO: -5.222 per-word bound, 37.3 perplexity estimate based on a held-out corpus of 5 documents with 114 words
INFO: PROGRESS: pass 7, at document #35/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.886929, 0.6223313, 0.18836613, 0.6198996, 0.28896782]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.887): 0.220*"name" + 0.106*"object" + 0.103*"function" + 0.074*"variable" + 0.046*"value" + 0.046*"code" + 0.021*"local" + 0.021*"source" + 0.014*"case" + 0.011*"approach"
INFO: topic #1 (0.622): 0.125*"list" + 0.073*"string" + 0.069*"way" + 0.043*"module" + 0.039*"return" + 0.038*"namespace" + 0.027*"reference" + 0.018*"index" + 0.017*"define" + 0.017*"element"
INFO: topic #2 (0.188): 0.070*"method" + 0.042*"foo" + 0.036*"debugging" + 0.025*"constructor" + 0.021*"sorcery" + 0.020*"frame" + 0.014*"kind" + 0.014*"initialization" + 0.013*"version" + 0.009*"order"
INFO: topic #3 (0.620): 0.094*"class" + 0.073*"example" + 0.048*"instance" + 0.033*"frame" + 0.027*"assignment" + 0.023*"call" + 0.022*"retrieve" + 0.022*"need" + 0.021*"varname" + 0.020*"course"
INFO: topic #4 (0.289): 0.059*"global" + 0.055*"var" + 0.051*"answer" + 0.045*"stack" + 0.040*"scope" + 0.024*"inspect" + 0.017*"bit" + 0.016*"python3" + 0.015*"idea" + 0.015*"process"
INFO: topic diff=0.258343, rho=0.205847
DEBUG: bound: at document #0
INFO: -7.230 per-word bound, 150.1 perplexity estimate based on a held-out corpus of 5 documents with 32 words
INFO: PROGRESS: pass 7, at document #40/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6480125, 0.57901424, 0.18523489, 0.5912959, 0.30987626]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.648): 0.209*"name" + 0.115*"function" + 0.103*"object" + 0.069*"variable" + 0.043*"value" + 0.043*"code" + 0.022*"case" + 0.020*"local" + 0.020*"source" + 0.010*"approach"
INFO: topic #1 (0.579): 0.115*"list" + 0.067*"string" + 0.064*"way" + 0.060*"module" + 0.036*"return" + 0.035*"namespace" + 0.025*"reference" + 0.020*"note" + 0.017*"index" + 0.016*"define"
INFO: topic #2 (0.185): 0.063*"foo" + 0.059*"method" + 0.030*"debugging" + 0.021*"constructor" + 0.018*"sorcery" + 0.017*"frame" + 0.012*"kind" + 0.012*"initialization" + 0.012*"version" + 0.008*"order"
INFO: topic #3 (0.591): 0.104*"class" + 0.065*"example" + 0.043*"instance" + 0.030*"frame" + 0.028*"course" + 0.028*"type" + 0.024*"work" + 0.024*"assignment" + 0.020*"call" + 0.019*"retrieve"
INFO: topic #4 (0.310): 0.072*"answer" + 0.060*"global" + 0.041*"loop" + 0.039*"var" + 0.032*"stack" + 0.028*"result" + 0.028*"scope" + 0.025*"filter" + 0.019*"each_item" + 0.019*"globals().item"
INFO: topic diff=0.152021, rho=0.205847
DEBUG: bound: at document #0
INFO: -6.001 per-word bound, 64.0 perplexity estimate based on a held-out corpus of 5 documents with 133 words
INFO: PROGRESS: pass 7, at document #45/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7497821, 0.5953376, 0.19821326, 0.56065005, 0.3015645]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.750): 0.227*"name" + 0.133*"function" + 0.109*"object" + 0.055*"value" + 0.052*"variable" + 0.030*"code" + 0.020*"case" + 0.019*"attribute" + 0.014*"local" + 0.014*"source"
INFO: topic #1 (0.595): 0.083*"list" + 0.076*"string" + 0.050*"way" + 0.047*"module" + 0.033*"match" + 0.032*"return" + 0.030*"note" + 0.030*"reference" + 0.024*"test_function" + 0.023*"namespace"
INFO: topic #2 (0.198): 0.057*"method" + 0.039*"debugging" + 0.038*"foo" + 0.027*"frame" + 0.026*"order" + 0.024*"story" + 0.021*"basestring" + 0.021*"grab" + 0.021*"eval" + 0.021*"guess"
INFO: topic #3 (0.561): 0.089*"class" + 0.066*"example" + 0.048*"instance" + 0.045*"course" + 0.028*"frame" + 0.026*"print" + 0.024*"type" + 0.021*"work" + 0.021*"assignment" + 0.019*"magic"
INFO: topic #4 (0.302): 0.070*"global" + 0.061*"answer" + 0.046*"stack" + 0.043*"result" + 0.035*"loop" + 0.032*"var" + 0.024*"scope" + 0.021*"filter" + 0.017*"globals().item" + 0.017*"each_item"
INFO: topic diff=0.366805, rho=0.205847
DEBUG: bound: at document #0
INFO: -5.890 per-word bound, 59.3 perplexity estimate based on a held-out corpus of 5 documents with 67 words
INFO: PROGRESS: pass 7, at document #50/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9163334, 0.6333005, 0.19635217, 0.55101544, 0.32158977]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.916): 0.228*"name" + 0.142*"function" + 0.093*"object" + 0.051*"variable" + 0.049*"value" + 0.029*"code" + 0.024*"attribute" + 0.016*"case" + 0.016*"local" + 0.012*"def"
INFO: topic #1 (0.633): 0.082*"string" + 0.071*"list" + 0.060*"way" + 0.058*"module" + 0.037*"match" + 0.036*"return" + 0.034*"note" + 0.025*"reference" + 0.021*"test_function" + 0.020*"namespace"
INFO: topic #2 (0.196): 0.071*"method" + 0.034*"debugging" + 0.033*"foo" + 0.024*"frame" + 0.023*"order" + 0.021*"story" + 0.019*"grab" + 0.019*"long" + 0.019*"traverse" + 0.019*"basestring"
INFO: topic #3 (0.551): 0.110*"class" + 0.068*"example" + 0.041*"instance" + 0.039*"course" + 0.026*"need" + 0.024*"frame" + 0.022*"print" + 0.020*"type" + 0.018*"work" + 0.018*"assignment"
INFO: topic #4 (0.322): 0.111*"global" + 0.066*"answer" + 0.036*"stack" + 0.034*"result" + 0.027*"loop" + 0.025*"var" + 0.018*"scope" + 0.016*"filter" + 0.016*"bla" + 0.016*"my_list"
INFO: topic diff=0.172452, rho=0.205847
DEBUG: bound: at document #0
INFO: -6.155 per-word bound, 71.2 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 7, at document #55/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9764881, 0.6532955, 0.20242113, 0.5972295, 0.33982152]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.976): 0.220*"name" + 0.122*"function" + 0.112*"object" + 0.049*"value" + 0.047*"variable" + 0.033*"code" + 0.022*"case" + 0.020*"attribute" + 0.015*"search" + 0.014*"source"
INFO: topic #1 (0.653): 0.073*"list" + 0.072*"string" + 0.063*"way" + 0.053*"match" + 0.051*"module" + 0.042*"return" + 0.040*"note" + 0.026*"reference" + 0.019*"test_function" + 0.017*"namespace"
INFO: topic #2 (0.202): 0.106*"method" + 0.028*"debugging" + 0.028*"foo" + 0.020*"frame" + 0.019*"order" + 0.018*"story" + 0.016*"traverse" + 0.016*"page" + 0.016*"long" + 0.016*"eval"
INFO: topic #3 (0.597): 0.118*"class" + 0.059*"instance" + 0.058*"example" + 0.036*"print" + 0.028*"player" + 0.028*"environment" + 0.027*"course" + 0.025*"track" + 0.021*"iterator" + 0.018*"need"
INFO: topic #4 (0.340): 0.108*"global" + 0.072*"answer" + 0.041*"loop" + 0.034*"scope" + 0.029*"stack" + 0.027*"result" + 0.020*"var" + 0.014*"atribute" + 0.013*"filter" + 0.013*"my_list"
INFO: topic diff=0.196603, rho=0.205847
DEBUG: bound: at document #0
INFO: -6.646 per-word bound, 100.2 perplexity estimate based on a held-out corpus of 5 documents with 183 words
INFO: PROGRESS: pass 7, at document #60/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8640109, 0.58722395, 0.21753332, 0.62386143, 0.33883852]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.864): 0.207*"name" + 0.136*"object" + 0.116*"function" + 0.046*"code" + 0.038*"value" + 0.037*"variable" + 0.025*"source" + 0.019*"case" + 0.014*"attribute" + 0.013*"line"
INFO: topic #1 (0.587): 0.082*"way" + 0.076*"string" + 0.069*"list" + 0.053*"note" + 0.052*"module" + 0.043*"match" + 0.041*"caller" + 0.034*"return" + 0.022*"reference" + 0.015*"test_function"
INFO: topic #2 (0.218): 0.083*"method" + 0.028*"initialization" + 0.025*"assignent" + 0.025*"production" + 0.025*"debugging" + 0.023*"frame" + 0.017*"constructor" + 0.014*"parameter" + 0.013*"data" + 0.013*"rethink"
INFO: topic #3 (0.624): 0.087*"class" + 0.051*"example" + 0.044*"instance" + 0.032*"frame" + 0.031*"file" + 0.030*"call" + 0.023*"c" + 0.023*"work" + 0.023*"assignment" + 0.022*"print"
INFO: topic #4 (0.339): 0.082*"global" + 0.055*"answer" + 0.048*"loop" + 0.044*"scope" + 0.040*"stack" + 0.025*"inspect" + 0.021*"result" + 0.019*"determine" + 0.019*"self" + 0.019*"init"
INFO: topic diff=0.530155, rho=0.205847
DEBUG: bound: at document #0
INFO: -6.075 per-word bound, 67.4 perplexity estimate based on a held-out corpus of 5 documents with 164 words
INFO: PROGRESS: pass 7, at document #65/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.913125, 0.5992985, 0.21647355, 0.62684155, 0.33946148]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.913): 0.201*"name" + 0.151*"object" + 0.097*"function" + 0.050*"value" + 0.049*"variable" + 0.039*"code" + 0.017*"source" + 0.017*"case" + 0.016*"attribute" + 0.011*"access"
INFO: topic #1 (0.599): 0.087*"way" + 0.066*"string" + 0.062*"list" + 0.059*"reference" + 0.043*"note" + 0.043*"namespace" + 0.034*"module" + 0.028*"match" + 0.027*"caller" + 0.024*"integer"
INFO: topic #2 (0.216): 0.087*"method" + 0.026*"parameter" + 0.025*"initialization" + 0.022*"assignent" + 0.022*"production" + 0.022*"debugging" + 0.021*"frame" + 0.015*"constructor" + 0.013*"https://stackoverflow.com/a/49331683/7386061" + 0.012*"moment"
INFO: topic #3 (0.627): 0.103*"class" + 0.065*"example" + 0.044*"instance" + 0.035*"assignment" + 0.034*"print" + 0.027*"c" + 0.027*"work" + 0.026*"frame" + 0.026*"file" + 0.024*"call"
INFO: topic #4 (0.339): 0.068*"var" + 0.052*"global" + 0.045*"design" + 0.043*"scope" + 0.035*"answer" + 0.031*"loop" + 0.030*"choice" + 0.030*"hash" + 0.026*"stack" + 0.016*"inspect"
INFO: topic diff=0.392597, rho=0.205847
DEBUG: bound: at document #0
INFO: -6.012 per-word bound, 64.5 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 7, at document #70/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.849106, 0.611653, 0.22363856, 0.6677801, 0.31372175]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.849): 0.194*"name" + 0.160*"object" + 0.089*"function" + 0.050*"code" + 0.049*"value" + 0.044*"variable" + 0.019*"case" + 0.016*"source" + 0.015*"attribute" + 0.014*"solution"
INFO: topic #1 (0.612): 0.080*"way" + 0.078*"reference" + 0.063*"string" + 0.051*"list" + 0.037*"module" + 0.036*"note" + 0.035*"namespace" + 0.035*"garbage" + 0.027*"return" + 0.023*"match"
INFO: topic #2 (0.224): 0.092*"method" + 0.035*"debugging" + 0.023*"parameter" + 0.022*"initialization" + 0.020*"production" + 0.020*"assignent" + 0.018*"frame" + 0.017*"version" + 0.013*"constructor" + 0.012*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.668): 0.174*"class" + 0.060*"instance" + 0.054*"example" + 0.027*"c" + 0.025*"assignment" + 0.024*"print" + 0.022*"situation" + 0.020*"retrieve" + 0.019*"work" + 0.019*"frame"
INFO: topic #4 (0.314): 0.063*"var" + 0.048*"global" + 0.041*"design" + 0.039*"scope" + 0.032*"answer" + 0.029*"loop" + 0.027*"choice" + 0.027*"hash" + 0.024*"stack" + 0.015*"inspect"
INFO: topic diff=0.193210, rho=0.205847
DEBUG: bound: at document #0
INFO: -6.075 per-word bound, 67.4 perplexity estimate based on a held-out corpus of 5 documents with 112 words
INFO: PROGRESS: pass 7, at document #75/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9566542, 0.68699914, 0.21696043, 0.7675325, 0.32393894]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.957): 0.191*"name" + 0.164*"object" + 0.083*"function" + 0.055*"variable" + 0.048*"code" + 0.040*"value" + 0.023*"case" + 0.017*"source" + 0.012*"attribute" + 0.012*"access"
INFO: topic #1 (0.687): 0.074*"way" + 0.067*"reference" + 0.057*"garbage" + 0.053*"list" + 0.051*"module" + 0.049*"namespace" + 0.046*"string" + 0.034*"note" + 0.020*"collection" + 0.020*"return"
INFO: topic #2 (0.217): 0.083*"method" + 0.049*"debugging" + 0.021*"parameter" + 0.020*"initialization" + 0.018*"production" + 0.018*"assignent" + 0.017*"frame" + 0.016*"version" + 0.012*"constructor" + 0.011*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.768): 0.144*"class" + 0.133*"instance" + 0.047*"example" + 0.040*"type" + 0.027*"c" + 0.025*"print" + 0.020*"track" + 0.019*"assignment" + 0.016*"situation" + 0.015*"retrieve"
INFO: topic #4 (0.324): 0.058*"global" + 0.052*"var" + 0.044*"answer" + 0.040*"filter" + 0.035*"design" + 0.033*"scope" + 0.024*"loop" + 0.023*"hash" + 0.023*"choice" + 0.020*"stack"
INFO: topic diff=0.270999, rho=0.205847
DEBUG: bound: at document #0
INFO: -6.585 per-word bound, 96.0 perplexity estimate based on a held-out corpus of 3 documents with 21 words
INFO: PROGRESS: pass 7, at document #78/78
DEBUG: performing inference on a chunk of 3 documents
DEBUG: 3/3 documents converged within 2000 iterations
INFO: optimized alpha [2.0576594, 0.6607741, 0.20897155, 0.8745577, 0.30730948]
DEBUG: updating topics
INFO: merging changes from 3 documents into a model of 78 documents
INFO: topic #0 (2.058): 0.187*"name" + 0.155*"object" + 0.089*"function" + 0.051*"code" + 0.050*"variable" + 0.036*"value" + 0.021*"case" + 0.018*"attribute" + 0.016*"thing" + 0.015*"source"
INFO: topic #1 (0.661): 0.085*"way" + 0.063*"reference" + 0.054*"garbage" + 0.050*"list" + 0.048*"module" + 0.046*"namespace" + 0.043*"string" + 0.032*"note" + 0.019*"collection" + 0.019*"return"
INFO: topic #2 (0.209): 0.075*"method" + 0.044*"debugging" + 0.019*"parameter" + 0.018*"initialization" + 0.017*"production" + 0.017*"assignent" + 0.015*"frame" + 0.015*"version" + 0.011*"constructor" + 0.010*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.875): 0.147*"class" + 0.126*"instance" + 0.046*"print" + 0.041*"example" + 0.034*"type" + 0.029*"part" + 0.023*"c" + 0.018*"track" + 0.016*"assignment" + 0.014*"situation"
INFO: topic #4 (0.307): 0.052*"global" + 0.047*"var" + 0.040*"answer" + 0.036*"filter" + 0.032*"design" + 0.030*"scope" + 0.022*"loop" + 0.021*"choice" + 0.021*"hash" + 0.018*"stack"
INFO: topic diff=0.134450, rho=0.205847
DEBUG: bound: at document #0
INFO: -5.250 per-word bound, 38.1 perplexity estimate based on a held-out corpus of 5 documents with 130 words
INFO: PROGRESS: pass 8, at document #5/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7908542, 0.64844346, 0.20173694, 0.6517477, 0.2690457]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.791): 0.175*"name" + 0.124*"object" + 0.092*"function" + 0.056*"variable" + 0.050*"code" + 0.040*"value" + 0.028*"thing" + 0.022*"attribute" + 0.020*"case" + 0.018*"language"
INFO: topic #1 (0.648): 0.085*"string" + 0.080*"list" + 0.072*"way" + 0.047*"reference" + 0.040*"garbage" + 0.036*"module" + 0.035*"namespace" + 0.032*"note" + 0.031*"return" + 0.014*"collection"
INFO: topic #2 (0.202): 0.078*"method" + 0.054*"debugging" + 0.026*"foo" + 0.024*"order" + 0.020*"snippet" + 0.020*"drawback" + 0.015*"parameter" + 0.014*"initialization" + 0.013*"production" + 0.013*"assignent"
INFO: topic #3 (0.652): 0.141*"class" + 0.120*"instance" + 0.044*"print" + 0.039*"example" + 0.033*"type" + 0.028*"part" + 0.022*"c" + 0.017*"track" + 0.016*"assignment" + 0.014*"situation"
INFO: topic #4 (0.269): 0.047*"global" + 0.043*"var" + 0.036*"answer" + 0.033*"filter" + 0.028*"design" + 0.027*"scope" + 0.020*"loop" + 0.019*"hash" + 0.019*"choice" + 0.017*"stack"
INFO: topic diff=0.234404, rho=0.201619
DEBUG: bound: at document #0
INFO: -6.404 per-word bound, 84.7 perplexity estimate based on a held-out corpus of 5 documents with 191 words
INFO: PROGRESS: pass 8, at document #10/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.4840839, 0.53444177, 0.2160679, 0.62985706, 0.28516558]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.484): 0.176*"name" + 0.102*"function" + 0.100*"object" + 0.070*"variable" + 0.061*"code" + 0.050*"value" + 0.024*"source" + 0.024*"case" + 0.022*"thing" + 0.018*"attribute"
INFO: topic #1 (0.534): 0.092*"list" + 0.084*"string" + 0.065*"way" + 0.043*"reference" + 0.039*"note" + 0.036*"garbage" + 0.032*"module" + 0.032*"namespace" + 0.028*"return" + 0.018*"documentation"
INFO: topic #2 (0.216): 0.093*"method" + 0.088*"foo" + 0.040*"debugging" + 0.028*"initialization" + 0.026*"version" + 0.024*"frame" + 0.018*"order" + 0.015*"drawback" + 0.015*"snippet" + 0.013*"word"
INFO: topic #3 (0.630): 0.079*"class" + 0.069*"instance" + 0.055*"frame" + 0.042*"example" + 0.035*"varname" + 0.031*"assignment" + 0.028*"need" + 0.027*"environment" + 0.025*"print" + 0.022*"part"
INFO: topic #4 (0.285): 0.071*"answer" + 0.050*"scope" + 0.045*"global" + 0.043*"var" + 0.027*"stack" + 0.023*"inspect" + 0.020*"filter" + 0.018*"bit" + 0.017*"design" + 0.017*"var_2"
INFO: topic diff=0.407078, rho=0.201619
DEBUG: bound: at document #0
INFO: -6.404 per-word bound, 84.7 perplexity estimate based on a held-out corpus of 5 documents with 45 words
INFO: PROGRESS: pass 8, at document #15/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.5705905, 0.5383432, 0.20394261, 0.5864261, 0.2797193]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.571): 0.174*"name" + 0.092*"object" + 0.090*"function" + 0.089*"variable" + 0.067*"value" + 0.054*"code" + 0.025*"case" + 0.021*"source" + 0.020*"thing" + 0.018*"access"
INFO: topic #1 (0.538): 0.079*"string" + 0.076*"list" + 0.064*"way" + 0.035*"reference" + 0.033*"return" + 0.032*"note" + 0.030*"garbage" + 0.027*"module" + 0.026*"namespace" + 0.023*"content"
INFO: topic #2 (0.204): 0.084*"method" + 0.080*"foo" + 0.036*"debugging" + 0.026*"initialization" + 0.024*"version" + 0.022*"frame" + 0.016*"order" + 0.014*"drawback" + 0.014*"snippet" + 0.012*"word"
INFO: topic #3 (0.586): 0.082*"class" + 0.067*"instance" + 0.053*"frame" + 0.040*"example" + 0.034*"varname" + 0.030*"assignment" + 0.027*"need" + 0.026*"environment" + 0.024*"print" + 0.022*"part"
INFO: topic #4 (0.280): 0.060*"answer" + 0.060*"scope" + 0.038*"global" + 0.036*"var" + 0.033*"bit" + 0.023*"stack" + 0.020*"inspect" + 0.017*"filter" + 0.015*"design" + 0.015*"var_1"
INFO: topic diff=0.135488, rho=0.201619
DEBUG: bound: at document #0
INFO: -5.910 per-word bound, 60.1 perplexity estimate based on a held-out corpus of 5 documents with 37 words
INFO: PROGRESS: pass 8, at document #20/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6296278, 0.5593637, 0.20450744, 0.55428535, 0.30899245]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.630): 0.184*"name" + 0.098*"variable" + 0.095*"function" + 0.083*"object" + 0.074*"value" + 0.049*"code" + 0.022*"case" + 0.019*"source" + 0.018*"thing" + 0.016*"access"
INFO: topic #1 (0.559): 0.086*"list" + 0.067*"string" + 0.060*"return" + 0.055*"way" + 0.034*"module" + 0.033*"namespace" + 0.030*"reference" + 0.028*"note" + 0.026*"garbage" + 0.023*"index"
INFO: topic #2 (0.205): 0.113*"method" + 0.067*"foo" + 0.032*"frame" + 0.031*"debugging" + 0.022*"initialization" + 0.020*"version" + 0.014*"order" + 0.012*"snippet" + 0.012*"drawback" + 0.010*"word"
INFO: topic #3 (0.554): 0.078*"class" + 0.064*"instance" + 0.053*"frame" + 0.039*"example" + 0.032*"varname" + 0.029*"assignment" + 0.025*"need" + 0.025*"environment" + 0.023*"print" + 0.021*"part"
INFO: topic #4 (0.309): 0.083*"answer" + 0.065*"scope" + 0.048*"global" + 0.046*"var" + 0.026*"bit" + 0.022*"result" + 0.018*"stack" + 0.018*"variation" + 0.016*"inspect" + 0.014*"filter"
INFO: topic diff=0.099746, rho=0.201619
DEBUG: bound: at document #0
INFO: -6.538 per-word bound, 92.9 perplexity estimate based on a held-out corpus of 5 documents with 69 words
INFO: PROGRESS: pass 8, at document #25/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7150586, 0.55390954, 0.20222571, 0.5925841, 0.31504264]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.715): 0.163*"name" + 0.120*"function" + 0.100*"variable" + 0.079*"object" + 0.067*"value" + 0.046*"code" + 0.019*"local" + 0.019*"case" + 0.016*"source" + 0.015*"thing"
INFO: topic #1 (0.554): 0.075*"string" + 0.070*"list" + 0.060*"return" + 0.055*"way" + 0.027*"module" + 0.027*"namespace" + 0.025*"reference" + 0.023*"note" + 0.021*"garbage" + 0.019*"index"
INFO: topic #2 (0.202): 0.097*"method" + 0.058*"foo" + 0.049*"debugging" + 0.028*"frame" + 0.019*"initialization" + 0.018*"version" + 0.012*"order" + 0.010*"drawback" + 0.010*"snippet" + 0.009*"word"
INFO: topic #3 (0.593): 0.072*"class" + 0.054*"example" + 0.053*"instance" + 0.044*"frame" + 0.030*"call" + 0.028*"need" + 0.027*"varname" + 0.026*"print" + 0.026*"type" + 0.024*"assignment"
INFO: topic #4 (0.315): 0.073*"var" + 0.067*"answer" + 0.057*"global" + 0.053*"scope" + 0.031*"inspect" + 0.021*"bit" + 0.019*"process" + 0.019*"idea" + 0.018*"result" + 0.015*"stack"
INFO: topic diff=0.173214, rho=0.201619
DEBUG: bound: at document #0
INFO: -6.250 per-word bound, 76.1 perplexity estimate based on a held-out corpus of 5 documents with 89 words
INFO: PROGRESS: pass 8, at document #30/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7471241, 0.5703548, 0.19993275, 0.61679333, 0.31588984]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.747): 0.166*"name" + 0.112*"function" + 0.093*"variable" + 0.072*"object" + 0.065*"code" + 0.055*"value" + 0.029*"source" + 0.019*"local" + 0.014*"case" + 0.011*"thing"
INFO: topic #1 (0.570): 0.083*"list" + 0.074*"string" + 0.052*"way" + 0.051*"module" + 0.045*"return" + 0.037*"reference" + 0.031*"namespace" + 0.023*"integer" + 0.020*"match" + 0.017*"note"
INFO: topic #2 (0.200): 0.081*"method" + 0.048*"foo" + 0.041*"debugging" + 0.028*"constructor" + 0.024*"sorcery" + 0.023*"frame" + 0.016*"initialization" + 0.015*"kind" + 0.015*"version" + 0.011*"order"
INFO: topic #3 (0.617): 0.079*"class" + 0.063*"example" + 0.046*"instance" + 0.039*"frame" + 0.026*"call" + 0.025*"need" + 0.025*"retrieve" + 0.024*"varname" + 0.023*"print" + 0.023*"type"
INFO: topic #4 (0.316): 0.066*"global" + 0.061*"var" + 0.056*"answer" + 0.050*"stack" + 0.044*"scope" + 0.026*"inspect" + 0.018*"bit" + 0.017*"python3" + 0.016*"process" + 0.016*"idea"
INFO: topic diff=0.221749, rho=0.201619
DEBUG: bound: at document #0
INFO: -5.211 per-word bound, 37.0 perplexity estimate based on a held-out corpus of 5 documents with 114 words
INFO: PROGRESS: pass 8, at document #35/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8880343, 0.6293788, 0.18875924, 0.6217569, 0.28945023]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.888): 0.219*"name" + 0.106*"object" + 0.104*"function" + 0.074*"variable" + 0.047*"value" + 0.046*"code" + 0.021*"local" + 0.021*"source" + 0.014*"case" + 0.011*"approach"
INFO: topic #1 (0.629): 0.123*"list" + 0.072*"string" + 0.068*"way" + 0.043*"module" + 0.039*"return" + 0.037*"namespace" + 0.032*"reference" + 0.018*"index" + 0.017*"define" + 0.017*"element"
INFO: topic #2 (0.189): 0.071*"method" + 0.043*"foo" + 0.036*"debugging" + 0.025*"constructor" + 0.021*"sorcery" + 0.020*"frame" + 0.014*"initialization" + 0.014*"kind" + 0.013*"version" + 0.010*"order"
INFO: topic #3 (0.622): 0.095*"class" + 0.072*"example" + 0.049*"instance" + 0.034*"frame" + 0.027*"assignment" + 0.023*"call" + 0.022*"need" + 0.022*"retrieve" + 0.021*"varname" + 0.020*"print"
INFO: topic #4 (0.289): 0.059*"global" + 0.055*"var" + 0.051*"answer" + 0.045*"stack" + 0.040*"scope" + 0.023*"inspect" + 0.017*"bit" + 0.016*"python3" + 0.014*"idea" + 0.014*"process"
INFO: topic diff=0.249943, rho=0.201619
DEBUG: bound: at document #0
INFO: -7.211 per-word bound, 148.2 perplexity estimate based on a held-out corpus of 5 documents with 32 words
INFO: PROGRESS: pass 8, at document #40/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6532031, 0.5854332, 0.18564199, 0.5932883, 0.30999097]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.653): 0.209*"name" + 0.115*"function" + 0.103*"object" + 0.069*"variable" + 0.044*"value" + 0.043*"code" + 0.022*"case" + 0.020*"local" + 0.020*"source" + 0.010*"approach"
INFO: topic #1 (0.585): 0.114*"list" + 0.067*"string" + 0.063*"way" + 0.059*"module" + 0.036*"return" + 0.035*"namespace" + 0.030*"reference" + 0.020*"note" + 0.017*"index" + 0.016*"define"
INFO: topic #2 (0.186): 0.063*"foo" + 0.060*"method" + 0.031*"debugging" + 0.021*"constructor" + 0.018*"sorcery" + 0.017*"frame" + 0.012*"initialization" + 0.012*"kind" + 0.012*"version" + 0.008*"order"
INFO: topic #3 (0.593): 0.104*"class" + 0.065*"example" + 0.044*"instance" + 0.030*"frame" + 0.028*"course" + 0.028*"type" + 0.024*"assignment" + 0.024*"work" + 0.020*"call" + 0.020*"need"
INFO: topic #4 (0.310): 0.072*"answer" + 0.060*"global" + 0.041*"loop" + 0.039*"var" + 0.032*"stack" + 0.028*"scope" + 0.028*"result" + 0.025*"filter" + 0.019*"each_item" + 0.019*"globals().item"
INFO: topic diff=0.148172, rho=0.201619
DEBUG: bound: at document #0
INFO: -5.977 per-word bound, 63.0 perplexity estimate based on a held-out corpus of 5 documents with 133 words
INFO: PROGRESS: pass 8, at document #45/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7491946, 0.601422, 0.19826254, 0.56238264, 0.3016243]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.749): 0.227*"name" + 0.133*"function" + 0.109*"object" + 0.055*"value" + 0.053*"variable" + 0.031*"code" + 0.020*"case" + 0.019*"attribute" + 0.014*"local" + 0.014*"source"
INFO: topic #1 (0.601): 0.083*"list" + 0.075*"string" + 0.050*"way" + 0.047*"module" + 0.034*"reference" + 0.033*"match" + 0.032*"return" + 0.030*"note" + 0.024*"test_function" + 0.023*"namespace"
INFO: topic #2 (0.198): 0.057*"method" + 0.039*"debugging" + 0.039*"foo" + 0.027*"frame" + 0.026*"order" + 0.024*"story" + 0.021*"basestring" + 0.021*"traverse" + 0.021*"deal" + 0.021*"long"
INFO: topic #3 (0.562): 0.089*"class" + 0.066*"example" + 0.048*"instance" + 0.045*"course" + 0.028*"frame" + 0.026*"print" + 0.024*"type" + 0.021*"assignment" + 0.021*"work" + 0.019*"magic"
INFO: topic #4 (0.302): 0.070*"global" + 0.061*"answer" + 0.045*"stack" + 0.043*"result" + 0.034*"loop" + 0.033*"var" + 0.024*"scope" + 0.021*"filter" + 0.016*"each_item" + 0.016*"globals().item"
INFO: topic diff=0.353398, rho=0.201619
DEBUG: bound: at document #0
INFO: -5.880 per-word bound, 58.9 perplexity estimate based on a held-out corpus of 5 documents with 67 words
INFO: PROGRESS: pass 8, at document #50/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.912066, 0.6381671, 0.19641258, 0.5529113, 0.32109785]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.912): 0.228*"name" + 0.142*"function" + 0.094*"object" + 0.052*"variable" + 0.049*"value" + 0.029*"code" + 0.024*"attribute" + 0.016*"case" + 0.016*"local" + 0.012*"def"
INFO: topic #1 (0.638): 0.081*"string" + 0.071*"list" + 0.060*"way" + 0.057*"module" + 0.037*"match" + 0.036*"return" + 0.034*"note" + 0.029*"reference" + 0.021*"test_function" + 0.020*"namespace"
INFO: topic #2 (0.196): 0.072*"method" + 0.034*"debugging" + 0.034*"foo" + 0.024*"frame" + 0.023*"order" + 0.021*"story" + 0.019*"basestring" + 0.019*"guess" + 0.019*"traverse" + 0.019*"page"
INFO: topic #3 (0.553): 0.110*"class" + 0.067*"example" + 0.041*"instance" + 0.038*"course" + 0.026*"need" + 0.024*"frame" + 0.022*"print" + 0.020*"type" + 0.018*"assignment" + 0.018*"work"
INFO: topic #4 (0.321): 0.110*"global" + 0.066*"answer" + 0.036*"stack" + 0.033*"result" + 0.027*"loop" + 0.026*"var" + 0.019*"scope" + 0.017*"filter" + 0.016*"bla" + 0.016*"my_list"
INFO: topic diff=0.166562, rho=0.201619
DEBUG: bound: at document #0
INFO: -6.137 per-word bound, 70.4 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 8, at document #55/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9726007, 0.65834147, 0.20235215, 0.59849375, 0.33883196]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.973): 0.220*"name" + 0.123*"function" + 0.112*"object" + 0.050*"value" + 0.047*"variable" + 0.033*"code" + 0.022*"case" + 0.020*"attribute" + 0.015*"search" + 0.014*"source"
INFO: topic #1 (0.658): 0.072*"list" + 0.072*"string" + 0.063*"way" + 0.052*"match" + 0.051*"module" + 0.041*"return" + 0.040*"note" + 0.031*"reference" + 0.018*"test_function" + 0.017*"namespace"
INFO: topic #2 (0.202): 0.106*"method" + 0.028*"debugging" + 0.028*"foo" + 0.020*"frame" + 0.019*"order" + 0.018*"story" + 0.016*"eval" + 0.016*"traverse" + 0.016*"grab" + 0.016*"guess"
INFO: topic #3 (0.598): 0.118*"class" + 0.059*"instance" + 0.058*"example" + 0.036*"print" + 0.028*"player" + 0.028*"environment" + 0.027*"course" + 0.025*"track" + 0.021*"iterator" + 0.018*"need"
INFO: topic #4 (0.339): 0.107*"global" + 0.072*"answer" + 0.041*"loop" + 0.034*"scope" + 0.029*"stack" + 0.027*"result" + 0.021*"var" + 0.014*"atribute" + 0.014*"filter" + 0.013*"bla"
INFO: topic diff=0.189382, rho=0.201619
DEBUG: bound: at document #0
INFO: -6.615 per-word bound, 98.0 perplexity estimate based on a held-out corpus of 5 documents with 183 words
INFO: PROGRESS: pass 8, at document #60/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8605782, 0.5918978, 0.21710703, 0.6240145, 0.33773035]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.861): 0.208*"name" + 0.136*"object" + 0.117*"function" + 0.046*"code" + 0.039*"value" + 0.037*"variable" + 0.025*"source" + 0.019*"case" + 0.014*"attribute" + 0.013*"line"
INFO: topic #1 (0.592): 0.081*"way" + 0.075*"string" + 0.069*"list" + 0.052*"note" + 0.052*"module" + 0.042*"match" + 0.040*"caller" + 0.034*"return" + 0.025*"reference" + 0.016*"other"
INFO: topic #2 (0.217): 0.082*"method" + 0.027*"initialization" + 0.025*"assignent" + 0.025*"production" + 0.025*"debugging" + 0.023*"frame" + 0.017*"constructor" + 0.013*"parameter" + 0.013*"data" + 0.013*"rethink"
INFO: topic #3 (0.624): 0.087*"class" + 0.051*"example" + 0.044*"instance" + 0.032*"frame" + 0.031*"file" + 0.029*"call" + 0.023*"work" + 0.023*"c" + 0.023*"assignment" + 0.022*"print"
INFO: topic #4 (0.338): 0.082*"global" + 0.055*"answer" + 0.048*"loop" + 0.044*"scope" + 0.040*"stack" + 0.025*"inspect" + 0.021*"result" + 0.018*"self" + 0.018*"init" + 0.018*"dimension"
INFO: topic diff=0.510885, rho=0.201619
DEBUG: bound: at document #0
INFO: -6.045 per-word bound, 66.0 perplexity estimate based on a held-out corpus of 5 documents with 164 words
INFO: PROGRESS: pass 8, at document #65/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9058253, 0.60297024, 0.21602906, 0.62614965, 0.3381023]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.906): 0.201*"name" + 0.151*"object" + 0.098*"function" + 0.050*"value" + 0.049*"variable" + 0.039*"code" + 0.017*"source" + 0.017*"case" + 0.016*"attribute" + 0.011*"access"
INFO: topic #1 (0.603): 0.086*"way" + 0.066*"string" + 0.064*"reference" + 0.062*"list" + 0.043*"note" + 0.042*"namespace" + 0.034*"module" + 0.028*"match" + 0.027*"caller" + 0.024*"integer"
INFO: topic #2 (0.216): 0.087*"method" + 0.026*"parameter" + 0.025*"initialization" + 0.022*"assignent" + 0.022*"production" + 0.022*"debugging" + 0.021*"frame" + 0.015*"constructor" + 0.013*"https://stackoverflow.com/a/49331683/7386061" + 0.012*"moment"
INFO: topic #3 (0.626): 0.103*"class" + 0.065*"example" + 0.044*"instance" + 0.035*"assignment" + 0.034*"print" + 0.027*"c" + 0.027*"work" + 0.027*"frame" + 0.026*"file" + 0.024*"call"
INFO: topic #4 (0.338): 0.068*"var" + 0.053*"global" + 0.044*"design" + 0.043*"scope" + 0.035*"answer" + 0.031*"loop" + 0.030*"hash" + 0.030*"choice" + 0.026*"stack" + 0.016*"inspect"
INFO: topic diff=0.379058, rho=0.201619
DEBUG: bound: at document #0
INFO: -5.994 per-word bound, 63.7 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 8, at document #70/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8414412, 0.61497724, 0.22299983, 0.6659398, 0.3129638]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.841): 0.195*"name" + 0.160*"object" + 0.089*"function" + 0.050*"code" + 0.050*"value" + 0.045*"variable" + 0.019*"case" + 0.016*"source" + 0.015*"attribute" + 0.014*"solution"
INFO: topic #1 (0.615): 0.083*"reference" + 0.079*"way" + 0.062*"string" + 0.051*"list" + 0.037*"module" + 0.035*"note" + 0.035*"namespace" + 0.034*"garbage" + 0.027*"return" + 0.023*"match"
INFO: topic #2 (0.223): 0.092*"method" + 0.035*"debugging" + 0.023*"parameter" + 0.022*"initialization" + 0.020*"production" + 0.020*"assignent" + 0.018*"frame" + 0.017*"version" + 0.013*"constructor" + 0.012*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.666): 0.173*"class" + 0.060*"instance" + 0.054*"example" + 0.027*"c" + 0.025*"assignment" + 0.024*"print" + 0.022*"situation" + 0.020*"retrieve" + 0.019*"work" + 0.019*"frame"
INFO: topic #4 (0.313): 0.062*"var" + 0.049*"global" + 0.041*"design" + 0.039*"scope" + 0.033*"answer" + 0.029*"loop" + 0.027*"hash" + 0.027*"choice" + 0.024*"stack" + 0.015*"inspect"
INFO: topic diff=0.186550, rho=0.201619
DEBUG: bound: at document #0
INFO: -6.063 per-word bound, 66.8 perplexity estimate based on a held-out corpus of 5 documents with 112 words
INFO: PROGRESS: pass 8, at document #75/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9449784, 0.68940854, 0.21646161, 0.7634001, 0.32280394]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.945): 0.192*"name" + 0.164*"object" + 0.084*"function" + 0.055*"variable" + 0.049*"code" + 0.040*"value" + 0.023*"case" + 0.017*"source" + 0.012*"attribute" + 0.012*"access"
INFO: topic #1 (0.689): 0.074*"way" + 0.073*"reference" + 0.056*"garbage" + 0.053*"list" + 0.050*"module" + 0.049*"namespace" + 0.046*"string" + 0.034*"note" + 0.020*"return" + 0.020*"collection"
INFO: topic #2 (0.216): 0.082*"method" + 0.048*"debugging" + 0.021*"parameter" + 0.020*"initialization" + 0.018*"production" + 0.018*"assignent" + 0.017*"frame" + 0.016*"version" + 0.012*"constructor" + 0.011*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.763): 0.144*"class" + 0.131*"instance" + 0.047*"example" + 0.039*"type" + 0.027*"c" + 0.025*"print" + 0.020*"track" + 0.019*"assignment" + 0.016*"situation" + 0.015*"retrieve"
INFO: topic #4 (0.323): 0.058*"global" + 0.052*"var" + 0.045*"answer" + 0.039*"filter" + 0.035*"design" + 0.033*"scope" + 0.024*"loop" + 0.023*"choice" + 0.023*"hash" + 0.020*"stack"
INFO: topic diff=0.261909, rho=0.201619
DEBUG: bound: at document #0
INFO: -6.570 per-word bound, 95.0 perplexity estimate based on a held-out corpus of 3 documents with 21 words
INFO: PROGRESS: pass 8, at document #78/78
DEBUG: performing inference on a chunk of 3 documents
DEBUG: 3/3 documents converged within 2000 iterations
INFO: optimized alpha [2.0436616, 0.6629405, 0.20862167, 0.8674924, 0.30648983]
DEBUG: updating topics
INFO: merging changes from 3 documents into a model of 78 documents
INFO: topic #0 (2.044): 0.187*"name" + 0.155*"object" + 0.090*"function" + 0.051*"code" + 0.050*"variable" + 0.036*"value" + 0.021*"case" + 0.018*"attribute" + 0.016*"thing" + 0.015*"source"
INFO: topic #1 (0.663): 0.084*"way" + 0.069*"reference" + 0.053*"garbage" + 0.050*"list" + 0.047*"module" + 0.046*"namespace" + 0.043*"string" + 0.032*"note" + 0.019*"return" + 0.019*"collection"
INFO: topic #2 (0.209): 0.075*"method" + 0.044*"debugging" + 0.019*"parameter" + 0.018*"initialization" + 0.017*"production" + 0.017*"assignent" + 0.015*"frame" + 0.014*"version" + 0.011*"constructor" + 0.010*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.867): 0.147*"class" + 0.125*"instance" + 0.045*"print" + 0.041*"example" + 0.034*"type" + 0.028*"part" + 0.023*"c" + 0.018*"track" + 0.016*"assignment" + 0.014*"situation"
INFO: topic #4 (0.306): 0.053*"global" + 0.048*"var" + 0.041*"answer" + 0.036*"filter" + 0.031*"design" + 0.030*"scope" + 0.022*"loop" + 0.021*"choice" + 0.021*"hash" + 0.018*"stack"
INFO: topic diff=0.130326, rho=0.201619
DEBUG: bound: at document #0
INFO: -5.234 per-word bound, 37.6 perplexity estimate based on a held-out corpus of 5 documents with 130 words
INFO: PROGRESS: pass 9, at document #5/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7920223, 0.6511194, 0.20162287, 0.65290546, 0.26934606]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.792): 0.176*"name" + 0.124*"object" + 0.092*"function" + 0.056*"variable" + 0.050*"code" + 0.041*"value" + 0.027*"thing" + 0.022*"attribute" + 0.020*"case" + 0.018*"language"
INFO: topic #1 (0.651): 0.084*"string" + 0.079*"list" + 0.072*"way" + 0.052*"reference" + 0.040*"garbage" + 0.036*"module" + 0.035*"namespace" + 0.032*"note" + 0.031*"return" + 0.014*"collection"
INFO: topic #2 (0.202): 0.078*"method" + 0.054*"debugging" + 0.026*"foo" + 0.024*"order" + 0.020*"snippet" + 0.020*"drawback" + 0.015*"parameter" + 0.015*"initialization" + 0.013*"production" + 0.013*"assignent"
INFO: topic #3 (0.653): 0.141*"class" + 0.120*"instance" + 0.043*"print" + 0.039*"example" + 0.033*"type" + 0.027*"part" + 0.022*"c" + 0.017*"track" + 0.016*"assignment" + 0.014*"situation"
INFO: topic #4 (0.269): 0.047*"global" + 0.043*"var" + 0.037*"answer" + 0.032*"filter" + 0.028*"design" + 0.027*"scope" + 0.020*"loop" + 0.019*"choice" + 0.019*"hash" + 0.017*"stack"
INFO: topic diff=0.226584, rho=0.197642
DEBUG: bound: at document #0
INFO: -6.375 per-word bound, 83.0 perplexity estimate based on a held-out corpus of 5 documents with 191 words
INFO: PROGRESS: pass 9, at document #10/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.4901426, 0.53821015, 0.21552575, 0.6310818, 0.28513163]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.490): 0.177*"name" + 0.102*"function" + 0.101*"object" + 0.070*"variable" + 0.061*"code" + 0.050*"value" + 0.024*"source" + 0.023*"case" + 0.022*"thing" + 0.018*"attribute"
INFO: topic #1 (0.538): 0.091*"list" + 0.083*"string" + 0.065*"way" + 0.047*"reference" + 0.039*"note" + 0.036*"garbage" + 0.032*"module" + 0.031*"namespace" + 0.028*"return" + 0.018*"documentation"
INFO: topic #2 (0.216): 0.093*"method" + 0.087*"foo" + 0.040*"debugging" + 0.028*"initialization" + 0.026*"version" + 0.024*"frame" + 0.018*"order" + 0.015*"drawback" + 0.015*"snippet" + 0.012*"parameter"
INFO: topic #3 (0.631): 0.079*"class" + 0.070*"instance" + 0.054*"frame" + 0.042*"example" + 0.035*"varname" + 0.031*"assignment" + 0.027*"need" + 0.027*"environment" + 0.025*"print" + 0.022*"part"
INFO: topic #4 (0.285): 0.070*"answer" + 0.049*"scope" + 0.045*"global" + 0.043*"var" + 0.027*"stack" + 0.023*"inspect" + 0.020*"filter" + 0.018*"bit" + 0.018*"design" + 0.017*"var_1"
INFO: topic diff=0.393748, rho=0.197642
DEBUG: bound: at document #0
INFO: -6.389 per-word bound, 83.8 perplexity estimate based on a held-out corpus of 5 documents with 45 words
INFO: PROGRESS: pass 9, at document #15/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.5745008, 0.54161847, 0.20369726, 0.5882934, 0.279892]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.575): 0.175*"name" + 0.093*"object" + 0.090*"function" + 0.088*"variable" + 0.067*"value" + 0.054*"code" + 0.025*"case" + 0.021*"source" + 0.020*"thing" + 0.017*"access"
INFO: topic #1 (0.542): 0.078*"string" + 0.075*"list" + 0.064*"way" + 0.039*"reference" + 0.033*"return" + 0.032*"note" + 0.030*"garbage" + 0.027*"module" + 0.026*"namespace" + 0.023*"content"
INFO: topic #2 (0.204): 0.084*"method" + 0.079*"foo" + 0.037*"debugging" + 0.026*"initialization" + 0.024*"version" + 0.022*"frame" + 0.016*"order" + 0.014*"drawback" + 0.014*"snippet" + 0.011*"parameter"
INFO: topic #3 (0.588): 0.082*"class" + 0.067*"instance" + 0.052*"frame" + 0.040*"example" + 0.033*"varname" + 0.030*"assignment" + 0.026*"need" + 0.026*"environment" + 0.024*"print" + 0.021*"part"
INFO: topic #4 (0.280): 0.060*"answer" + 0.059*"scope" + 0.039*"global" + 0.036*"var" + 0.032*"bit" + 0.023*"stack" + 0.020*"inspect" + 0.017*"filter" + 0.015*"design" + 0.014*"warning"
INFO: topic diff=0.130623, rho=0.197642
DEBUG: bound: at document #0
INFO: -5.906 per-word bound, 60.0 perplexity estimate based on a held-out corpus of 5 documents with 37 words
INFO: PROGRESS: pass 9, at document #20/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6322005, 0.5621342, 0.2042652, 0.55662966, 0.30861324]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.632): 0.184*"name" + 0.097*"variable" + 0.095*"function" + 0.084*"object" + 0.073*"value" + 0.049*"code" + 0.022*"case" + 0.019*"source" + 0.018*"thing" + 0.016*"access"
INFO: topic #1 (0.562): 0.085*"list" + 0.067*"string" + 0.059*"return" + 0.055*"way" + 0.034*"reference" + 0.034*"module" + 0.033*"namespace" + 0.028*"note" + 0.026*"garbage" + 0.022*"index"
INFO: topic #2 (0.204): 0.113*"method" + 0.067*"foo" + 0.031*"debugging" + 0.031*"frame" + 0.022*"initialization" + 0.020*"version" + 0.014*"order" + 0.012*"snippet" + 0.012*"drawback" + 0.009*"parameter"
INFO: topic #3 (0.557): 0.079*"class" + 0.064*"instance" + 0.053*"frame" + 0.039*"example" + 0.032*"varname" + 0.029*"assignment" + 0.025*"need" + 0.025*"environment" + 0.023*"print" + 0.021*"part"
INFO: topic #4 (0.309): 0.082*"answer" + 0.064*"scope" + 0.048*"global" + 0.046*"var" + 0.026*"bit" + 0.021*"result" + 0.018*"stack" + 0.018*"variation" + 0.016*"inspect" + 0.014*"filter"
INFO: topic diff=0.097051, rho=0.197642
DEBUG: bound: at document #0
INFO: -6.524 per-word bound, 92.0 perplexity estimate based on a held-out corpus of 5 documents with 69 words
INFO: PROGRESS: pass 9, at document #25/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7163866, 0.5568201, 0.20201993, 0.5938907, 0.31456128]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.716): 0.164*"name" + 0.120*"function" + 0.099*"variable" + 0.080*"object" + 0.066*"value" + 0.046*"code" + 0.019*"local" + 0.019*"case" + 0.016*"source" + 0.015*"thing"
INFO: topic #1 (0.557): 0.074*"string" + 0.069*"list" + 0.059*"return" + 0.055*"way" + 0.027*"reference" + 0.027*"module" + 0.027*"namespace" + 0.023*"note" + 0.021*"garbage" + 0.018*"procedure"
INFO: topic #2 (0.202): 0.098*"method" + 0.058*"foo" + 0.049*"debugging" + 0.027*"frame" + 0.019*"initialization" + 0.018*"version" + 0.012*"order" + 0.010*"drawback" + 0.010*"snippet" + 0.008*"parameter"
INFO: topic #3 (0.594): 0.073*"class" + 0.054*"example" + 0.054*"instance" + 0.044*"frame" + 0.029*"call" + 0.028*"need" + 0.027*"varname" + 0.026*"print" + 0.026*"type" + 0.024*"assignment"
INFO: topic #4 (0.315): 0.072*"var" + 0.067*"answer" + 0.056*"global" + 0.053*"scope" + 0.030*"inspect" + 0.021*"bit" + 0.018*"idea" + 0.018*"process" + 0.018*"result" + 0.015*"stack"
INFO: topic diff=0.167131, rho=0.197642
DEBUG: bound: at document #0
INFO: -6.229 per-word bound, 75.0 perplexity estimate based on a held-out corpus of 5 documents with 89 words
INFO: PROGRESS: pass 9, at document #30/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.746723, 0.57248515, 0.19973882, 0.61741644, 0.3153105]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.747): 0.167*"name" + 0.112*"function" + 0.092*"variable" + 0.073*"object" + 0.064*"code" + 0.055*"value" + 0.029*"source" + 0.019*"local" + 0.014*"case" + 0.011*"thing"
INFO: topic #1 (0.572): 0.083*"list" + 0.073*"string" + 0.052*"way" + 0.051*"module" + 0.045*"return" + 0.039*"reference" + 0.030*"namespace" + 0.022*"integer" + 0.020*"match" + 0.017*"note"
INFO: topic #2 (0.200): 0.081*"method" + 0.049*"foo" + 0.041*"debugging" + 0.028*"constructor" + 0.024*"sorcery" + 0.023*"frame" + 0.016*"initialization" + 0.015*"version" + 0.014*"kind" + 0.011*"order"
INFO: topic #3 (0.617): 0.080*"class" + 0.063*"example" + 0.047*"instance" + 0.039*"frame" + 0.026*"call" + 0.025*"need" + 0.025*"retrieve" + 0.024*"varname" + 0.023*"print" + 0.023*"type"
INFO: topic #4 (0.315): 0.065*"global" + 0.061*"var" + 0.056*"answer" + 0.049*"stack" + 0.044*"scope" + 0.026*"inspect" + 0.018*"bit" + 0.017*"python3" + 0.016*"idea" + 0.016*"process"
INFO: topic diff=0.213442, rho=0.197642
DEBUG: bound: at document #0
INFO: -5.200 per-word bound, 36.8 perplexity estimate based on a held-out corpus of 5 documents with 114 words
INFO: PROGRESS: pass 9, at document #35/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8862016, 0.6344442, 0.18886104, 0.62275684, 0.28964067]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.886): 0.219*"name" + 0.106*"object" + 0.104*"function" + 0.074*"variable" + 0.047*"value" + 0.046*"code" + 0.021*"source" + 0.021*"local" + 0.014*"case" + 0.011*"approach"
INFO: topic #1 (0.634): 0.122*"list" + 0.072*"string" + 0.068*"way" + 0.042*"module" + 0.038*"return" + 0.037*"reference" + 0.037*"namespace" + 0.018*"index" + 0.017*"define" + 0.017*"element"
INFO: topic #2 (0.189): 0.072*"method" + 0.043*"foo" + 0.036*"debugging" + 0.024*"constructor" + 0.021*"sorcery" + 0.020*"frame" + 0.015*"initialization" + 0.014*"version" + 0.013*"kind" + 0.010*"order"
INFO: topic #3 (0.623): 0.095*"class" + 0.072*"example" + 0.050*"instance" + 0.034*"frame" + 0.027*"assignment" + 0.023*"call" + 0.022*"need" + 0.022*"retrieve" + 0.021*"varname" + 0.020*"print"
INFO: topic #4 (0.290): 0.059*"global" + 0.055*"var" + 0.051*"answer" + 0.044*"stack" + 0.040*"scope" + 0.023*"inspect" + 0.017*"bit" + 0.016*"python3" + 0.014*"idea" + 0.014*"process"
INFO: topic diff=0.242108, rho=0.197642
DEBUG: bound: at document #0
INFO: -7.193 per-word bound, 146.3 perplexity estimate based on a held-out corpus of 5 documents with 32 words
INFO: PROGRESS: pass 9, at document #40/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.6557418, 0.59020287, 0.18577638, 0.5945117, 0.30981374]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.656): 0.209*"name" + 0.114*"function" + 0.103*"object" + 0.069*"variable" + 0.044*"value" + 0.043*"code" + 0.022*"case" + 0.020*"source" + 0.020*"local" + 0.010*"approach"
INFO: topic #1 (0.590): 0.112*"list" + 0.066*"string" + 0.063*"way" + 0.058*"module" + 0.036*"return" + 0.034*"reference" + 0.034*"namespace" + 0.020*"note" + 0.016*"index" + 0.016*"define"
INFO: topic #2 (0.186): 0.063*"foo" + 0.061*"method" + 0.031*"debugging" + 0.021*"constructor" + 0.018*"sorcery" + 0.018*"frame" + 0.013*"initialization" + 0.012*"version" + 0.011*"kind" + 0.008*"order"
INFO: topic #3 (0.595): 0.104*"class" + 0.064*"example" + 0.045*"instance" + 0.031*"frame" + 0.028*"type" + 0.027*"course" + 0.024*"assignment" + 0.024*"work" + 0.020*"call" + 0.020*"need"
INFO: topic #4 (0.310): 0.072*"answer" + 0.060*"global" + 0.040*"loop" + 0.039*"var" + 0.032*"stack" + 0.029*"scope" + 0.028*"result" + 0.024*"filter" + 0.019*"each_item" + 0.019*"globals().item"
INFO: topic diff=0.144454, rho=0.197642
DEBUG: bound: at document #0
INFO: -5.955 per-word bound, 62.0 perplexity estimate based on a held-out corpus of 5 documents with 133 words
INFO: PROGRESS: pass 9, at document #45/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.7470326, 0.60590845, 0.19806333, 0.5635543, 0.30145308]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.747): 0.227*"name" + 0.133*"function" + 0.109*"object" + 0.055*"value" + 0.053*"variable" + 0.031*"code" + 0.020*"case" + 0.019*"attribute" + 0.014*"source" + 0.014*"local"
INFO: topic #1 (0.606): 0.082*"list" + 0.074*"string" + 0.049*"way" + 0.046*"module" + 0.037*"reference" + 0.032*"match" + 0.031*"return" + 0.029*"note" + 0.024*"test_function" + 0.023*"namespace"
INFO: topic #2 (0.198): 0.058*"method" + 0.039*"foo" + 0.039*"debugging" + 0.027*"frame" + 0.026*"order" + 0.023*"story" + 0.021*"deal" + 0.021*"page" + 0.021*"basestring" + 0.021*"traverse"
INFO: topic #3 (0.564): 0.090*"class" + 0.066*"example" + 0.049*"instance" + 0.044*"course" + 0.029*"frame" + 0.026*"print" + 0.024*"type" + 0.021*"assignment" + 0.021*"work" + 0.018*"magic"
INFO: topic #4 (0.301): 0.069*"global" + 0.061*"answer" + 0.045*"stack" + 0.042*"result" + 0.034*"loop" + 0.033*"var" + 0.024*"scope" + 0.021*"filter" + 0.016*"each_item" + 0.016*"globals().item"
INFO: topic diff=0.340931, rho=0.197642
DEBUG: bound: at document #0
INFO: -5.870 per-word bound, 58.5 perplexity estimate based on a held-out corpus of 5 documents with 67 words
INFO: PROGRESS: pass 9, at document #50/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.9061918, 0.64146686, 0.19622739, 0.55436975, 0.32032582]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.906): 0.228*"name" + 0.142*"function" + 0.094*"object" + 0.052*"variable" + 0.049*"value" + 0.030*"code" + 0.024*"attribute" + 0.016*"case" + 0.016*"local" + 0.012*"def"
INFO: topic #1 (0.641): 0.080*"string" + 0.071*"list" + 0.059*"way" + 0.057*"module" + 0.036*"match" + 0.035*"return" + 0.034*"note" + 0.032*"reference" + 0.020*"test_function" + 0.020*"namespace"
INFO: topic #2 (0.196): 0.072*"method" + 0.034*"foo" + 0.034*"debugging" + 0.024*"frame" + 0.022*"order" + 0.020*"story" + 0.019*"eval" + 0.019*"grab" + 0.019*"long" + 0.019*"deal"
INFO: topic #3 (0.554): 0.109*"class" + 0.067*"example" + 0.042*"instance" + 0.038*"course" + 0.026*"need" + 0.025*"frame" + 0.022*"print" + 0.021*"type" + 0.018*"assignment" + 0.018*"work"
INFO: topic #4 (0.320): 0.109*"global" + 0.066*"answer" + 0.036*"stack" + 0.033*"result" + 0.027*"loop" + 0.026*"var" + 0.019*"scope" + 0.017*"filter" + 0.016*"bla" + 0.016*"my_list"
INFO: topic diff=0.160710, rho=0.197642
DEBUG: bound: at document #0
INFO: -6.119 per-word bound, 69.5 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 9, at document #55/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.96657, 0.6620083, 0.20203543, 0.5989764, 0.33759558]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.967): 0.220*"name" + 0.123*"function" + 0.112*"object" + 0.050*"value" + 0.048*"variable" + 0.033*"code" + 0.022*"case" + 0.020*"attribute" + 0.015*"search" + 0.014*"source"
INFO: topic #1 (0.662): 0.072*"list" + 0.071*"string" + 0.062*"way" + 0.051*"match" + 0.050*"module" + 0.041*"return" + 0.039*"note" + 0.035*"reference" + 0.018*"test_function" + 0.018*"namespace"
INFO: topic #2 (0.202): 0.106*"method" + 0.029*"foo" + 0.029*"debugging" + 0.020*"frame" + 0.019*"order" + 0.017*"story" + 0.016*"long" + 0.016*"grab" + 0.016*"traverse" + 0.016*"page"
INFO: topic #3 (0.599): 0.117*"class" + 0.059*"instance" + 0.058*"example" + 0.036*"print" + 0.028*"player" + 0.027*"environment" + 0.027*"course" + 0.025*"track" + 0.020*"iterator" + 0.018*"need"
INFO: topic #4 (0.338): 0.107*"global" + 0.072*"answer" + 0.040*"loop" + 0.034*"scope" + 0.029*"stack" + 0.027*"result" + 0.021*"var" + 0.015*"atribute" + 0.014*"filter" + 0.013*"bla"
INFO: topic diff=0.182226, rho=0.197642
DEBUG: bound: at document #0
INFO: -6.587 per-word bound, 96.1 perplexity estimate based on a held-out corpus of 5 documents with 183 words
INFO: PROGRESS: pass 9, at document #60/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8563641, 0.59548706, 0.21645561, 0.62360346, 0.33645618]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.856): 0.208*"name" + 0.135*"object" + 0.117*"function" + 0.046*"code" + 0.039*"value" + 0.038*"variable" + 0.025*"source" + 0.019*"case" + 0.014*"attribute" + 0.013*"line"
INFO: topic #1 (0.595): 0.080*"way" + 0.074*"string" + 0.069*"list" + 0.051*"note" + 0.051*"module" + 0.042*"match" + 0.039*"caller" + 0.034*"return" + 0.029*"reference" + 0.017*"other"
INFO: topic #2 (0.216): 0.082*"method" + 0.027*"initialization" + 0.025*"assignent" + 0.025*"production" + 0.025*"debugging" + 0.023*"frame" + 0.017*"constructor" + 0.013*"parameter" + 0.013*"rethink" + 0.013*"base"
INFO: topic #3 (0.624): 0.088*"class" + 0.051*"example" + 0.044*"instance" + 0.032*"frame" + 0.031*"file" + 0.029*"call" + 0.023*"assignment" + 0.023*"work" + 0.023*"c" + 0.022*"print"
INFO: topic #4 (0.336): 0.082*"global" + 0.055*"answer" + 0.048*"loop" + 0.044*"scope" + 0.040*"stack" + 0.025*"inspect" + 0.021*"result" + 0.018*"dimension" + 0.018*"init" + 0.018*"self"
INFO: topic diff=0.493373, rho=0.197642
DEBUG: bound: at document #0
INFO: -6.017 per-word bound, 64.8 perplexity estimate based on a held-out corpus of 5 documents with 164 words
INFO: PROGRESS: pass 9, at document #65/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.8984306, 0.6058557, 0.21538843, 0.6251075, 0.33659932]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.898): 0.202*"name" + 0.151*"object" + 0.099*"function" + 0.050*"value" + 0.049*"variable" + 0.039*"code" + 0.018*"source" + 0.017*"case" + 0.016*"attribute" + 0.011*"access"
INFO: topic #1 (0.606): 0.085*"way" + 0.070*"reference" + 0.065*"string" + 0.062*"list" + 0.042*"note" + 0.041*"namespace" + 0.034*"module" + 0.028*"match" + 0.026*"caller" + 0.023*"integer"
INFO: topic #2 (0.215): 0.087*"method" + 0.026*"parameter" + 0.024*"initialization" + 0.022*"production" + 0.022*"assignent" + 0.022*"debugging" + 0.021*"frame" + 0.015*"constructor" + 0.013*"https://stackoverflow.com/a/49331683/7386061" + 0.012*"glance"
INFO: topic #3 (0.625): 0.103*"class" + 0.065*"example" + 0.044*"instance" + 0.035*"assignment" + 0.033*"print" + 0.027*"frame" + 0.027*"work" + 0.027*"c" + 0.025*"file" + 0.024*"call"
INFO: topic #4 (0.337): 0.067*"var" + 0.053*"global" + 0.044*"design" + 0.043*"scope" + 0.036*"answer" + 0.031*"loop" + 0.029*"hash" + 0.029*"choice" + 0.026*"stack" + 0.016*"inspect"
INFO: topic diff=0.366519, rho=0.197642
DEBUG: bound: at document #0
INFO: -5.978 per-word bound, 63.0 perplexity estimate based on a held-out corpus of 5 documents with 73 words
INFO: PROGRESS: pass 9, at document #70/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.833918, 0.61754626, 0.22218142, 0.6638326, 0.31205508]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.834): 0.195*"name" + 0.160*"object" + 0.090*"function" + 0.050*"code" + 0.050*"value" + 0.045*"variable" + 0.019*"case" + 0.016*"source" + 0.015*"attribute" + 0.014*"solution"
INFO: topic #1 (0.618): 0.088*"reference" + 0.078*"way" + 0.062*"string" + 0.051*"list" + 0.036*"module" + 0.035*"note" + 0.034*"namespace" + 0.034*"garbage" + 0.027*"return" + 0.023*"match"
INFO: topic #2 (0.222): 0.091*"method" + 0.035*"debugging" + 0.023*"parameter" + 0.022*"initialization" + 0.020*"production" + 0.020*"assignent" + 0.018*"frame" + 0.017*"version" + 0.013*"constructor" + 0.012*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.664): 0.172*"class" + 0.060*"instance" + 0.054*"example" + 0.026*"c" + 0.025*"assignment" + 0.024*"print" + 0.022*"situation" + 0.020*"retrieve" + 0.020*"frame" + 0.019*"work"
INFO: topic #4 (0.312): 0.062*"var" + 0.049*"global" + 0.041*"design" + 0.040*"scope" + 0.033*"answer" + 0.029*"loop" + 0.027*"choice" + 0.027*"hash" + 0.024*"stack" + 0.015*"inspect"
INFO: topic diff=0.180382, rho=0.197642
DEBUG: bound: at document #0
INFO: -6.050 per-word bound, 66.3 perplexity estimate based on a held-out corpus of 5 documents with 112 words
INFO: PROGRESS: pass 9, at document #75/78
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.933479, 0.6909233, 0.21578717, 0.7591167, 0.32154584]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 78 documents
INFO: topic #0 (1.933): 0.193*"name" + 0.164*"object" + 0.085*"function" + 0.056*"variable" + 0.049*"code" + 0.040*"value" + 0.023*"case" + 0.017*"source" + 0.012*"attribute" + 0.012*"access"
INFO: topic #1 (0.691): 0.079*"reference" + 0.073*"way" + 0.055*"garbage" + 0.053*"list" + 0.050*"module" + 0.048*"namespace" + 0.046*"string" + 0.034*"note" + 0.020*"return" + 0.019*"collection"
INFO: topic #2 (0.216): 0.082*"method" + 0.048*"debugging" + 0.021*"parameter" + 0.020*"initialization" + 0.018*"production" + 0.018*"assignent" + 0.017*"frame" + 0.016*"version" + 0.012*"constructor" + 0.011*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.759): 0.143*"class" + 0.130*"instance" + 0.048*"example" + 0.039*"type" + 0.027*"c" + 0.025*"print" + 0.020*"track" + 0.019*"assignment" + 0.016*"situation" + 0.015*"retrieve"
INFO: topic #4 (0.322): 0.059*"global" + 0.052*"var" + 0.045*"answer" + 0.039*"filter" + 0.034*"design" + 0.033*"scope" + 0.024*"loop" + 0.023*"hash" + 0.023*"choice" + 0.020*"stack"
INFO: topic diff=0.253282, rho=0.197642
DEBUG: bound: at document #0
INFO: -6.555 per-word bound, 94.1 perplexity estimate based on a held-out corpus of 3 documents with 21 words
INFO: PROGRESS: pass 9, at document #78/78
DEBUG: performing inference on a chunk of 3 documents
DEBUG: 3/3 documents converged within 2000 iterations
INFO: optimized alpha [2.0298607, 0.66435075, 0.2081011, 0.8605092, 0.30554962]
DEBUG: updating topics
INFO: merging changes from 3 documents into a model of 78 documents
INFO: topic #0 (2.030): 0.188*"name" + 0.155*"object" + 0.090*"function" + 0.051*"code" + 0.050*"variable" + 0.037*"value" + 0.021*"case" + 0.018*"attribute" + 0.016*"thing" + 0.015*"source"
INFO: topic #1 (0.664): 0.084*"way" + 0.074*"reference" + 0.052*"garbage" + 0.050*"list" + 0.047*"module" + 0.045*"namespace" + 0.043*"string" + 0.032*"note" + 0.019*"return" + 0.018*"collection"
INFO: topic #2 (0.208): 0.075*"method" + 0.044*"debugging" + 0.019*"parameter" + 0.018*"initialization" + 0.017*"production" + 0.017*"assignent" + 0.015*"frame" + 0.014*"version" + 0.011*"constructor" + 0.010*"https://stackoverflow.com/a/49331683/7386061"
INFO: topic #3 (0.861): 0.147*"class" + 0.124*"instance" + 0.045*"print" + 0.041*"example" + 0.034*"type" + 0.028*"part" + 0.023*"c" + 0.017*"track" + 0.016*"assignment" + 0.014*"situation"
INFO: topic #4 (0.306): 0.053*"global" + 0.048*"var" + 0.041*"answer" + 0.036*"filter" + 0.031*"design" + 0.031*"scope" + 0.022*"loop" + 0.021*"hash" + 0.021*"choice" + 0.019*"stack"
INFO: topic diff=0.126390, rho=0.197642
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=385, num_topics=5, decay=0.5, chunksize=5> in 0.42s', 'datetime': '2023-05-09T14:37:44.615588', 'gensim': '4.3.1', 'python': '3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}
INFO: {'id': 8875330, 'content': 'It can\'t be ordinarily done, though this can be achieved by using introspection and facilities meant for debugging a program. The code must run from a ".py" file though, and not from just compiled bytecode, or inside a zipped module - as it relies on the reading of the file source code, from within the method that should find about "where it is running". The trick is to access the execution frame where the object was initialized from - with inspect.currentframe - the frame object has a "f_lineno"  value which states the line number where the call to the object method (in this case, __init__) has been called. The function inspect.filename allows one to retrieve the source code for the file, and fetch the apropriate line number.  A naive parse then peek the part preeceding an "=" sign, and assumes it is the variable that will contain the object. That won\'t work for multiple assignents, expressions composing with the object before the assignemtn is made, objects being appended to lists or added to dictionaries or sets,  object instantiation in intialization of for loops, and God knows which more situations -- \n And have in mind that after the first attribution, the object could be referenced by any other variable as well. Botton line: it is  possible, but as a toy - it can\'t be used i production code - \njust have the varibal name to be passed as a string during object initialization, just as one has to do when creating a collections.namedtuple The "right way" to do it, if you are needing the name, is to explicitly pass the name to the object initialization, as a string parameter, like in: And still, if absolutely need to type the objects\'name only once, there is another way - read on.\nDue to Python\'s syntax, some special assignments, not using the "=" operator do allow an object to know it is assigned name. So, other statemtns that perform assignents in Python are the for, with, def and class keywords - It is possible to abuse this, as specfically a class creation and a function definition are assignment statements that create objects which "know" their names. Let\'s focus on the def statement. It ordinarily creates a function. But using a decorator you can use "def" to create any kind of object - and have the name used for the function available to the constructor: (This last way of doing it could be used in production code, unlike the one which resorts to reading the source file)', 'score': 0.8244810481428666}
INFO: {'id': 72890920, 'content': 'How can I do the same for a variable? As opposed to functions, Python variables do not have the __name__ attribute. The problem comes up because you are confused about terminology, semantics or both. "variables" don\'t belong in the same category as "functions". A "variable" is not a thing that takes up space in memory while the code is running. It is just a name that exists in your source code - so that when you\'re writing the code, you can explain which thing you\'re talking about. Python uses names in the source code to refer to (i.e., give a name to) values. (In many languages, a variable is more like a name for a specific location in memory where the value will be stored. But Python\'s names actually name the thing in question.) In Python, a function is a value. (In some languages, this is not the case; although there are bytes of memory used to represent the actual executable code, it isn\'t a discrete chunk of memory that your program logic gets to interact with directly.) In Python, every value is an object, meaning that you can assign names to it freely, pass it as an argument, return it from a function, etc. (In many languages, this is not the case.) Objects in Python have attributes, which are the things you access using the . syntax. Functions in Python have a __name__ attribute, which is assigned when the function is created. Specifically, when a def statement is executed (in most languages, creation of a function works quite differently), the name that appears after def is used as a value for the __name__ attribute, and also, independently, as a variable name that will get the function object assigned to it. But most objects don\'t have an attribute like that. In other words, if I have a variable such as: That\'s the thing: you don\'t "have" the variable in the sense that you\'re thinking of. You have the object that is named by that variable. Anything else depends on the information incidentally being stored in some other object - such as the locals() of the enclosing function. But it would be better to store the information yourself. Instead of relying on a variable name to carry information for you, explicitly build the mapping between the string name you want to use for the object, and the object itself.', 'score': 0.8217727686674365}
INFO: {'id': 57648979, 'content': "This isn't possible in Python. In theory the language could store down the first assignment name in some form, but it doesn't. Python also doesn't have anything like C#'s nameof() that could approximate this. The main issue here is that the name is just a pointer to the object, you could have multiple names for the same thing (or none at the level you are working at - what would be the name of a value in a list, for example?), so which one would you expect to get? Generally, if you want to do something like this, you want to use a data structure like a dictionary instead, that way you have access to the keys. The best you could do is something where you forgo the manual assignment and construct the object using code that gives the object that name and assigns the variable dynamically. This would still have the issue that the name wouldn't match other references, and would be fragile code. Using a dictionary would be easier in that case. You could also use __setattr__() to do something like this if you were assigning to a class attribute rather than a top-level variable. However, again, I'd argue a dictionary is the better option. ", 'score': 0.8146793292632254}
INFO: {'id': 30922184, 'content': "Here's one approach. I wouldn't recommend this for anything important, because it'll be quite brittle. But it can be done. Create a function that uses the inspect module to find the source code that called it. Then you can parse the source code to identify the variable names that you want to retrieve. For example, here's a function called autodict that takes a list of variables and returns a dictionary mapping variable names to their values. E.g.: Would give: Inspecting the source code itself is better than searching through the locals() or globals() because the latter approach doesn't tell you which of the variables are the ones you want. At any rate, here's the code: The action happens in the line with inspect.getouterframes, which returns the string within the code that called autodict. The obvious downside to this sort of magic is that it makes assumptions about how the source code is structured. And of course, it won't work at all if it's run inside the interpreter.", 'score': 0.8136453658861674}
INFO: {'id': 17200177, 'content': 'The object does not have a "name". A variable which refers to the object is not a "name" of the object. The object cannot know about any of the variables which refer to it, not least because variables are not a first-class subject of the language. If you wish to alter the way that object prints, override either __repr__ or __unicode__. If this is for debugging purposes, use a debugger. That\'s what it\'s for.', 'score': 0.8010494222439878}
INFO: {'id': 19156516, 'content': "Finally found a way to get through. As I know the class name, I would search for the object created for that class in garbage collector(gc) like this... The above code returns an instance of the class which will be like this. Unfortunately,its in String format which doesn't suit the requirement. It should be of 'obj' type. From the above value, parse the id(0x6f55250) and get the object reference based on the id. Hence required_obj will hold the object reference exactly in the 'obj' format. :-)", 'score': 0.8001890285226793}
INFO: {'id': 18425523, 'content': 'Even if variable values don\'t point back to the name, you have access to the list of every assigned variable and its value, so I\'m astounded that only one person suggested looping through there to look for your var name. Someone mentioned on that answer that you might have to walk the stack and check everyone\'s locals and globals to find foo, but if foo is assigned in the scope where you\'re calling this retrieve_name function, you can use inspect\'s current frame to get you all of those local variables. My explanation might be a little bit too wordy (maybe I should\'ve used a "foo" less words), but here\'s how it would look in code (Note that if there is more than one variable assigned to the same value, you will get both of those variable names): If you\'re calling this function from another function, something like: And you want the baz instead of bar, you\'ll just need to go back a scope further. This can be done by adding an extra .f_back in the caller_local_vars initialization. See an example here: ideone', 'score': 0.7957404034676069}
INFO: {'id': 18425336, 'content': 'In Python, the def and class keywords will bind a specific name to the object they define (function or class). Similarly, modules are given a name by virtue of being called something specific in the filesystem. In all three cases, there\'s an obvious way to assign a "canonical" name to the object in question. However, for other kinds of objects, such a canonical name may simply not exist. For example, consider the elements of a list. The elements in the list are not individually named, and it is entirely possible that the only way to refer to them in a program is by using list indices on the containing list. If such a list of objects was passed into your function, you could not possibly assign meaningful identifiers to the values. Python doesn\'t save the name on the left hand side of an assignment into the assigned object because: So, for example, functions defined using lambda will always have the "name" <lambda>, rather than a specific function name. The best approach would be simply to ask the caller to pass in an (optional) list of names. If typing the \'...\',\'...\' is too cumbersome, you could accept e.g. a single string containing a comma-separated list of names (like namedtuple does).', 'score': 0.7952775836614993}
INFO: {'id': 59364138, 'content': "Use the Wrapper helper from python-varname: For list comprehension part, you can do: I am the author of the python-varname package. Please let me know if you have any questions or you can submit issues on Github. Yes and No. We are retrieving the variable names at runtime, so we need a function to be called to enable us to access the previous frames to retrieve the variable names. That's why we need a Wrapper there. In that function, at runtime, we are parsing the source code/AST nodes in the previous frames to get the exact variable name. However, the source code/AST nodes in the previous frames are not always available, or they could be modified by other environments (e.g: pytest's assert statement). One simple example is that the codes run via exec().  Even though we are still able to retrieve some information from the bytecode, it needs too much effort and it is also error-prone. First of all, we need to identify which frame the variable is given. It's not always simply the direct previous frame. For example, we may have another wrapper for the function: In the above example, we have to skip the frame inside wrapped to get to the right frame x = wrapped() so that we are able to locate x. The arguments frame and ignore of varname allow us to skip some of these intermediate frames. See more details in the README file and the API docs of the package. Then we need to parse the AST node to locate where the variable is assigned value (function call) to. It's not always just a simple assignment. Sometimes there could be complex AST nodes, for example, x = [wrapped()]. We need to identify the correct assignment by traversing the AST tree. Once we identify the assignment node, it is reliable. varname is all depending on executing package to look for the node. The node executing detects is ensured to be the correct one (see also this). It partially works with environments where other AST magics apply, including pytest, ipython, macropy, birdseye, reticulate with R, etc. Neither executing nor varname is 100% working with those environments. Well, yes and no, again. If your scenario is simple, the code provided by @juan Isaza or @scohe001 probably is enough for you to work with the case where a variable is defined at the direct previous frame and the AST node is a simple assignment. You just need to go one frame back and retrieve the information there. However, if the scenario becomes complicated, or we need to adopt different application scenarios, you probably need a package like python-varname, to handle them. These scenarios may include to: How about the f-string? Like the answer provided by @Aivar Paalberg. It's definitely fast and reliable. However, it's not at runtime, meaning that you have to know it's foo before you print the name out. But with varname, you don't have to know that variable is coming: python-varname is not only able to detect the variable name from an assignment, but also: Read more from its documentation. However, the final word I want to say is that, try to avoid using it whenever you can. Because you can't make sure that the client code will run in an environment where the source node is available or AST node is accessible. And of course, it costs resources to parse the source code, identify the environment, retrieve the AST nodes and evaluate them when needed.", 'score': 0.7932087322367938}
INFO: {'id': 57649418, 'content': "Actually there is a way to get names of the variables and attributes.\nYou can get the list of all the names without namespace, and their values as a dictionary using the vars function. It printed all the predefined variables without a namespace. (built-in functions such as len and print have __ builtins __ namespace.). But if you defined a variable: Then you can find the a you defined. This also works for object. You'll get all the names of the object's namespace by calling vars with the object as an argument. Using the vars function and dictionary handling you can achieve getting the object's variable name by the variable values, but there can be another value with identical values causing conflicts. Summary:\nUsing the vars built-in function and dictionary handling you can get the variable name of a value, but it has a chance to fail, when the values are not unique in the namespace.", 'score': 0.7928163090434124}
INFO: {'id': 38599196, 'content': 'A much better design principle is not to rely on the specific name of the object as shown below: This can lead to a whole wealth of issues with assignment binding, referencing, and most importantly does not allow you to name your objects per user or program choice. Instead add an instance variable to your class called self._name (9.6 Classes - Private Variables) or self.name if you want to allow access outside the scope of the class (in this example, you can name it anything). Not only is this more Object-Oriented design, but now you can implement methods like __hash__ to be able to create a hash based on a name for example to use an object as a key (there are many more reasons why this design choice is better!). Sample output:', 'score': 0.7907547199769356}
INFO: {'id': 57648972, 'content': 'What you think of as a "variable" is in Python nothing more than a reference to an object.\nSee naming and binding in the Python documentation. There is no 1:1 relation between objects and references. There can be more than one reference to an object. The CPython implementation even uses reference counting; an object will be de-allocated when there its reference count drops to 0. The closest thing that an object has to a name is its "identity", which you can get by calling the id() function on the object. This is an integer which is unique during the lifetime of the object. There is no universal way to get the the name of a reference/variable as a string.  If the name refers to an object that is subject to garbage collection, there is a roundabout way to get it (with thanks to Iain Shelvington for pointing it out in the comments): This will print out [\'test\']. Note that this does not apply to atomic objects like integers, strings and floats. It will only work for objects where gc.is_tracked(name) returns True.', 'score': 0.7902839157590356}
INFO: {'id': 18425275, 'content': 'The only objects in Python that have canonical names are modules, functions, and classes, and of course there is no guarantee that this canonical name has any meaning in any namespace after the function or class has been defined or the module imported. These names can also be modified after the objects are created so they may not always be particularly trustworthy. What you want to do is not possible without recursively walking the tree of named objects; a name is a one-way reference to an object. A common or garden-variety Python object contains no references to its names. Imagine if every integer, every dict, every list, every Boolean needed to maintain a list of strings that represented names that referred to it! It would be an implementation nightmare, with little benefit to the programmer.', 'score': 0.7894231584642306}
INFO: {'id': 30019630, 'content': 'As others have mentioned, this is a really tricky question. Solutions to this are not "one size fits all", not even remotely. The difficulty (or ease) is really going to depend on your situation. I have come to this problem on several occasions, but most recently while creating a debugging function. I wanted the function to take some unknown objects as arguments and print their declared names and contents. Getting the contents is easy of course, but the declared name is another story. What follows is some of what I have come up with. Determining the name of a function is really easy as it has the __name__ attribute containing the function\'s declared name. Just as an example, if you create the function def test_function(): pass, then copy_function = test_function, then name_of_function(copy_function), it will return test_function. Check whether the object has a __name__ attribute and return it if so (declared functions only). Note that you may remove this test as the name will still be in globals(). Compare the value of arg with the values of items in globals() and return the name of the first match. Note that I am filtering out names starting with \'_\'. The result will consist of the name of the first matching object otherwise None. The result will consist of a list (for multiple matches), a string (for a single match), otherwise None. Of course you should adjust this behavior as needed.', 'score': 0.7883899760085119}
INFO: {'id': 18983728, 'content': "Python provides the types module that defined classes for built-in types and the locals() and globals() functions that return a list of local and global variables in the application. One quick way to find objects by type is to do this. It's worth going through the Python library documentation and read the docs for modules that work with the code directly. Some of which are inspect, gc, types, codeop, code, imp, ast. bdb, pdb. The IDLE source code is also very informative.", 'score': 0.7873637237126321}
INFO: {'id': 17200188, 'content': "object1 is just an identifier(or variable) pointing to an instance object, objects don't have names. a,b,c are simply references that allow us to access a same object, when an object has 0 references it is automatically garbage collected. A quick hack will be to pass the name when creating the instance:", 'score': 0.7836623367503321}
INFO: {'id': 8875313, 'content': "Yes, it is possible*.  However, the problem is more difficult than it seems upon first glance:  Regardless, knowing how to find the names of an object can sometimes be useful for debugging purposes - and here is how to do it:   If you're ever tempted to base logic around the names of your variables, pause for a moment and consider if redesign/refactor of code could solve the problem.  The need to recover an object's name from the object itself usually means that underlying data structures in your program need a rethink.   * at least in Cpython", 'score': 0.7826831738709648}
INFO: {'id': 1539517, 'content': "Use a reverse dict. The reverse dict will map each function reference to the exact name you gave it in fun_dict, which may or may not be the name you used when you defined the function.  And, this technique generalizes to other objects, including integers. For extra fun and insanity, you can store the forward and reverse values in the same dict.  I wouldn't do that if you were mapping strings to strings, but if you are doing something like function references and strings, it's not too crazy.", 'score': 0.7817993988819608}
INFO: {'id': 18983610, 'content': 'Instances are created within a namespace: In this case, some_object is a name inside the "namespace" of the function that points at a MyClass instance. Once you leave the namespace (i.e., the function ends), Python\'s garbage collection cleans up the name and the instance. If there would be some other location that also has a pointer to the object, the cleanup wouldn\'t happen. So: no, there\'s no place where a list of instances is maintained. It would be a different case where you to use a database with an ORM (object-relational mapper). In Django\'s ORM you can do MyClass.objects.all() if MyClass is a database object. Something to look into if you really need the functionality. Update: See Bakuriu\'s answer. The garbage collector (which I mentioned) knows about all the instances :-) And he suggests the "weakref" module that prevents my won\'t-be-cleaned-up problem.', 'score': 0.7800615060176204}
INFO: {'id': 63661634, 'content': "I was independently working on this and have the following. It's not as comprehensive as driax's answer, but efficiently covers the case described and doesn't rely on searching for the object's id in global variables or parsing source code...", 'score': 0.7741624495769611}
INFO: {'id': 71791073, 'content': 'Note that an object may be referred to as multiple names.\nIt is also possible that there is no object name referring to the object. Below is one approach that achieves your goal. It uses globals(), the dictionary that stores mappings from names to objects inside the global environment. Essentially, the __str__ method searches the object in the global listings (so it can be very slow if there are many objects) and keeps the name if matches.\nYou could possibly use locals instead to narrow the search scope. In the example, C is referring to the same object as A. So print(C) tells both A and C are the names.', 'score': 0.7733173741638825}
INFO: {'id': 23258737, 'content': "I ran into this page while wondering the same question. As others have noted, it's simple enough to just grab the __name__ attribute from a function in order to determine the name of the function. It's marginally trickier with objects that don't have a sane way to determine __name__, i.e. base/primitive objects like basestring instances, ints, longs, etc. Long story short, you could probably use the inspect module to make an educated guess about which one it is, but you would have to probably know what frame you're working in/traverse down the stack to find the right one. But I'd hate to imagine how much fun this would be trying to deal with eval/exec'ed code. whats_my_name_again.py:", 'score': 0.7705901108217589}
INFO: {'id': 67092520, 'content': 'I presume you do not mean to just print the name p3.name. In case you mean to keep track of all the instances of your class, please refer to: Python: Find Instance of a class by value and How to keep track of class instances? If I apply the same logic as mentioned in the two references I have quoted above, your code could look something like this: The get_players_at_seat() function is a class method that returns an iterator containing all players in instances that have their seat property set to the given value of seat. You can then iterate over the iterator and print the names of the players at seat 3.', 'score': 0.7689971408223765}
INFO: {'id': 1539174, 'content': 'And the reason I want to have the name of the function is because I want to create fun_dict without writing the names of the functions twice, since that seems like a good way to create bugs. For this purpose you have a wonderful getattr function, that allows you to get an object by known name. So you could do for example: funcs.py: main.py:', 'score': 0.7662700844065349}
INFO: {'id': 1539112, 'content': "Generally when you are wanting to do something like this, you create a class to hold all of these functions and name them with some clear prefix cmd_ or the like.  You then take the string from the command, and try to get that attribute from the class with the cmd_ prefixed to it.  Now you only need to add a new function/method to the class, and it's available to your callers.  And you can use the doc strings for automatically creating the help text. As described in other answers, you may be able to do the same approach with globals() and regular functions in your module to more closely match what you asked for. Something like this:", 'score': 0.7639214741855236}
INFO: {'id': 54033089, 'content': 'If the goal is to help you keep track of your variables, you can write a simple function that labels the variable and returns its value and type. For example, suppose i_f=3.01 and you round it to an integer called i_n to use in a code, and then need a string i_s  that will go into a report.  This prints to the window at each call for debugging purposes and also yields a string for the written report.  The only downside is that you have to type the variable twice each time you call the function. I am a Python newbie and found this very useful way to log my efforts as I program and try to cope with all the objects in Python.  One flaw is that whatis() fails if it calls a function described outside the procedure where it is used.  For example, int(i_f) was a valid function call only because the int function is known to Python.  You could call whatis() using int(i_f**2), but if for some strange reason you choose to define a function called int_squared it must be declared inside the procedure where whatis() is used.', 'score': 0.7629968029541976}
INFO: {'id': 18983795, 'content': "You cann get names for all the instances as they may not all have names, or the names they do have may be in scope. You may be able to get the instances. If you are willing to keep track of the instances yourself, use a WeakSet: Note that just deleting a name may not destroy the instance. other still exists until the garbage collected: If you don't want to track them manually, then it is possible to use gc.get_objects() and filter out the instances you want, but that means you have to filter through all the objects in your program every time you do this. Even in the above example that means processing nearly 12,000 objects to find the 3 instances you want.", 'score': 0.7599665837995342}
INFO: {'id': 59721785, 'content': 'Following method will not return the name of variable but using this method you can create data frame easily if variable is available in global scope.', 'score': 0.7556521749710141}
INFO: {'id': 1538772, 'content': 'Note that while, as noted, objects in general do not and cannot know what variables are bound to them, functions defined with def do have names in the __name__ attribute (the name used in def).  Also if the functions are defined in the same module (as in your example) then globals() will contain a superset of the dictionary you want. ', 'score': 0.7553295887340357}
INFO: {'id': 41586688, 'content': "As many others have said, it can't be done properly. However inspired by jsbueno's, I have an alternative to his solution.  Like his solution, I inspect the callers stack frame, which means it only works properly for Python-implemented callers (see note below). Unlike him, I inspect the bytecode of the caller directly (instead of loading and parsing the source code). Using Python 3.4+'s dis.get_instructions() this can be done with some hope of minimal compatibility. Though this is still some hacky code. Note: C-implemented functions don't show up as Python stack frames and are thus hidden to this script. This will result in false positives. Consider Python function f() which calls a = g(). g() is C-implemented and calls b = f2(). When f2() tries to lookup up the assigned name, it will get a instead of b because the script is oblivious to C functions. (At least this is how I guess it will work :P ) Usage example:", 'score': 0.7546171165980174}
INFO: {'id': 21339843, 'content': "If you are looking to get the names of functions or lambdas or other function-like objects that are defined in the interpreter, you can use dill.source.getname from dill.  It pretty much looks for the __name__ method, but in certain cases it knows other magic for how to find the name... or a name for the object.  I don't want to get into an argument about finding the one true name for a python object, whatever that means.", 'score': 0.75103686985429}
INFO: {'id': 40536047, 'content': 'On python3, this function will get the outer most name in the stack: It is useful anywhere on the code. Traverses the reversed stack looking for the first match.', 'score': 0.7503490915563508}
INFO: {'id': 54349277, 'content': 'Python has names which are mapped to objects in a hashmap called a namespace. At any instant in time, a name always refers to exactly one object, but a single object can be referred to by any arbitrary number of names. Given a name, it is very efficient for the hashmap to look up the single object which that name refers to. However given an object, which as mentioned can be referred to by multiple names, there is no efficient way to look up the names which refer to it. What you have to do is iterate through all the names in the namespace and check each one individually and see if it maps to your given object. This can easily be done with a list comprehension: This will evaluate to a list of strings containing the names of all local "variables" which are currently mapped to the object  myobj. Of course locals() can be substituted with any dict that you want to search for names that point to a given object. Obviously this search can be slow for very large namespaces because they must be traversed in their entirety.', 'score': 0.7496802920976238}
INFO: {'id': 1539123, 'content': "Here's another way to think about it.  Suppose there were a name() function that returned the name of its argument.  Given the following code: What should name(e[2]) return, and why?", 'score': 0.7455527344250974}
INFO: {'id': 18983693, 'content': "If you are the one creating the class you can simply store weak-references when instantiating the class: Using weak-references allow the instances to be deallocated before the class. See the weakref module for details on what it does. Note that you may be able to use this technique even with classes that you didn't write. You simply have to monkey-patch the class.\nFor example: Then you can do: And all instances created after the execution of this statement will be found in ExternalClass.instances. Depending on the class you may have to replace __new__ instead of __init__. You can do this even without any special code in the class, simply using the garbage collector: And you can always obtain the class object since you can find it using object.__subclasses__ method: (assuming there is only a class with that name, otherwise you should try all of them) However I cannot think of a situation where this is the right thing to do, so avoid this code in real applications. I've done some testing and I believe that this solution may not work for built-in classes or classes defined in C extensions. If you are in this case the last resort is to use gc.get_objects() to retrieve all tracked objects. However this will work only if the object support cyclic garbage collection, so there isn't a method that works in every possible situation.", 'score': 0.745173596409347}
INFO: {'id': 60826880, 'content': "I have a method, and while not the most efficient...it works! (and it doesn't involve any fancy modules). Basically it compares your Variable's ID to globals() Variables' IDs, then returns the match's name.", 'score': 0.744566903521771}
INFO: {'id': 54423514, 'content': 'just another way to do this based on the content of input variable: (it returns the name of the first variable that matches to the input variable, otherwise None. One can modify it to get all variable names which are having the same content as input variable)', 'score': 0.7382130182461909}
INFO: {'id': 57503767, 'content': 'You can try the following to retrieve the name of a function you defined (does not work for built-in functions though):', 'score': 0.7358352626693281}
INFO: {'id': 18983535, 'content': "Here the version getting the instances from memory, I wouldn't recommend using this in live code but it can be convenient for debugging:", 'score': 0.7354244075524411}
INFO: {'id': 54999371, 'content': 'This function will print variable name with its value:', 'score': 0.7345781405867449}
INFO: {'id': 59804094, 'content': "In case you get an error if myvar points to another variable, try this (suggested by @mherzog)- locals() - Return a dictionary containing the current scope's local variables.\nby iterating through this dictionary we can check the key which has a value equal to the defined variable, just extracting the key will give us the text of variable in string format. from (after a bit changes)\nhttps://www.tutorialspoint.com/How-to-get-a-variable-name-as-a-string-in-Python", 'score': 0.7315337521482385}
INFO: {'id': 71715076, 'content': 'Hi there is one way to get the variable name that stores an instance of a class\nis to use locals() function, it returns a dictionary that contains the variable name as a string and its value', 'score': 0.7315090502983111}
INFO: {'id': 71712672, 'content': 'It\'s totally possible to get the name of an instance variable, so long as it is the property of a class. I got this from Effective Python by Brett Slatkin. Hope it helps someone: The class must implement the get, set, and set_name dunder methods, which are part of the "Descriptor Protocol" This worked when I ran it: You can then add methods and or extend your datatype as you like. As a bonus, the set_name(self, owner, name) dunder also passes the parent instance, so the Field class instance can register itself with the parent. I got this from Effective Python by Brett Slatkin. It took a while to figure out how to implement.', 'score': 0.7306155585231049}
INFO: {'id': 18425285, 'content': "I don't believe this is possible. Consider the following example: The a and b point to the same object, but the object can't know what variables point to it.", 'score': 0.7303306152248228}
INFO: {'id': 65678960, 'content': 'Whenever I have to do it, mostly while communicating json schema and constants with the frontend I define a class as follows Then define the variable with name and value. Now you can access the name and value using the object.', 'score': 0.7298119159334836}
INFO: {'id': 73495512, 'content': 'If you already have a list of dataframes, as is stated in the comments, then it is easy enough to make that list into a list of strings.\nInstead of going from list of variables to strings, go the other way, a list of strings to variables with the builtin exec function combined with f-strings (assuming that the variables are already assigned, i.e. vel, vol, and area are variable names of existing pandas dataframes): If: This iterates through the list and uses each dataframe to write to excel, and defines the sheetname:', 'score': 0.728608134443216}
INFO: {'id': 46471018, 'content': "I think it's so difficult to do this in Python because of the simple fact that you never will not know the name of the variable you're using. So, in his example, you could do: Instead of:", 'score': 0.7280946016471626}
INFO: {'id': 67419557, 'content': 'As you see and is noted here, there can be multiple variables with the same value or even address, so using a wrapper to keep the names with the data is best.', 'score': 0.7275393754399405}
INFO: {'id': 69960020, 'content': 'Some of the previous cases would fail if there are two variables with the same value. So it is convenient to alert it: Defining function: Use: If you have 2 variables with the same value like var_1 = 8 and var_2 = 8, then a warning will appear.', 'score': 0.7266763099823642}
INFO: {'id': 63171710, 'content': "Many of the answers return just one variable name. But that won't work well if more than one variable have the same value. Here's a variation of Amr Sharaki's answer which returns multiple results if more variables have the same value.", 'score': 0.7240390837829047}
INFO: {'id': 59079732, 'content': 'Maybe this could be useful: The function goes through the list of IDs of values from the global scope (the namespace could be edited), finds the index of the wanted/required var or function based on its ID, and then returns the name from the list of global names based on the acquired index.  ', 'score': 0.7236664732693572}
INFO: {'id': 33912052, 'content': 'Here is a simple function to achieve what you want, assuming you wish to retrieve the name of the variable where the instance is assigned from a method call : Here is an usage example :', 'score': 0.7234384222181226}
INFO: {'id': 1538466, 'content': 'Variable names can be found in the globals() and locals() dicts. But they won\'t give you what you\'re looking for above. "bla" will contain the value of each item of my_list, not the variable.', 'score': 0.7214859441961233}
INFO: {'id': 58451182, 'content': "With Python 3.8 one can simply use f-string debugging feature: One drawback of this method is that in order to get 'foo' printed you have to add f'{foo=}' yourself. In other words, you already have to know the name of the variable. In other words, the above code snippet is exactly the same as just", 'score': 0.7184777763370178}
INFO: {'id': 30019808, 'content': 'You define a class and add the Unicode private function insert the class like Of course you have to add extra variable self.name which is the name of the object.', 'score': 0.716695240266102}
INFO: {'id': 66833271, 'content': "When finding the name of a variable from its value,\nyou may have several variables equal to the same value,\nfor example var1 = 'hello' and var2 = 'hello'. My solution: Outputs", 'score': 0.716470803727978}
INFO: {'id': 39240374, 'content': 'Here is my answer, I am also using globals().items() I added except_word because I want to filter off some word used in for loop. \nIf you didn\'t add it, the keyword in for loop may confuse this function, sometimes the keyword like "each_item" in the following case may show in the function\'s result, depends on what you have done to your loop. eg. eg. Hope this can help.', 'score': 0.7133419728560298}
INFO: {'id': 1538380, 'content': 'Objects do not necessarily have names in Python, so you can\'t get the name. When you create a variable, like the x, y, z above then those names just act as "pointers" or "references" to the objects. The object itself does not know what name(s) you are using for it, and you can not easily (if at all) get the names of all references to that object. However, it\'s not unusual for objects to have a __name__ attribute. Functions do have a __name__ (unless they are lambdas), so we can build fun_dict by doing e.g.', 'score': 0.7105235259876403}
INFO: {'id': 17196512, 'content': 'use the __name__ attribute: Class: Function: A quick hack for classes will be:', 'score': 0.7069137053439692}
INFO: {'id': 8875258, 'content': "No. Objects and names live in separate dimensions. One object can have many names during its lifetime, and it's impossible to determine which one might be the one you want. Even in here: two names denote the same object (self when __init__ runs, x in global scope).", 'score': 0.7055088255399371}
INFO: {'id': 64053336, 'content': "Based on what it looks like you're trying to do you could use this approach. In your case, your functions would all live in the module foo. Then you could: Or more succinctly:", 'score': 0.7054283391920108}
INFO: {'id': 18425312, 'content': 'If you wanted to write your own function, it could be done such that you could check for a variable defined in locals then check globals. If nothing is found you could compare on id() to see if the variable points to the same location in memory. If your variable is in a class, you could use className.dict.keys() or vars(self) to see if your variable has been defined.', 'score': 0.6980608273806179}
INFO: {'id': 17196943, 'content': 'the function part has already been answered at this SO post. The code would be: For the class part, use: A.__name__ or A().__class__.__name (for an instance)', 'score': 0.681631411486821}
INFO: {'id': 49331805, 'content': 'I have posted a complete solution here: https://stackoverflow.com/a/49331683/7386061 It works without parameters. For example you could just do:', 'score': 0.6797941912417365}
INFO: {'id': 17200322, 'content': 'The common way to do this is something along these lines: Prints: However, there is no guarantee that this object remains bound to the original name: Prints object1, as expected, twice. If you want to see things under the hood -- use a debugger. ', 'score': 0.6734108083433985}
INFO: {'id': 1538399, 'content': "That's not really possible, as there could be multiple variables that have the same value, or a value might have no variable, or a value might have the same value as a variable only by chance. If you really want to do that, you can use However, it would be better if you would iterate over names in the first place: \xa0", 'score': 0.6592879599056882}
INFO: {'id': 59914969, 'content': "assuming this: then you can search through the environment by the object's id, returning the key when there is a match.", 'score': 0.6513108248228867}
INFO: {'id': 67092322, 'content': 'The simplest way would be to put all your player objects into a list & loop through the list checking their atributes,', 'score': 0.6233088304133617}
INFO: {'id': 53684586, 'content': "I try to get name from inspect locals, but it cann't process var likes a[1], b.val.\nAfter it, I got a new idea --- get var name from the code, and I try it succ!\ncode like below: ", 'score': 0.6151443201240493}
INFO: {'id': 51347986, 'content': "I wrote the package sorcery to do this kind of magic robustly. You can write: and pass that to the dataframe constructor. It's equivalent to:", 'score': 0.5982753116665576}
INFO: {'id': 16139159, 'content': 'This one-liner works, for all types of objects, as long as they are in globals() dict, which they should be: or, equivalently:', 'score': 0.5889493659168156}
INFO: {'id': 71962669, 'content': 'You can get your variable as kwargs and return it as string: Note: variable name must be equal to itself.', 'score': 0.5865093940869386}
INFO: {'id': 69496355, 'content': "Compressed version of iDilip's answer:", 'score': 0.5179235224638813}
INFO: {'id': 38599084, 'content': "You'd have to first give them names. E.g.", 'score': 0.4387458728921126}
INFO: {'id': 68743685, 'content': "I know This is late answer. Ex:. Performance note: don't use it in large modules.", 'score': 0.42995406303117156}
INFO: {'id': 75046191, 'content': '', 'score': 0.0}
INFO: {'id': 19201952, 'content': "It's used like this:", 'score': 0.0}
INFO: {'id': 18983557, 'content': '', 'score': 0.0}
