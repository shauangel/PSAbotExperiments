INFO: --------------------
INFO: Why am I getting an UnboundLocalError when the variable has a value?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<327 unique tokens: ["'", '+', '2.x', '3.x', '=']...> from 10 documents (total 987 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<327 unique tokens: ["\'", \'+\', \'2.x\', \'3.x\', \'=\']...> from 10 documents (total 987 corpus positions)', 'datetime': '2023-03-20T16:52:31.223378', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.030 per-word bound, 130.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.076*"variable" + 0.048*"function" + 0.048*"global" + 0.040*"local" + 0.031*"scope" + 0.020*"name" + 0.019*"c" + 0.017*"value" + 0.017*"=" + 0.017*"assignment"
INFO: topic #1 (1.000): 0.057*"variable" + 0.037*"local" + 0.036*"scope" + 0.035*"global" + 0.026*"name" + 0.024*"function" + 0.023*"c" + 0.023*"assignment" + 0.022*"num" + 0.021*"line"
INFO: topic #2 (1.000): 0.047*"variable" + 0.040*"function" + 0.030*"global" + 0.027*"local" + 0.017*"program" + 0.016*"scope" + 0.016*"value" + 0.015*"num" + 0.015*"assignment" + 0.014*"access"
INFO: topic diff=2.910917, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.116 per-word bound, 1109.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.103*"variable" + 0.078*"global" + 0.067*"function" + 0.055*"local" + 0.033*"scope" + 0.024*"value" + 0.018*"name" + 0.018*"assignment" + 0.016*"inside" + 0.015*"error"
INFO: topic #1 (1.000): 0.059*"variable" + 0.040*"local" + 0.037*"global" + 0.034*"scope" + 0.025*"function" + 0.024*"name" + 0.024*"assignment" + 0.018*"line" + 0.018*"c" + 0.018*"value"
INFO: topic #2 (1.000): 0.056*"variable" + 0.047*"global" + 0.047*"function" + 0.039*"f" + 0.039*"var1" + 0.029*"local" + 0.024*"value" + 0.013*"scope" + 0.011*"load" + 0.011*"return"
INFO: topic diff=2.307186, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 61.618826026097224
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.633060607590513
DEBUG: bound: at document #0
INFO: -5.873 per-word bound, 58.6 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.108*"variable" + 0.072*"function" + 0.070*"global" + 0.049*"local" + 0.031*"scope" + 0.030*"value" + 0.017*"inside" + 0.016*"access" + 0.015*"assignment" + 0.015*"program"
INFO: topic #1 (1.000): 0.058*"variable" + 0.039*"local" + 0.038*"global" + 0.034*"scope" + 0.028*"function" + 0.025*"name" + 0.023*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"num"
INFO: topic #2 (1.000): 0.045*"variable" + 0.040*"function" + 0.039*"global" + 0.029*"var1" + 0.029*"f" + 0.023*"value" + 0.023*"local" + 0.012*"other" + 0.010*"scope" + 0.008*"return"
INFO: topic diff=1.031924, rho=0.500000
DEBUG: bound: at document #0
INFO: -6.794 per-word bound, 110.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.084*"global" + 0.078*"function" + 0.062*"local" + 0.034*"scope" + 0.027*"value" + 0.022*"inside" + 0.019*"assignment" + 0.017*"work" + 0.016*"error"
INFO: topic #1 (1.000): 0.055*"variable" + 0.038*"local" + 0.037*"global" + 0.033*"scope" + 0.027*"function" + 0.025*"name" + 0.022*"c" + 0.021*"assignment" + 0.021*"line" + 0.021*"="
INFO: topic #2 (1.000): 0.066*"f" + 0.066*"var1" + 0.047*"global" + 0.044*"variable" + 0.035*"function" + 0.028*"value" + 0.022*"local" + 0.018*"return" + 0.018*"caller" + 0.018*"load"
INFO: topic diff=1.040256, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 49.15207192328064
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -0.6430816148048812
DEBUG: bound: at document #0
INFO: -5.575 per-word bound, 47.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.079*"function" + 0.072*"global" + 0.052*"local" + 0.033*"value" + 0.032*"scope" + 0.021*"inside" + 0.019*"access" + 0.019*"program" + 0.017*"loop"
INFO: topic #1 (1.000): 0.057*"variable" + 0.039*"local" + 0.038*"global" + 0.034*"scope" + 0.028*"function" + 0.026*"name" + 0.024*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"num"
INFO: topic #2 (1.000): 0.055*"var1" + 0.055*"f" + 0.041*"global" + 0.038*"variable" + 0.031*"function" + 0.026*"value" + 0.019*"local" + 0.015*"return" + 0.015*"caller" + 0.015*"load"
INFO: topic diff=0.661229, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.191 per-word bound, 73.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.128*"variable" + 0.083*"function" + 0.083*"global" + 0.064*"local" + 0.035*"scope" + 0.027*"value" + 0.025*"inside" + 0.021*"assignment" + 0.018*"work" + 0.017*"error"
INFO: topic #1 (1.000): 0.055*"variable" + 0.038*"global" + 0.037*"local" + 0.033*"scope" + 0.028*"function" + 0.025*"name" + 0.023*"c" + 0.022*"line" + 0.021*"=" + 0.021*"assignment"
INFO: topic #2 (1.000): 0.074*"f" + 0.074*"var1" + 0.049*"global" + 0.036*"variable" + 0.031*"value" + 0.028*"function" + 0.019*"return" + 0.019*"caller" + 0.019*"load" + 0.019*"change"
INFO: topic diff=0.658182, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 46.862232663504486
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -0.6273759589810953
DEBUG: bound: at document #0
INFO: -5.509 per-word bound, 45.6 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.125*"variable" + 0.083*"function" + 0.073*"global" + 0.055*"local" + 0.033*"value" + 0.033*"scope" + 0.023*"inside" + 0.020*"access" + 0.020*"program" + 0.018*"loop"
INFO: topic #1 (1.000): 0.057*"variable" + 0.038*"global" + 0.038*"local" + 0.034*"scope" + 0.028*"function" + 0.026*"name" + 0.024*"c" + 0.022*"line" + 0.021*"assignment" + 0.021*"num"
INFO: topic #2 (1.000): 0.063*"f" + 0.063*"var1" + 0.043*"global" + 0.032*"variable" + 0.029*"value" + 0.025*"function" + 0.017*"return" + 0.017*"load" + 0.017*"caller" + 0.017*"change"
INFO: topic diff=0.442532, rho=0.408248
DEBUG: bound: at document #0
INFO: -6.072 per-word bound, 67.3 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.132*"variable" + 0.086*"function" + 0.082*"global" + 0.066*"local" + 0.036*"scope" + 0.027*"value" + 0.025*"inside" + 0.021*"assignment" + 0.018*"work" + 0.017*"error"
INFO: topic #1 (1.000): 0.055*"variable" + 0.038*"global" + 0.037*"local" + 0.033*"scope" + 0.028*"function" + 0.025*"name" + 0.023*"c" + 0.022*"line" + 0.021*"=" + 0.021*"assignment"
INFO: topic #2 (1.000): 0.077*"var1" + 0.077*"f" + 0.050*"global" + 0.034*"value" + 0.030*"variable" + 0.022*"function" + 0.020*"load" + 0.020*"caller" + 0.020*"return" + 0.020*"change"
INFO: topic diff=0.427104, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 46.246845283475274
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -0.6283650804079436
DEBUG: bound: at document #0
INFO: -5.487 per-word bound, 44.9 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.128*"variable" + 0.085*"function" + 0.072*"global" + 0.056*"local" + 0.033*"scope" + 0.032*"value" + 0.023*"inside" + 0.020*"access" + 0.020*"program" + 0.018*"loop"
INFO: topic #1 (1.000): 0.056*"variable" + 0.038*"global" + 0.038*"local" + 0.034*"scope" + 0.028*"function" + 0.026*"name" + 0.024*"c" + 0.022*"line" + 0.021*"assignment" + 0.021*"num"
INFO: topic #2 (1.000): 0.066*"var1" + 0.066*"f" + 0.045*"global" + 0.032*"value" + 0.027*"variable" + 0.020*"function" + 0.018*"load" + 0.018*"return" + 0.018*"caller" + 0.017*"change"
INFO: topic diff=0.308470, rho=0.377964
DEBUG: bound: at document #0
INFO: -6.030 per-word bound, 65.3 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.134*"variable" + 0.088*"function" + 0.080*"global" + 0.066*"local" + 0.036*"scope" + 0.027*"value" + 0.025*"inside" + 0.021*"assignment" + 0.017*"work" + 0.017*"error"
INFO: topic #1 (1.000): 0.055*"variable" + 0.038*"global" + 0.037*"local" + 0.033*"scope" + 0.028*"function" + 0.025*"name" + 0.023*"c" + 0.022*"line" + 0.021*"=" + 0.021*"assignment"
INFO: topic #2 (1.000): 0.078*"var1" + 0.078*"f" + 0.051*"global" + 0.036*"value" + 0.024*"variable" + 0.020*"caller" + 0.020*"load" + 0.020*"return" + 0.020*"change" + 0.017*"function"
INFO: topic diff=0.312378, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 46.02455728242735
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -0.5758429069586006
DEBUG: bound: at document #0
INFO: -5.476 per-word bound, 44.5 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.130*"variable" + 0.086*"function" + 0.072*"global" + 0.058*"local" + 0.034*"scope" + 0.032*"value" + 0.024*"inside" + 0.020*"access" + 0.019*"program" + 0.018*"loop"
INFO: topic #1 (1.000): 0.056*"variable" + 0.038*"global" + 0.038*"local" + 0.034*"scope" + 0.028*"function" + 0.026*"name" + 0.024*"c" + 0.022*"line" + 0.021*"assignment" + 0.021*"num"
INFO: topic #2 (1.000): 0.069*"f" + 0.069*"var1" + 0.046*"global" + 0.035*"value" + 0.022*"variable" + 0.018*"return" + 0.018*"caller" + 0.018*"load" + 0.018*"change" + 0.016*"function"
INFO: topic diff=0.238933, rho=0.353553
DEBUG: bound: at document #0
INFO: -6.008 per-word bound, 64.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.136*"variable" + 0.089*"function" + 0.079*"global" + 0.067*"local" + 0.036*"scope" + 0.026*"value" + 0.025*"inside" + 0.021*"assignment" + 0.017*"work" + 0.017*"error"
INFO: topic #1 (1.000): 0.055*"variable" + 0.038*"global" + 0.037*"local" + 0.033*"scope" + 0.028*"function" + 0.025*"name" + 0.023*"c" + 0.023*"line" + 0.021*"=" + 0.021*"assignment"
INFO: topic #2 (1.000): 0.079*"f" + 0.079*"var1" + 0.052*"global" + 0.038*"value" + 0.020*"load" + 0.020*"return" + 0.020*"caller" + 0.020*"change" + 0.020*"variable" + 0.017*"condition"
INFO: topic diff=0.253317, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 45.91359460279649
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -1.6937716286864024
DEBUG: bound: at document #0
INFO: -5.469 per-word bound, 44.3 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.131*"variable" + 0.087*"function" + 0.072*"global" + 0.059*"local" + 0.034*"scope" + 0.031*"value" + 0.024*"inside" + 0.019*"access" + 0.019*"program" + 0.018*"loop"
INFO: topic #1 (1.000): 0.056*"variable" + 0.038*"global" + 0.038*"local" + 0.034*"scope" + 0.028*"function" + 0.026*"name" + 0.024*"c" + 0.022*"line" + 0.021*"assignment" + 0.021*"num"
INFO: topic #2 (1.000): 0.070*"f" + 0.070*"var1" + 0.047*"global" + 0.037*"value" + 0.018*"load" + 0.018*"return" + 0.018*"caller" + 0.018*"change" + 0.018*"variable" + 0.015*"condition"
INFO: topic diff=0.208676, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.994 per-word bound, 63.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.137*"variable" + 0.090*"function" + 0.079*"global" + 0.068*"local" + 0.036*"scope" + 0.026*"value" + 0.025*"inside" + 0.021*"assignment" + 0.017*"work" + 0.017*"error"
INFO: topic #1 (1.000): 0.055*"variable" + 0.038*"global" + 0.037*"local" + 0.033*"scope" + 0.028*"function" + 0.025*"name" + 0.023*"c" + 0.023*"line" + 0.021*"=" + 0.021*"assignment"
INFO: topic #2 (1.000): 0.080*"var1" + 0.080*"f" + 0.052*"global" + 0.040*"value" + 0.021*"load" + 0.021*"caller" + 0.021*"return" + 0.021*"change" + 0.016*"condition" + 0.016*"variable"
INFO: topic diff=0.220319, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 45.83893439119654
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -1.6844919029938439
DEBUG: bound: at document #0
INFO: -5.464 per-word bound, 44.1 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.132*"variable" + 0.088*"function" + 0.072*"global" + 0.059*"local" + 0.034*"scope" + 0.030*"value" + 0.024*"inside" + 0.019*"access" + 0.019*"program" + 0.018*"assignment"
INFO: topic #1 (1.000): 0.056*"variable" + 0.038*"global" + 0.038*"local" + 0.034*"scope" + 0.028*"function" + 0.026*"name" + 0.024*"c" + 0.022*"line" + 0.021*"assignment" + 0.021*"num"
INFO: topic #2 (1.000): 0.071*"var1" + 0.071*"f" + 0.048*"global" + 0.039*"value" + 0.018*"load" + 0.018*"caller" + 0.018*"return" + 0.018*"change" + 0.017*"other" + 0.015*"condition"
INFO: topic diff=0.195064, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.983 per-word bound, 63.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.138*"variable" + 0.091*"function" + 0.078*"global" + 0.068*"local" + 0.036*"scope" + 0.025*"value" + 0.025*"inside" + 0.021*"assignment" + 0.017*"work" + 0.017*"error"
INFO: topic #1 (1.000): 0.055*"variable" + 0.038*"global" + 0.037*"local" + 0.033*"scope" + 0.028*"function" + 0.025*"name" + 0.023*"c" + 0.023*"line" + 0.021*"=" + 0.021*"assignment"
INFO: topic #2 (1.000): 0.080*"f" + 0.080*"var1" + 0.053*"global" + 0.042*"value" + 0.021*"return" + 0.021*"caller" + 0.021*"load" + 0.021*"change" + 0.015*"condition" + 0.014*"other"
INFO: topic diff=0.199858, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 45.77651687069052
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -1.8973040022871057
DEBUG: bound: at document #0
INFO: -5.460 per-word bound, 44.0 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.133*"variable" + 0.089*"function" + 0.072*"global" + 0.060*"local" + 0.034*"scope" + 0.030*"value" + 0.024*"inside" + 0.019*"access" + 0.019*"program" + 0.018*"assignment"
INFO: topic #1 (1.000): 0.056*"variable" + 0.038*"global" + 0.038*"local" + 0.034*"scope" + 0.028*"function" + 0.026*"name" + 0.024*"c" + 0.022*"line" + 0.021*"assignment" + 0.021*"num"
INFO: topic #2 (1.000): 0.071*"f" + 0.071*"var1" + 0.048*"global" + 0.041*"value" + 0.019*"return" + 0.019*"caller" + 0.019*"load" + 0.019*"change" + 0.018*"other" + 0.014*"condition"
INFO: topic diff=0.185438, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.973 per-word bound, 62.8 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.139*"variable" + 0.092*"function" + 0.078*"global" + 0.068*"local" + 0.036*"scope" + 0.025*"value" + 0.025*"inside" + 0.021*"assignment" + 0.017*"work" + 0.017*"error"
INFO: topic #1 (1.000): 0.055*"variable" + 0.038*"global" + 0.037*"local" + 0.033*"scope" + 0.028*"function" + 0.025*"name" + 0.023*"c" + 0.023*"line" + 0.021*"=" + 0.021*"assignment"
INFO: topic #2 (1.000): 0.080*"f" + 0.080*"var1" + 0.053*"global" + 0.043*"value" + 0.021*"load" + 0.021*"caller" + 0.021*"return" + 0.021*"change" + 0.015*"other" + 0.014*"condition"
INFO: topic diff=0.185887, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 45.720229954330165
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -1.8973040022871057
DEBUG: bound: at document #0
INFO: -5.456 per-word bound, 43.9 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.134*"variable" + 0.090*"function" + 0.072*"global" + 0.061*"local" + 0.034*"scope" + 0.029*"value" + 0.024*"inside" + 0.019*"access" + 0.019*"program" + 0.018*"assignment"
INFO: topic #1 (1.000): 0.056*"variable" + 0.038*"global" + 0.038*"local" + 0.034*"scope" + 0.028*"function" + 0.026*"name" + 0.024*"c" + 0.022*"line" + 0.021*"assignment" + 0.021*"num"
INFO: topic #2 (1.000): 0.072*"f" + 0.072*"var1" + 0.049*"global" + 0.042*"value" + 0.020*"other" + 0.019*"return" + 0.019*"load" + 0.019*"caller" + 0.019*"change" + 0.013*"condition"
INFO: topic diff=0.177273, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.964 per-word bound, 62.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.139*"variable" + 0.092*"function" + 0.077*"global" + 0.069*"local" + 0.036*"scope" + 0.025*"inside" + 0.025*"value" + 0.021*"assignment" + 0.017*"work" + 0.016*"error"
INFO: topic #1 (1.000): 0.055*"variable" + 0.038*"global" + 0.038*"local" + 0.033*"scope" + 0.028*"function" + 0.025*"name" + 0.023*"c" + 0.023*"line" + 0.021*"=" + 0.021*"assignment"
INFO: topic #2 (1.000): 0.081*"var1" + 0.081*"f" + 0.053*"global" + 0.045*"value" + 0.021*"caller" + 0.021*"return" + 0.021*"load" + 0.021*"change" + 0.016*"other" + 0.013*"condition"
INFO: topic diff=0.175650, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 45.66940019651752
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.8938224939223227
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5> in 0.19s', 'datetime': '2023-03-20T16:52:31.438599', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/questions/1/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-20T16:52:31.438877', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/questions/1/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/1/model.state
DEBUG: {'uri': 'model/questions/1/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/questions/1/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-20T16:52:31.442632', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/questions/1/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/questions/1/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/1/model
INFO: topic #0 (1.000): 0.139*"variable" + 0.092*"function" + 0.077*"global" + 0.069*"local" + 0.036*"scope" + 0.025*"inside" + 0.025*"value" + 0.021*"assignment" + 0.017*"work" + 0.016*"error"
INFO: topic #1 (1.000): 0.055*"variable" + 0.038*"global" + 0.038*"local" + 0.033*"scope" + 0.028*"function" + 0.025*"name" + 0.023*"c" + 0.023*"line" + 0.021*"=" + 0.021*"assignment"
INFO: topic #2 (1.000): 0.081*"var1" + 0.081*"f" + 0.053*"global" + 0.045*"value" + 0.021*"caller" + 0.021*"return" + 0.021*"load" + 0.021*"change" + 0.016*"other" + 0.013*"condition"
INFO: Question Similarity: [0.09997576475143433, 0.2740594744682312, 0.33948254585266113, 0.1766795516014099, 0.14734762907028198, 0.04911869764328003, 0.1273798942565918, 0.3242040276527405, 0.06313157081604004, 0.2122756838798523]
INFO: 71229058: -0.1086620260306182
INFO: 72836918: -0.13482299313062948
INFO: 370363: -0.2075517936052079
INFO: 370752: -0.20810327046030258
INFO: 370364: -0.20810850388893326
INFO: 370830: -0.20926407501441327
INFO: 476123: -0.2098818503193369
INFO: 75045222: -0.2100669546648439
INFO: 24035261: -0.21043058947823623
INFO: 370380: -0.21049030950509232
INFO: 40409182: -0.21056433506490668
INFO: 34153129: -0.2105802578971618
INFO: 1745180: -0.21098910771532778
INFO: 73661023: -0.2110889802894665
INFO: 72633950: -0.21228248169533911
INFO: 71164410: -0.25838196835997246
INFO: 74297685: -0.2990266019652505
INFO: 74412646: -0.35988280646413234
INFO: 74412647: -0.36058390257530376
INFO: 74412557: -0.3666816217875685
INFO: 53956671: -0.4822212455451921
INFO: 53956563: -0.48963973183992
INFO: 75285878: -0.5796648959645767
INFO: 10852006: -0.680449952015551
INFO: 10852003: -0.7112651170211375
INFO: 21836774: -0.7267689733974376
INFO: 26579841: -0.7303157873696104
INFO: 74454524: -0.7347502126214643
INFO: 10851939: -0.7377504956955441
INFO: Recommended Keywords
INFO: appropriate score: -0.8049667
INFO: change score: -0.7661956
INFO: function score: -0.751896
INFO: problem score: -0.7505207
INFO: example score: -0.74150634
INFO: key score: -0.7196987
INFO: method score: -0.71351486
INFO: direct score: -0.70690364
INFO: instance score: -0.7032822
INFO: information score: -0.7017975
INFO: value score: -0.68999904
INFO: define score: -0.68675715
INFO: condition score: -0.68645114
INFO: definition score: -0.6852581
INFO: result score: -0.6838171
INFO: assign score: -0.67886585
INFO: solution score: -0.6730231
INFO: calculated score: -0.6696802
INFO: utility score: -0.6460479
INFO: assume score: -0.6277582
INFO: addition score: -0.6205175
INFO: simple score: -0.6168455
INFO: link score: -0.6111696
INFO: case score: -0.606441
INFO: unit score: -0.6050914
INFO: variable score: -0.6041731
INFO: solve score: -0.60042834
INFO: variables score: -0.595387
INFO: scope score: -0.5932758
INFO: test score: -0.5920714
INFO: default score: -0.58605546
INFO: point score: -0.5839505
INFO: different score: -0.5778885
INFO: complete score: -0.57148874
INFO: reference score: -0.5688233
INFO: other score: -0.545663
INFO: execute score: -0.541965
INFO: code score: -0.54111886
INFO: offset score: -0.5367361
INFO: object score: -0.5331195
INFO: parameter score: -0.5307971
INFO: behavior score: -0.52901214
INFO: implementation score: -0.52867526
INFO: practice score: -0.5283277
INFO: mechanism score: -0.52340573
INFO: update score: -0.5206645
INFO: testing score: -0.5198779
INFO: question score: -0.51963615
INFO: statement score: -0.517858
INFO: documentation score: -0.5164973
INFO: locally score: -0.51189864
INFO: c score: -0.50998896
INFO: note score: -0.50806373
INFO: block score: -0.5065579
INFO: conditional score: -0.5024945
INFO: augmented score: -0.49976915
INFO: clear score: -0.49393997
INFO: completeness score: -0.4826746
INFO: b score: -0.48233345
INFO: tweak score: -0.48132977
INFO: work score: -0.48080248
INFO: error score: -0.48056412
INFO: load score: -0.47944185
INFO: right score: -0.47827622
INFO: access score: -0.4633587
INFO: idea score: -0.46272826
INFO: global score: -0.46230108
INFO: way score: -0.46202233
INFO: accessing score: -0.46122435
INFO: time score: -0.45721915
INFO: new score: -0.45549378
INFO: assignment score: -0.4546755
INFO: local score: -0.45361483
INFO: class score: -0.45045593
INFO: good score: -0.44704688
INFO: notice score: -0.4464808
INFO: table score: -0.44068733
INFO: module score: -0.43689618
INFO: program score: -0.43241045
INFO: long score: -0.4275951
INFO: caller score: -0.42465714
INFO: mutable score: -0.41918173
INFO: line score: -0.41905597
INFO: bit score: -0.41883746
INFO: sure score: -0.41604838
INFO: name score: -0.4095058
INFO: lookup score: -0.40930837
INFO: = score: -0.4061434
INFO: traditional score: -0.4057981
INFO: compile score: -0.4050804
INFO: inside score: -0.4042593
INFO: return score: -0.40214008
INFO: original score: -0.39694378
INFO: f score: -0.38547125
INFO: force score: -0.3825935
INFO: copy score: -0.38151312
INFO: keyword score: -0.38076553
INFO: mind score: -0.3799199
INFO: outside score: -0.3798233
INFO: lie score: -0.3792785
INFO: post score: -0.37408137
INFO: initialization score: -0.37238172
INFO: interesting score: -0.37117675
INFO: misleading score: -0.37090805
INFO: loop score: -0.36611143
INFO: message score: -0.34774217
INFO: parse score: -0.3469973
INFO: detail score: -0.34683123
INFO: semantic score: -0.34592566
INFO: comment score: -0.34211662
INFO: little score: -0.3405092
INFO: quirk score: -0.33359098
INFO: life score: -0.32920307
INFO: scan score: -0.32104647
INFO: rename score: -0.3172064
INFO: compiler score: -0.31620023
INFO: language score: -0.31552964
INFO: nonlocal score: -0.31448373
INFO: side score: -0.31161645
INFO: issue score: -0.3115643
INFO: pointer score: -0.30951563
INFO: builtin score: -0.30579895
INFO: interpreter score: -0.30347818
INFO: pass score: -0.2966497
INFO: read score: -0.29464766
INFO: byte score: -0.29459202
INFO: aware score: -0.2812446
INFO: look score: -0.27981403
INFO: first score: -0.27903324
INFO: foo score: -0.2733341
INFO: help score: -0.26743206
INFO: print score: -0.25867087
INFO: version score: -0.2514618
INFO: start score: -0.25028378
INFO: answer score: -0.24289294
INFO: fine score: -0.23888876
INFO: mask score: -0.23431641
INFO: dictionary score: -0.21628268
INFO: num score: -0.21432583
INFO: var1 score: -0.21081996
INFO: uppermost score: -0.20285141
INFO: gotcha score: -0.17859776
INFO: bytecode score: -0.17053407
INFO: near score: -0.13570495
INFO: get_team score: -0.0
INFO: unboundlocalerror score: -0.0
INFO: uncomment score: -0.0
INFO: c+=1 score: -0.0
INFO: bar=0 score: -0.0
INFO: docs.python.org/3.1/faq/programming.html?highlight=nonlocal#why-am-i-getting-an-unboundlocalerror-when-the-variable-has-a-value score: -0.0
INFO: docs.python.org/3.1/faq/programming.html?highlight=nonlocal#how-do-i-write-a-function-with-output-parameters-call-by-reference score: -0.0
INFO: load_global score: -0.0
INFO: ' score: -0.0
INFO: coffee_machine score: -0.0
INFO: boss(live score: -0.0
INFO: 2.7.6 score: -0.0
INFO: mystery score: 0.012161775
INFO: del score: 0.12756075
INFO: team score: 0.13721843
INFO: ============================================================
INFO: --------------------
INFO: What are the rules for local and global variables in Python?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<310 unique tokens: ['42', '=', 'access', 'accidental', 'add']...> from 9 documents (total 996 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<310 unique tokens: ['42', '=', 'access', 'accidental', 'add']...> from 9 documents (total 996 corpus positions)", 'datetime': '2023-03-20T16:52:33.858677', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 9 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.051 per-word bound, 132.6 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 0, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.125*"global" + 0.115*"variable" + 0.057*"function" + 0.040*"module" + 0.034*"local" + 0.030*"name" + 0.012*"example" + 0.010*"keyword" + 0.010*"scope" + 0.010*"class"
INFO: topic #1 (1.000): 0.125*"global" + 0.073*"variable" + 0.056*"local" + 0.039*"function" + 0.025*"name" + 0.021*"module" + 0.014*"change" + 0.009*"keyword" + 0.009*"example" + 0.009*"case"
INFO: topic #2 (1.000): 0.095*"global" + 0.088*"variable" + 0.069*"local" + 0.043*"function" + 0.026*"module" + 0.022*"name" + 0.016*"change" + 0.014*"value" + 0.010*"reference" + 0.010*"inside"
INFO: topic diff=3.302373, rho=1.000000
DEBUG: bound: at document #0
INFO: -9.465 per-word bound, 706.5 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 0, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.131*"global" + 0.108*"variable" + 0.070*"function" + 0.045*"module" + 0.032*"local" + 0.030*"name" + 0.018*"value" + 0.017*"assign" + 0.016*"keyword" + 0.013*"attribute"
INFO: topic #1 (1.000): 0.109*"global" + 0.066*"variable" + 0.044*"local" + 0.040*"function" + 0.025*"name" + 0.023*"value" + 0.014*"object" + 0.012*"case" + 0.012*"module" + 0.010*"one"
INFO: topic #2 (1.000): 0.082*"global" + 0.075*"variable" + 0.056*"local" + 0.043*"function" + 0.025*"value" + 0.020*"name" + 0.019*"module" + 0.009*"change" + 0.009*"case" + 0.009*"keyword"
INFO: topic diff=2.807355, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 44.605998696545456
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.8640260607136329
DEBUG: bound: at document #0
INFO: -5.297 per-word bound, 39.3 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 1, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.130*"global" + 0.109*"variable" + 0.061*"function" + 0.041*"module" + 0.036*"local" + 0.030*"name" + 0.012*"keyword" + 0.012*"example" + 0.011*"value" + 0.011*"scope"
INFO: topic #1 (1.000): 0.099*"global" + 0.069*"variable" + 0.056*"local" + 0.037*"function" + 0.023*"name" + 0.020*"case" + 0.018*"p2o" + 0.016*"value" + 0.015*"p1o" + 0.013*"one"
INFO: topic #2 (1.000): 0.083*"variable" + 0.063*"global" + 0.060*"local" + 0.028*"value" + 0.027*"change" + 0.027*"function" + 0.019*"type" + 0.018*"bool" + 0.018*"name" + 0.016*"non"
INFO: topic diff=1.312422, rho=0.512989
DEBUG: bound: at document #0
INFO: -6.820 per-word bound, 113.0 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 1, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.129*"global" + 0.101*"variable" + 0.066*"function" + 0.044*"module" + 0.034*"local" + 0.029*"name" + 0.015*"assign" + 0.015*"keyword" + 0.014*"value" + 0.012*"example"
INFO: topic #1 (1.000): 0.080*"global" + 0.063*"variable" + 0.037*"local" + 0.036*"function" + 0.033*"value" + 0.021*"name" + 0.017*"programmer" + 0.017*"project" + 0.017*"fct1" + 0.017*"big"
INFO: topic #2 (1.000): 0.067*"variable" + 0.052*"global" + 0.048*"local" + 0.025*"value" + 0.024*"function" + 0.021*"change" + 0.015*"name" + 0.015*"type" + 0.014*"bool" + 0.012*"non"
INFO: topic diff=1.141850, rho=0.512989
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 38.3301710591138
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -2.0129647233794485
DEBUG: bound: at document #0
INFO: -5.172 per-word bound, 36.1 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 2, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.130*"global" + 0.106*"variable" + 0.061*"function" + 0.042*"module" + 0.037*"local" + 0.030*"name" + 0.012*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"value"
INFO: topic #1 (1.000): 0.078*"global" + 0.069*"variable" + 0.049*"local" + 0.036*"function" + 0.025*"value" + 0.022*"case" + 0.021*"name" + 0.019*"p2o" + 0.017*"p1o" + 0.015*"one"
INFO: topic #2 (1.000): 0.078*"variable" + 0.050*"local" + 0.042*"global" + 0.038*"change" + 0.029*"value" + 0.026*"type" + 0.026*"bool" + 0.024*"non" + 0.014*"different" + 0.014*"immutual"
INFO: topic diff=0.755977, rho=0.456435
DEBUG: bound: at document #0
INFO: -6.009 per-word bound, 64.4 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 2, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.130*"global" + 0.100*"variable" + 0.065*"function" + 0.043*"module" + 0.035*"local" + 0.029*"name" + 0.015*"keyword" + 0.014*"assign" + 0.012*"value" + 0.012*"scope"
INFO: topic #1 (1.000): 0.069*"global" + 0.064*"variable" + 0.038*"value" + 0.036*"function" + 0.035*"local" + 0.020*"name" + 0.019*"fct1" + 0.019*"programmer" + 0.019*"bad" + 0.019*"programming"
INFO: topic #2 (1.000): 0.063*"variable" + 0.040*"local" + 0.035*"global" + 0.030*"change" + 0.025*"value" + 0.021*"type" + 0.020*"bool" + 0.019*"non" + 0.012*"example" + 0.012*"different"
INFO: topic diff=0.551318, rho=0.456435
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 37.007434178397865
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -1.193692940547342
DEBUG: bound: at document #0
INFO: -5.119 per-word bound, 34.7 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 3, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.130*"global" + 0.105*"variable" + 0.061*"function" + 0.041*"module" + 0.037*"local" + 0.030*"name" + 0.012*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"class"
INFO: topic #1 (1.000): 0.069*"global" + 0.068*"variable" + 0.047*"local" + 0.035*"function" + 0.030*"value" + 0.023*"case" + 0.021*"name" + 0.019*"p2o" + 0.018*"p1o" + 0.016*"one"
INFO: topic #2 (1.000): 0.075*"variable" + 0.042*"change" + 0.041*"local" + 0.032*"global" + 0.030*"value" + 0.029*"type" + 0.029*"bool" + 0.028*"non" + 0.015*"immutual" + 0.015*"general"
INFO: topic diff=0.484484, rho=0.415227
DEBUG: bound: at document #0
INFO: -5.901 per-word bound, 59.8 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 3, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.131*"global" + 0.100*"variable" + 0.064*"function" + 0.043*"module" + 0.036*"local" + 0.029*"name" + 0.015*"keyword" + 0.014*"assign" + 0.012*"scope" + 0.011*"example"
INFO: topic #1 (1.000): 0.064*"variable" + 0.063*"global" + 0.041*"value" + 0.036*"function" + 0.035*"local" + 0.021*"name" + 0.019*"fct1" + 0.019*"programmer" + 0.019*"bad" + 0.019*"programming"
INFO: topic #2 (1.000): 0.061*"variable" + 0.034*"change" + 0.034*"local" + 0.027*"global" + 0.026*"value" + 0.023*"type" + 0.023*"bool" + 0.022*"non" + 0.013*"example" + 0.013*"different"
INFO: topic diff=0.371253, rho=0.415227
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 36.55979440576121
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -1.1842965603586786
DEBUG: bound: at document #0
INFO: -5.094 per-word bound, 34.2 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 4, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.131*"global" + 0.105*"variable" + 0.061*"function" + 0.041*"module" + 0.038*"local" + 0.030*"name" + 0.013*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"class"
INFO: topic #1 (1.000): 0.067*"variable" + 0.063*"global" + 0.046*"local" + 0.035*"function" + 0.033*"value" + 0.023*"case" + 0.022*"name" + 0.019*"p2o" + 0.019*"p1o" + 0.017*"one"
INFO: topic #2 (1.000): 0.074*"variable" + 0.044*"change" + 0.034*"local" + 0.030*"type" + 0.030*"bool" + 0.030*"value" + 0.030*"non" + 0.027*"global" + 0.016*"place" + 0.016*"ex"
INFO: topic diff=0.365473, rho=0.383482
DEBUG: bound: at document #0
INFO: -5.865 per-word bound, 58.3 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 4, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.131*"global" + 0.101*"variable" + 0.064*"function" + 0.043*"module" + 0.036*"local" + 0.029*"name" + 0.014*"keyword" + 0.014*"assign" + 0.011*"scope" + 0.011*"example"
INFO: topic #1 (1.000): 0.063*"variable" + 0.059*"global" + 0.042*"value" + 0.036*"local" + 0.035*"function" + 0.021*"name" + 0.019*"fct1" + 0.019*"programmer" + 0.019*"bad" + 0.019*"programming"
INFO: topic #2 (1.000): 0.061*"variable" + 0.036*"change" + 0.029*"local" + 0.026*"value" + 0.024*"type" + 0.024*"bool" + 0.024*"non" + 0.023*"global" + 0.014*"example" + 0.014*"different"
INFO: topic diff=0.310785, rho=0.383482
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 36.36074343236495
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -1.1380867483213493
DEBUG: bound: at document #0
INFO: -5.080 per-word bound, 33.8 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 5, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.132*"global" + 0.105*"variable" + 0.061*"function" + 0.041*"module" + 0.038*"local" + 0.030*"name" + 0.013*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"class"
INFO: topic #1 (1.000): 0.067*"variable" + 0.058*"global" + 0.047*"local" + 0.035*"function" + 0.034*"value" + 0.023*"case" + 0.022*"name" + 0.018*"p2o" + 0.018*"p1o" + 0.017*"one"
INFO: topic #2 (1.000): 0.072*"variable" + 0.045*"change" + 0.031*"type" + 0.031*"bool" + 0.030*"non" + 0.030*"value" + 0.030*"local" + 0.023*"global" + 0.016*"place" + 0.016*"ex"
INFO: topic diff=0.306959, rho=0.358057
DEBUG: bound: at document #0
INFO: -5.846 per-word bound, 57.5 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 5, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.132*"global" + 0.101*"variable" + 0.064*"function" + 0.043*"module" + 0.036*"local" + 0.029*"name" + 0.015*"keyword" + 0.013*"assign" + 0.011*"scope" + 0.011*"example"
INFO: topic #1 (1.000): 0.063*"variable" + 0.056*"global" + 0.043*"value" + 0.037*"local" + 0.035*"function" + 0.021*"name" + 0.019*"programmer" + 0.019*"fct1" + 0.019*"project" + 0.019*"bad"
INFO: topic #2 (1.000): 0.061*"variable" + 0.037*"change" + 0.026*"value" + 0.025*"type" + 0.025*"bool" + 0.025*"local" + 0.025*"non" + 0.020*"global" + 0.014*"example" + 0.014*"different"
INFO: topic diff=0.279286, rho=0.358057
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 36.249557162801274
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -1.1051131476839708
DEBUG: bound: at document #0
INFO: -5.071 per-word bound, 33.6 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 6, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.132*"global" + 0.105*"variable" + 0.061*"function" + 0.041*"module" + 0.038*"local" + 0.030*"name" + 0.013*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"class"
INFO: topic #1 (1.000): 0.066*"variable" + 0.055*"global" + 0.047*"local" + 0.036*"value" + 0.034*"function" + 0.023*"case" + 0.022*"name" + 0.018*"p2o" + 0.018*"p1o" + 0.017*"one"
INFO: topic #2 (1.000): 0.072*"variable" + 0.046*"change" + 0.031*"type" + 0.031*"bool" + 0.031*"non" + 0.030*"value" + 0.026*"local" + 0.021*"global" + 0.016*"place" + 0.016*"ex"
INFO: topic diff=0.274121, rho=0.337100
DEBUG: bound: at document #0
INFO: -5.834 per-word bound, 57.0 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 6, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.133*"global" + 0.101*"variable" + 0.064*"function" + 0.043*"module" + 0.037*"local" + 0.029*"name" + 0.015*"keyword" + 0.013*"assign" + 0.011*"scope" + 0.011*"example"
INFO: topic #1 (1.000): 0.062*"variable" + 0.053*"global" + 0.043*"value" + 0.037*"local" + 0.035*"function" + 0.022*"name" + 0.019*"programmer" + 0.019*"fct1" + 0.019*"project" + 0.019*"bad"
INFO: topic #2 (1.000): 0.061*"variable" + 0.038*"change" + 0.026*"value" + 0.026*"type" + 0.026*"bool" + 0.026*"non" + 0.022*"local" + 0.018*"global" + 0.014*"example" + 0.014*"different"
INFO: topic diff=0.257596, rho=0.337100
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 36.17662754594028
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -1.0958334219914125
DEBUG: bound: at document #0
INFO: -5.064 per-word bound, 33.5 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 7, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.132*"global" + 0.105*"variable" + 0.061*"function" + 0.041*"module" + 0.038*"local" + 0.030*"name" + 0.013*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"class"
INFO: topic #1 (1.000): 0.065*"variable" + 0.053*"global" + 0.047*"local" + 0.036*"value" + 0.034*"function" + 0.023*"case" + 0.023*"name" + 0.018*"p2o" + 0.018*"p1o" + 0.017*"one"
INFO: topic #2 (1.000): 0.071*"variable" + 0.046*"change" + 0.031*"type" + 0.031*"bool" + 0.031*"non" + 0.030*"value" + 0.024*"local" + 0.018*"global" + 0.016*"place" + 0.016*"ex"
INFO: topic diff=0.252340, rho=0.319438
DEBUG: bound: at document #0
INFO: -5.825 per-word bound, 56.7 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 7, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.133*"global" + 0.102*"variable" + 0.064*"function" + 0.042*"module" + 0.037*"local" + 0.029*"name" + 0.015*"keyword" + 0.013*"assign" + 0.011*"scope" + 0.011*"example"
INFO: topic #1 (1.000): 0.062*"variable" + 0.051*"global" + 0.043*"value" + 0.038*"local" + 0.034*"function" + 0.022*"name" + 0.019*"programmer" + 0.019*"fct1" + 0.019*"project" + 0.019*"big"
INFO: topic #2 (1.000): 0.061*"variable" + 0.038*"change" + 0.026*"value" + 0.026*"type" + 0.026*"bool" + 0.026*"non" + 0.020*"local" + 0.016*"global" + 0.014*"example" + 0.014*"different"
INFO: topic diff=0.240766, rho=0.319438
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 36.12119103805536
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -1.0958334219914125
DEBUG: bound: at document #0
INFO: -5.059 per-word bound, 33.3 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 8, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.133*"global" + 0.105*"variable" + 0.061*"function" + 0.041*"module" + 0.038*"local" + 0.030*"name" + 0.013*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"class"
INFO: topic #1 (1.000): 0.064*"variable" + 0.051*"global" + 0.048*"local" + 0.037*"value" + 0.034*"function" + 0.023*"name" + 0.023*"case" + 0.018*"p2o" + 0.018*"p1o" + 0.017*"one"
INFO: topic #2 (1.000): 0.070*"variable" + 0.046*"change" + 0.031*"type" + 0.031*"bool" + 0.031*"non" + 0.030*"value" + 0.021*"local" + 0.016*"place" + 0.016*"ex" + 0.016*"need"
INFO: topic diff=0.235934, rho=0.304290
DEBUG: bound: at document #0
INFO: -5.817 per-word bound, 56.4 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 8, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.133*"global" + 0.102*"variable" + 0.064*"function" + 0.042*"module" + 0.037*"local" + 0.029*"name" + 0.015*"keyword" + 0.013*"assign" + 0.011*"scope" + 0.011*"example"
INFO: topic #1 (1.000): 0.061*"variable" + 0.050*"global" + 0.043*"value" + 0.039*"local" + 0.034*"function" + 0.022*"name" + 0.019*"programmer" + 0.019*"fct1" + 0.019*"project" + 0.019*"big"
INFO: topic #2 (1.000): 0.061*"variable" + 0.039*"change" + 0.027*"value" + 0.026*"type" + 0.026*"bool" + 0.026*"non" + 0.019*"local" + 0.015*"example" + 0.014*"different" + 0.014*"global"
INFO: topic diff=0.226694, rho=0.304290
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 36.07353941002185
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -1.0834335965575486
DEBUG: bound: at document #0
INFO: -5.054 per-word bound, 33.2 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 9, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.133*"global" + 0.105*"variable" + 0.061*"function" + 0.041*"module" + 0.038*"local" + 0.029*"name" + 0.013*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"class"
INFO: topic #1 (1.000): 0.063*"variable" + 0.049*"global" + 0.048*"local" + 0.037*"value" + 0.033*"function" + 0.023*"name" + 0.023*"case" + 0.018*"p2o" + 0.018*"p1o" + 0.017*"one"
INFO: topic #2 (1.000): 0.069*"variable" + 0.046*"change" + 0.031*"type" + 0.031*"bool" + 0.031*"non" + 0.030*"value" + 0.020*"local" + 0.016*"place" + 0.016*"ex" + 0.016*"need"
INFO: topic diff=0.222693, rho=0.291111
DEBUG: bound: at document #0
INFO: -5.811 per-word bound, 56.1 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 9, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.134*"global" + 0.102*"variable" + 0.064*"function" + 0.042*"module" + 0.037*"local" + 0.029*"name" + 0.015*"keyword" + 0.013*"assign" + 0.011*"scope" + 0.011*"example"
INFO: topic #1 (1.000): 0.060*"variable" + 0.048*"global" + 0.043*"value" + 0.039*"local" + 0.034*"function" + 0.022*"name" + 0.019*"project" + 0.019*"bad" + 0.019*"programmer" + 0.019*"fct1"
INFO: topic #2 (1.000): 0.060*"variable" + 0.039*"change" + 0.027*"type" + 0.027*"bool" + 0.027*"value" + 0.027*"non" + 0.017*"local" + 0.014*"example" + 0.014*"different" + 0.014*"place"
INFO: topic diff=0.214735, rho=0.291111
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 36.030122071488314
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.093585789180804
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5> in 0.16s', 'datetime': '2023-03-20T16:52:34.017374', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/questions/2/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-20T16:52:34.017530', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/questions/2/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/2/model.state
DEBUG: {'uri': 'model/questions/2/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/questions/2/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-20T16:52:34.020324', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/questions/2/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/questions/2/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/2/model
INFO: topic #0 (1.000): 0.134*"global" + 0.102*"variable" + 0.064*"function" + 0.042*"module" + 0.037*"local" + 0.029*"name" + 0.015*"keyword" + 0.013*"assign" + 0.011*"scope" + 0.011*"example"
INFO: topic #1 (1.000): 0.060*"variable" + 0.048*"global" + 0.043*"value" + 0.039*"local" + 0.034*"function" + 0.022*"name" + 0.019*"project" + 0.019*"bad" + 0.019*"programmer" + 0.019*"fct1"
INFO: topic #2 (1.000): 0.060*"variable" + 0.039*"change" + 0.027*"type" + 0.027*"bool" + 0.027*"value" + 0.027*"non" + 0.017*"local" + 0.014*"example" + 0.014*"different" + 0.014*"place"
INFO: Question Similarity: [0.2037978172302246, 0.1842917799949646, 0.05656999349594116, 0.41414839029312134, 0.1270071268081665, 0.12564557790756226, 0.0890117883682251, 0.0569494366645813, 0.2582508325576782, 0.0730162262916565]
INFO: 14053178: -0.09964847771465919
INFO: 14053041: -0.10194463318066702
INFO: 14051943: -0.10345759887246225
INFO: 14051937: -0.1035966132691668
INFO: 14052167: -0.10365418873165641
INFO: 62099136: -0.126605276249705
INFO: 75048571: -0.12716741376968
INFO: 62099139: -0.13074073105990539
INFO: 72922161: -0.19053501865135153
INFO: 72922552: -0.19058292168129531
INFO: 62212528: -0.23523003219806068
INFO: 62212545: -0.28392824197241395
INFO: 34559513: -0.34758801625671243
INFO: 423668: -0.34812642304820623
INFO: 423401: -0.3484953159767239
INFO: 24572187: -0.35044254091933524
INFO: 427818: -0.35192681405830945
INFO: 423641: -0.35195997968218806
INFO: 71663780: -0.3524089033714517
INFO: 63629668: -0.35297929446015197
INFO: 61992762: -0.35341394460787506
INFO: 6664227: -0.35484501081856756
INFO: 46058078: -0.3561578272342258
INFO: 423596: -0.35649575811662815
INFO: 71074895: -0.35672774581529537
INFO: 19347254: -0.35941728886176927
INFO: 19151605: -0.36112178559951286
INFO: 45769568: -0.36128025433200356
INFO: 34664752: -0.36868706686315816
INFO: 33320055: -0.3692845918935413
INFO: 75200331: -0.3695629216958625
INFO: 71883300: -0.3697484405412323
INFO: 67339244: -0.37270149973265476
INFO: 27287648: -0.3811963070955322
INFO: 27580376: -0.3887456685550145
INFO: 43285234: -0.41376435778113047
INFO: 28329600: -0.44778957586254853
INFO: 72690281: -0.5155496703553573
INFO: 75020199: -1.0589578179617174
INFO: Recommended Keywords
INFO: example score: -0.823193
INFO: particular score: -0.8148449
INFO: function score: -0.8056702
INFO: different score: -0.79410577
INFO: instance score: -0.7918747
INFO: type score: -0.789144
INFO: assign score: -0.78559494
INFO: system score: -0.75596225
INFO: element score: -0.7523744
INFO: definition score: -0.74393696
INFO: simple score: -0.7429652
INFO: useful score: -0.7374592
INFO: change score: -0.71946776
INFO: process score: -0.7153267
INFO: add score: -0.7058726
INFO: method score: -0.7033998
INFO: attribute score: -0.7024585
INFO: variable score: -0.6911278
INFO: information score: -0.6871704
INFO: code score: -0.68620604
INFO: similar score: -0.6797558
INFO: scope score: -0.67925507
INFO: need score: -0.67790544
INFO: internal score: -0.6766937
INFO: problem score: -0.671713
INFO: effect score: -0.66796386
INFO: object score: -0.6653935
INFO: key score: -0.6604012
INFO: requirement score: -0.65869343
INFO: solution score: -0.6554036
INFO: explicit score: -0.64701843
INFO: usual score: -0.64108205
INFO: reference score: -0.6403799
INFO: addition score: -0.63107973
INFO: case score: -0.62991565
INFO: refer score: -0.6215941
INFO: value score: -0.61004204
INFO: non score: -0.60587126
INFO: expression score: -0.6058708
INFO: usable score: -0.6024945
INFO: default score: -0.59119904
INFO: configuration score: -0.58886415
INFO: keyword score: -0.58322704
INFO: available score: -0.57590777
INFO: mutable score: -0.57333237
INFO: result score: -0.57042134
INFO: output score: -0.5667584
INFO: module score: -0.5641865
INFO: parameter score: -0.55963904
INFO: true score: -0.55412644
INFO: natural score: -0.55378157
INFO: array score: -0.5536924
INFO: connection score: -0.5520093
INFO: error score: -0.5435381
INFO: condition score: -0.54090244
INFO: project score: -0.54022634
INFO: test score: -0.5393159
INFO: see score: -0.5373983
INFO: confusing score: -0.53328025
INFO: choice score: -0.53321135
INFO: global score: -0.5262395
INFO: exception score: -0.52444255
INFO: document score: -0.5225599
INFO: sample score: -0.5172975
INFO: unclear score: -0.5172473
INFO: share score: -0.5171464
INFO: behavior score: -0.51613367
INFO: reason score: -0.5160359
INFO: heuristic score: -0.5157422
INFO: explanation score: -0.5139354
INFO: notion score: -0.5135637
INFO: operation score: -0.5124753
INFO: namespace score: -0.5056517
INFO: parallel score: -0.5030215
INFO: programmer score: -0.5014649
INFO: access score: -0.49785063
INFO: singleton score: -0.49665835
INFO: make score: -0.4950102
INFO: symbol score: -0.48959377
INFO: well score: -0.4892497
INFO: execute score: -0.48469722
INFO: avoid score: -0.48328206
INFO: infinite score: -0.48149994
INFO: info score: -0.48085523
INFO: file score: -0.46969408
INFO: note score: -0.4669762
INFO: load score: -0.46437228
INFO: programming score: -0.4628585
INFO: contrary score: -0.46263102
INFO: design score: -0.46093357
INFO: datum score: -0.4564122
INFO: accessible score: -0.45137718
INFO: point score: -0.4454747
INFO: way score: -0.4259122
INFO: callable score: -0.42539617
INFO: import score: -0.4234048
INFO: statement score: -0.4204285
INFO: main score: -0.4154167
INFO: body score: -0.41071385
INFO: original score: -0.41056022
INFO: rare score: -0.40842885
INFO: loop score: -0.40558207
INFO: coding score: -0.40525746
INFO: platform score: -0.40215614
INFO: table score: -0.40157998
INFO: explore score: -0.3953557
INFO: program score: -0.3948473
INFO: small score: -0.3937505
INFO: argument score: -0.39122856
INFO: one score: -0.3909269
INFO: new score: -0.39076012
INFO: mutual score: -0.39070067
INFO: big score: -0.38932323
INFO: single score: -0.3886526
INFO: call score: -0.38351402
INFO: hand score: -0.3815392
INFO: list score: -0.38025728
INFO: class score: -0.37386447
INFO: local score: -0.37283793
INFO: config score: -0.3602609
INFO: assignment score: -0.359921
INFO: state score: -0.358174
INFO: execution score: -0.3509821
INFO: max score: -0.3474532
INFO: bad score: -0.3463391
INFO: name score: -0.34219304
INFO: troublesome score: -0.33933145
INFO: print score: -0.33558142
INFO: inside score: -0.33200666
INFO: place score: -0.3315163
INFO: dictionary score: -0.32504416
INFO: wish score: -0.3234677
INFO: foo score: -0.3207088
INFO: work score: -0.31956208
INFO: multiprocessing score: -0.31233802
INFO: advanced score: -0.30980816
INFO: string score: -0.30863532
INFO: answer score: -0.30845436
INFO: bool score: -0.30673018
INFO: caller score: -0.30180258
INFO: linux score: -0.29978654
INFO: outside score: -0.29796165
INFO: care score: -0.29708484
INFO: time score: -0.27628285
INFO: situation score: -0.27373356
INFO: unexpected score: -0.2737019
INFO: plan score: -0.27036735
INFO: end score: -0.266686
INFO: declare score: -0.25956044
INFO: util score: -0.25176263
INFO: declaration score: -0.24785617
INFO: overshadow score: -0.24096856
INFO: show score: -0.23903736
INFO: want score: -0.23515421
INFO: = score: -0.2269848
INFO: thing score: -0.22417115
INFO: private score: -0.22318506
INFO: return score: -0.206198
INFO: line score: -0.20140542
INFO: points score: -0.19762297
INFO: fall score: -0.18940921
INFO: baz score: -0.18573539
INFO: rest score: -0.18388963
INFO: run score: -0.17868981
INFO: tell score: -0.17462708
INFO: side score: -0.17037085
INFO: apple score: -0.15564263
INFO: window score: -0.15409452
INFO: wholesale score: -0.14896397
INFO: first score: -0.14495341
INFO: start score: -0.13041428
INFO: try score: -0.122141995
INFO: command score: -0.114607066
INFO: hope score: -0.10119729
INFO: ex score: -0.07921292
INFO: var score: -0.07152835
INFO: bar score: -0.06694232
INFO: decoration score: -0.05132048
INFO: mess score: -0.022508923
INFO: oop score: -0.005789431
INFO: globvar score: -0.0
INFO: global_var score: -0.0
INFO: func1 score: -0.0
INFO: my_global score: -0.0
INFO: called.loop score: -0.0
INFO: func_1 score: -0.0
INFO: func_2 score: -0.0
INFO: update_variables score: -0.0
INFO: macos score: -0.0
INFO: envrionment score: -0.0
INFO: getstocks.py score: -0.0
INFO: runner_test.py score: -0.0
INFO: identifi score: -0.0
INFO: p1o score: -0.0
INFO: p2o score: -0.0
INFO: immutual score: -0.0
INFO: d. score: -0.0
INFO: totalcarbs(local score: -0.0
INFO: totalcarbs(global score: -0.0
INFO: fct1 score: -0.0
INFO: fct2 score: -0.0
INFO: main_function score: -0.0
INFO: f_value score: -0.0
INFO: mailinfo score: -0.0
INFO: mail_body score: -0.0
INFO: function1 score: -0.0
INFO: mac score: 0.0768658
INFO: battleship score: 0.08126613
INFO: zealot score: 0.08776208
INFO: runner score: 0.29621354
INFO: ============================================================
INFO: --------------------
INFO: Why do lambdas defined in a loop with different values all return the same result?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<193 unique tokens: ['answer', 'array', 'call', 'code', 'context']...> from 9 documents (total 531 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<193 unique tokens: ['answer', 'array', 'call', 'code', 'context']...> from 9 documents (total 531 corpus positions)", 'datetime': '2023-03-20T16:52:36.511160', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 9 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.561 per-word bound, 188.9 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 0, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.062*"value" + 0.059*"function" + 0.052*"lambda" + 0.032*"default" + 0.032*"parameter" + 0.021*"way" + 0.020*"loop" + 0.020*"code" + 0.018*"final" + 0.017*"name"
INFO: topic #1 (1.000): 0.070*"lambda" + 0.056*"function" + 0.050*"value" + 0.032*"loop" + 0.030*"final" + 0.025*"code" + 0.024*"parameter" + 0.022*"closure" + 0.022*"time" + 0.021*"name"
INFO: topic #2 (1.000): 0.087*"value" + 0.083*"lambda" + 0.066*"function" + 0.038*"loop" + 0.032*"default" + 0.031*"parameter" + 0.027*"code" + 0.025*"variable" + 0.023*"time" + 0.020*"final"
INFO: topic diff=5.592035, rho=1.000000
DEBUG: bound: at document #0
INFO: -9.590 per-word bound, 771.0 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 0, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.061*"lambda" + 0.056*"function" + 0.044*"value" + 0.025*"comprehension" + 0.023*"example" + 0.021*"default" + 0.020*"way" + 0.018*"output" + 0.018*"list" + 0.018*"variable"
INFO: topic #1 (1.000): 0.079*"lambda" + 0.059*"function" + 0.039*"value" + 0.031*"time" + 0.028*"loop" + 0.026*"example" + 0.020*"variable" + 0.019*"comprehension" + 0.018*"foo" + 0.017*"list"
INFO: topic #2 (1.000): 0.088*"lambda" + 0.082*"function" + 0.079*"value" + 0.045*"variable" + 0.035*"loop" + 0.033*"time" + 0.030*"default" + 0.029*"example" + 0.027*"argument" + 0.025*"list"
INFO: topic diff=5.127007, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 55.44446646565976
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.9936202127840678
DEBUG: bound: at document #0
INFO: -6.071 per-word bound, 67.2 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 1, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.056*"lambda" + 0.050*"function" + 0.040*"value" + 0.022*"comprehension" + 0.021*"example" + 0.019*"default" + 0.018*"way" + 0.017*"output" + 0.016*"variable" + 0.016*"list"
INFO: topic #1 (1.000): 0.075*"lambda" + 0.054*"function" + 0.037*"value" + 0.029*"time" + 0.027*"loop" + 0.024*"example" + 0.019*"variable" + 0.017*"comprehension" + 0.017*"foo" + 0.016*"list"
INFO: topic #2 (1.000): 0.083*"lambda" + 0.081*"value" + 0.074*"function" + 0.036*"loop" + 0.032*"variable" + 0.031*"default" + 0.028*"parameter" + 0.027*"time" + 0.024*"code" + 0.020*"example"
INFO: topic diff=1.081099, rho=0.512989
DEBUG: bound: at document #0
INFO: -5.891 per-word bound, 59.3 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 1, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.085*"lambda" + 0.052*"comprehension" + 0.044*"list" + 0.034*"output" + 0.026*"function" + 0.022*"way" + 0.021*"value" + 0.019*"bad" + 0.019*"variable" + 0.018*"line"
INFO: topic #1 (1.000): 0.067*"lambda" + 0.058*"function" + 0.038*"value" + 0.030*"time" + 0.029*"example" + 0.025*"loop" + 0.022*"variable" + 0.021*"foo" + 0.020*"statement" + 0.017*"comprehension"
INFO: topic #2 (1.000): 0.084*"value" + 0.081*"function" + 0.076*"lambda" + 0.040*"variable" + 0.036*"default" + 0.034*"loop" + 0.028*"parameter" + 0.027*"time" + 0.024*"argument" + 0.023*"way"
INFO: topic diff=1.288049, rho=0.512989
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 42.902448503377286
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.1147813902771857
DEBUG: bound: at document #0
INFO: -5.698 per-word bound, 51.9 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 2, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.077*"lambda" + 0.044*"comprehension" + 0.038*"list" + 0.033*"output" + 0.023*"function" + 0.020*"way" + 0.019*"value" + 0.017*"variable" + 0.016*"bad" + 0.016*"line"
INFO: topic #1 (1.000): 0.065*"lambda" + 0.056*"function" + 0.037*"value" + 0.029*"time" + 0.028*"example" + 0.025*"loop" + 0.021*"variable" + 0.020*"foo" + 0.019*"statement" + 0.017*"comprehension"
INFO: topic #2 (1.000): 0.083*"value" + 0.078*"lambda" + 0.074*"function" + 0.035*"loop" + 0.034*"default" + 0.030*"parameter" + 0.030*"variable" + 0.025*"code" + 0.025*"time" + 0.020*"way"
INFO: topic diff=0.743179, rho=0.456435
DEBUG: bound: at document #0
INFO: -5.368 per-word bound, 41.3 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 2, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.104*"lambda" + 0.065*"comprehension" + 0.062*"list" + 0.046*"output" + 0.023*"pythonic" + 0.022*"way" + 0.022*"bad" + 0.021*"line" + 0.021*"topic" + 0.021*"bit"
INFO: topic #1 (1.000): 0.063*"lambda" + 0.060*"function" + 0.038*"value" + 0.032*"example" + 0.031*"time" + 0.025*"loop" + 0.024*"variable" + 0.021*"foo" + 0.021*"statement" + 0.017*"different"
INFO: topic #2 (1.000): 0.087*"value" + 0.079*"function" + 0.073*"lambda" + 0.038*"default" + 0.035*"variable" + 0.034*"loop" + 0.032*"parameter" + 0.026*"code" + 0.024*"time" + 0.023*"way"
INFO: topic diff=0.834666, rho=0.456435
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 39.87678219448951
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -1.3905571023364232
DEBUG: bound: at document #0
INFO: -5.560 per-word bound, 47.2 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 3, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.095*"lambda" + 0.056*"list" + 0.054*"comprehension" + 0.046*"output" + 0.020*"way" + 0.019*"pythonic" + 0.019*"bad" + 0.019*"functional" + 0.018*"line" + 0.018*"variable"
INFO: topic #1 (1.000): 0.062*"lambda" + 0.059*"function" + 0.037*"value" + 0.031*"example" + 0.030*"time" + 0.024*"loop" + 0.024*"variable" + 0.020*"foo" + 0.020*"statement" + 0.016*"different"
INFO: topic #2 (1.000): 0.085*"value" + 0.076*"lambda" + 0.073*"function" + 0.035*"loop" + 0.035*"default" + 0.032*"parameter" + 0.028*"variable" + 0.027*"code" + 0.023*"time" + 0.021*"way"
INFO: topic diff=0.445562, rho=0.415227
DEBUG: bound: at document #0
INFO: -5.268 per-word bound, 38.5 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 3, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.114*"lambda" + 0.073*"list" + 0.071*"comprehension" + 0.055*"output" + 0.026*"pythonic" + 0.024*"bad" + 0.022*"way" + 0.022*"line" + 0.022*"functional" + 0.021*"plenty"
INFO: topic #1 (1.000): 0.063*"function" + 0.062*"lambda" + 0.039*"value" + 0.033*"example" + 0.031*"time" + 0.026*"variable" + 0.025*"loop" + 0.021*"foo" + 0.021*"statement" + 0.017*"different"
INFO: topic #2 (1.000): 0.089*"value" + 0.076*"function" + 0.072*"lambda" + 0.039*"default" + 0.035*"parameter" + 0.034*"loop" + 0.032*"variable" + 0.028*"code" + 0.023*"time" + 0.023*"way"
INFO: topic diff=0.509778, rho=0.415227
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 38.962541705438795
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -1.3658741059648551
DEBUG: bound: at document #0
INFO: -5.513 per-word bound, 45.7 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 4, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.105*"lambda" + 0.068*"list" + 0.060*"comprehension" + 0.057*"output" + 0.022*"pythonic" + 0.020*"functional" + 0.020*"way" + 0.020*"bad" + 0.020*"practice" + 0.019*"partial"
INFO: topic #1 (1.000): 0.061*"function" + 0.061*"lambda" + 0.038*"value" + 0.032*"example" + 0.031*"time" + 0.025*"variable" + 0.025*"loop" + 0.020*"foo" + 0.020*"statement" + 0.016*"different"
INFO: topic #2 (1.000): 0.086*"value" + 0.075*"lambda" + 0.073*"function" + 0.036*"default" + 0.035*"loop" + 0.034*"parameter" + 0.028*"code" + 0.027*"variable" + 0.023*"time" + 0.021*"final"
INFO: topic diff=0.286526, rho=0.383482
DEBUG: bound: at document #0
INFO: -5.232 per-word bound, 37.6 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 4, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.120*"lambda" + 0.082*"list" + 0.077*"comprehension" + 0.064*"output" + 0.029*"pythonic" + 0.024*"bad" + 0.022*"partial" + 0.022*"functional" + 0.021*"way" + 0.021*"practice"
INFO: topic #1 (1.000): 0.065*"function" + 0.060*"lambda" + 0.039*"value" + 0.034*"example" + 0.032*"time" + 0.027*"variable" + 0.026*"loop" + 0.021*"foo" + 0.021*"statement" + 0.017*"different"
INFO: topic #2 (1.000): 0.089*"value" + 0.074*"function" + 0.072*"lambda" + 0.039*"default" + 0.036*"parameter" + 0.034*"loop" + 0.030*"code" + 0.029*"variable" + 0.023*"time" + 0.022*"way"
INFO: topic diff=0.360976, rho=0.383482
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 38.574724803375396
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -1.337768624707431
DEBUG: bound: at document #0
INFO: -5.492 per-word bound, 45.0 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 5, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.113*"lambda" + 0.078*"list" + 0.068*"output" + 0.065*"comprehension" + 0.025*"pythonic" + 0.021*"bad" + 0.021*"functional" + 0.020*"practice" + 0.020*"way" + 0.020*"partial"
INFO: topic #1 (1.000): 0.063*"function" + 0.059*"lambda" + 0.039*"value" + 0.033*"example" + 0.031*"time" + 0.027*"variable" + 0.025*"loop" + 0.020*"foo" + 0.020*"statement" + 0.016*"different"
INFO: topic #2 (1.000): 0.087*"value" + 0.074*"lambda" + 0.072*"function" + 0.036*"default" + 0.035*"loop" + 0.035*"parameter" + 0.029*"code" + 0.026*"variable" + 0.023*"time" + 0.022*"final"
INFO: topic diff=0.248978, rho=0.358057
DEBUG: bound: at document #0
INFO: -5.213 per-word bound, 37.1 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 5, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.126*"lambda" + 0.090*"list" + 0.081*"comprehension" + 0.072*"output" + 0.031*"pythonic" + 0.025*"bad" + 0.021*"partial" + 0.021*"functional" + 0.021*"practice" + 0.021*"way"
INFO: topic #1 (1.000): 0.066*"function" + 0.058*"lambda" + 0.040*"value" + 0.034*"example" + 0.032*"time" + 0.028*"variable" + 0.026*"loop" + 0.021*"foo" + 0.021*"statement" + 0.017*"argument"
INFO: topic #2 (1.000): 0.090*"value" + 0.073*"function" + 0.072*"lambda" + 0.039*"default" + 0.038*"parameter" + 0.034*"loop" + 0.031*"code" + 0.028*"variable" + 0.023*"time" + 0.021*"way"
INFO: topic diff=0.300098, rho=0.358057
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 38.35610952095782
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -1.2770196495637107
DEBUG: bound: at document #0
INFO: -5.480 per-word bound, 44.6 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 6, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.119*"lambda" + 0.086*"list" + 0.077*"output" + 0.069*"comprehension" + 0.027*"pythonic" + 0.022*"bad" + 0.020*"functional" + 0.020*"practice" + 0.019*"partial" + 0.019*"way"
INFO: topic #1 (1.000): 0.065*"function" + 0.057*"lambda" + 0.039*"value" + 0.034*"example" + 0.032*"time" + 0.028*"variable" + 0.026*"loop" + 0.020*"foo" + 0.020*"statement" + 0.017*"argument"
INFO: topic #2 (1.000): 0.087*"value" + 0.074*"lambda" + 0.071*"function" + 0.037*"default" + 0.036*"parameter" + 0.035*"loop" + 0.030*"code" + 0.026*"variable" + 0.023*"time" + 0.022*"final"
INFO: topic diff=0.231277, rho=0.337100
DEBUG: bound: at document #0
INFO: -5.200 per-word bound, 36.8 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 6, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.130*"lambda" + 0.095*"list" + 0.084*"comprehension" + 0.078*"output" + 0.033*"pythonic" + 0.025*"bad" + 0.021*"partial" + 0.021*"functional" + 0.020*"practice" + 0.020*"way"
INFO: topic #1 (1.000): 0.068*"function" + 0.057*"lambda" + 0.040*"value" + 0.035*"example" + 0.032*"time" + 0.029*"variable" + 0.026*"loop" + 0.021*"foo" + 0.021*"statement" + 0.019*"argument"
INFO: topic #2 (1.000): 0.090*"value" + 0.072*"function" + 0.072*"lambda" + 0.039*"default" + 0.039*"parameter" + 0.034*"loop" + 0.032*"code" + 0.027*"variable" + 0.022*"time" + 0.022*"name"
INFO: topic diff=0.263966, rho=0.337100
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 38.212321252449726
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -1.2675312507084884
DEBUG: bound: at document #0
INFO: -5.472 per-word bound, 44.4 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 7, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.124*"lambda" + 0.092*"list" + 0.084*"output" + 0.072*"comprehension" + 0.029*"pythonic" + 0.022*"bad" + 0.020*"functional" + 0.020*"practice" + 0.019*"partial" + 0.019*"way"
INFO: topic #1 (1.000): 0.066*"function" + 0.056*"lambda" + 0.040*"value" + 0.034*"example" + 0.032*"time" + 0.029*"variable" + 0.026*"loop" + 0.020*"foo" + 0.020*"statement" + 0.018*"argument"
INFO: topic #2 (1.000): 0.087*"value" + 0.074*"lambda" + 0.071*"function" + 0.037*"default" + 0.037*"parameter" + 0.035*"loop" + 0.031*"code" + 0.025*"variable" + 0.023*"time" + 0.022*"final"
INFO: topic diff=0.219001, rho=0.319438
DEBUG: bound: at document #0
INFO: -5.191 per-word bound, 36.5 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 7, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.133*"lambda" + 0.100*"list" + 0.086*"comprehension" + 0.081*"output" + 0.034*"pythonic" + 0.026*"bad" + 0.020*"partial" + 0.020*"functional" + 0.020*"practice" + 0.019*"way"
INFO: topic #1 (1.000): 0.069*"function" + 0.056*"lambda" + 0.041*"value" + 0.035*"example" + 0.032*"time" + 0.030*"variable" + 0.027*"loop" + 0.021*"foo" + 0.021*"statement" + 0.019*"argument"
INFO: topic #2 (1.000): 0.090*"value" + 0.072*"lambda" + 0.071*"function" + 0.040*"parameter" + 0.039*"default" + 0.034*"loop" + 0.033*"code" + 0.026*"variable" + 0.022*"time" + 0.022*"name"
INFO: topic diff=0.238966, rho=0.319438
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 38.108581136102856
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -1.2684037176392764
DEBUG: bound: at document #0
INFO: -5.465 per-word bound, 44.2 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 8, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.128*"lambda" + 0.097*"list" + 0.088*"output" + 0.074*"comprehension" + 0.030*"pythonic" + 0.023*"bad" + 0.019*"functional" + 0.019*"practice" + 0.019*"way" + 0.018*"partial"
INFO: topic #1 (1.000): 0.067*"function" + 0.055*"lambda" + 0.040*"value" + 0.035*"example" + 0.032*"time" + 0.029*"variable" + 0.026*"loop" + 0.021*"foo" + 0.021*"statement" + 0.019*"argument"
INFO: topic #2 (1.000): 0.088*"value" + 0.074*"lambda" + 0.070*"function" + 0.037*"parameter" + 0.037*"default" + 0.035*"loop" + 0.031*"code" + 0.025*"variable" + 0.023*"time" + 0.022*"final"
INFO: topic diff=0.208513, rho=0.304290
DEBUG: bound: at document #0
INFO: -5.184 per-word bound, 36.4 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 8, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.136*"lambda" + 0.103*"list" + 0.088*"comprehension" + 0.084*"output" + 0.034*"pythonic" + 0.026*"bad" + 0.020*"partial" + 0.020*"functional" + 0.020*"practice" + 0.019*"way"
INFO: topic #1 (1.000): 0.070*"function" + 0.055*"lambda" + 0.041*"value" + 0.035*"example" + 0.033*"time" + 0.030*"variable" + 0.027*"loop" + 0.021*"foo" + 0.021*"statement" + 0.020*"argument"
INFO: topic #2 (1.000): 0.090*"value" + 0.072*"lambda" + 0.070*"function" + 0.041*"parameter" + 0.039*"default" + 0.034*"code" + 0.034*"loop" + 0.026*"variable" + 0.022*"time" + 0.022*"name"
INFO: topic diff=0.220706, rho=0.304290
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 38.02990808858667
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -1.267261860751667
DEBUG: bound: at document #0
INFO: -5.460 per-word bound, 44.0 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 9, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.131*"lambda" + 0.100*"list" + 0.092*"output" + 0.076*"comprehension" + 0.030*"pythonic" + 0.023*"bad" + 0.019*"functional" + 0.019*"practice" + 0.018*"way" + 0.018*"partial"
INFO: topic #1 (1.000): 0.068*"function" + 0.054*"lambda" + 0.040*"value" + 0.035*"example" + 0.032*"time" + 0.030*"variable" + 0.027*"loop" + 0.021*"foo" + 0.021*"statement" + 0.020*"argument"
INFO: topic #2 (1.000): 0.088*"value" + 0.073*"lambda" + 0.070*"function" + 0.038*"parameter" + 0.037*"default" + 0.035*"loop" + 0.032*"code" + 0.025*"variable" + 0.023*"time" + 0.022*"final"
INFO: topic diff=0.199409, rho=0.291111
DEBUG: bound: at document #0
INFO: -5.179 per-word bound, 36.2 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 9, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.138*"lambda" + 0.105*"list" + 0.089*"comprehension" + 0.086*"output" + 0.034*"pythonic" + 0.026*"bad" + 0.020*"functional" + 0.020*"partial" + 0.020*"practice" + 0.019*"way"
INFO: topic #1 (1.000): 0.070*"function" + 0.054*"lambda" + 0.041*"value" + 0.035*"example" + 0.033*"time" + 0.030*"variable" + 0.027*"loop" + 0.021*"foo" + 0.021*"statement" + 0.020*"argument"
INFO: topic #2 (1.000): 0.090*"value" + 0.072*"lambda" + 0.070*"function" + 0.042*"parameter" + 0.039*"default" + 0.034*"code" + 0.034*"loop" + 0.026*"variable" + 0.023*"name" + 0.022*"time"
INFO: topic diff=0.206515, rho=0.291111
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 37.96690557052763
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.2626055003115013
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5> in 0.15s', 'datetime': '2023-03-20T16:52:36.663343', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/questions/3/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-20T16:52:36.663502', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/questions/3/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/3/model.state
DEBUG: {'uri': 'model/questions/3/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/questions/3/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-20T16:52:36.665460', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/questions/3/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/questions/3/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/3/model
INFO: topic #0 (1.000): 0.138*"lambda" + 0.105*"list" + 0.089*"comprehension" + 0.086*"output" + 0.034*"pythonic" + 0.026*"bad" + 0.020*"functional" + 0.020*"partial" + 0.020*"practice" + 0.019*"way"
INFO: topic #1 (1.000): 0.070*"function" + 0.054*"lambda" + 0.041*"value" + 0.035*"example" + 0.033*"time" + 0.030*"variable" + 0.027*"loop" + 0.021*"foo" + 0.021*"statement" + 0.020*"argument"
INFO: topic #2 (1.000): 0.090*"value" + 0.072*"lambda" + 0.070*"function" + 0.042*"parameter" + 0.039*"default" + 0.034*"code" + 0.034*"loop" + 0.026*"variable" + 0.023*"name" + 0.022*"time"
INFO: Question Similarity: [0.07075375318527222, 0.10912275314331055, 0.3426234722137451, 0.13805431127548218, 0.13586008548736572, 0.22070395946502686, 0.09046471118927002, 0.1506548523902893, 0.11590653657913208, 0.06816387176513672]
INFO: 62429245: -0.11686621838677458
INFO: 62429135: -0.12877757310999913
INFO: 62429146: -0.12885456618319427
INFO: 33984811: -0.15455399640793427
INFO: 57736125: -0.17064743425828316
INFO: 63123965: -0.1912429946034636
INFO: 63123379: -0.20884767331339657
INFO: 74746676: -0.26239314913166706
INFO: 74746577: -0.2727705355158905
INFO: 74746462: -0.2770977501487347
INFO: 11723478: -0.2952933158401357
INFO: 11723314: -0.31054573052372025
INFO: 66039891: -0.3139959539313071
INFO: 66039895: -0.3322356749375357
INFO: 66039981: -0.34025069817852777
INFO: 72921203: -0.34365290030165163
INFO: 11723328: -0.3474804127683691
INFO: 72921246: -0.3484355783650811
INFO: 72921168: -0.38630688879327363
INFO: 72921569: -0.42064638046971187
INFO: 72921188: -0.4424257086481859
INFO: 57288183: -0.5260605620904419
INFO: 46847190: -0.5496025727090267
INFO: 19837590: -0.5529300062930752
INFO: 19837683: -0.5593827535301523
INFO: 68717304: -0.8661286000400242
INFO: Recommended Keywords
INFO: function score: -0.8185712
INFO: variable score: -0.7912254
INFO: instance score: -0.7799505
INFO: parameter score: -0.760557
INFO: correct score: -0.73204917
INFO: simple score: -0.7187668
INFO: step score: -0.7126234
INFO: definition score: -0.7090845
INFO: problem score: -0.7054536
INFO: iteration score: -0.70204675
INFO: value score: -0.6972153
INFO: define score: -0.6958885
INFO: method score: -0.6940989
INFO: example score: -0.6928182
INFO: assign score: -0.67815125
INFO: consider score: -0.6772227
INFO: code score: -0.6770841
INFO: minimal score: -0.67145306
INFO: default score: -0.65877926
INFO: functional score: -0.6470371
INFO: object score: -0.64327914
INFO: solution score: -0.6332157
INFO: argument score: -0.6252891
INFO: change score: -0.6203096
INFO: result score: -0.6197285
INFO: output score: -0.6147754
INFO: order score: -0.61209685
INFO: generate score: -0.6083572
INFO: mutable score: -0.59930974
INFO: approach score: -0.58196396
INFO: efficient score: -0.5814544
INFO: practice score: -0.57764244
INFO: fix score: -0.5737141
INFO: comprehension score: -0.5711855
INFO: necessary score: -0.5651787
INFO: sufficient score: -0.56357664
INFO: partial score: -0.5624591
INFO: context score: -0.55607647
INFO: item score: -0.5553916
INFO: loop score: -0.5494904
INFO: statement score: -0.547999
INFO: dependency score: -0.5459312
INFO: question score: -0.5345855
INFO: expression score: -0.52703315
INFO: different score: -0.52301025
INFO: convert score: -0.5174773
INFO: scope score: -0.5164069
INFO: update score: -0.51278883
INFO: array score: -0.50619483
INFO: lambda score: -0.50501615
INFO: point score: -0.504686
INFO: current score: -0.5041436
INFO: additional score: -0.50171494
INFO: reference score: -0.5013473
INFO: f score: -0.49304727
INFO: x score: -0.4904565
INFO: common score: -0.48813155
INFO: precision score: -0.48378003
INFO: syntax score: -0.4837552
INFO: map score: -0.4834728
INFO: compiler score: -0.47400212
INFO: topic score: -0.4731388
INFO: foo score: -0.4679239
INFO: option score: -0.4665637
INFO: bad score: -0.44256103
INFO: answer score: -0.42418623
INFO: x0 score: -0.42229992
INFO: bit score: -0.4218586
INFO: verbose score: -0.42034364
INFO: bind score: -0.41681272
INFO: workaround score: -0.41608635
INFO: list score: -0.40858552
INFO: believe score: -0.40599412
INFO: closure score: -0.40538815
INFO: call score: -0.403975
INFO: explanation score: -0.4006605
INFO: presence score: -0.40058255
INFO: behavior score: -0.3989779
INFO: due score: -0.39235175
INFO: = score: -0.39046657
INFO: callable score: -0.38888386
INFO: way score: -0.3810934
INFO: full score: -0.3802068
INFO: plenty score: -0.3798304
INFO: single score: -0.3768763
INFO: variant score: -0.3748694
INFO: high score: -0.3715321
INFO: double score: -0.3671879
INFO: inner score: -0.362798
INFO: general score: -0.35897258
INFO: cryptic score: -0.35795087
INFO: preserve score: -0.35638583
INFO: documentation score: -0.35143593
INFO: resolve score: -0.35012868
INFO: body score: -0.34918573
INFO: previous score: -0.31701484
INFO: outer score: -0.31442583
INFO: state score: -0.31256792
INFO: rep score: -0.29792714
INFO: new score: -0.29434496
INFO: issue score: -0.2942857
INFO: time score: -0.2930344
INFO: well score: -0.2884263
INFO: short score: -0.2858499
INFO: name score: -0.2793386
INFO: exec score: -0.2757814
INFO: little score: -0.27182922
INFO: work score: -0.26000366
INFO: small score: -0.2596105
INFO: print score: -0.25784317
INFO: messy score: -0.24378924
INFO: line score: -0.23659095
INFO: introspect score: -0.23335606
INFO: run score: -0.22324087
INFO: printed score: -0.17480208
INFO: clean score: -0.16402107
INFO: early score: -0.16000095
INFO: first score: -0.1534557
INFO: help score: -0.1394092
INFO: last score: -0.13451886
INFO: store score: -0.12623632
INFO: lot score: -0.1197349
INFO: next score: -0.0904732
INFO: final score: -0.082735956
INFO: opinion score: -0.071126185
INFO: late score: -0.07062218
INFO: job score: -0.06406522
INFO: official score: -0.062476378
INFO: complaint score: -0.008022035
INFO: doesn#t score: -0.0
INFO: x. score: -0.0
INFO: range(2 score: -0.0
INFO: functools.partial score: -0.0
INFO: send_param score: -0.0
INFO: print(val score: -0.0
INFO: l[3 score: -0.0
INFO: pythonic score: -0.0
INFO: lambda+filter score: -0.0
INFO: testobj(1 score: -0.0
INFO: testobj score: -0.0
INFO: blog score: 0.0016296243
INFO: finished score: 0.12726618
INFO: ============================================================
INFO: --------------------
INFO: How do I share global variables across modules?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<208 unique tokens: ['answer', 'code', 'function', 'global', 'main']...> from 7 documents (total 476 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<208 unique tokens: ['answer', 'code', 'function', 'global', 'main']...> from 7 documents (total 476 corpus positions)", 'datetime': '2023-03-20T16:52:39.170813', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 7 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -9.593 per-word bound, 772.1 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 0, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.100*"module" + 0.082*"global" + 0.049*"variable" + 0.028*"file" + 0.025*"visibility" + 0.022*"import" + 0.021*"code" + 0.015*"function" + 0.014*"order" + 0.014*"answer"
INFO: topic #1 (1.000): 0.052*"global" + 0.040*"variable" + 0.038*"import" + 0.028*"module" + 0.027*"constant" + 0.026*"entity" + 0.025*"level" + 0.024*"namespace" + 0.018*"configuration" + 0.018*"override"
INFO: topic #2 (1.000): 0.114*"global" + 0.040*"module" + 0.032*"variable" + 0.023*"import" + 0.021*"file" + 0.016*"namespace" + 0.016*"level" + 0.016*"code" + 0.015*"test" + 0.015*"entity"
INFO: topic diff=5.842626, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.036 per-word bound, 1049.9 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 0, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.111*"module" + 0.097*"variable" + 0.071*"global" + 0.068*"function" + 0.035*"name" + 0.022*"import" + 0.013*"scope" + 0.011*"object" + 0.011*"explicit" + 0.011*"keyword"
INFO: topic #1 (1.000): 0.080*"variable" + 0.052*"assign" + 0.046*"global" + 0.045*"import" + 0.044*"local" + 0.037*"value" + 0.035*"access" + 0.029*"example" + 0.025*"level" + 0.025*"module"
INFO: topic #2 (1.000): 0.085*"global" + 0.039*"module" + 0.035*"variable" + 0.021*"import" + 0.015*"name" + 0.014*"solution" + 0.014*"test" + 0.012*"instance" + 0.011*"level" + 0.011*"code"
INFO: topic diff=5.317268, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 67.29199328576995
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.6298228023657733
DEBUG: bound: at document #0
INFO: -8.448 per-word bound, 349.2 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 1, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.116*"module" + 0.093*"variable" + 0.074*"global" + 0.064*"function" + 0.031*"name" + 0.021*"import" + 0.012*"scope" + 0.011*"answer" + 0.010*"code" + 0.010*"object"
INFO: topic #1 (1.000): 0.065*"variable" + 0.048*"global" + 0.041*"import" + 0.035*"assign" + 0.031*"local" + 0.029*"access" + 0.027*"level" + 0.027*"value" + 0.023*"module" + 0.022*"example"
INFO: topic #2 (1.000): 0.111*"global" + 0.030*"module" + 0.030*"file" + 0.024*"import" + 0.024*"variable" + 0.020*"solution" + 0.017*"test" + 0.017*"execute" + 0.017*"code" + 0.017*"copy"
INFO: topic diff=1.232621, rho=0.542326
DEBUG: bound: at document #0
INFO: -5.299 per-word bound, 39.4 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 1, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.089*"module" + 0.087*"variable" + 0.062*"global" + 0.052*"function" + 0.039*"name" + 0.023*"import" + 0.015*"scope" + 0.012*"object" + 0.012*"value" + 0.012*"explicit"
INFO: topic #1 (1.000): 0.066*"assign" + 0.062*"variable" + 0.059*"local" + 0.042*"global" + 0.042*"import" + 0.039*"access" + 0.035*"level" + 0.035*"value" + 0.030*"actual" + 0.030*"example"
INFO: topic #2 (1.000): 0.082*"global" + 0.024*"module" + 0.022*"file" + 0.020*"import" + 0.018*"variable" + 0.016*"solution" + 0.014*"code" + 0.014*"test" + 0.013*"execute" + 0.013*"copy"
INFO: topic diff=0.999430, rho=0.542326
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 52.66696500018234
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.4537347214102463
DEBUG: bound: at document #0
INFO: -7.501 per-word bound, 181.2 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 2, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.095*"module" + 0.086*"variable" + 0.064*"global" + 0.050*"function" + 0.037*"name" + 0.022*"import" + 0.014*"scope" + 0.012*"object" + 0.012*"value" + 0.012*"keyword"
INFO: topic #1 (1.000): 0.054*"variable" + 0.046*"global" + 0.043*"assign" + 0.039*"import" + 0.038*"local" + 0.033*"level" + 0.031*"access" + 0.026*"namespace" + 0.025*"value" + 0.022*"instance"
INFO: topic #2 (1.000): 0.114*"global" + 0.048*"file" + 0.024*"visibility" + 0.021*"import" + 0.021*"execute" + 0.021*"copy" + 0.021*"file2.py" + 0.021*"alterd" + 0.020*"definition" + 0.020*"approach"
INFO: topic diff=0.845700, rho=0.476731
DEBUG: bound: at document #0
INFO: -5.105 per-word bound, 34.4 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 2, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.086*"variable" + 0.085*"module" + 0.060*"global" + 0.048*"function" + 0.039*"name" + 0.024*"import" + 0.015*"scope" + 0.015*"value" + 0.012*"object" + 0.012*"keyword"
INFO: topic #1 (1.000): 0.065*"assign" + 0.062*"local" + 0.052*"variable" + 0.043*"global" + 0.041*"level" + 0.038*"import" + 0.036*"access" + 0.035*"list" + 0.031*"actual" + 0.030*"namespace"
INFO: topic #2 (1.000): 0.086*"global" + 0.036*"file" + 0.018*"visibility" + 0.017*"import" + 0.017*"code" + 0.016*"execute" + 0.016*"solution" + 0.016*"copy" + 0.016*"file2.py" + 0.016*"alterd"
INFO: topic diff=0.588389, rho=0.476731
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 48.07541185811754
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -1.8405784418194069
DEBUG: bound: at document #0
INFO: -7.123 per-word bound, 139.4 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 3, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.090*"module" + 0.086*"variable" + 0.062*"global" + 0.047*"function" + 0.037*"name" + 0.024*"import" + 0.015*"scope" + 0.014*"value" + 0.012*"object" + 0.012*"keyword"
INFO: topic #1 (1.000): 0.047*"variable" + 0.047*"global" + 0.042*"assign" + 0.040*"local" + 0.037*"import" + 0.036*"level" + 0.030*"namespace" + 0.029*"access" + 0.024*"list" + 0.022*"actual"
INFO: topic #2 (1.000): 0.116*"global" + 0.056*"file" + 0.034*"visibility" + 0.022*"code" + 0.022*"execute" + 0.022*"copy" + 0.022*"file2.py" + 0.022*"alterd" + 0.022*"definition" + 0.022*"approach"
INFO: topic diff=0.544688, rho=0.430331
DEBUG: bound: at document #0
INFO: -5.057 per-word bound, 33.3 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 3, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.086*"variable" + 0.083*"module" + 0.059*"global" + 0.047*"function" + 0.039*"name" + 0.025*"import" + 0.016*"value" + 0.015*"scope" + 0.012*"object" + 0.012*"keyword"
INFO: topic #1 (1.000): 0.054*"local" + 0.053*"assign" + 0.045*"variable" + 0.043*"global" + 0.043*"level" + 0.041*"list" + 0.035*"import" + 0.034*"namespace" + 0.031*"access" + 0.026*"actual"
INFO: topic #2 (1.000): 0.091*"global" + 0.044*"file" + 0.026*"visibility" + 0.019*"code" + 0.017*"execute" + 0.017*"copy" + 0.017*"file2.py" + 0.017*"alterd" + 0.017*"definition" + 0.017*"approach"
INFO: topic diff=0.347810, rho=0.430331
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 46.3848688613983
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -3.905987595253753
DEBUG: bound: at document #0
INFO: -6.968 per-word bound, 125.2 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 4, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.088*"module" + 0.086*"variable" + 0.061*"global" + 0.046*"function" + 0.037*"name" + 0.025*"import" + 0.015*"value" + 0.015*"scope" + 0.012*"object" + 0.012*"keyword"
INFO: topic #1 (1.000): 0.047*"global" + 0.043*"variable" + 0.037*"level" + 0.035*"local" + 0.035*"import" + 0.034*"assign" + 0.032*"namespace" + 0.028*"list" + 0.026*"access" + 0.021*"instance"
INFO: topic #2 (1.000): 0.117*"global" + 0.059*"file" + 0.039*"visibility" + 0.024*"code" + 0.022*"execute" + 0.022*"copy" + 0.022*"file2.py" + 0.022*"alterd" + 0.022*"definition" + 0.022*"approach"
INFO: topic diff=0.364008, rho=0.395285
DEBUG: bound: at document #0
INFO: -5.036 per-word bound, 32.8 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 4, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.086*"variable" + 0.082*"module" + 0.059*"global" + 0.045*"function" + 0.039*"name" + 0.025*"import" + 0.017*"value" + 0.015*"scope" + 0.013*"assign" + 0.013*"access"
INFO: topic #1 (1.000): 0.046*"list" + 0.044*"global" + 0.041*"level" + 0.041*"variable" + 0.040*"local" + 0.037*"assign" + 0.036*"namespace" + 0.033*"import" + 0.026*"able" + 0.026*"case"
INFO: topic #2 (1.000): 0.094*"global" + 0.047*"file" + 0.030*"visibility" + 0.021*"code" + 0.018*"execute" + 0.018*"copy" + 0.018*"file2.py" + 0.018*"alterd" + 0.018*"definition" + 0.018*"approach"
INFO: topic diff=0.236116, rho=0.395285
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 45.52891237541841
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -3.8727476904366624
DEBUG: bound: at document #0
INFO: -6.886 per-word bound, 118.2 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 5, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.086*"module" + 0.085*"variable" + 0.060*"global" + 0.045*"function" + 0.037*"name" + 0.025*"import" + 0.016*"value" + 0.014*"scope" + 0.013*"assign" + 0.012*"access"
INFO: topic #1 (1.000): 0.047*"global" + 0.041*"variable" + 0.036*"level" + 0.034*"import" + 0.033*"namespace" + 0.031*"list" + 0.027*"local" + 0.025*"assign" + 0.023*"access" + 0.022*"constant"
INFO: topic #2 (1.000): 0.118*"global" + 0.060*"file" + 0.041*"visibility" + 0.025*"code" + 0.022*"execute" + 0.022*"copy" + 0.022*"file2.py" + 0.022*"alterd" + 0.022*"definition" + 0.022*"approach"
INFO: topic diff=0.278375, rho=0.367607
DEBUG: bound: at document #0
INFO: -5.024 per-word bound, 32.5 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 5, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.085*"variable" + 0.081*"module" + 0.059*"global" + 0.045*"function" + 0.038*"name" + 0.026*"import" + 0.017*"value" + 0.015*"assign" + 0.015*"scope" + 0.013*"access"
INFO: topic #1 (1.000): 0.050*"list" + 0.044*"global" + 0.038*"variable" + 0.038*"level" + 0.035*"namespace" + 0.032*"import" + 0.028*"able" + 0.028*"case" + 0.028*"note" + 0.028*"local"
INFO: topic #2 (1.000): 0.097*"global" + 0.049*"file" + 0.032*"visibility" + 0.022*"code" + 0.018*"execute" + 0.018*"copy" + 0.018*"file2.py" + 0.018*"alterd" + 0.018*"definition" + 0.018*"approach"
INFO: topic diff=0.215076, rho=0.367607
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 45.07535218173865
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -3.898244130260236
DEBUG: bound: at document #0
INFO: -6.840 per-word bound, 114.6 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 6, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.085*"variable" + 0.085*"module" + 0.060*"global" + 0.044*"function" + 0.037*"name" + 0.026*"import" + 0.016*"value" + 0.015*"assign" + 0.014*"scope" + 0.013*"access"
INFO: topic #1 (1.000): 0.047*"global" + 0.039*"variable" + 0.034*"level" + 0.033*"import" + 0.033*"namespace" + 0.033*"list" + 0.023*"constant" + 0.023*"entity" + 0.022*"access" + 0.021*"able"
INFO: topic #2 (1.000): 0.119*"global" + 0.060*"file" + 0.041*"visibility" + 0.026*"code" + 0.022*"execute" + 0.022*"copy" + 0.022*"file2.py" + 0.022*"alterd" + 0.022*"definition" + 0.022*"approach"
INFO: topic diff=0.234990, rho=0.345033
DEBUG: bound: at document #0
INFO: -5.016 per-word bound, 32.4 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 6, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.085*"variable" + 0.081*"module" + 0.059*"global" + 0.045*"function" + 0.038*"name" + 0.026*"import" + 0.017*"value" + 0.016*"assign" + 0.015*"scope" + 0.014*"access"
INFO: topic #1 (1.000): 0.052*"list" + 0.044*"global" + 0.037*"variable" + 0.034*"level" + 0.034*"namespace" + 0.031*"import" + 0.029*"able" + 0.029*"case" + 0.029*"note" + 0.025*"mutable"
INFO: topic #2 (1.000): 0.099*"global" + 0.050*"file" + 0.033*"visibility" + 0.023*"code" + 0.018*"execute" + 0.018*"copy" + 0.018*"file2.py" + 0.018*"alterd" + 0.018*"definition" + 0.018*"approach"
INFO: topic diff=0.207339, rho=0.345033
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 44.83807813451615
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -3.898244130260236
DEBUG: bound: at document #0
INFO: -6.816 per-word bound, 112.7 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 7, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.085*"variable" + 0.084*"module" + 0.059*"global" + 0.044*"function" + 0.037*"name" + 0.026*"import" + 0.017*"value" + 0.016*"assign" + 0.014*"scope" + 0.013*"access"
INFO: topic #1 (1.000): 0.047*"global" + 0.038*"variable" + 0.035*"list" + 0.033*"import" + 0.033*"level" + 0.032*"namespace" + 0.023*"constant" + 0.023*"entity" + 0.021*"able" + 0.021*"case"
INFO: topic #2 (1.000): 0.120*"global" + 0.061*"file" + 0.041*"visibility" + 0.027*"code" + 0.022*"execute" + 0.022*"copy" + 0.022*"file2.py" + 0.022*"alterd" + 0.022*"approach" + 0.022*"definition"
INFO: topic diff=0.210456, rho=0.326164
DEBUG: bound: at document #0
INFO: -5.012 per-word bound, 32.3 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 7, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.085*"variable" + 0.080*"module" + 0.058*"global" + 0.044*"function" + 0.038*"name" + 0.026*"import" + 0.017*"value" + 0.017*"assign" + 0.015*"scope" + 0.014*"access"
INFO: topic #1 (1.000): 0.053*"list" + 0.044*"global" + 0.036*"variable" + 0.032*"namespace" + 0.032*"level" + 0.031*"import" + 0.030*"able" + 0.030*"case" + 0.030*"note" + 0.025*"mutable"
INFO: topic #2 (1.000): 0.101*"global" + 0.051*"file" + 0.034*"visibility" + 0.024*"code" + 0.018*"execute" + 0.018*"copy" + 0.018*"file2.py" + 0.018*"alterd" + 0.018*"approach" + 0.018*"definition"
INFO: topic diff=0.198917, rho=0.326164
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 44.70427272661153
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -3.898244130260236
DEBUG: bound: at document #0
INFO: -6.802 per-word bound, 111.5 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 8, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.085*"variable" + 0.084*"module" + 0.059*"global" + 0.044*"function" + 0.037*"name" + 0.026*"import" + 0.017*"value" + 0.016*"assign" + 0.014*"scope" + 0.013*"access"
INFO: topic #1 (1.000): 0.047*"global" + 0.038*"variable" + 0.036*"list" + 0.033*"import" + 0.032*"namespace" + 0.031*"level" + 0.024*"constant" + 0.024*"entity" + 0.022*"able" + 0.022*"case"
INFO: topic #2 (1.000): 0.120*"global" + 0.061*"file" + 0.041*"visibility" + 0.027*"code" + 0.022*"execute" + 0.022*"copy" + 0.022*"file2.py" + 0.022*"alterd" + 0.022*"approach" + 0.022*"definition"
INFO: topic diff=0.195583, rho=0.310087
DEBUG: bound: at document #0
INFO: -5.008 per-word bound, 32.2 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 8, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.085*"variable" + 0.080*"module" + 0.058*"global" + 0.044*"function" + 0.038*"name" + 0.026*"import" + 0.017*"value" + 0.017*"assign" + 0.015*"scope" + 0.014*"local"
INFO: topic #1 (1.000): 0.054*"list" + 0.044*"global" + 0.035*"variable" + 0.031*"namespace" + 0.031*"import" + 0.031*"able" + 0.031*"case" + 0.031*"note" + 0.030*"level" + 0.024*"mutable"
INFO: topic #2 (1.000): 0.102*"global" + 0.052*"file" + 0.034*"visibility" + 0.025*"code" + 0.019*"execute" + 0.019*"copy" + 0.019*"file2.py" + 0.019*"alterd" + 0.019*"approach" + 0.019*"definition"
INFO: topic diff=0.189947, rho=0.310087
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 44.61627141217651
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -3.9050314690148595
DEBUG: bound: at document #0
INFO: -6.791 per-word bound, 110.8 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 9, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.085*"variable" + 0.083*"module" + 0.059*"global" + 0.044*"function" + 0.037*"name" + 0.027*"import" + 0.017*"value" + 0.016*"assign" + 0.014*"scope" + 0.014*"local"
INFO: topic #1 (1.000): 0.047*"global" + 0.037*"variable" + 0.037*"list" + 0.032*"import" + 0.031*"namespace" + 0.030*"level" + 0.024*"constant" + 0.024*"entity" + 0.023*"able" + 0.023*"case"
INFO: topic #2 (1.000): 0.120*"global" + 0.061*"file" + 0.041*"visibility" + 0.028*"code" + 0.022*"execute" + 0.022*"copy" + 0.022*"file2.py" + 0.022*"alterd" + 0.022*"approach" + 0.022*"definition"
INFO: topic diff=0.184737, rho=0.296174
DEBUG: bound: at document #0
INFO: -5.006 per-word bound, 32.1 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 9, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.085*"variable" + 0.080*"module" + 0.058*"global" + 0.044*"function" + 0.037*"name" + 0.026*"import" + 0.017*"value" + 0.017*"assign" + 0.015*"scope" + 0.014*"local"
INFO: topic #1 (1.000): 0.054*"list" + 0.044*"global" + 0.035*"variable" + 0.031*"able" + 0.031*"case" + 0.031*"note" + 0.031*"import" + 0.030*"namespace" + 0.029*"level" + 0.023*"mutable"
INFO: topic #2 (1.000): 0.103*"global" + 0.052*"file" + 0.035*"visibility" + 0.026*"code" + 0.019*"execute" + 0.019*"copy" + 0.019*"file2.py" + 0.019*"alterd" + 0.019*"approach" + 0.019*"definition"
INFO: topic diff=0.181550, rho=0.296174
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 44.54951033669688
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -3.8914567915056124
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5> in 0.11s', 'datetime': '2023-03-20T16:52:39.283136', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/questions/4/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-20T16:52:39.283293', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/questions/4/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/4/model.state
DEBUG: {'uri': 'model/questions/4/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/questions/4/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-20T16:52:39.285619', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/questions/4/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/questions/4/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/4/model
INFO: topic #0 (1.000): 0.085*"variable" + 0.080*"module" + 0.058*"global" + 0.044*"function" + 0.037*"name" + 0.026*"import" + 0.017*"value" + 0.017*"assign" + 0.015*"scope" + 0.014*"local"
INFO: topic #1 (1.000): 0.054*"list" + 0.044*"global" + 0.035*"variable" + 0.031*"able" + 0.031*"case" + 0.031*"note" + 0.031*"import" + 0.030*"namespace" + 0.029*"level" + 0.023*"mutable"
INFO: topic #2 (1.000): 0.103*"global" + 0.052*"file" + 0.035*"visibility" + 0.026*"code" + 0.019*"execute" + 0.019*"copy" + 0.019*"file2.py" + 0.019*"alterd" + 0.019*"approach" + 0.019*"definition"
INFO: Question Similarity: [0.3989792466163635, 0.30291616916656494, 0.4253098964691162, 0.35540640354156494, 0.32764148712158203, 0.21634775400161743, 0.23531293869018555, 0.39179182052612305, 0.14853441715240479, 0.18363893032073975]
INFO: 1978076: -0.2471124793157429
INFO: 35904211: -0.24716247944752548
INFO: 34168541: -0.24877844842750382
INFO: 1977383: -0.2594091100903496
INFO: 48870337: -0.30809817452053584
INFO: 66869622: -0.47929332610424386
INFO: 71785774: -0.5469571389406277
INFO: 64836766: -0.6230404077615278
INFO: 59221129: -0.8227644409897195
INFO: 68153138: -1.0125645380183368
INFO: Recommended Keywords
INFO: function score: -0.7917397
INFO: assign score: -0.75979596
INFO: example score: -0.7584093
INFO: approach score: -0.7436202
INFO: code score: -0.7385173
INFO: necessary score: -0.717141
INFO: application score: -0.71246785
INFO: value score: -0.7108475
INFO: problem score: -0.709774
INFO: scope score: -0.70522356
INFO: implementation score: -0.6936733
INFO: definition score: -0.6836835
INFO: variable score: -0.683502
INFO: information score: -0.6694859
INFO: actual score: -0.6589368
INFO: execute score: -0.6565501
INFO: solution score: -0.63345146
INFO: file score: -0.63163733
INFO: static score: -0.62836456
INFO: order score: -0.6097712
INFO: explicit score: -0.6079188
INFO: object score: -0.60765547
INFO: available score: -0.59337664
INFO: constant score: -0.59109163
INFO: helpful score: -0.5899513
INFO: global score: -0.5875059
INFO: level score: -0.5788185
INFO: database score: -0.57280934
INFO: special score: -0.5725212
INFO: share score: -0.5550568
INFO: copy score: -0.5540387
INFO: override score: -0.54847205
INFO: current score: -0.5470504
INFO: test score: -0.5466763
INFO: immutable score: -0.5402173
INFO: import score: -0.5391111
INFO: important score: -0.53788483
INFO: module score: -0.531828
INFO: namespace score: -0.52951396
INFO: visibility score: -0.51424867
INFO: documentation score: -0.51307315
INFO: access score: -0.5032337
INFO: configuration score: -0.49755502
INFO: keyword score: -0.49480942
INFO: canonical score: -0.48667708
INFO: artificial score: -0.46809343
INFO: underscores score: -0.46800768
INFO: entity score: -0.4661528
INFO: workaround score: -0.4390078
INFO: technique score: -0.43297845
INFO: accessible score: -0.42961895
INFO: point score: -0.4289159
INFO: program score: -0.41881657
INFO: new score: -0.417609
INFO: note score: -0.41676053
INFO: helper score: -0.4107761
INFO: way score: -0.40242568
INFO: main score: -0.38805443
INFO: local score: -0.37688336
INFO: single score: -0.36539492
INFO: state score: -0.35328275
INFO: many score: -0.35291705
INFO: subtle score: -0.3511104
INFO: direction score: -0.3460382
INFO: config score: -0.30982938
INFO: name score: -0.28402564
INFO: outside score: -0.27502665
INFO: answer score: -0.27327034
INFO: short score: -0.26882577
INFO: mymodule score: -0.25205278
INFO: quirk score: -0.25020272
INFO: none score: -0.22722638
INFO: deal score: -0.22720027
INFO: line score: -0.19336857
INFO: int score: -0.18591692
INFO: cfg score: -0.16778591
INFO: first score: -0.14615482
INFO: c score: -0.1355302
INFO: people score: -0.10823281
INFO: stuff score: -0.06593495
INFO: var score: -0.04338688
INFO: alterd score: -0.0
INFO: file2.py score: -0.0
INFO: first_var score: -0.0
INFO: explicity score: -0.0
INFO: steveha score: -0.0
INFO: wisty score: -0.0
INFO: db_name score: -0.0
INFO: module_name.var_name score: -0.0
INFO: accident score: 0.04034358
INFO: ============================================================
INFO: --------------------
INFO: Why are default values shared between objects?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<300 unique tokens: ['=', 'access', 'aliasing', 'answer', 'append']...> from 10 documents (total 883 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<300 unique tokens: ['=', 'access', 'aliasing', 'answer', 'append']...> from 10 documents (total 883 corpus positions)", 'datetime': '2023-03-20T16:52:41.239147', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.003 per-word bound, 128.2 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.080*"default" + 0.052*"value" + 0.041*"class" + 0.030*"instance" + 0.021*"type" + 0.021*"immutable" + 0.021*"code" + 0.020*"method" + 0.018*"function" + 0.017*"mutable"
INFO: topic #1 (1.000): 0.074*"default" + 0.058*"argument" + 0.039*"value" + 0.035*"list" + 0.034*"instance" + 0.032*"class" + 0.029*"function" + 0.026*"mutable" + 0.022*"time" + 0.019*"code"
INFO: topic #2 (1.000): 0.080*"value" + 0.067*"default" + 0.051*"function" + 0.033*"time" + 0.032*"argument" + 0.030*"object" + 0.028*"arg" + 0.026*"mutable" + 0.025*"instance" + 0.023*"list"
INFO: topic diff=3.220219, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.370 per-word bound, 1323.1 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.081*"default" + 0.067*"value" + 0.042*"class" + 0.025*"instance" + 0.025*"variable" + 0.020*"method" + 0.020*"object" + 0.018*"type" + 0.017*"function" + 0.017*"new"
INFO: topic #1 (1.000): 0.069*"default" + 0.053*"list" + 0.047*"value" + 0.045*"argument" + 0.037*"function" + 0.026*"class" + 0.026*"empty" + 0.023*"instance" + 0.022*"time" + 0.020*"none"
INFO: topic #2 (1.000): 0.085*"value" + 0.063*"function" + 0.057*"default" + 0.035*"object" + 0.033*"list" + 0.033*"time" + 0.032*"none" + 0.024*"argument" + 0.019*"mutable" + 0.018*"name"
INFO: topic diff=2.548635, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 56.04574772625503
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.4556237643087246
DEBUG: bound: at document #0
INFO: -5.529 per-word bound, 46.2 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"default" + 0.054*"value" + 0.048*"class" + 0.039*"instance" + 0.026*"type" + 0.024*"method" + 0.023*"variable" + 0.022*"immutable" + 0.017*"mutable" + 0.017*"new"
INFO: topic #1 (1.000): 0.068*"default" + 0.056*"argument" + 0.044*"value" + 0.044*"list" + 0.033*"class" + 0.032*"instance" + 0.032*"function" + 0.026*"mutable" + 0.020*"time" + 0.018*"caller"
INFO: topic #2 (1.000): 0.084*"value" + 0.079*"default" + 0.069*"function" + 0.044*"time" + 0.041*"object" + 0.036*"arg" + 0.033*"argument" + 0.029*"none" + 0.025*"list" + 0.021*"creation"
INFO: topic diff=1.582970, rho=0.500000
DEBUG: bound: at document #0
INFO: -7.571 per-word bound, 190.2 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"default" + 0.064*"value" + 0.044*"class" + 0.030*"instance" + 0.026*"variable" + 0.022*"method" + 0.020*"type" + 0.016*"field" + 0.015*"way" + 0.015*"reset"
INFO: topic #1 (1.000): 0.062*"default" + 0.051*"list" + 0.049*"argument" + 0.044*"value" + 0.034*"function" + 0.028*"class" + 0.025*"instance" + 0.025*"empty" + 0.022*"mutable" + 0.021*"caller"
INFO: topic #2 (1.000): 0.074*"value" + 0.069*"function" + 0.062*"default" + 0.040*"time" + 0.040*"object" + 0.037*"none" + 0.034*"list" + 0.027*"argument" + 0.023*"l" + 0.022*"arg"
INFO: topic diff=1.072062, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 45.58355121756197
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.0918023767031104
DEBUG: bound: at document #0
INFO: -5.328 per-word bound, 40.2 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"default" + 0.055*"value" + 0.049*"class" + 0.040*"instance" + 0.026*"type" + 0.025*"method" + 0.024*"variable" + 0.021*"immutable" + 0.017*"mutable" + 0.016*"new"
INFO: topic #1 (1.000): 0.065*"default" + 0.056*"argument" + 0.044*"list" + 0.044*"value" + 0.033*"class" + 0.032*"instance" + 0.031*"function" + 0.027*"mutable" + 0.019*"caller" + 0.018*"time"
INFO: topic #2 (1.000): 0.080*"default" + 0.078*"value" + 0.070*"function" + 0.046*"time" + 0.043*"object" + 0.035*"arg" + 0.035*"argument" + 0.033*"none" + 0.026*"list" + 0.020*"creation"
INFO: topic diff=0.970390, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.685 per-word bound, 102.9 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.070*"default" + 0.064*"value" + 0.046*"class" + 0.033*"instance" + 0.027*"variable" + 0.023*"method" + 0.020*"type" + 0.016*"reset" + 0.016*"way" + 0.016*"field"
INFO: topic #1 (1.000): 0.061*"default" + 0.050*"argument" + 0.048*"list" + 0.043*"value" + 0.033*"function" + 0.030*"class" + 0.027*"instance" + 0.024*"mutable" + 0.024*"empty" + 0.023*"caller"
INFO: topic #2 (1.000): 0.070*"value" + 0.070*"function" + 0.065*"default" + 0.042*"time" + 0.041*"object" + 0.039*"none" + 0.036*"list" + 0.029*"argument" + 0.028*"l" + 0.023*"arg"
INFO: topic diff=0.506513, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 43.44357357161736
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -1.0896713983886528
DEBUG: bound: at document #0
INFO: -5.257 per-word bound, 38.2 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"default" + 0.056*"value" + 0.050*"class" + 0.041*"instance" + 0.026*"type" + 0.026*"method" + 0.024*"variable" + 0.021*"immutable" + 0.017*"mutable" + 0.016*"new"
INFO: topic #1 (1.000): 0.064*"default" + 0.056*"argument" + 0.043*"list" + 0.043*"value" + 0.034*"class" + 0.033*"instance" + 0.031*"function" + 0.028*"mutable" + 0.020*"caller" + 0.018*"time"
INFO: topic #2 (1.000): 0.080*"default" + 0.075*"value" + 0.070*"function" + 0.046*"time" + 0.043*"object" + 0.035*"argument" + 0.034*"none" + 0.034*"arg" + 0.028*"list" + 0.020*"creation"
INFO: topic diff=0.623414, rho=0.408248
DEBUG: bound: at document #0
INFO: -6.526 per-word bound, 92.2 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"default" + 0.064*"value" + 0.046*"class" + 0.034*"instance" + 0.027*"variable" + 0.023*"method" + 0.021*"type" + 0.017*"reset" + 0.016*"way" + 0.016*"field"
INFO: topic #1 (1.000): 0.061*"default" + 0.051*"argument" + 0.045*"list" + 0.043*"value" + 0.033*"function" + 0.031*"class" + 0.029*"instance" + 0.025*"mutable" + 0.023*"caller" + 0.022*"empty"
INFO: topic #2 (1.000): 0.070*"function" + 0.069*"value" + 0.066*"default" + 0.042*"time" + 0.041*"object" + 0.039*"none" + 0.038*"list" + 0.030*"argument" + 0.030*"l" + 0.024*"arg"
INFO: topic diff=0.328010, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 42.6962738371125
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -1.0896713983886528
DEBUG: bound: at document #0
INFO: -5.225 per-word bound, 37.4 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"default" + 0.057*"value" + 0.050*"class" + 0.041*"instance" + 0.026*"method" + 0.026*"type" + 0.025*"variable" + 0.020*"immutable" + 0.017*"mutable" + 0.016*"new"
INFO: topic #1 (1.000): 0.064*"default" + 0.056*"argument" + 0.043*"value" + 0.042*"list" + 0.034*"class" + 0.033*"instance" + 0.031*"function" + 0.028*"mutable" + 0.020*"caller" + 0.018*"time"
INFO: topic #2 (1.000): 0.079*"default" + 0.074*"value" + 0.070*"function" + 0.046*"time" + 0.043*"object" + 0.036*"argument" + 0.035*"none" + 0.034*"arg" + 0.030*"list" + 0.019*"creation"
INFO: topic diff=0.445904, rho=0.377964
DEBUG: bound: at document #0
INFO: -6.465 per-word bound, 88.3 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"default" + 0.063*"value" + 0.047*"class" + 0.034*"instance" + 0.027*"variable" + 0.024*"method" + 0.021*"type" + 0.016*"reset" + 0.016*"way" + 0.016*"field"
INFO: topic #1 (1.000): 0.061*"default" + 0.051*"argument" + 0.043*"value" + 0.043*"list" + 0.033*"function" + 0.032*"class" + 0.029*"instance" + 0.026*"mutable" + 0.023*"caller" + 0.019*"empty"
INFO: topic #2 (1.000): 0.069*"function" + 0.069*"value" + 0.067*"default" + 0.043*"time" + 0.040*"object" + 0.040*"list" + 0.040*"none" + 0.031*"argument" + 0.030*"l" + 0.024*"arg"
INFO: topic diff=0.285023, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 42.360445438486096
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -1.0896713983886528
DEBUG: bound: at document #0
INFO: -5.207 per-word bound, 36.9 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"default" + 0.057*"value" + 0.050*"class" + 0.041*"instance" + 0.026*"method" + 0.026*"type" + 0.025*"variable" + 0.020*"immutable" + 0.017*"mutable" + 0.016*"new"
INFO: topic #1 (1.000): 0.064*"default" + 0.056*"argument" + 0.043*"value" + 0.042*"list" + 0.034*"class" + 0.033*"instance" + 0.031*"function" + 0.028*"mutable" + 0.021*"caller" + 0.017*"code"
INFO: topic #2 (1.000): 0.079*"default" + 0.074*"value" + 0.069*"function" + 0.047*"time" + 0.042*"object" + 0.036*"none" + 0.036*"argument" + 0.033*"arg" + 0.032*"list" + 0.019*"creation"
INFO: topic diff=0.352539, rho=0.353553
DEBUG: bound: at document #0
INFO: -6.430 per-word bound, 86.2 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"default" + 0.063*"value" + 0.047*"class" + 0.035*"instance" + 0.027*"variable" + 0.024*"method" + 0.022*"type" + 0.016*"way" + 0.016*"reset" + 0.016*"field"
INFO: topic #1 (1.000): 0.062*"default" + 0.051*"argument" + 0.043*"value" + 0.042*"list" + 0.033*"function" + 0.032*"class" + 0.030*"instance" + 0.027*"mutable" + 0.024*"caller" + 0.018*"problem"
INFO: topic #2 (1.000): 0.069*"function" + 0.069*"value" + 0.067*"default" + 0.043*"time" + 0.041*"list" + 0.040*"object" + 0.039*"none" + 0.031*"argument" + 0.029*"l" + 0.024*"arg"
INFO: topic diff=0.264688, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 42.16178059731794
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -1.0755266390933607
DEBUG: bound: at document #0
INFO: -5.196 per-word bound, 36.7 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"default" + 0.057*"value" + 0.050*"class" + 0.041*"instance" + 0.027*"method" + 0.026*"type" + 0.025*"variable" + 0.020*"immutable" + 0.017*"mutable" + 0.016*"new"
INFO: topic #1 (1.000): 0.064*"default" + 0.056*"argument" + 0.043*"value" + 0.041*"list" + 0.034*"class" + 0.033*"instance" + 0.031*"function" + 0.029*"mutable" + 0.021*"caller" + 0.018*"code"
INFO: topic #2 (1.000): 0.078*"default" + 0.073*"value" + 0.069*"function" + 0.047*"time" + 0.042*"object" + 0.036*"none" + 0.035*"argument" + 0.033*"list" + 0.033*"arg" + 0.019*"creation"
INFO: topic diff=0.299727, rho=0.333333
DEBUG: bound: at document #0
INFO: -6.404 per-word bound, 84.7 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"default" + 0.063*"value" + 0.047*"class" + 0.035*"instance" + 0.027*"variable" + 0.024*"method" + 0.022*"type" + 0.016*"way" + 0.016*"reset" + 0.016*"field"
INFO: topic #1 (1.000): 0.062*"default" + 0.052*"argument" + 0.043*"value" + 0.040*"list" + 0.033*"function" + 0.033*"class" + 0.030*"instance" + 0.027*"mutable" + 0.024*"caller" + 0.018*"problem"
INFO: topic #2 (1.000): 0.069*"function" + 0.069*"value" + 0.068*"default" + 0.043*"time" + 0.042*"list" + 0.040*"object" + 0.039*"none" + 0.032*"argument" + 0.029*"l" + 0.024*"arg"
INFO: topic diff=0.251087, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 42.03657870355136
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -1.0755266390933607
DEBUG: bound: at document #0
INFO: -5.188 per-word bound, 36.5 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"default" + 0.057*"value" + 0.050*"class" + 0.041*"instance" + 0.027*"method" + 0.026*"type" + 0.025*"variable" + 0.020*"immutable" + 0.017*"mutable" + 0.016*"new"
INFO: topic #1 (1.000): 0.064*"default" + 0.056*"argument" + 0.043*"value" + 0.040*"list" + 0.034*"class" + 0.033*"instance" + 0.031*"function" + 0.029*"mutable" + 0.021*"caller" + 0.018*"code"
INFO: topic #2 (1.000): 0.078*"default" + 0.073*"value" + 0.069*"function" + 0.047*"time" + 0.042*"object" + 0.036*"none" + 0.035*"argument" + 0.034*"list" + 0.032*"arg" + 0.019*"creation"
INFO: topic diff=0.266967, rho=0.316228
DEBUG: bound: at document #0
INFO: -6.384 per-word bound, 83.5 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"default" + 0.063*"value" + 0.047*"class" + 0.035*"instance" + 0.027*"variable" + 0.025*"method" + 0.022*"type" + 0.016*"way" + 0.016*"immutable" + 0.016*"field"
INFO: topic #1 (1.000): 0.062*"default" + 0.052*"argument" + 0.043*"value" + 0.040*"list" + 0.033*"function" + 0.033*"class" + 0.031*"instance" + 0.027*"mutable" + 0.024*"caller" + 0.018*"problem"
INFO: topic #2 (1.000): 0.069*"function" + 0.069*"value" + 0.068*"default" + 0.043*"time" + 0.042*"list" + 0.040*"object" + 0.039*"none" + 0.032*"argument" + 0.028*"l" + 0.024*"arg"
INFO: topic diff=0.238751, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 41.95801496984372
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -1.0365822289305007
DEBUG: bound: at document #0
INFO: -5.182 per-word bound, 36.3 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"default" + 0.057*"value" + 0.050*"class" + 0.041*"instance" + 0.027*"method" + 0.026*"type" + 0.026*"variable" + 0.020*"immutable" + 0.017*"mutable" + 0.016*"new"
INFO: topic #1 (1.000): 0.064*"default" + 0.056*"argument" + 0.043*"value" + 0.040*"list" + 0.034*"class" + 0.033*"instance" + 0.031*"function" + 0.029*"mutable" + 0.021*"caller" + 0.018*"code"
INFO: topic #2 (1.000): 0.078*"default" + 0.073*"value" + 0.069*"function" + 0.047*"time" + 0.042*"object" + 0.036*"none" + 0.035*"argument" + 0.035*"list" + 0.032*"arg" + 0.018*"creation"
INFO: topic diff=0.244534, rho=0.301511
DEBUG: bound: at document #0
INFO: -6.368 per-word bound, 82.6 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"default" + 0.063*"value" + 0.048*"class" + 0.036*"instance" + 0.027*"variable" + 0.025*"method" + 0.022*"type" + 0.016*"way" + 0.016*"immutable" + 0.016*"field"
INFO: topic #1 (1.000): 0.062*"default" + 0.052*"argument" + 0.043*"value" + 0.039*"list" + 0.033*"function" + 0.033*"class" + 0.031*"instance" + 0.028*"mutable" + 0.024*"caller" + 0.018*"problem"
INFO: topic #2 (1.000): 0.069*"value" + 0.069*"function" + 0.068*"default" + 0.043*"time" + 0.043*"list" + 0.040*"object" + 0.039*"none" + 0.032*"argument" + 0.028*"l" + 0.025*"arg"
INFO: topic diff=0.227128, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 41.90426752986513
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -1.0365822289305007
DEBUG: bound: at document #0
INFO: -5.177 per-word bound, 36.2 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"default" + 0.058*"value" + 0.050*"class" + 0.041*"instance" + 0.026*"method" + 0.026*"type" + 0.026*"variable" + 0.020*"immutable" + 0.017*"mutable" + 0.016*"new"
INFO: topic #1 (1.000): 0.064*"default" + 0.056*"argument" + 0.043*"value" + 0.040*"list" + 0.034*"class" + 0.033*"instance" + 0.031*"function" + 0.029*"mutable" + 0.021*"caller" + 0.018*"code"
INFO: topic #2 (1.000): 0.077*"default" + 0.073*"value" + 0.069*"function" + 0.047*"time" + 0.042*"object" + 0.036*"none" + 0.036*"list" + 0.035*"argument" + 0.032*"arg" + 0.018*"creation"
INFO: topic diff=0.228156, rho=0.288675
DEBUG: bound: at document #0
INFO: -6.356 per-word bound, 81.9 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"default" + 0.063*"value" + 0.048*"class" + 0.036*"instance" + 0.027*"variable" + 0.025*"method" + 0.022*"type" + 0.016*"way" + 0.016*"immutable" + 0.016*"field"
INFO: topic #1 (1.000): 0.063*"default" + 0.052*"argument" + 0.043*"value" + 0.039*"list" + 0.033*"function" + 0.033*"class" + 0.031*"instance" + 0.028*"mutable" + 0.024*"caller" + 0.018*"problem"
INFO: topic #2 (1.000): 0.069*"value" + 0.068*"function" + 0.068*"default" + 0.044*"time" + 0.043*"list" + 0.040*"object" + 0.039*"none" + 0.032*"argument" + 0.028*"l" + 0.025*"arg"
INFO: topic diff=0.216698, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 41.86196148168909
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.0365822289305007
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5> in 0.18s', 'datetime': '2023-03-20T16:52:41.417924', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/questions/5/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-20T16:52:41.418078', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/questions/5/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/5/model.state
DEBUG: {'uri': 'model/questions/5/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/questions/5/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-20T16:52:41.421228', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/questions/5/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/questions/5/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/5/model
INFO: topic #0 (1.000): 0.068*"default" + 0.063*"value" + 0.048*"class" + 0.036*"instance" + 0.027*"variable" + 0.025*"method" + 0.022*"type" + 0.016*"way" + 0.016*"immutable" + 0.016*"field"
INFO: topic #1 (1.000): 0.063*"default" + 0.052*"argument" + 0.043*"value" + 0.039*"list" + 0.033*"function" + 0.033*"class" + 0.031*"instance" + 0.028*"mutable" + 0.024*"caller" + 0.018*"problem"
INFO: topic #2 (1.000): 0.069*"value" + 0.068*"function" + 0.068*"default" + 0.044*"time" + 0.043*"list" + 0.040*"object" + 0.039*"none" + 0.032*"argument" + 0.028*"l" + 0.025*"arg"
INFO: Question Similarity: [0.25903064012527466, 0.15963959693908691, 0.27537524700164795, 0.20878994464874268, 0.1713152527809143, 0.1682124137878418, 0.4628903865814209, 0.20760440826416016, 0.22944653034210205, 0.1243329644203186]
INFO: 32939277: -0.2590776279102128
INFO: 61756644: -0.31657904701679335
INFO: 67959907: -0.3798644440910252
INFO: 63603063: -0.39880259727577266
INFO: 2681303: -0.40117347568887485
INFO: 2681363: -0.4064818677459695
INFO: 30515149: -0.40814877475160816
INFO: 2681507: -0.41353336929667506
INFO: 62758003: -0.4138729576205178
INFO: 2681286: -0.4159548346543812
INFO: 65867534: -0.4934628852166866
INFO: 65780484: -0.4940582868801999
INFO: 56880524: -0.5006573695425686
INFO: 56879961: -0.5034401399217894
INFO: 65780209: -0.5045378430224492
INFO: 56883874: -0.5069254921284615
INFO: 65780083: -0.5106872088524851
INFO: 65780080: -0.5131076303848155
INFO: 54132750: -0.5356965706850215
INFO: 65780089: -0.5453539040415231
INFO: 6838275: -0.5515591589257871
INFO: 6838271: -0.5884067603834692
INFO: 6838283: -0.6094521250457924
INFO: 6838280: -0.6352147641073248
INFO: 6840648: -0.6576368643453852
INFO: 6838605: -0.6694240553323797
INFO: 61424772: -0.8463053034059723
INFO: 61424917: -0.8586780937369897
INFO: 61424805: -0.8734590432924536
INFO: Recommended Keywords
INFO: difference score: -0.8361836
INFO: example score: -0.83489734
INFO: instance score: -0.83268636
INFO: useful score: -0.77114147
INFO: possible score: -0.76020104
INFO: function score: -0.7578593
INFO: method score: -0.7577841
INFO: type score: -0.7536434
INFO: problem score: -0.74294764
INFO: definition score: -0.7245747
INFO: variable score: -0.71004903
INFO: context score: -0.7015066
INFO: object score: -0.70065784
INFO: attribute score: -0.6913911
INFO: value score: -0.6883193
INFO: different score: -0.687628
INFO: solution score: -0.68560606
INFO: case score: -0.6842779
INFO: need score: -0.68378264
INFO: change score: -0.68083394
INFO: convenient score: -0.6797465
INFO: order score: -0.67682797
INFO: default score: -0.67539495
INFO: true score: -0.6701351
INFO: equal score: -0.6700537
INFO: unmodified score: -0.65748954
INFO: approach score: -0.65377694
INFO: real score: -0.6518086
INFO: result score: -0.64345366
INFO: argument score: -0.64187056
INFO: matter score: -0.6407536
INFO: initial score: -0.63793975
INFO: mutable score: -0.6336858
INFO: mean score: -0.62861043
INFO: fix score: -0.6269989
INFO: explanation score: -0.61646885
INFO: point score: -0.6103301
INFO: code score: -0.6070003
INFO: standard score: -0.60612893
INFO: immutable score: -0.6012447
INFO: behavior score: -0.59369016
INFO: reason score: -0.5934077
INFO: reference score: -0.5871284
INFO: check score: -0.58171386
INFO: note score: -0.5750234
INFO: careful score: -0.5687396
INFO: whole score: -0.5677595
INFO: output score: -0.550754
INFO: behaviour score: -0.5453082
INFO: way score: -0.54347175
INFO: empty score: -0.5385998
INFO: view score: -0.53820467
INFO: propagation score: -0.5317136
INFO: right score: -0.5273073
INFO: parameter score: -0.525759
INFO: field score: -0.5225111
INFO: other score: -0.52056587
INFO: meaning score: -0.5194537
INFO: moment score: -0.51678264
INFO: answer score: -0.5145692
INFO: unwanted score: -0.5139636
INFO: time score: -0.51003665
INFO: none score: -0.5098452
INFO: call score: -0.49360996
INFO: idea score: -0.48842704
INFO: prevent score: -0.48457897
INFO: long score: -0.47449294
INFO: reset score: -0.47385275
INFO: class score: -0.47334215
INFO: tuple score: -0.4731404
INFO: caller score: -0.46507367
INFO: symbolic score: -0.46419027
INFO: pointer score: -0.46246254
INFO: refer score: -0.4617311
INFO: integer score: -0.45439607
INFO: arg score: -0.45358887
INFO: good score: -0.4477503
INFO: array score: -0.4465246
INFO: important score: -0.43658292
INFO: subsequent score: -0.43399328
INFO: b score: -0.4326665
INFO: datum score: -0.4311409
INFO: create score: -0.43034032
INFO: list score: -0.43005976
INFO: exhibit score: -0.42918608
INFO: little score: -0.42727494
INFO: constructor score: -0.41695905
INFO: invocation score: -0.41455695
INFO: file score: -0.40851653
INFO: f score: -0.40638807
INFO: feature score: -0.4047117
INFO: thing score: -0.3995657
INFO: creation score: -0.39911768
INFO: c score: -0.39759853
INFO: documentation score: -0.39703292
INFO: surprising score: -0.39696953
INFO: body score: -0.3957646
INFO: property score: -0.38420925
INFO: mylist score: -0.3831732
INFO: want score: -0.37971583
INFO: operation score: -0.37874585
INFO: original score: -0.3771332
INFO: declaration score: -0.37104487
INFO: mention score: -0.36973527
INFO: state score: -0.36757872
INFO: new score: -0.36297107
INFO: previous score: -0.35419962
INFO: info score: -0.3498065
INFO: install score: -0.34809896
INFO: inside score: -0.34789056
INFO: work score: -0.34128493
INFO: my_list score: -0.32578033
INFO: first score: -0.32183036
INFO: bug score: -0.31528652
INFO: l score: -0.30903882
INFO: hope score: -0.3048452
INFO: taste score: -0.30402583
INFO: try score: -0.2959605
INFO: print score: -0.29056984
INFO: outside score: -0.2853581
INFO: worth score: -0.27041537
INFO: header score: -0.26873934
INFO: bad score: -0.26045963
INFO: name score: -0.25458467
INFO: dict score: -0.23557246
INFO: fine score: -0.23431477
INFO: show score: -0.23158635
INFO: line score: -0.22582045
INFO: lot score: -0.22188227
INFO: backport score: -0.21765865
INFO: deadly score: -0.21408848
INFO: unwary score: -0.21010634
INFO: num score: -0.19863711
INFO: strange score: -0.19027522
INFO: place score: -0.1862025
INFO: nice score: -0.17505762
INFO: plot score: -0.16617316
INFO: bp score: -0.15220088
INFO: dozen score: -0.14775458
INFO: str score: -0.14290354
INFO: bunch score: -0.11586701
INFO: goal score: -0.11341664
INFO: everytime score: -0.09096452
INFO: ownership score: -0.08911384
INFO: def score: -0.085645065
INFO: snippet score: -0.08414258
INFO: repr score: -0.030847764
INFO: dunder score: -0.0
INFO: i=6 score: -0.0
INFO: f(arg score: -0.0
INFO: self.root score: -0.0
INFO: dataclasse score: -0.0
INFO: dataclass score: -0.0
INFO: t]he score: -0.0
INFO: unchangable score: -0.0
INFO: attributeerror score: -0.0
INFO: b. score: -0.0
INFO: a. score: -0.0
INFO: function_name>.__default score: -0.0
INFO: l= score: -0.0
INFO: http://effbot.org/zone/default-values.htm score: -0.0
INFO: self.default_attr score: -0.0
INFO: imho score: -0.0
INFO: pythonic score: -0.0
INFO: member score: 0.0010283194
INFO: decorator score: 0.07975058
INFO: manager score: 0.15793449
INFO: ============================================================
INFO: --------------------
INFO: How can I pass optional or keyword parameters from one function to another?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<221 unique tokens: ['argument', 'caller', 'default', 'example', 'function']...> from 10 documents (total 546 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<221 unique tokens: ['argument', 'caller', 'default', 'example', 'function']...> from 10 documents (total 546 corpus positions)", 'datetime': '2023-03-20T16:52:43.766169', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.341 per-word bound, 162.1 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.097*"argument" + 0.064*"value" + 0.051*"default" + 0.042*"parameter" + 0.028*"b" + 0.026*"none" + 0.024*"optional" + 0.018*"positional" + 0.017*"easy" + 0.017*"c"
INFO: topic #1 (1.000): 0.087*"argument" + 0.055*"parameter" + 0.027*"function" + 0.027*"keyword" + 0.024*"name" + 0.022*"default" + 0.022*"optional" + 0.022*"positional" + 0.021*"value" + 0.021*"kwargs"
INFO: topic #2 (1.000): 0.098*"argument" + 0.067*"parameter" + 0.032*"optional" + 0.028*"function" + 0.026*"keyword" + 0.025*"default" + 0.022*"name" + 0.021*"positional" + 0.020*"none" + 0.019*"example"
INFO: topic diff=4.739007, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.454 per-word bound, 1403.0 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.084*"argument" + 0.059*"default" + 0.059*"value" + 0.049*"positional" + 0.042*"optional" + 0.041*"args" + 0.035*"parameter" + 0.033*"keyword" + 0.030*"c" + 0.025*"b"
INFO: topic #1 (1.000): 0.094*"argument" + 0.062*"function" + 0.050*"parameter" + 0.042*"keyword" + 0.028*"positional" + 0.025*"optional" + 0.020*"example" + 0.015*"args" + 0.014*"value" + 0.014*"line"
INFO: topic #2 (1.000): 0.092*"argument" + 0.063*"parameter" + 0.046*"optional" + 0.043*"function" + 0.041*"keyword" + 0.037*"positional" + 0.026*"default" + 0.021*"args" + 0.018*"example" + 0.017*"kwargs"
INFO: topic diff=4.152728, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 56.081951746616326
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.9560943694593576
DEBUG: bound: at document #0
INFO: -6.060 per-word bound, 66.7 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.089*"argument" + 0.083*"value" + 0.073*"default" + 0.038*"b" + 0.037*"args" + 0.035*"positional" + 0.032*"optional" + 0.028*"c" + 0.027*"parameter" + 0.027*"keyword"
INFO: topic #1 (1.000): 0.098*"argument" + 0.056*"function" + 0.047*"parameter" + 0.041*"keyword" + 0.025*"positional" + 0.022*"optional" + 0.017*"example" + 0.016*"args" + 0.015*"case" + 0.015*"operations(a"
INFO: topic #2 (1.000): 0.092*"argument" + 0.068*"parameter" + 0.036*"optional" + 0.031*"function" + 0.028*"keyword" + 0.027*"positional" + 0.023*"default" + 0.021*"name" + 0.021*"example" + 0.019*"none"
INFO: topic diff=1.324222, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.979 per-word bound, 63.1 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.071*"default" + 0.068*"argument" + 0.063*"value" + 0.062*"positional" + 0.057*"args" + 0.053*"optional" + 0.041*"keyword" + 0.036*"kwarg" + 0.035*"c" + 0.031*"b"
INFO: topic #1 (1.000): 0.087*"argument" + 0.057*"function" + 0.040*"parameter" + 0.037*"keyword" + 0.021*"positional" + 0.020*"optional" + 0.020*"line" + 0.017*"example" + 0.016*"multiple" + 0.016*"different"
INFO: topic #2 (1.000): 0.087*"argument" + 0.068*"parameter" + 0.036*"optional" + 0.031*"function" + 0.028*"keyword" + 0.027*"positional" + 0.023*"default" + 0.020*"example" + 0.019*"name" + 0.018*"none"
INFO: topic diff=1.265999, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 44.179102588261316
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.1816246549472138
DEBUG: bound: at document #0
INFO: -5.690 per-word bound, 51.6 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.082*"value" + 0.079*"default" + 0.077*"argument" + 0.051*"args" + 0.047*"positional" + 0.043*"b" + 0.042*"optional" + 0.036*"keyword" + 0.031*"c" + 0.030*"kwargs"
INFO: topic #1 (1.000): 0.091*"argument" + 0.054*"function" + 0.040*"parameter" + 0.036*"keyword" + 0.020*"positional" + 0.019*"optional" + 0.017*"line" + 0.015*"example" + 0.014*"case" + 0.014*"multiple"
INFO: topic #2 (1.000): 0.090*"argument" + 0.069*"parameter" + 0.033*"optional" + 0.028*"function" + 0.024*"keyword" + 0.024*"positional" + 0.024*"name" + 0.022*"default" + 0.022*"none" + 0.022*"example"
INFO: topic diff=0.774229, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.504 per-word bound, 45.4 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.074*"default" + 0.068*"positional" + 0.065*"args" + 0.064*"argument" + 0.063*"value" + 0.057*"optional" + 0.046*"keyword" + 0.038*"kwarg" + 0.035*"c" + 0.033*"b"
INFO: topic #1 (1.000): 0.086*"argument" + 0.056*"function" + 0.038*"parameter" + 0.035*"keyword" + 0.021*"line" + 0.019*"positional" + 0.018*"optional" + 0.017*"multiple" + 0.017*"example" + 0.017*"different"
INFO: topic #2 (1.000): 0.087*"argument" + 0.069*"parameter" + 0.032*"optional" + 0.028*"function" + 0.024*"positional" + 0.023*"keyword" + 0.022*"name" + 0.022*"default" + 0.021*"example" + 0.021*"none"
INFO: topic diff=0.663294, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 42.20803180349329
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -1.1143070668848771
DEBUG: bound: at document #0
INFO: -5.604 per-word bound, 48.6 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.080*"default" + 0.079*"value" + 0.073*"argument" + 0.059*"args" + 0.053*"positional" + 0.046*"optional" + 0.043*"b" + 0.041*"keyword" + 0.035*"kwargs" + 0.032*"c"
INFO: topic #1 (1.000): 0.089*"argument" + 0.054*"function" + 0.038*"parameter" + 0.035*"keyword" + 0.019*"line" + 0.017*"optional" + 0.017*"positional" + 0.015*"example" + 0.015*"multiple" + 0.015*"dispatch"
INFO: topic #2 (1.000): 0.090*"argument" + 0.069*"parameter" + 0.031*"optional" + 0.027*"function" + 0.026*"name" + 0.024*"none" + 0.023*"positional" + 0.022*"keyword" + 0.022*"example" + 0.022*"default"
INFO: topic diff=0.418010, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.416 per-word bound, 42.7 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.075*"default" + 0.070*"positional" + 0.070*"args" + 0.063*"argument" + 0.063*"value" + 0.058*"optional" + 0.048*"keyword" + 0.037*"kwarg" + 0.035*"kwargs" + 0.034*"c"
INFO: topic #1 (1.000): 0.085*"argument" + 0.056*"function" + 0.037*"parameter" + 0.034*"keyword" + 0.021*"line" + 0.018*"optional" + 0.017*"multiple" + 0.017*"different" + 0.017*"dispatch" + 0.017*"positional"
INFO: topic #2 (1.000): 0.088*"argument" + 0.069*"parameter" + 0.031*"optional" + 0.027*"function" + 0.024*"name" + 0.022*"positional" + 0.022*"none" + 0.022*"keyword" + 0.021*"example" + 0.021*"default"
INFO: topic diff=0.432827, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 41.62087443697528
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -1.2906654496374668
DEBUG: bound: at document #0
INFO: -5.569 per-word bound, 47.5 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.080*"default" + 0.077*"value" + 0.072*"argument" + 0.063*"args" + 0.056*"positional" + 0.048*"optional" + 0.044*"keyword" + 0.043*"b" + 0.037*"kwargs" + 0.031*"c"
INFO: topic #1 (1.000): 0.089*"argument" + 0.055*"function" + 0.037*"parameter" + 0.033*"keyword" + 0.019*"line" + 0.017*"optional" + 0.016*"positional" + 0.016*"multiple" + 0.016*"example" + 0.015*"dispatch"
INFO: topic #2 (1.000): 0.091*"argument" + 0.069*"parameter" + 0.031*"optional" + 0.026*"function" + 0.026*"name" + 0.025*"none" + 0.022*"example" + 0.022*"positional" + 0.022*"keyword" + 0.021*"default"
INFO: topic diff=0.299082, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.383 per-word bound, 41.7 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.076*"default" + 0.072*"args" + 0.071*"positional" + 0.064*"argument" + 0.063*"value" + 0.058*"optional" + 0.050*"keyword" + 0.036*"kwarg" + 0.036*"kwargs" + 0.034*"b"
INFO: topic #1 (1.000): 0.085*"argument" + 0.056*"function" + 0.037*"parameter" + 0.033*"keyword" + 0.021*"line" + 0.018*"optional" + 0.018*"multiple" + 0.017*"different" + 0.017*"dispatch" + 0.017*"example"
INFO: topic #2 (1.000): 0.088*"argument" + 0.069*"parameter" + 0.030*"optional" + 0.026*"function" + 0.025*"name" + 0.023*"none" + 0.022*"example" + 0.022*"positional" + 0.021*"keyword" + 0.021*"default"
INFO: topic diff=0.336852, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 41.334450291599566
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -0.6996138158701138
DEBUG: bound: at document #0
INFO: -5.548 per-word bound, 46.8 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.079*"default" + 0.075*"value" + 0.072*"argument" + 0.066*"args" + 0.059*"positional" + 0.049*"optional" + 0.045*"keyword" + 0.042*"b" + 0.038*"kwargs" + 0.031*"c"
INFO: topic #1 (1.000): 0.088*"argument" + 0.055*"function" + 0.036*"parameter" + 0.033*"keyword" + 0.020*"line" + 0.017*"optional" + 0.016*"multiple" + 0.016*"dispatch" + 0.016*"different" + 0.016*"example"
INFO: topic #2 (1.000): 0.091*"argument" + 0.069*"parameter" + 0.030*"optional" + 0.026*"name" + 0.026*"function" + 0.025*"none" + 0.022*"example" + 0.021*"positional" + 0.021*"default" + 0.021*"keyword"
INFO: topic diff=0.264029, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.365 per-word bound, 41.2 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.076*"default" + 0.073*"args" + 0.072*"positional" + 0.064*"argument" + 0.063*"value" + 0.058*"optional" + 0.051*"keyword" + 0.036*"kwargs" + 0.035*"kwarg" + 0.034*"b"
INFO: topic #1 (1.000): 0.085*"argument" + 0.057*"function" + 0.037*"parameter" + 0.033*"keyword" + 0.022*"line" + 0.018*"optional" + 0.018*"multiple" + 0.017*"different" + 0.017*"dispatch" + 0.017*"example"
INFO: topic #2 (1.000): 0.089*"argument" + 0.069*"parameter" + 0.030*"optional" + 0.026*"function" + 0.025*"name" + 0.024*"none" + 0.022*"example" + 0.021*"positional" + 0.021*"default" + 0.021*"keyword"
INFO: topic diff=0.289277, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 41.140853842124876
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -0.7107551299203084
DEBUG: bound: at document #0
INFO: -5.532 per-word bound, 46.3 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.079*"default" + 0.074*"value" + 0.072*"argument" + 0.067*"args" + 0.060*"positional" + 0.049*"optional" + 0.047*"keyword" + 0.041*"b" + 0.038*"kwargs" + 0.031*"c"
INFO: topic #1 (1.000): 0.087*"argument" + 0.056*"function" + 0.036*"parameter" + 0.032*"keyword" + 0.020*"line" + 0.017*"optional" + 0.016*"multiple" + 0.016*"different" + 0.016*"dispatch" + 0.016*"example"
INFO: topic #2 (1.000): 0.091*"argument" + 0.069*"parameter" + 0.030*"optional" + 0.027*"name" + 0.026*"none" + 0.026*"function" + 0.022*"example" + 0.021*"positional" + 0.021*"default" + 0.021*"keyword"
INFO: topic diff=0.243274, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.353 per-word bound, 40.9 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.075*"default" + 0.073*"args" + 0.072*"positional" + 0.065*"argument" + 0.063*"value" + 0.057*"optional" + 0.051*"keyword" + 0.037*"kwargs" + 0.035*"kwarg" + 0.034*"b"
INFO: topic #1 (1.000): 0.085*"argument" + 0.057*"function" + 0.037*"parameter" + 0.032*"keyword" + 0.022*"line" + 0.018*"optional" + 0.018*"multiple" + 0.017*"different" + 0.017*"dispatch" + 0.017*"example"
INFO: topic #2 (1.000): 0.089*"argument" + 0.069*"parameter" + 0.029*"optional" + 0.026*"function" + 0.025*"name" + 0.025*"none" + 0.022*"example" + 0.021*"positional" + 0.021*"default" + 0.021*"keyword"
INFO: topic diff=0.258977, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 40.99345764351041
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -0.7107551299203084
DEBUG: bound: at document #0
INFO: -5.519 per-word bound, 45.9 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.078*"default" + 0.073*"value" + 0.072*"argument" + 0.067*"args" + 0.061*"positional" + 0.049*"optional" + 0.048*"keyword" + 0.041*"b" + 0.038*"kwargs" + 0.031*"parameter"
INFO: topic #1 (1.000): 0.087*"argument" + 0.056*"function" + 0.036*"parameter" + 0.032*"keyword" + 0.020*"line" + 0.017*"optional" + 0.016*"multiple" + 0.016*"dispatch" + 0.016*"different" + 0.016*"example"
INFO: topic #2 (1.000): 0.091*"argument" + 0.069*"parameter" + 0.030*"optional" + 0.027*"name" + 0.026*"none" + 0.026*"function" + 0.022*"example" + 0.021*"default" + 0.021*"positional" + 0.021*"keyword"
INFO: topic diff=0.227593, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.345 per-word bound, 40.6 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.075*"default" + 0.073*"args" + 0.072*"positional" + 0.066*"argument" + 0.063*"value" + 0.057*"optional" + 0.052*"keyword" + 0.037*"kwargs" + 0.034*"b" + 0.034*"kwarg"
INFO: topic #1 (1.000): 0.085*"argument" + 0.057*"function" + 0.037*"parameter" + 0.032*"keyword" + 0.022*"line" + 0.018*"multiple" + 0.018*"optional" + 0.017*"different" + 0.017*"dispatch" + 0.017*"example"
INFO: topic #2 (1.000): 0.089*"argument" + 0.068*"parameter" + 0.029*"optional" + 0.026*"function" + 0.026*"name" + 0.025*"none" + 0.022*"example" + 0.021*"default" + 0.021*"positional" + 0.020*"keyword"
INFO: topic diff=0.237120, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 40.88122559864427
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -0.7172400835303373
DEBUG: bound: at document #0
INFO: -5.509 per-word bound, 45.5 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.078*"default" + 0.073*"argument" + 0.072*"value" + 0.068*"args" + 0.062*"positional" + 0.049*"optional" + 0.048*"keyword" + 0.040*"b" + 0.038*"kwargs" + 0.032*"parameter"
INFO: topic #1 (1.000): 0.086*"argument" + 0.056*"function" + 0.036*"parameter" + 0.031*"keyword" + 0.020*"line" + 0.017*"optional" + 0.016*"multiple" + 0.016*"dispatch" + 0.016*"different" + 0.016*"example"
INFO: topic #2 (1.000): 0.091*"argument" + 0.069*"parameter" + 0.030*"optional" + 0.027*"name" + 0.026*"none" + 0.026*"function" + 0.022*"example" + 0.021*"default" + 0.021*"positional" + 0.021*"keyword"
INFO: topic diff=0.215106, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.338 per-word bound, 40.5 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.075*"default" + 0.073*"args" + 0.073*"positional" + 0.066*"argument" + 0.063*"value" + 0.057*"optional" + 0.052*"keyword" + 0.037*"kwargs" + 0.034*"b" + 0.034*"parameter"
INFO: topic #1 (1.000): 0.084*"argument" + 0.057*"function" + 0.037*"parameter" + 0.032*"keyword" + 0.022*"line" + 0.018*"multiple" + 0.018*"optional" + 0.017*"different" + 0.017*"dispatch" + 0.017*"example"
INFO: topic #2 (1.000): 0.089*"argument" + 0.068*"parameter" + 0.029*"optional" + 0.026*"function" + 0.026*"name" + 0.025*"none" + 0.022*"example" + 0.021*"default" + 0.021*"positional" + 0.020*"keyword"
INFO: topic diff=0.219841, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 40.79646242648088
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -0.6189892469406408
DEBUG: bound: at document #0
INFO: -5.500 per-word bound, 45.3 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.077*"default" + 0.073*"argument" + 0.071*"value" + 0.068*"args" + 0.063*"positional" + 0.050*"optional" + 0.049*"keyword" + 0.040*"b" + 0.038*"kwargs" + 0.032*"parameter"
INFO: topic #1 (1.000): 0.086*"argument" + 0.056*"function" + 0.036*"parameter" + 0.031*"keyword" + 0.020*"line" + 0.017*"optional" + 0.017*"multiple" + 0.016*"dispatch" + 0.016*"different" + 0.016*"example"
INFO: topic #2 (1.000): 0.091*"argument" + 0.069*"parameter" + 0.030*"optional" + 0.027*"name" + 0.027*"none" + 0.026*"function" + 0.022*"example" + 0.021*"default" + 0.021*"positional" + 0.020*"keyword"
INFO: topic diff=0.202144, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.333 per-word bound, 40.3 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.075*"default" + 0.073*"positional" + 0.073*"args" + 0.067*"argument" + 0.062*"value" + 0.056*"optional" + 0.052*"keyword" + 0.037*"kwargs" + 0.034*"b" + 0.034*"parameter"
INFO: topic #1 (1.000): 0.084*"argument" + 0.057*"function" + 0.037*"parameter" + 0.031*"keyword" + 0.022*"line" + 0.018*"multiple" + 0.018*"optional" + 0.017*"different" + 0.017*"dispatch" + 0.017*"example"
INFO: topic #2 (1.000): 0.090*"argument" + 0.068*"parameter" + 0.029*"optional" + 0.026*"name" + 0.026*"function" + 0.026*"none" + 0.022*"example" + 0.021*"default" + 0.020*"positional" + 0.020*"keyword"
INFO: topic diff=0.205620, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 40.72787580225916
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -0.6117238450664799
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5> in 0.17s', 'datetime': '2023-03-20T16:52:43.933565', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/questions/6/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-20T16:52:43.933720', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/questions/6/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/6/model.state
DEBUG: {'uri': 'model/questions/6/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/questions/6/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-20T16:52:43.936149', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/questions/6/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/questions/6/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/6/model
INFO: topic #0 (1.000): 0.075*"default" + 0.073*"positional" + 0.073*"args" + 0.067*"argument" + 0.062*"value" + 0.056*"optional" + 0.052*"keyword" + 0.037*"kwargs" + 0.034*"b" + 0.034*"parameter"
INFO: topic #1 (1.000): 0.084*"argument" + 0.057*"function" + 0.037*"parameter" + 0.031*"keyword" + 0.022*"line" + 0.018*"multiple" + 0.018*"optional" + 0.017*"different" + 0.017*"dispatch" + 0.017*"example"
INFO: topic #2 (1.000): 0.090*"argument" + 0.068*"parameter" + 0.029*"optional" + 0.026*"name" + 0.026*"function" + 0.026*"none" + 0.022*"example" + 0.021*"default" + 0.020*"positional" + 0.020*"keyword"
INFO: Question Similarity: [0.1107819676399231, 0.0679863691329956, 0.13246041536331177, 0.11179757118225098, 0.4317936301231384, 0.175725519657135, 0.07899463176727295, 0.176108717918396, 0.2747569680213928, 0.0950937271118164]
INFO: 70002467: -0.1493813191567188
INFO: 9539977: -0.15395048102844136
INFO: 9539945: -0.15439287938252938
INFO: 70710559: -0.15558735614055236
INFO: 71352026: -0.15565397913175766
INFO: 67103403: -0.15736971335166974
INFO: 72512025: -0.15753213451238562
INFO: 63810047: -0.17068765968659094
INFO: 63810326: -0.17084071489247674
INFO: 63812075: -0.17087329269684612
INFO: 49583388: -0.20554092681337174
INFO: 68168421: -0.24564436775631007
INFO: 68168423: -0.24956630530215404
INFO: 69095633: -0.25501074232575544
INFO: 68407936: -0.2590685739704521
INFO: 71618773: -0.2863060198318564
INFO: 67028677: -0.3725812543544857
INFO: 67028449: -0.3747816601328161
INFO: 67040767: -0.37595067310699987
INFO: 56817421: -0.3791931704194908
INFO: 50397783: -0.5887507764882729
INFO: 67402968: -0.9277950897672668
INFO: 67403023: -0.9464078087422197
INFO: Recommended Keywords
INFO: example score: -0.80878615
INFO: possible score: -0.77967364
INFO: function score: -0.7657122
INFO: default score: -0.7602077
INFO: multiple score: -0.74954623
INFO: specific score: -0.73645073
INFO: keyword score: -0.73408854
INFO: arbitrary score: -0.7288793
INFO: different score: -0.7277601
INFO: type score: -0.7209789
INFO: method score: -0.7187286
INFO: variable score: -0.7037848
INFO: positional score: -0.70373535
INFO: error score: -0.700605
INFO: similar score: -0.69897145
INFO: reverse score: -0.6891355
INFO: restriction score: -0.6761505
INFO: pattern score: -0.66961807
INFO: mechanism score: -0.66815776
INFO: case score: -0.66553986
INFO: code score: -0.64791447
INFO: tuple score: -0.6471078
INFO: non score: -0.6434961
INFO: order score: -0.6417187
INFO: omitting score: -0.631988
INFO: ambiguity score: -0.62149364
INFO: value score: -0.6210769
INFO: parameter score: -0.61604095
INFO: approach score: -0.6145724
INFO: helpful score: -0.6060085
INFO: args score: -0.59855574
INFO: free score: -0.57729405
INFO: argument score: -0.5679147
INFO: option score: -0.5613266
INFO: output score: -0.55823016
INFO: sense score: -0.55339324
INFO: easy score: -0.5458186
INFO: optional score: -0.5442324
INFO: logic score: -0.54200673
INFO: signature score: -0.5356325
INFO: eg score: -0.53436905
INFO: note score: -0.52816963
INFO: way score: -0.51162225
INFO: resolve score: -0.5033409
INFO: module score: -0.49499676
INFO: map score: -0.48747987
INFO: produce score: -0.48360485
INFO: syntactic score: -0.48202503
INFO: arg score: -0.4799735
INFO: statement score: -0.4798645
INFO: implementation score: -0.4766405
INFO: matrix score: -0.47494984
INFO: single score: -0.4721611
INFO: operator score: -0.46401918
INFO: prefix score: -0.4627494
INFO: vector score: -0.457398
INFO: dict score: -0.45244387
INFO: base score: -0.45225996
INFO: emulate score: -0.45040673
INFO: length score: -0.44907263
INFO: support score: -0.44459683
INFO: b score: -0.4414351
INFO: answer score: -0.4341554
INFO: foo score: -0.42694414
INFO: write score: -0.4203978
INFO: dispatch score: -0.40677935
INFO: none score: -0.40483916
INFO: many score: -0.39006835
INFO: well score: -0.38802126
INFO: caller score: -0.3797725
INFO: various score: -0.37196997
INFO: reason score: -0.3707034
INFO: collision score: -0.36884192
INFO: several score: -0.36692068
INFO: fast score: -0.36043045
INFO: line score: -0.34917328
INFO: list score: -0.34631544
INFO: f score: -0.34072256
INFO: access score: -0.3369667
INFO: c score: -0.31909126
INFO: word score: -0.31711438
INFO: let score: -0.31510675
INFO: name score: -0.31251281
INFO: print score: -0.30602282
INFO: number score: -0.30585527
INFO: version score: -0.3051147
INFO: grammar score: -0.3043723
INFO: want score: -0.28619367
INFO: position score: -0.28584498
INFO: v score: -0.27464432
INFO: pass score: -0.27354512
INFO: inspect score: -0.27134618
INFO: env score: -0.26888713
INFO: remark score: -0.2484177
INFO: work score: -0.24021527
INFO: mandatory score: -0.23637965
INFO: engineering score: -0.22188912
INFO: first score: -0.19002318
INFO: library score: -0.16372827
INFO: place score: -0.16017543
INFO: forgot score: -0.1592063
INFO: conflict score: -0.15548003
INFO: world score: -0.14244342
INFO: upgrading score: -0.14025916
INFO: e score: -0.113963775
INFO: union score: -0.11033113
INFO: recent score: -0.09528165
INFO: var score: -0.0855312
INFO: kw score: -0.06486352
INFO: hacky score: -0.051908553
INFO: cem score: -0.046189442
INFO: dedicate score: -0.029843617
INFO: torch score: -0.015185528
INFO: optional[list score: -0.0
INFO: | score: -0.0
INFO: test(m score: -0.0
INFO: avión score: -0.0
INFO: arg="default_value score: -0.0
INFO: kwargs score: -0.0
INFO: c. score: -0.0
INFO: args->c score: -0.0
INFO: obj.some_function score: -0.0
INFO: g="foo score: -0.0
INFO: getfullargspec score: -0.0
INFO: parameterise score: -0.0
INFO: operations(a score: -0.0
INFO: pranav score: -0.0
INFO: hosangadi score: -0.0
INFO: kwarg score: -0.0
INFO: multipledispatch score: -0.0
INFO: randint score: -0.0
INFO: gen_pyi.py score: -0.0
INFO: function_hint score: -0.0
INFO: useme2declare score: -0.0
INFO: using*args score: -0.0
INFO: e.g score: -0.0
INFO: n’t score: -0.0
INFO: factory score: 0.08209265
INFO: decorator score: 0.09964455
INFO: ============================================================
INFO: --------------------
INFO: What is the difference between arguments and parameters?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<397 unique tokens: ['1st', '2nd', '=', 'able', 'absolute']...> from 10 documents (total 1569 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<397 unique tokens: ['1st', '2nd', '=', 'able', 'absolute']...> from 10 documents (total 1569 corpus positions)", 'datetime': '2023-03-20T16:52:46.098367', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.033 per-word bound, 131.0 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.074*"parameter" + 0.060*"function" + 0.048*"argument" + 0.044*"variable" + 0.036*"value" + 0.024*"program" + 0.018*"type" + 0.015*"actual" + 0.013*"object" + 0.013*"address"
INFO: topic #1 (1.000): 0.100*"argument" + 0.097*"parameter" + 0.069*"function" + 0.038*"value" + 0.025*"method" + 0.024*"actual" + 0.023*"variable" + 0.019*"formal" + 0.017*"name" + 0.016*"definition"
INFO: topic #2 (1.000): 0.088*"parameter" + 0.083*"function" + 0.051*"argument" + 0.039*"value" + 0.038*"variable" + 0.023*"type" + 0.021*"foo" + 0.015*"point" + 0.014*"actual" + 0.013*"program"
INFO: topic diff=3.699186, rho=1.000000
DEBUG: bound: at document #0
INFO: -8.402 per-word bound, 338.2 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"parameter" + 0.061*"function" + 0.045*"argument" + 0.034*"value" + 0.033*"program" + 0.029*"variable" + 0.013*"definition" + 0.013*"actual" + 0.010*"call" + 0.010*"type"
INFO: topic #1 (1.000): 0.109*"argument" + 0.107*"parameter" + 0.086*"function" + 0.052*"value" + 0.034*"definition" + 0.026*"call" + 0.023*"method" + 0.023*"variable" + 0.023*"name" + 0.022*"actual"
INFO: topic #2 (1.000): 0.100*"function" + 0.087*"parameter" + 0.053*"argument" + 0.040*"value" + 0.025*"variable" + 0.017*"program" + 0.013*"datum" + 0.013*"type" + 0.013*"actual" + 0.013*"definition"
INFO: topic diff=2.094350, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 41.44035703194642
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.8873027371720076
DEBUG: bound: at document #0
INFO: -5.283 per-word bound, 38.9 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"program" + 0.048*"function" + 0.045*"parameter" + 0.032*"variable" + 0.031*"argument" + 0.029*"c++" + 0.028*"address" + 0.028*"output" + 0.026*"value" + 0.021*"object"
INFO: topic #1 (1.000): 0.103*"parameter" + 0.102*"argument" + 0.074*"function" + 0.043*"value" + 0.025*"method" + 0.023*"actual" + 0.022*"definition" + 0.022*"variable" + 0.019*"name" + 0.019*"call"
INFO: topic #2 (1.000): 0.102*"function" + 0.075*"parameter" + 0.050*"variable" + 0.047*"argument" + 0.045*"value" + 0.032*"foo" + 0.023*"type" + 0.021*"point" + 0.012*"string" + 0.012*"message"
INFO: topic diff=1.122155, rho=0.500000
DEBUG: bound: at document #0
INFO: -6.433 per-word bound, 86.4 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.056*"program" + 0.044*"parameter" + 0.043*"function" + 0.030*"argument" + 0.025*"c++" + 0.021*"value" + 0.020*"variable" + 0.019*"c." + 0.017*"address" + 0.016*"output"
INFO: topic #1 (1.000): 0.103*"parameter" + 0.102*"argument" + 0.079*"function" + 0.048*"value" + 0.032*"definition" + 0.024*"call" + 0.023*"method" + 0.022*"name" + 0.022*"variable" + 0.021*"actual"
INFO: topic #2 (1.000): 0.113*"function" + 0.079*"parameter" + 0.058*"argument" + 0.044*"value" + 0.033*"variable" + 0.024*"datum" + 0.020*"f" + 0.019*"foo" + 0.014*"question" + 0.014*"type"
INFO: topic diff=0.839689, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 36.126899831890505
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -2.29756344280667
DEBUG: bound: at document #0
INFO: -5.209 per-word bound, 37.0 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.070*"program" + 0.038*"function" + 0.038*"c++" + 0.034*"address" + 0.034*"output" + 0.031*"parameter" + 0.026*"variable" + 0.025*"int" + 0.024*"object" + 0.023*"argument"
INFO: topic #1 (1.000): 0.102*"parameter" + 0.100*"argument" + 0.072*"function" + 0.042*"value" + 0.025*"method" + 0.023*"definition" + 0.023*"actual" + 0.021*"variable" + 0.020*"name" + 0.019*"call"
INFO: topic #2 (1.000): 0.111*"function" + 0.075*"parameter" + 0.055*"variable" + 0.055*"argument" + 0.050*"value" + 0.033*"foo" + 0.024*"type" + 0.023*"point" + 0.016*"datum" + 0.013*"part"
INFO: topic diff=0.691324, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.585 per-word bound, 48.0 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.065*"program" + 0.035*"function" + 0.032*"parameter" + 0.031*"c++" + 0.025*"c." + 0.022*"argument" + 0.021*"address" + 0.021*"output" + 0.019*"declaration" + 0.017*"actual"
INFO: topic #1 (1.000): 0.102*"parameter" + 0.100*"argument" + 0.077*"function" + 0.047*"value" + 0.031*"definition" + 0.023*"method" + 0.023*"call" + 0.022*"name" + 0.021*"variable" + 0.021*"actual"
INFO: topic #2 (1.000): 0.117*"function" + 0.079*"parameter" + 0.064*"argument" + 0.048*"value" + 0.039*"variable" + 0.025*"datum" + 0.021*"f" + 0.021*"foo" + 0.015*"type" + 0.015*"point"
INFO: topic diff=0.404271, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 35.3169220670176
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -1.589759152081429
DEBUG: bound: at document #0
INFO: -5.175 per-word bound, 36.1 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.074*"program" + 0.041*"c++" + 0.035*"output" + 0.035*"address" + 0.033*"function" + 0.026*"int" + 0.025*"object" + 0.025*"parameter" + 0.024*"copy" + 0.024*"equivalent"
INFO: topic #1 (1.000): 0.102*"parameter" + 0.100*"argument" + 0.071*"function" + 0.041*"value" + 0.025*"method" + 0.023*"definition" + 0.022*"actual" + 0.021*"variable" + 0.020*"name" + 0.019*"call"
INFO: topic #2 (1.000): 0.114*"function" + 0.076*"parameter" + 0.060*"argument" + 0.057*"variable" + 0.052*"value" + 0.034*"foo" + 0.024*"type" + 0.023*"point" + 0.018*"datum" + 0.014*"part"
INFO: topic diff=0.441444, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.484 per-word bound, 44.8 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"program" + 0.034*"c++" + 0.031*"function" + 0.026*"c." + 0.025*"parameter" + 0.023*"output" + 0.023*"address" + 0.021*"declaration" + 0.018*"actual" + 0.018*"argument"
INFO: topic #1 (1.000): 0.102*"parameter" + 0.100*"argument" + 0.076*"function" + 0.046*"value" + 0.030*"definition" + 0.023*"method" + 0.023*"call" + 0.022*"name" + 0.021*"actual" + 0.020*"variable"
INFO: topic #2 (1.000): 0.119*"function" + 0.080*"parameter" + 0.067*"argument" + 0.050*"value" + 0.042*"variable" + 0.026*"datum" + 0.023*"foo" + 0.021*"f" + 0.017*"type" + 0.016*"point"
INFO: topic diff=0.272853, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 35.051202951069676
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -1.5243882041467216
DEBUG: bound: at document #0
INFO: -5.156 per-word bound, 35.7 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.077*"program" + 0.042*"c++" + 0.036*"output" + 0.035*"address" + 0.030*"function" + 0.027*"int" + 0.025*"object" + 0.024*"copy" + 0.024*"equivalent" + 0.024*"separate"
INFO: topic #1 (1.000): 0.102*"parameter" + 0.099*"argument" + 0.071*"function" + 0.041*"value" + 0.025*"method" + 0.023*"definition" + 0.022*"actual" + 0.020*"variable" + 0.020*"name" + 0.019*"call"
INFO: topic #2 (1.000): 0.115*"function" + 0.077*"parameter" + 0.062*"argument" + 0.057*"variable" + 0.053*"value" + 0.034*"foo" + 0.025*"type" + 0.022*"point" + 0.019*"datum" + 0.014*"part"
INFO: topic diff=0.318047, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.448 per-word bound, 43.7 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"program" + 0.035*"c++" + 0.028*"function" + 0.026*"c." + 0.024*"output" + 0.024*"address" + 0.023*"declaration" + 0.020*"parameter" + 0.019*"actual" + 0.019*"int"
INFO: topic #1 (1.000): 0.102*"parameter" + 0.099*"argument" + 0.075*"function" + 0.046*"value" + 0.030*"definition" + 0.024*"method" + 0.022*"call" + 0.022*"name" + 0.021*"actual" + 0.020*"variable"
INFO: topic #2 (1.000): 0.119*"function" + 0.080*"parameter" + 0.069*"argument" + 0.051*"value" + 0.044*"variable" + 0.026*"datum" + 0.024*"foo" + 0.021*"f" + 0.018*"type" + 0.016*"point"
INFO: topic diff=0.225957, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 34.91957607678108
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -1.7393903052331694
DEBUG: bound: at document #0
INFO: -5.144 per-word bound, 35.4 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.078*"program" + 0.042*"c++" + 0.036*"output" + 0.035*"address" + 0.028*"int" + 0.028*"function" + 0.026*"object" + 0.024*"copy" + 0.024*"equivalent" + 0.024*"separate"
INFO: topic #1 (1.000): 0.102*"parameter" + 0.099*"argument" + 0.071*"function" + 0.042*"value" + 0.025*"method" + 0.024*"definition" + 0.022*"actual" + 0.020*"name" + 0.020*"variable" + 0.019*"call"
INFO: topic #2 (1.000): 0.116*"function" + 0.077*"parameter" + 0.064*"argument" + 0.057*"variable" + 0.054*"value" + 0.034*"foo" + 0.026*"type" + 0.022*"point" + 0.019*"datum" + 0.014*"string"
INFO: topic diff=0.257320, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.428 per-word bound, 43.1 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.075*"program" + 0.036*"c++" + 0.026*"function" + 0.026*"c." + 0.025*"output" + 0.025*"address" + 0.024*"declaration" + 0.020*"int" + 0.019*"actual" + 0.018*"object"
INFO: topic #1 (1.000): 0.103*"parameter" + 0.099*"argument" + 0.075*"function" + 0.045*"value" + 0.029*"definition" + 0.024*"method" + 0.022*"call" + 0.022*"name" + 0.021*"actual" + 0.020*"variable"
INFO: topic #2 (1.000): 0.120*"function" + 0.080*"parameter" + 0.070*"argument" + 0.051*"value" + 0.045*"variable" + 0.025*"datum" + 0.025*"foo" + 0.020*"f" + 0.019*"type" + 0.017*"point"
INFO: topic diff=0.208646, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 34.83541396854114
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -1.9308512668357298
DEBUG: bound: at document #0
INFO: -5.135 per-word bound, 35.1 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.080*"program" + 0.042*"c++" + 0.036*"output" + 0.035*"address" + 0.029*"int" + 0.026*"function" + 0.026*"object" + 0.024*"copy" + 0.024*"equivalent" + 0.024*"separate"
INFO: topic #1 (1.000): 0.102*"parameter" + 0.099*"argument" + 0.071*"function" + 0.042*"value" + 0.025*"method" + 0.024*"definition" + 0.022*"actual" + 0.020*"name" + 0.020*"variable" + 0.019*"call"
INFO: topic #2 (1.000): 0.117*"function" + 0.078*"parameter" + 0.065*"argument" + 0.057*"variable" + 0.054*"value" + 0.033*"foo" + 0.026*"type" + 0.022*"point" + 0.019*"datum" + 0.014*"string"
INFO: topic diff=0.224888, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.415 per-word bound, 42.7 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.077*"program" + 0.036*"c++" + 0.026*"c." + 0.025*"output" + 0.025*"address" + 0.024*"function" + 0.024*"declaration" + 0.021*"int" + 0.019*"actual" + 0.019*"object"
INFO: topic #1 (1.000): 0.103*"parameter" + 0.099*"argument" + 0.075*"function" + 0.045*"value" + 0.029*"definition" + 0.024*"method" + 0.022*"call" + 0.022*"name" + 0.021*"actual" + 0.020*"variable"
INFO: topic #2 (1.000): 0.120*"function" + 0.081*"parameter" + 0.070*"argument" + 0.051*"value" + 0.046*"variable" + 0.025*"foo" + 0.025*"datum" + 0.020*"type" + 0.020*"f" + 0.017*"point"
INFO: topic diff=0.197221, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 34.77420950175532
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -1.887644900043646
DEBUG: bound: at document #0
INFO: -5.128 per-word bound, 35.0 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.081*"program" + 0.043*"c++" + 0.036*"output" + 0.035*"address" + 0.030*"int" + 0.026*"object" + 0.024*"function" + 0.024*"copy" + 0.024*"equivalent" + 0.024*"separate"
INFO: topic #1 (1.000): 0.102*"parameter" + 0.099*"argument" + 0.071*"function" + 0.042*"value" + 0.025*"method" + 0.024*"definition" + 0.022*"actual" + 0.020*"name" + 0.020*"variable" + 0.020*"call"
INFO: topic #2 (1.000): 0.118*"function" + 0.078*"parameter" + 0.065*"argument" + 0.057*"variable" + 0.054*"value" + 0.033*"foo" + 0.027*"type" + 0.022*"point" + 0.020*"datum" + 0.015*"string"
INFO: topic diff=0.204305, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.405 per-word bound, 42.4 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.078*"program" + 0.037*"c++" + 0.026*"output" + 0.026*"address" + 0.026*"c." + 0.024*"declaration" + 0.023*"function" + 0.022*"int" + 0.019*"actual" + 0.019*"object"
INFO: topic #1 (1.000): 0.103*"parameter" + 0.099*"argument" + 0.075*"function" + 0.045*"value" + 0.029*"definition" + 0.024*"method" + 0.022*"call" + 0.022*"name" + 0.021*"actual" + 0.020*"variable"
INFO: topic #2 (1.000): 0.120*"function" + 0.081*"parameter" + 0.070*"argument" + 0.052*"value" + 0.046*"variable" + 0.026*"foo" + 0.025*"datum" + 0.021*"type" + 0.019*"f" + 0.017*"point"
INFO: topic diff=0.187124, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 34.7279745105589
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -1.887644900043646
DEBUG: bound: at document #0
INFO: -5.123 per-word bound, 34.8 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.082*"program" + 0.043*"c++" + 0.036*"output" + 0.035*"address" + 0.031*"int" + 0.026*"object" + 0.024*"copy" + 0.024*"equivalent" + 0.024*"separate" + 0.023*"function"
INFO: topic #1 (1.000): 0.102*"parameter" + 0.099*"argument" + 0.071*"function" + 0.042*"value" + 0.025*"method" + 0.024*"definition" + 0.022*"actual" + 0.021*"name" + 0.020*"variable" + 0.020*"call"
INFO: topic #2 (1.000): 0.118*"function" + 0.078*"parameter" + 0.066*"argument" + 0.057*"variable" + 0.054*"value" + 0.033*"foo" + 0.027*"type" + 0.022*"point" + 0.020*"datum" + 0.015*"string"
INFO: topic diff=0.189114, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.396 per-word bound, 42.1 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.079*"program" + 0.037*"c++" + 0.026*"output" + 0.026*"address" + 0.025*"c." + 0.025*"declaration" + 0.023*"int" + 0.022*"function" + 0.019*"actual" + 0.019*"object"
INFO: topic #1 (1.000): 0.103*"parameter" + 0.100*"argument" + 0.075*"function" + 0.045*"value" + 0.029*"definition" + 0.024*"method" + 0.022*"call" + 0.022*"name" + 0.021*"actual" + 0.020*"variable"
INFO: topic #2 (1.000): 0.121*"function" + 0.081*"parameter" + 0.070*"argument" + 0.052*"value" + 0.047*"variable" + 0.026*"foo" + 0.025*"datum" + 0.022*"type" + 0.019*"f" + 0.017*"point"
INFO: topic diff=0.177824, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 34.691785745600015
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -1.8773760529242391
DEBUG: bound: at document #0
INFO: -5.118 per-word bound, 34.7 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.082*"program" + 0.043*"c++" + 0.036*"output" + 0.035*"address" + 0.032*"int" + 0.026*"object" + 0.024*"copy" + 0.024*"equivalent" + 0.024*"separate" + 0.023*"declaration"
INFO: topic #1 (1.000): 0.102*"parameter" + 0.099*"argument" + 0.071*"function" + 0.042*"value" + 0.025*"method" + 0.024*"definition" + 0.022*"actual" + 0.021*"name" + 0.020*"variable" + 0.020*"call"
INFO: topic #2 (1.000): 0.119*"function" + 0.079*"parameter" + 0.066*"argument" + 0.057*"variable" + 0.055*"value" + 0.033*"foo" + 0.028*"type" + 0.021*"point" + 0.020*"datum" + 0.015*"string"
INFO: topic diff=0.177107, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.389 per-word bound, 41.9 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.080*"program" + 0.037*"c++" + 0.027*"output" + 0.026*"address" + 0.025*"c." + 0.025*"declaration" + 0.024*"int" + 0.020*"function" + 0.020*"object" + 0.019*"actual"
INFO: topic #1 (1.000): 0.103*"parameter" + 0.100*"argument" + 0.075*"function" + 0.045*"value" + 0.028*"definition" + 0.024*"method" + 0.022*"call" + 0.022*"name" + 0.021*"actual" + 0.020*"variable"
INFO: topic #2 (1.000): 0.121*"function" + 0.081*"parameter" + 0.070*"argument" + 0.052*"value" + 0.047*"variable" + 0.026*"foo" + 0.025*"datum" + 0.022*"type" + 0.019*"f" + 0.017*"point"
INFO: topic diff=0.169455, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 34.66199789277356
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.8732307507913841
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5> in 0.20s', 'datetime': '2023-03-20T16:52:46.300946', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/questions/7/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-20T16:52:46.301114', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/questions/7/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/7/model.state
DEBUG: {'uri': 'model/questions/7/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/questions/7/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-20T16:52:46.304262', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/questions/7/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/questions/7/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/7/model
INFO: topic #0 (1.000): 0.080*"program" + 0.037*"c++" + 0.027*"output" + 0.026*"address" + 0.025*"c." + 0.025*"declaration" + 0.024*"int" + 0.020*"function" + 0.020*"object" + 0.019*"actual"
INFO: topic #1 (1.000): 0.103*"parameter" + 0.100*"argument" + 0.075*"function" + 0.045*"value" + 0.028*"definition" + 0.024*"method" + 0.022*"call" + 0.022*"name" + 0.021*"actual" + 0.020*"variable"
INFO: topic #2 (1.000): 0.121*"function" + 0.081*"parameter" + 0.070*"argument" + 0.052*"value" + 0.047*"variable" + 0.026*"foo" + 0.025*"datum" + 0.022*"type" + 0.019*"f" + 0.017*"point"
INFO: Question Similarity: [0.03763139247894287, 0.27221667766571045, 0.7087501883506775, 0.17243289947509766, 0.05437415838241577, 0.6915662586688995, 0.12265866994857788, 0.10482025146484375, 0.03931593894958496, 0.07596439123153687]
INFO: 59480969: -0.0606603827579216
INFO: 33401833: -0.06070661918135016
INFO: 23992345: -0.0610008110819194
INFO: 49361685: -0.061074129970047845
INFO: 156859: -0.06108738274934334
INFO: 47738789: -0.06116736373779643
INFO: 44516192: -0.06127741125010874
INFO: 24367269: -0.06178169684212694
INFO: 43695598: -0.061847971894033946
INFO: 156875: -0.06190052472682682
INFO: 50638397: -0.06206788729064418
INFO: 21067354: -0.06216778255724963
INFO: 72799457: -0.06237947716169849
INFO: 35923448: -0.06286906014913483
INFO: 48330590: -0.06292683303197724
INFO: 48048161: -0.0631423839434934
INFO: 19619127: -0.06316597997754854
INFO: 71307720: -0.06356405421357735
INFO: 43252753: -0.06405212505046369
INFO: 20726232: -0.06451520735203338
INFO: 156785: -0.06492196490245035
INFO: 36172609: -0.06497698280839269
INFO: 156792: -0.06511591620323422
INFO: 44798271: -0.06525211470794097
INFO: 59928588: -0.06792405464825935
INFO: 156787: -0.06833670492526428
INFO: 48048951: -0.06995409143448368
INFO: 40832360: -0.06998225951939877
INFO: 17120743: -0.07145583271066956
INFO: 22472316: -0.07145921594362944
INFO: 53567855: -0.07297270517476136
INFO: 74946446: -0.07313639440819121
INFO: 43602455: -0.07560020936248318
INFO: 18447280: -0.07560094796770363
INFO: 61764546: -0.07560234055669605
INFO: 46360559: -0.07617137298316565
INFO: 156778: -0.07887772694409237
INFO: 51231722: -0.07891553123459304
INFO: 45325837: -0.08056599162785126
INFO: 63941585: -0.1051073166235253
INFO: 63941603: -0.1287403221062618
INFO: 63942770: -0.13191666165764632
INFO: 30101989: -0.13300452984817734
INFO: 63941653: -0.13614266217192528
INFO: 30102009: -0.16691082260549697
INFO: 3176321: -0.21593115361034707
INFO: 3176327: -0.23040710899010008
INFO: 4905833: -0.24342717634996786
INFO: 3176323: -0.24639720056052047
INFO: 51054593: -0.25067041300121284
INFO: 51054544: -0.25643622943649064
INFO: 69118816: -0.43518097982998155
INFO: 72422146: -0.7334268986635829
INFO: 70921285: -1.1784192775795337
INFO: 67754922: -1.2193482239581925
INFO: 47169062: -1.2225375310635649
INFO: 69273218: -1.245136851506895
INFO: 1788926: -1.3151513939811494
INFO: Recommended Keywords
INFO: function score: -0.8534216
INFO: difference score: -0.8251211
INFO: instance score: -0.8158242
INFO: definition score: -0.8145172
INFO: parameter score: -0.8077495
INFO: example score: -0.80279034
INFO: variable score: -0.80219007
INFO: define score: -0.80116934
INFO: particular score: -0.7939566
INFO: actual score: -0.78644335
INFO: method score: -0.78041446
INFO: exact score: -0.77017784
INFO: simple score: -0.75880027
INFO: certain score: -0.7503038
INFO: mean score: -0.7340254
INFO: specific score: -0.73140526
INFO: value score: -0.73124075
INFO: object score: -0.728903
INFO: case score: -0.72888863
INFO: calculate score: -0.7196462
INFO: absolute score: -0.7177973
INFO: address score: -0.71775687
INFO: equate score: -0.70732516
INFO: real score: -0.68618274
INFO: reference score: -0.6842827
INFO: variables score: -0.669706
INFO: usage score: -0.6672709
INFO: need score: -0.6644607
INFO: correct score: -0.6621151
INFO: input score: -0.66088146
INFO: datum score: -0.65583277
INFO: type score: -0.65575445
INFO: term score: -0.6554373
INFO: standard score: -0.65233696
INFO: integer score: -0.64783484
INFO: description score: -0.6471171
INFO: argument score: -0.6434945
INFO: helpful score: -0.64090043
INFO: source score: -0.64046735
INFO: expression score: -0.6367238
INFO: sense score: -0.6330772
INFO: mechanism score: -0.62867415
INFO: index score: -0.6275918
INFO: invoke score: -0.6275898
INFO: arguments score: -0.62127525
INFO: determine score: -0.6186001
INFO: output score: -0.61731267
INFO: order score: -0.61716115
INFO: alternative score: -0.615902
INFO: confusing score: -0.61519194
INFO: f score: -0.6134887
INFO: information score: -0.608228
INFO: result score: -0.60625505
INFO: positional score: -0.5997811
INFO: mutable score: -0.5933939
INFO: different score: -0.58807683
INFO: formal score: -0.5835401
INFO: thought score: -0.5828752
INFO: notation score: -0.5823164
INFO: key score: -0.5820028
INFO: response score: -0.57933897
INFO: immutable score: -0.5740069
INFO: data score: -0.57332087
INFO: structure score: -0.5671527
INFO: macro score: -0.56681
INFO: code score: -0.56587553
INFO: placeholder score: -0.5616307
INFO: statement score: -0.55905575
INFO: process score: -0.55677694
INFO: equivalent score: -0.5538848
INFO: common score: -0.5529928
INFO: view score: -0.5520919
INFO: meaning score: -0.5518979
INFO: parenthesis score: -0.5489862
INFO: instantiation score: -0.5475567
INFO: kind score: -0.54690516
INFO: default score: -0.54088557
INFO: easy score: -0.5407803
INFO: connection score: -0.5375374
INFO: point score: -0.52955556
INFO: perspective score: -0.52723384
INFO: arg score: -0.5251447
INFO: distinction score: -0.5216643
INFO: signature score: -0.5084658
INFO: special score: -0.5084631
INFO: foo score: -0.5076646
INFO: natural score: -0.49900666
INFO: copy score: -0.49542466
INFO: distinguishing score: -0.49526453
INFO: keyword score: -0.49131307
INFO: human score: -0.4873839
INFO: person score: -0.4850309
INFO: datatype score: -0.4786518
INFO: much score: -0.47641507
INFO: program score: -0.47255772
INFO: dot score: -0.4704713
INFO: similar score: -0.46312007
INFO: wrong score: -0.46086973
INFO: mnemonic score: -0.46016622
INFO: call score: -0.45533988
INFO: interchangeable score: -0.45440042
INFO: answer score: -0.45308867
INFO: dilemma score: -0.44841796
INFO: documentation score: -0.44790727
INFO: comma score: -0.44672066
INFO: compile score: -0.44403177
INFO: invocation score: -0.44322872
INFO: conceptual score: -0.4411231
INFO: metaphor score: -0.43907386
INFO: c++ score: -0.43651512
INFO: able score: -0.43403444
INFO: blank score: -0.43311065
INFO: bit score: -0.43253607
INFO: body score: -0.42494053
INFO: write score: -0.42225304
INFO: int score: -0.42015964
INFO: practice score: -0.41988727
INFO: identifier score: -0.41360492
INFO: let score: -0.4116216
INFO: runtime score: -0.39851925
INFO: thing score: -0.39444494
INFO: machine score: -0.39442298
INFO: oracle score: -0.39226288
INFO: question score: -0.38882107
INFO: computer score: -0.38566455
INFO: mind score: -0.38533935
INFO: number score: -0.38521773
INFO: convention score: -0.38483927
INFO: info score: -0.3827808
INFO: optional score: -0.3787294
INFO: string score: -0.37223005
INFO: plane score: -0.3648741
INFO: visible score: -0.35870576
INFO: thesis score: -0.35794967
INFO: remember score: -0.35583073
INFO: separate score: -0.35413003
INFO: constructor score: -0.35355246
INFO: declare score: -0.35212338
INFO: issue score: -0.35109022
INFO: well score: -0.34751043
INFO: fill score: -0.34699264
INFO: brain score: -0.34563658
INFO: message score: -0.3452693
INFO: x score: -0.34357738
INFO: programming score: -0.3401961
INFO: time score: -0.33985412
INFO: name score: -0.33406946
INFO: programmer score: -0.3298075
INFO: b score: -0.32551205
INFO: language score: -0.32514247
INFO: min score: -0.3242126
INFO: myname score: -0.31966367
INFO: various score: -0.31926617
INFO: declaration score: -0.31758258
INFO: c score: -0.31468672
INFO: text score: -0.3137685
INFO: inside score: -0.3133251
INFO: synonyms score: -0.31168896
INFO: previous score: -0.31111628
INFO: func score: -0.301632
INFO: plug score: -0.30047342
INFO: role score: -0.3000259
INFO: install score: -0.29793516
INFO: thematic score: -0.29466447
INFO: format score: -0.27912477
INFO: position score: -0.27691287
INFO: mathematics score: -0.27579823
INFO: caller score: -0.2633012
INFO: opposite score: -0.25802153
INFO: = score: -0.25427115
INFO: look score: -0.25418887
INFO: pass score: -0.24573332
INFO: main score: -0.24338979
INFO: list score: -0.23706101
INFO: toolkit score: -0.23174639
INFO: prototype score: -0.23059043
INFO: java score: -0.2226918
INFO: replace score: -0.21331407
INFO: sqrt score: -0.213294
INFO: socket score: -0.20434293
INFO: nice score: -0.19941044
INFO: part score: -0.1938169
INFO: lingo score: -0.19297181
INFO: egg score: -0.18430683
INFO: big score: -0.17982228
INFO: tutorial score: -0.17916444
INFO: site score: -0.17276426
INFO: faq score: -0.16918705
INFO: concrete score: -0.1651597
INFO: run score: -0.16315058
INFO: place score: -0.14957988
INFO: money score: -0.14432138
INFO: stop score: -0.142739
INFO: book score: -0.13724029
INFO: wall score: -0.1333127
INFO: people score: -0.11769067
INFO: exam score: -0.11418887
INFO: def score: -0.11140369
INFO: wikipedia score: -0.103580564
INFO: course score: -0.10257414
INFO: head score: -0.1000467
INFO: day score: -0.09757328
INFO: bar score: -0.09673299
INFO: happy score: -0.0967132
INFO: store score: -0.09121514
INFO: unleaded score: -0.061896235
INFO: next score: -0.060920205
INFO: monkey score: -0.06058315
INFO: author score: -0.047149703
INFO: airplane score: -0.044993512
INFO: community score: -0.03355367
INFO: petrol score: -0.033276435
INFO: second score: -0.024615372
INFO: unicorn score: -0.014011053
INFO: sausage score: -0.007191023
INFO: pee score: -0.0071013253
INFO: car score: -0.003465526
INFO: printname score: -0.0
INFO: console.log(name score: -0.0
INFO: printname("peter score: -0.0
INFO: mcsd score: -0.0
INFO: cerfification score: -0.0
INFO: basics.both score: -0.0
INFO: f(x score: -0.0
INFO: f(3 score: -0.0
INFO: alabahari score: -0.0
INFO: p. score: -0.0
INFO: savitch score: -0.0
INFO: http://en.wikipedia.org/wiki/parameter_(computer_science)#parameters_and_argument score: -0.0
INFO: kwargs score: -0.0
INFO: somevar score: -0.0
INFO: isinstance score: -0.0
INFO: c. score: -0.0
INFO: fun(arg score: -0.0
INFO: print(arg score: -0.0
INFO: n’t score: -0.0
INFO: italian score: 0.0018554407
INFO: breakfast score: 0.0215119
INFO: airline score: 0.048162907
INFO: peter score: 0.051778197
INFO: joseph score: 0.052783806
INFO: professor score: 0.05741459
INFO: seat score: 0.061074592
INFO: walter score: 0.06629666
INFO: passenger score: 0.076348625
INFO: russian score: 0.08811756
INFO: university score: 0.16736889
INFO: ============================================================
INFO: --------------------
INFO: How do I write a function with output parameters (call by reference)?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<494 unique tokens: ['=', '@andrea', '@blair', '@david', '@mark']...> from 9 documents (total 1884 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<494 unique tokens: ['=', '@andrea', '@blair', '@david', '@mark']...> from 9 documents (total 1884 corpus positions)", 'datetime': '2023-03-20T16:52:49.233431', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 9 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.275 per-word bound, 154.9 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 0, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.059*"object" + 0.057*"reference" + 0.041*"value" + 0.036*"function" + 0.028*"variable" + 0.018*"parameter" + 0.016*"name" + 0.016*"new" + 0.013*"change" + 0.013*"list"
INFO: topic #1 (1.000): 0.053*"object" + 0.052*"reference" + 0.041*"value" + 0.038*"variable" + 0.033*"function" + 0.015*"change" + 0.015*"list" + 0.013*"mutable" + 0.013*"method" + 0.013*"type"
INFO: topic #2 (1.000): 0.044*"function" + 0.039*"value" + 0.039*"object" + 0.035*"reference" + 0.031*"variable" + 0.020*"parameter" + 0.017*"mutable" + 0.015*"list" + 0.015*"type" + 0.014*"new"
INFO: topic diff=1.962411, rho=1.000000
DEBUG: bound: at document #0
INFO: -11.839 per-word bound, 3663.1 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 0, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.060*"object" + 0.056*"function" + 0.050*"value" + 0.044*"reference" + 0.032*"variable" + 0.015*"new" + 0.015*"return" + 0.014*"parameter" + 0.013*"name" + 0.013*"argument"
INFO: topic #1 (1.000): 0.048*"object" + 0.041*"reference" + 0.040*"value" + 0.039*"variable" + 0.037*"function" + 0.012*"change" + 0.012*"argument" + 0.011*"list" + 0.011*"mutable" + 0.010*"method"
INFO: topic #2 (1.000): 0.067*"function" + 0.048*"variable" + 0.036*"value" + 0.027*"object" + 0.023*"reference" + 0.021*"output" + 0.017*"parameter" + 0.016*"input" + 0.016*"way" + 0.016*"return"
INFO: topic diff=1.715676, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 72.25277986330855
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.9322104432307489
DEBUG: bound: at document #0
INFO: -6.000 per-word bound, 64.0 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 1, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.060*"object" + 0.054*"reference" + 0.043*"value" + 0.041*"function" + 0.033*"variable" + 0.015*"parameter" + 0.015*"name" + 0.015*"new" + 0.014*"change" + 0.013*"list"
INFO: topic #1 (1.000): 0.041*"object" + 0.036*"reference" + 0.035*"value" + 0.034*"variable" + 0.032*"function" + 0.011*"change" + 0.011*"argument" + 0.010*"list" + 0.010*"mutable" + 0.010*"type"
INFO: topic #2 (1.000): 0.051*"function" + 0.038*"value" + 0.030*"variable" + 0.022*"return" + 0.022*"parameter" + 0.019*"reference" + 0.018*"type" + 0.016*"object" + 0.016*"output" + 0.015*"way"
INFO: topic diff=1.252182, rho=0.512989
DEBUG: bound: at document #0
INFO: -8.670 per-word bound, 407.4 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 1, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.061*"object" + 0.049*"function" + 0.048*"reference" + 0.048*"value" + 0.033*"variable" + 0.015*"new" + 0.014*"name" + 0.013*"parameter" + 0.013*"change" + 0.012*"instance"
INFO: topic #1 (1.000): 0.032*"object" + 0.028*"value" + 0.027*"function" + 0.025*"variable" + 0.023*"reference" + 0.014*"arg" + 0.014*"argument" + 0.012*"solution" + 0.011*"issue" + 0.011*"result"
INFO: topic #2 (1.000): 0.069*"function" + 0.048*"variable" + 0.032*"value" + 0.026*"output" + 0.026*"return" + 0.024*"command" + 0.020*"way" + 0.020*"input" + 0.017*"parameter" + 0.017*"line"
INFO: topic diff=1.083031, rho=0.512989
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 58.25711545543906
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -2.47716425686112
DEBUG: bound: at document #0
INFO: -5.766 per-word bound, 54.4 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 2, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.060*"object" + 0.054*"reference" + 0.044*"value" + 0.041*"function" + 0.033*"variable" + 0.015*"parameter" + 0.015*"new" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: topic #1 (1.000): 0.025*"object" + 0.023*"value" + 0.022*"function" + 0.020*"variable" + 0.019*"reference" + 0.011*"argument" + 0.011*"arg" + 0.010*"solution" + 0.009*"issue" + 0.009*"result"
INFO: topic #2 (1.000): 0.053*"function" + 0.034*"value" + 0.029*"variable" + 0.028*"return" + 0.020*"parameter" + 0.019*"output" + 0.018*"type" + 0.017*"way" + 0.015*"mat" + 0.014*"code"
INFO: topic diff=0.794754, rho=0.456435
DEBUG: bound: at document #0
INFO: -7.442 per-word bound, 173.9 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 2, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.061*"object" + 0.049*"reference" + 0.048*"value" + 0.048*"function" + 0.034*"variable" + 0.015*"new" + 0.014*"name" + 0.013*"change" + 0.013*"parameter" + 0.012*"instance"
INFO: topic #1 (1.000): 0.018*"arg" + 0.017*"solution" + 0.016*"issue" + 0.016*"argument" + 0.016*"result" + 0.016*"object" + 0.016*"window" + 0.016*"dict.hpp" + 0.016*"dict.i" + 0.016*"os"
INFO: topic #2 (1.000): 0.070*"function" + 0.046*"variable" + 0.030*"return" + 0.029*"value" + 0.027*"command" + 0.027*"output" + 0.021*"way" + 0.020*"input" + 0.018*"line" + 0.017*"parameter"
INFO: topic diff=0.596313, rho=0.456435
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 55.32909265002572
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -3.8591329598362436
DEBUG: bound: at document #0
INFO: -5.701 per-word bound, 52.0 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 3, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.060*"object" + 0.054*"reference" + 0.044*"value" + 0.041*"function" + 0.034*"variable" + 0.015*"parameter" + 0.015*"new" + 0.014*"name" + 0.014*"change" + 0.013*"list"
INFO: topic #1 (1.000): 0.014*"arg" + 0.013*"solution" + 0.013*"argument" + 0.013*"issue" + 0.012*"object" + 0.012*"result" + 0.012*"window" + 0.012*"dict.hpp" + 0.012*"dict.i" + 0.012*"os"
INFO: topic #2 (1.000): 0.054*"function" + 0.032*"return" + 0.030*"value" + 0.028*"variable" + 0.021*"output" + 0.019*"type" + 0.018*"parameter" + 0.018*"way" + 0.016*"mat" + 0.015*"code"
INFO: topic diff=0.449701, rho=0.415227
DEBUG: bound: at document #0
INFO: -7.201 per-word bound, 147.2 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 3, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.061*"object" + 0.049*"reference" + 0.048*"value" + 0.047*"function" + 0.034*"variable" + 0.015*"new" + 0.014*"parameter" + 0.014*"change" + 0.014*"name" + 0.012*"instance"
INFO: topic #1 (1.000): 0.020*"result" + 0.019*"well" + 0.019*"issue" + 0.019*"solution" + 0.019*"window" + 0.019*"funny" + 0.019*"typemap" + 0.019*"test" + 0.019*"os" + 0.019*"multi"
INFO: topic #2 (1.000): 0.070*"function" + 0.044*"variable" + 0.033*"return" + 0.028*"command" + 0.028*"output" + 0.026*"value" + 0.021*"way" + 0.020*"input" + 0.018*"line" + 0.017*"script"
INFO: topic diff=0.361292, rho=0.415227
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 54.24769319127706
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -1.9885061705279652
DEBUG: bound: at document #0
INFO: -5.674 per-word bound, 51.1 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 4, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.060*"object" + 0.053*"reference" + 0.045*"value" + 0.041*"function" + 0.034*"variable" + 0.015*"parameter" + 0.015*"new" + 0.014*"change" + 0.014*"name" + 0.013*"list"
INFO: topic #1 (1.000): 0.015*"result" + 0.015*"well" + 0.015*"issue" + 0.014*"solution" + 0.014*"dict.i" + 0.014*"dict.hpp" + 0.014*"window" + 0.014*"funny" + 0.014*"os" + 0.014*"typemap"
INFO: topic #2 (1.000): 0.055*"function" + 0.034*"return" + 0.027*"value" + 0.027*"variable" + 0.023*"output" + 0.019*"type" + 0.018*"way" + 0.017*"parameter" + 0.017*"code" + 0.016*"command"
INFO: topic diff=0.293259, rho=0.383482
DEBUG: bound: at document #0
INFO: -7.096 per-word bound, 136.8 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 4, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.061*"object" + 0.049*"reference" + 0.048*"value" + 0.046*"function" + 0.034*"variable" + 0.015*"new" + 0.014*"parameter" + 0.014*"change" + 0.014*"name" + 0.012*"instance"
INFO: topic #1 (1.000): 0.021*"result" + 0.021*"well" + 0.020*"issue" + 0.020*"dict.hpp" + 0.020*"window" + 0.020*"dict.i" + 0.020*"funny" + 0.020*"test" + 0.020*"typemap" + 0.020*"os"
INFO: topic #2 (1.000): 0.069*"function" + 0.043*"variable" + 0.035*"return" + 0.029*"output" + 0.028*"command" + 0.024*"value" + 0.021*"way" + 0.020*"input" + 0.018*"line" + 0.017*"script"
INFO: topic diff=0.263302, rho=0.383482
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 53.72104597233284
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -1.9812407686537374
DEBUG: bound: at document #0
INFO: -5.659 per-word bound, 50.5 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 5, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.060*"object" + 0.053*"reference" + 0.045*"value" + 0.042*"function" + 0.034*"variable" + 0.015*"parameter" + 0.015*"new" + 0.015*"change" + 0.014*"name" + 0.013*"list"
INFO: topic #1 (1.000): 0.016*"result" + 0.016*"well" + 0.015*"issue" + 0.015*"solution" + 0.015*"window" + 0.015*"funny" + 0.015*"typemap" + 0.015*"test" + 0.015*"os" + 0.015*"multi"
INFO: topic #2 (1.000): 0.055*"function" + 0.035*"return" + 0.027*"variable" + 0.025*"value" + 0.025*"output" + 0.019*"type" + 0.018*"way" + 0.017*"code" + 0.017*"command" + 0.017*"mat"
INFO: topic diff=0.229239, rho=0.358057
DEBUG: bound: at document #0
INFO: -7.043 per-word bound, 131.8 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 5, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.061*"object" + 0.049*"reference" + 0.048*"value" + 0.046*"function" + 0.035*"variable" + 0.015*"new" + 0.014*"parameter" + 0.014*"change" + 0.014*"name" + 0.013*"instance"
INFO: topic #1 (1.000): 0.022*"result" + 0.022*"well" + 0.020*"issue" + 0.020*"dict.hpp" + 0.020*"window" + 0.020*"dict.i" + 0.020*"funny" + 0.020*"test" + 0.020*"typemap" + 0.020*"os"
INFO: topic #2 (1.000): 0.069*"function" + 0.041*"variable" + 0.036*"return" + 0.030*"output" + 0.028*"command" + 0.023*"value" + 0.021*"way" + 0.020*"input" + 0.018*"line" + 0.017*"script"
INFO: topic diff=0.219726, rho=0.358057
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 53.44552614950613
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -1.9812407686537374
DEBUG: bound: at document #0
INFO: -5.649 per-word bound, 50.2 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 6, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.060*"object" + 0.053*"reference" + 0.045*"value" + 0.042*"function" + 0.034*"variable" + 0.015*"parameter" + 0.015*"new" + 0.015*"change" + 0.014*"name" + 0.013*"list"
INFO: topic #1 (1.000): 0.017*"result" + 0.017*"well" + 0.016*"issue" + 0.016*"solution" + 0.016*"window" + 0.016*"funny" + 0.016*"typemap" + 0.016*"test" + 0.016*"os" + 0.016*"multi"
INFO: topic #2 (1.000): 0.056*"function" + 0.036*"return" + 0.027*"variable" + 0.026*"output" + 0.024*"value" + 0.019*"type" + 0.018*"way" + 0.018*"command" + 0.018*"code" + 0.017*"mat"
INFO: topic diff=0.198219, rho=0.337100
DEBUG: bound: at document #0
INFO: -7.011 per-word bound, 129.0 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 6, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.061*"object" + 0.050*"reference" + 0.048*"value" + 0.046*"function" + 0.035*"variable" + 0.015*"new" + 0.014*"parameter" + 0.014*"change" + 0.014*"name" + 0.013*"instance"
INFO: topic #1 (1.000): 0.022*"result" + 0.022*"well" + 0.020*"issue" + 0.020*"dict.hpp" + 0.020*"window" + 0.020*"dict.i" + 0.020*"funny" + 0.020*"test" + 0.020*"typemap" + 0.020*"os"
INFO: topic #2 (1.000): 0.068*"function" + 0.041*"variable" + 0.036*"return" + 0.030*"output" + 0.028*"command" + 0.022*"value" + 0.021*"way" + 0.020*"input" + 0.017*"line" + 0.017*"pass"
INFO: topic diff=0.193342, rho=0.337100
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 53.2893464347616
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -1.9290240661261888
DEBUG: bound: at document #0
INFO: -5.643 per-word bound, 50.0 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 7, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.060*"object" + 0.053*"reference" + 0.045*"value" + 0.042*"function" + 0.034*"variable" + 0.015*"parameter" + 0.015*"new" + 0.015*"change" + 0.014*"name" + 0.013*"list"
INFO: topic #1 (1.000): 0.017*"result" + 0.017*"well" + 0.016*"issue" + 0.016*"solution" + 0.016*"window" + 0.016*"funny" + 0.016*"typemap" + 0.016*"test" + 0.016*"os" + 0.016*"multi"
INFO: topic #2 (1.000): 0.056*"function" + 0.037*"return" + 0.027*"output" + 0.027*"variable" + 0.023*"value" + 0.019*"type" + 0.018*"command" + 0.018*"way" + 0.018*"code" + 0.017*"mat"
INFO: topic diff=0.177842, rho=0.319438
DEBUG: bound: at document #0
INFO: -6.990 per-word bound, 127.1 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 7, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.061*"object" + 0.050*"reference" + 0.048*"value" + 0.046*"function" + 0.035*"variable" + 0.015*"new" + 0.014*"parameter" + 0.014*"change" + 0.014*"name" + 0.013*"instance"
INFO: topic #1 (1.000): 0.022*"result" + 0.022*"well" + 0.020*"issue" + 0.020*"dict.hpp" + 0.020*"window" + 0.020*"dict.i" + 0.020*"funny" + 0.020*"test" + 0.020*"typemap" + 0.020*"os"
INFO: topic #2 (1.000): 0.068*"function" + 0.040*"variable" + 0.037*"return" + 0.031*"output" + 0.028*"command" + 0.021*"value" + 0.021*"way" + 0.020*"input" + 0.017*"pass" + 0.017*"code"
INFO: topic diff=0.174090, rho=0.319438
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 53.19019562265801
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -1.4924425908228622
DEBUG: bound: at document #0
INFO: -5.639 per-word bound, 49.8 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 8, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.060*"object" + 0.053*"reference" + 0.046*"value" + 0.042*"function" + 0.034*"variable" + 0.015*"parameter" + 0.015*"new" + 0.015*"change" + 0.014*"name" + 0.013*"list"
INFO: topic #1 (1.000): 0.018*"result" + 0.017*"well" + 0.016*"issue" + 0.016*"dict.hpp" + 0.016*"window" + 0.016*"dict.i" + 0.016*"funny" + 0.016*"test" + 0.016*"typemap" + 0.016*"os"
INFO: topic #2 (1.000): 0.057*"function" + 0.037*"return" + 0.028*"output" + 0.027*"variable" + 0.023*"value" + 0.019*"type" + 0.019*"command" + 0.019*"code" + 0.018*"way" + 0.017*"mat"
INFO: topic diff=0.163688, rho=0.304290
DEBUG: bound: at document #0
INFO: -6.975 per-word bound, 125.8 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 8, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.061*"object" + 0.050*"reference" + 0.048*"value" + 0.046*"function" + 0.035*"variable" + 0.015*"new" + 0.014*"parameter" + 0.014*"change" + 0.014*"name" + 0.013*"instance"
INFO: topic #1 (1.000): 0.022*"well" + 0.022*"result" + 0.020*"issue" + 0.020*"dict.hpp" + 0.020*"window" + 0.020*"dict.i" + 0.020*"funny" + 0.020*"test" + 0.020*"typemap" + 0.020*"os"
INFO: topic #2 (1.000): 0.068*"function" + 0.040*"variable" + 0.037*"return" + 0.031*"output" + 0.028*"command" + 0.021*"value" + 0.021*"way" + 0.020*"input" + 0.018*"pass" + 0.018*"code"
INFO: topic diff=0.159569, rho=0.304290
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 53.11986509952934
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -1.4894391455776166
DEBUG: bound: at document #0
INFO: -5.635 per-word bound, 49.7 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 9, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.060*"object" + 0.053*"reference" + 0.046*"value" + 0.042*"function" + 0.034*"variable" + 0.015*"parameter" + 0.015*"new" + 0.015*"change" + 0.014*"name" + 0.013*"list"
INFO: topic #1 (1.000): 0.018*"result" + 0.018*"well" + 0.016*"issue" + 0.016*"dict.hpp" + 0.016*"window" + 0.016*"dict.i" + 0.016*"funny" + 0.016*"test" + 0.016*"typemap" + 0.016*"os"
INFO: topic #2 (1.000): 0.057*"function" + 0.038*"return" + 0.028*"output" + 0.027*"variable" + 0.022*"value" + 0.019*"command" + 0.019*"code" + 0.019*"type" + 0.018*"way" + 0.017*"pass"
INFO: topic diff=0.152916, rho=0.291111
DEBUG: bound: at document #0
INFO: -6.963 per-word bound, 124.7 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 9, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.061*"object" + 0.050*"reference" + 0.048*"value" + 0.045*"function" + 0.035*"variable" + 0.015*"new" + 0.014*"parameter" + 0.014*"change" + 0.014*"name" + 0.013*"list"
INFO: topic #1 (1.000): 0.022*"well" + 0.022*"result" + 0.020*"issue" + 0.020*"dict.hpp" + 0.020*"window" + 0.020*"dict.i" + 0.020*"funny" + 0.020*"test" + 0.020*"typemap" + 0.020*"os"
INFO: topic #2 (1.000): 0.068*"function" + 0.039*"variable" + 0.038*"return" + 0.032*"output" + 0.028*"command" + 0.021*"way" + 0.021*"value" + 0.020*"input" + 0.018*"pass" + 0.018*"code"
INFO: topic diff=0.148414, rho=0.291111
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 53.066247074577426
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.4874248217592416
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5> in 0.22s', 'datetime': '2023-03-20T16:52:49.451356', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/questions/8/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-20T16:52:49.451519', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/questions/8/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/8/model.state
DEBUG: {'uri': 'model/questions/8/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/questions/8/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-20T16:52:49.455367', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/questions/8/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/questions/8/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/8/model
INFO: topic #0 (1.000): 0.061*"object" + 0.050*"reference" + 0.048*"value" + 0.045*"function" + 0.035*"variable" + 0.015*"new" + 0.014*"parameter" + 0.014*"change" + 0.014*"name" + 0.013*"list"
INFO: topic #1 (1.000): 0.022*"well" + 0.022*"result" + 0.020*"issue" + 0.020*"dict.hpp" + 0.020*"window" + 0.020*"dict.i" + 0.020*"funny" + 0.020*"test" + 0.020*"typemap" + 0.020*"os"
INFO: topic #2 (1.000): 0.068*"function" + 0.039*"variable" + 0.038*"return" + 0.032*"output" + 0.028*"command" + 0.021*"way" + 0.021*"value" + 0.020*"input" + 0.018*"pass" + 0.018*"code"
INFO: Question Similarity: [0.07703560590744019, 0.14776098728179932, 0.11576366424560547, 0.06378495693206787, 0.06334757804870605, 0.06596022844314575, 0.12983381748199463, 0.16314393281936646, 0.16417986154556274, 0.18532365560531616]
INFO: 65786490: -0.12568524640129516
INFO: 38692659: -0.12580108894659467
INFO: 65785486: -0.1280804547768337
INFO: 66113656: -0.12843758111751832
INFO: 54736424: -0.13123508014290142
INFO: 54736439: -0.13127363661361663
INFO: 54736346: -0.1312946873490705
INFO: 54315603: -0.15130742300693537
INFO: 21700609: -0.1513632267217994
INFO: 39054982: -0.15136755516719996
INFO: 15697476: -0.15137440440638944
INFO: 25810863: -0.15139108480121055
INFO: 8140747: -0.15144692650214134
INFO: 986145: -0.15146364191270775
INFO: 71049904: -0.15153123115150394
INFO: 3127336: -0.15156229165935037
INFO: 62970753: -0.1516215900377284
INFO: 12440140: -0.1521177404289682
INFO: 986339: -0.1521244895435577
INFO: 986495: -0.15213853109549694
INFO: 73945173: -0.15219697152292333
INFO: 35260424: -0.15225843127244043
INFO: 12686527: -0.15231562022550946
INFO: 986044: -0.15293531680603759
INFO: 56069248: -0.15293542110566521
INFO: 68167731: -0.15318304769764202
INFO: 40345432: -0.1535619337540744
INFO: 36775894: -0.15390511740186683
INFO: 29293411: -0.15406228173244263
INFO: 38834546: -0.15437966697193242
INFO: 50157212: -0.1546583341661722
INFO: 25670170: -0.15540328245382892
INFO: 65935869: -0.1554371942664986
INFO: 6963425: -0.15645595642187596
INFO: 66819159: -0.15645749001574552
INFO: 55992875: -0.15648025838052246
INFO: 21684541: -0.1580663745455623
INFO: 46136730: -0.15996852884133853
INFO: 986335: -0.16131950276350435
INFO: 75696407: -0.16132394139307843
INFO: 71579032: -0.16926452261209501
INFO: 69913926: -0.22834793007783974
INFO: 69913928: -0.23436930488042232
INFO: 53929523: -0.25603386889058094
INFO: 53929719: -0.25649788917902155
INFO: 74505976: -0.2909564617411153
INFO: 4702442: -0.2945498937863768
INFO: 4702301: -0.2966053904696554
INFO: 4702272: -0.2966439872329203
INFO: 4702280: -0.29825776874504706
INFO: 4702267: -0.3037546305671286
INFO: 49184305: -0.32387606909571914
INFO: 49183847: -0.33011826978173237
INFO: 47050775: -0.5135718531760599
INFO: Recommended Keywords
INFO: example score: -0.81800705
INFO: instance score: -0.80224127
INFO: possible score: -0.7923169
INFO: change score: -0.7824992
INFO: input score: -0.7765134
INFO: function score: -0.76839817
INFO: actual score: -0.7679063
INFO: assign score: -0.7579616
INFO: corresponding score: -0.7551926
INFO: element score: -0.75034636
INFO: attribute score: -0.73618203
INFO: context score: -0.72863454
INFO: reference score: -0.7258028
INFO: correct score: -0.7245424
INFO: definition score: -0.7227156
INFO: simple score: -0.719615
INFO: inputs score: -0.7036145
INFO: effect score: -0.7026603
INFO: object score: -0.6992274
INFO: type score: -0.69828653
INFO: basic score: -0.69729954
INFO: component score: -0.6928359
INFO: calculation score: -0.68956584
INFO: variable score: -0.68946534
INFO: problem score: -0.68252736
INFO: normal score: -0.6802263
INFO: similar score: -0.6797476
INFO: method score: -0.6781858
INFO: process score: -0.67697996
INFO: different score: -0.67668337
INFO: well score: -0.6718966
INFO: useful score: -0.67154896
INFO: value score: -0.667025
INFO: arbitrary score: -0.6633082
INFO: model score: -0.6595504
INFO: complicated score: -0.65587896
INFO: concept score: -0.65514123
INFO: real score: -0.6534506
INFO: explicit score: -0.6482105
INFO: true score: -0.6475461
INFO: case score: -0.63404095
INFO: need score: -0.6332032
INFO: look score: -0.6331175
INFO: fact score: -0.6323531
INFO: key score: -0.6320756
INFO: structure score: -0.6317764
INFO: result score: -0.629594
INFO: contexts score: -0.62533665
INFO: solution score: -0.6175538
INFO: internal score: -0.6162131
INFO: restriction score: -0.6128534
INFO: error score: -0.61090535
INFO: approach score: -0.6089386
INFO: parameter score: -0.60529685
INFO: multiple score: -0.6027039
INFO: scheme score: -0.60118586
INFO: explanation score: -0.5994144
INFO: clear score: -0.5937409
INFO: create score: -0.5928167
INFO: item score: -0.5891061
INFO: target score: -0.5889092
INFO: condition score: -0.5878469
INFO: issue score: -0.5839944
INFO: mutable score: -0.5835728
INFO: scope score: -0.581884
INFO: common score: -0.5812307
INFO: code score: -0.5794719
INFO: requirement score: -0.57890326
INFO: information score: -0.57524675
INFO: addition score: -0.573678
INFO: sense score: -0.5653549
INFO: significant score: -0.56320506
INFO: other score: -0.56042606
INFO: generator score: -0.5589773
INFO: point score: -0.55667275
INFO: separate score: -0.5527805
INFO: diagram score: -0.55271626
INFO: additional score: -0.551044
INFO: kind score: -0.5496474
INFO: default score: -0.5484981
INFO: content score: -0.5469282
INFO: tool score: -0.54680157
INFO: reliable score: -0.54670787
INFO: careful score: -0.5445768
INFO: address score: -0.5445652
INFO: test score: -0.5438074
INFO: output score: -0.5429953
INFO: incorrect score: -0.54062843
INFO: immutable score: -0.53689754
INFO: pointer score: -0.53087735
INFO: data score: -0.5293901
INFO: original score: -0.52317053
INFO: hold score: -0.5225265
INFO: easy score: -0.5190563
INFO: handle score: -0.51796764
INFO: update score: -0.51601064
INFO: word score: -0.5102137
INFO: understand score: -0.5074518
INFO: idea score: -0.50723267
INFO: way score: -0.5053987
INFO: prefer score: -0.5050739
INFO: one score: -0.48881143
INFO: simulate score: -0.48702997
INFO: implement score: -0.4866551
INFO: copy score: -0.485635
INFO: lookup score: -0.48353848
INFO: behavior score: -0.4828121
INFO: memory score: -0.48229957
INFO: question score: -0.48223093
INFO: inconvenient score: -0.48175886
INFO: quite score: -0.47792217
INFO: accept score: -0.47722828
INFO: option score: -0.47569972
INFO: general score: -0.4756251
INFO: self score: -0.47392508
INFO: body score: -0.47021374
INFO: name score: -0.46645766
INFO: database score: -0.46334073
INFO: statement score: -0.463004
INFO: argument score: -0.46269593
INFO: new score: -0.4617863
INFO: traditional score: -0.46023452
INFO: many score: -0.45523947
INFO: boolean score: -0.45341375
INFO: location score: -0.4492143
INFO: documentation score: -0.44897363
INFO: tuple score: -0.44846573
INFO: hand score: -0.4477365
INFO: array score: -0.44699582
INFO: single score: -0.44492817
INFO: operator score: -0.44316986
INFO: entry score: -0.4408429
INFO: insight score: -0.4404355
INFO: empty score: -0.43919286
INFO: long score: -0.43778715
INFO: execute score: -0.43642166
INFO: integer score: -0.43397605
INFO: functionality score: -0.4336391
INFO: hint score: -0.43305185
INFO: little score: -0.4323442
INFO: able score: -0.43054006
INFO: thread score: -0.42916855
INFO: design score: -0.42774177
INFO: visible score: -0.42589825
INFO: window score: -0.424846
INFO: call score: -0.4239305
INFO: treat score: -0.42314965
INFO: list score: -0.4210121
INFO: date score: -0.41807532
INFO: topic score: -0.41776928
INFO: situation score: -0.41550574
INFO: field score: -0.41079512
INFO: namespace score: -0.40960863
INFO: time score: -0.40801707
INFO: suggestion score: -0.40345103
INFO: identifier score: -0.40232533
INFO: practice score: -0.40179586
INFO: dummy score: -0.39769357
INFO: subclass score: -0.39526215
INFO: bind score: -0.39288625
INFO: section score: -0.388609
INFO: global score: -0.38860705
INFO: inside score: -0.38643274
INFO: reading score: -0.38299266
INFO: good score: -0.38243797
INFO: workaround score: -0.37975508
INFO: property score: -0.37868264
INFO: end score: -0.37096903
INFO: safe score: -0.36830375
INFO: assignment score: -0.36713862
INFO: execution score: -0.36458477
INFO: class score: -0.36317816
INFO: multi score: -0.36300358
INFO: state score: -0.35963556
INFO: access score: -0.35591555
INFO: answer score: -0.35558808
INFO: string score: -0.35525146
INFO: funny score: -0.34918323
INFO: mention score: -0.34804347
INFO: figure score: -0.34448838
INFO: naive score: -0.3443445
INFO: outside score: -0.34161264
INFO: language score: -0.34072724
INFO: work score: -0.34034875
INFO: line score: -0.33948848
INFO: right score: -0.339021
INFO: screen score: -0.33546692
INFO: n score: -0.3350024
INFO: wrapper score: -0.33232555
INFO: sure score: -0.33136904
INFO: post score: -0.330138
INFO: arrow score: -0.3300186
INFO: interesting score: -0.32594785
INFO: thing score: -0.32416838
INFO: mind score: -0.3238827
INFO: b score: -0.3235402
INFO: print score: -0.3219365
INFO: c score: -0.32191455
INFO: const score: -0.32084128
INFO: wrap score: -0.32058403
INFO: command score: -0.31938535
INFO: programming score: -0.31706858
INFO: outer score: -0.3131132
INFO: program score: -0.31278992
INFO: dictionary score: -0.3105806
INFO: local score: -0.30924508
INFO: arg score: -0.3072773
INFO: x score: -0.30726737
INFO: javascript score: -0.30127898
INFO: edit score: -0.28561226
INFO: perl score: -0.28437284
INFO: mutation score: -0.28118625
INFO: caller score: -0.27991706
INFO: show score: -0.27837417
INFO: first score: -0.27396828
INFO: convincing score: -0.27237347
INFO: collection score: -0.26282927
INFO: dict score: -0.26238552
INFO: side score: -0.26169875
INFO: container score: -0.25977945
INFO: pass score: -0.257685
INFO: java score: -0.2558329
INFO: hack score: -0.2546066
INFO: handy score: -0.25312307
INFO: lot score: -0.25228325
INFO: calling score: -0.2516133
INFO: place score: -0.25045678
INFO: opinion score: -0.25002286
INFO: green score: -0.24926625
INFO: dll score: -0.24583778
INFO: = score: -0.24296467
INFO: great score: -0.23989607
INFO: return score: -0.22430108
INFO: int score: -0.2215316
INFO: numpy score: -0.21737145
INFO: dubious score: -0.21184334
INFO: faq score: -0.20967253
INFO: strange score: -0.2034062
INFO: worth score: -0.19889292
INFO: num score: -0.19023353
INFO: store score: -0.18956365
INFO: os score: -0.18724476
INFO: hope score: -0.18582413
INFO: snippet score: -0.18494402
INFO: elegant score: -0.18231332
INFO: second score: -0.17635287
INFO: script score: -0.17320514
INFO: c++ score: -0.16724576
INFO: yellow score: -0.16086994
INFO: people score: -0.1522819
INFO: str score: -0.15194094
INFO: yesterday score: -0.14106986
INFO: stuff score: -0.10929342
INFO: mat score: -0.1016997
INFO: publishing score: -0.07629868
INFO: year score: -0.069616996
INFO: member score: -0.064478606
INFO: api score: -0.06313408
INFO: var score: -0.060791686
INFO: ugly score: -0.052123886
INFO: fun score: -0.047148157
INFO: trick score: -0.04552441
INFO: dataclasse score: -0.0
INFO: ctype score: -0.0
INFO: pythonic score: -0.0
INFO: fortran score: -0.0
INFO: fredrik score: -0.0
INFO: lundh score: -0.0
INFO: @refproperty score: -0.0
INFO: self._myvar score: -0.0
INFO: setattr score: -0.0
INFO: functools.partial score: -0.0
INFO: settatr score: -0.0
INFO: self.variable score: -0.0
INFO: outer_list score: -0.0
INFO: the_list score: -0.0
INFO: http://docs.python.org/3/faq/programming.html#what-are-the-rules-for-local-and-global-variables-in-python score: -0.0
INFO: change_me score: -0.0
INFO: blair score: -0.0
INFO: conrad score: -0.0
INFO: cournapeau score: -0.0
INFO: my_fun score: -0.0
INFO: out_arr score: -0.0
INFO: tark score: -0.0
INFO: tolonen score: -0.0
INFO: pywin32 score: -0.0
INFO: readbinfile(filename score: -0.0
INFO: wantarray score: -0.0
INFO: pointer(ctype score: -0.0
INFO: unncessary score: -0.0
INFO: a. score: -0.0
INFO: b. score: -0.0
INFO: num1 score: -0.0
INFO: num2 score: -0.0
INFO: test_func2(num score: -0.0
INFO: test_func(test_obj score: -0.0
INFO: test_obj score: -0.0
INFO: testclass score: -0.0
INFO: typemap score: -0.0
INFO: dict.hpp score: -0.0
INFO: dict.i score: -0.0
INFO: folk score: 0.007881902
INFO: david score: 0.019795032
INFO: title score: 0.031651154
INFO: pep score: 0.051478874
INFO: decorator score: 0.09195645
INFO: tutor score: 0.11440807
INFO: masterclass score: 0.12948753
INFO: ============================================================
INFO: --------------------
INFO: How do you make a higher order function in Python?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<226 unique tokens: ['argument', 'callable', 'class', 'convenient', 'debate']...> from 9 documents (total 555 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<226 unique tokens: ['argument', 'callable', 'class', 'convenient', 'debate']...> from 9 documents (total 555 corpus positions)", 'datetime': '2023-03-20T16:52:57.134502', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 9 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.256 per-word bound, 152.8 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 0, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.061*"function" + 0.047*"argument" + 0.029*"high" + 0.025*"order" + 0.023*"type" + 0.019*"positional" + 0.018*"f" + 0.018*"args" + 0.017*"decorator" + 0.017*"return"
INFO: topic #1 (1.000): 0.178*"function" + 0.078*"argument" + 0.034*"order" + 0.032*"high" + 0.032*"decorator" + 0.030*"name" + 0.022*"call" + 0.016*"lambda" + 0.016*"way" + 0.014*"return"
INFO: topic #2 (1.000): 0.040*"function" + 0.038*"argument" + 0.025*"high" + 0.021*"type" + 0.019*"positional" + 0.016*"tuple" + 0.016*"order" + 0.016*"return" + 0.015*"decorator" + 0.015*"args"
INFO: topic diff=4.982106, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.377 per-word bound, 1330.0 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 0, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.069*"function" + 0.033*"argument" + 0.031*"return" + 0.028*"class" + 0.025*"f" + 0.020*"new" + 0.018*"high" + 0.016*"order" + 0.014*"version" + 0.014*"hof"
INFO: topic #1 (1.000): 0.206*"function" + 0.063*"argument" + 0.044*"example" + 0.030*"order" + 0.030*"class" + 0.028*"return" + 0.028*"high" + 0.022*"reference" + 0.021*"time" + 0.021*"way"
INFO: topic #2 (1.000): 0.041*"function" + 0.033*"first" + 0.030*"new" + 0.029*"html_tag" + 0.026*"return" + 0.024*"second" + 0.022*"argument" + 0.014*"high" + 0.014*"multiple" + 0.014*"hof"
INFO: topic diff=4.236423, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 53.02342179258817
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -3.6082238346471533
DEBUG: bound: at document #0
INFO: -5.681 per-word bound, 51.3 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 1, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.045*"function" + 0.035*"argument" + 0.030*"return" + 0.028*"f" + 0.026*"type" + 0.018*"class" + 0.017*"high" + 0.017*"first" + 0.017*"args" + 0.016*"programming"
INFO: topic #1 (1.000): 0.185*"function" + 0.072*"argument" + 0.034*"order" + 0.032*"high" + 0.027*"decorator" + 0.024*"name" + 0.022*"example" + 0.020*"call" + 0.019*"return" + 0.018*"way"
INFO: topic #2 (1.000): 0.036*"function" + 0.032*"first" + 0.025*"new" + 0.025*"html_tag" + 0.023*"return" + 0.020*"argument" + 0.020*"second" + 0.014*"multiple" + 0.013*"high" + 0.012*"version"
INFO: topic diff=1.069040, rho=0.512989
DEBUG: bound: at document #0
INFO: -6.227 per-word bound, 74.9 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 1, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.041*"function" + 0.030*"argument" + 0.029*"return" + 0.028*"f" + 0.024*"class" + 0.019*"type" + 0.016*"programming" + 0.014*"high" + 0.013*"first" + 0.012*"args"
INFO: topic #1 (1.000): 0.206*"function" + 0.067*"argument" + 0.042*"example" + 0.034*"order" + 0.032*"class" + 0.031*"high" + 0.023*"return" + 0.021*"decorator" + 0.021*"way" + 0.021*"reference"
INFO: topic #2 (1.000): 0.040*"function" + 0.037*"new" + 0.032*"html_tag" + 0.030*"return" + 0.027*"first" + 0.025*"second" + 0.018*"version" + 0.018*"hof" + 0.016*"time" + 0.014*"argument"
INFO: topic diff=0.997487, rho=0.512989
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 44.55827370801575
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -5.696101153194561
DEBUG: bound: at document #0
INFO: -5.425 per-word bound, 43.0 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 2, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.036*"type" + 0.034*"argument" + 0.031*"args" + 0.030*"tuple" + 0.028*"f" + 0.026*"return" + 0.023*"function" + 0.021*"programming" + 0.019*"solution" + 0.019*"element"
INFO: topic #1 (1.000): 0.189*"function" + 0.073*"argument" + 0.035*"order" + 0.033*"high" + 0.028*"decorator" + 0.024*"name" + 0.023*"example" + 0.020*"call" + 0.019*"class" + 0.019*"way"
INFO: topic #2 (1.000): 0.038*"function" + 0.034*"new" + 0.029*"html_tag" + 0.029*"return" + 0.027*"first" + 0.024*"second" + 0.017*"hof" + 0.017*"version" + 0.015*"time" + 0.014*"argument"
INFO: topic diff=0.786877, rho=0.456435
DEBUG: bound: at document #0
INFO: -5.799 per-word bound, 55.7 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 2, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.028*"type" + 0.028*"argument" + 0.024*"f" + 0.024*"args" + 0.023*"tuple" + 0.023*"return" + 0.020*"function" + 0.019*"programming" + 0.016*"body" + 0.015*"solution"
INFO: topic #1 (1.000): 0.204*"function" + 0.071*"argument" + 0.041*"example" + 0.036*"order" + 0.033*"high" + 0.032*"class" + 0.023*"decorator" + 0.022*"way" + 0.021*"value" + 0.020*"reference"
INFO: topic #2 (1.000): 0.043*"function" + 0.037*"new" + 0.034*"return" + 0.032*"html_tag" + 0.026*"first" + 0.025*"second" + 0.020*"time" + 0.019*"hof" + 0.019*"version" + 0.013*"reason"
INFO: topic diff=0.589914, rho=0.456435
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 41.469639526957295
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -6.233045382007897
DEBUG: bound: at document #0
INFO: -5.282 per-word bound, 38.9 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 3, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.040*"type" + 0.038*"args" + 0.037*"tuple" + 0.033*"argument" + 0.024*"f" + 0.022*"programming" + 0.021*"return" + 0.021*"body" + 0.021*"solution" + 0.021*"element"
INFO: topic #1 (1.000): 0.191*"function" + 0.074*"argument" + 0.036*"order" + 0.034*"high" + 0.028*"decorator" + 0.024*"example" + 0.024*"name" + 0.021*"call" + 0.020*"class" + 0.019*"way"
INFO: topic #2 (1.000): 0.041*"function" + 0.035*"new" + 0.033*"return" + 0.030*"html_tag" + 0.026*"first" + 0.024*"second" + 0.019*"time" + 0.018*"hof" + 0.018*"version" + 0.013*"multiple"
INFO: topic diff=0.568041, rho=0.415227
DEBUG: bound: at document #0
INFO: -5.715 per-word bound, 52.5 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 3, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.032*"type" + 0.030*"args" + 0.030*"tuple" + 0.028*"argument" + 0.021*"f" + 0.020*"programming" + 0.018*"return" + 0.018*"body" + 0.017*"solution" + 0.017*"element"
INFO: topic #1 (1.000): 0.203*"function" + 0.073*"argument" + 0.040*"example" + 0.037*"order" + 0.034*"high" + 0.030*"class" + 0.024*"decorator" + 0.022*"way" + 0.021*"value" + 0.019*"reference"
INFO: topic #2 (1.000): 0.046*"function" + 0.037*"new" + 0.037*"return" + 0.031*"html_tag" + 0.026*"first" + 0.025*"second" + 0.024*"time" + 0.019*"hof" + 0.019*"version" + 0.013*"f"
INFO: topic diff=0.383775, rho=0.415227
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 40.282822164976054
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -7.301787175597792
DEBUG: bound: at document #0
INFO: -5.217 per-word bound, 37.2 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 4, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.042*"type" + 0.040*"args" + 0.040*"tuple" + 0.032*"argument" + 0.022*"programming" + 0.022*"f" + 0.022*"body" + 0.021*"list" + 0.021*"solution" + 0.021*"element"
INFO: topic #1 (1.000): 0.191*"function" + 0.076*"argument" + 0.037*"order" + 0.035*"high" + 0.028*"decorator" + 0.025*"example" + 0.024*"name" + 0.021*"call" + 0.020*"class" + 0.020*"way"
INFO: topic #2 (1.000): 0.044*"function" + 0.037*"return" + 0.035*"new" + 0.030*"html_tag" + 0.026*"first" + 0.024*"second" + 0.022*"time" + 0.018*"version" + 0.018*"hof" + 0.013*"f"
INFO: topic diff=0.419459, rho=0.383482
DEBUG: bound: at document #0
INFO: -5.681 per-word bound, 51.3 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 4, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.034*"type" + 0.032*"args" + 0.032*"tuple" + 0.027*"argument" + 0.020*"programming" + 0.019*"f" + 0.019*"body" + 0.018*"list" + 0.018*"solution" + 0.018*"element"
INFO: topic #1 (1.000): 0.202*"function" + 0.075*"argument" + 0.039*"example" + 0.038*"order" + 0.036*"high" + 0.027*"class" + 0.024*"decorator" + 0.022*"way" + 0.021*"value" + 0.019*"reference"
INFO: topic #2 (1.000): 0.049*"function" + 0.039*"return" + 0.037*"new" + 0.031*"html_tag" + 0.026*"first" + 0.026*"time" + 0.025*"second" + 0.019*"hof" + 0.019*"version" + 0.014*"f"
INFO: topic diff=0.301473, rho=0.383482
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 39.77651820126864
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -7.677080895843698
DEBUG: bound: at document #0
INFO: -5.186 per-word bound, 36.4 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 5, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.042*"type" + 0.041*"args" + 0.041*"tuple" + 0.031*"argument" + 0.023*"programming" + 0.022*"body" + 0.022*"list" + 0.021*"solution" + 0.021*"element" + 0.021*"https://docs.python.org/3/library/typing.html#callable"
INFO: topic #1 (1.000): 0.191*"function" + 0.076*"argument" + 0.037*"order" + 0.036*"high" + 0.028*"decorator" + 0.026*"example" + 0.024*"name" + 0.021*"call" + 0.020*"way" + 0.019*"class"
INFO: topic #2 (1.000): 0.047*"function" + 0.039*"return" + 0.035*"new" + 0.029*"html_tag" + 0.026*"first" + 0.025*"time" + 0.024*"second" + 0.018*"hof" + 0.018*"version" + 0.014*"f"
INFO: topic diff=0.336175, rho=0.358057
DEBUG: bound: at document #0
INFO: -5.660 per-word bound, 50.6 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 5, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.035*"type" + 0.034*"args" + 0.034*"tuple" + 0.027*"argument" + 0.020*"programming" + 0.020*"body" + 0.018*"f" + 0.018*"list" + 0.018*"solution" + 0.018*"element"
INFO: topic #1 (1.000): 0.201*"function" + 0.077*"argument" + 0.039*"example" + 0.039*"order" + 0.037*"high" + 0.025*"decorator" + 0.023*"way" + 0.022*"class" + 0.021*"value" + 0.019*"reference"
INFO: topic #2 (1.000): 0.052*"function" + 0.040*"return" + 0.036*"new" + 0.031*"html_tag" + 0.027*"time" + 0.026*"first" + 0.024*"second" + 0.019*"class" + 0.018*"hof" + 0.018*"version"
INFO: topic diff=0.274579, rho=0.358057
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 39.48475447846175
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -7.692484166522797
DEBUG: bound: at document #0
INFO: -5.168 per-word bound, 35.9 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 6, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.043*"type" + 0.041*"args" + 0.041*"tuple" + 0.030*"argument" + 0.023*"programming" + 0.022*"body" + 0.022*"list" + 0.022*"solution" + 0.022*"element" + 0.022*"https://docs.python.org/3/library/typing.html#callable"
INFO: topic #1 (1.000): 0.191*"function" + 0.077*"argument" + 0.038*"order" + 0.037*"high" + 0.029*"decorator" + 0.026*"example" + 0.024*"name" + 0.021*"call" + 0.020*"way" + 0.017*"class"
INFO: topic #2 (1.000): 0.050*"function" + 0.040*"return" + 0.035*"new" + 0.029*"html_tag" + 0.026*"first" + 0.026*"time" + 0.023*"second" + 0.019*"class" + 0.018*"version" + 0.018*"hof"
INFO: topic diff=0.288055, rho=0.337100
DEBUG: bound: at document #0
INFO: -5.644 per-word bound, 50.0 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 6, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.036*"type" + 0.034*"args" + 0.034*"tuple" + 0.027*"argument" + 0.020*"programming" + 0.020*"body" + 0.019*"list" + 0.018*"solution" + 0.018*"element" + 0.018*"https://docs.python.org/3/library/typing.html#callable"
INFO: topic #1 (1.000): 0.199*"function" + 0.078*"argument" + 0.039*"order" + 0.039*"example" + 0.038*"high" + 0.025*"decorator" + 0.023*"way" + 0.020*"value" + 0.019*"name" + 0.019*"call"
INFO: topic #2 (1.000): 0.055*"function" + 0.041*"return" + 0.036*"new" + 0.030*"html_tag" + 0.027*"time" + 0.026*"class" + 0.025*"first" + 0.024*"second" + 0.018*"version" + 0.018*"hof"
INFO: topic diff=0.255305, rho=0.337100
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 39.29102436715871
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -7.898416908394748
DEBUG: bound: at document #0
INFO: -5.155 per-word bound, 35.6 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 7, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.043*"type" + 0.041*"args" + 0.041*"tuple" + 0.030*"argument" + 0.023*"programming" + 0.022*"body" + 0.022*"list" + 0.022*"solution" + 0.022*"element" + 0.022*"https://docs.python.org/3/library/typing.html#callable"
INFO: topic #1 (1.000): 0.191*"function" + 0.078*"argument" + 0.038*"order" + 0.037*"high" + 0.029*"decorator" + 0.026*"example" + 0.024*"name" + 0.021*"call" + 0.020*"way" + 0.015*"value"
INFO: topic #2 (1.000): 0.053*"function" + 0.042*"return" + 0.034*"new" + 0.029*"html_tag" + 0.026*"time" + 0.026*"first" + 0.025*"class" + 0.023*"second" + 0.017*"version" + 0.017*"hof"
INFO: topic diff=0.258689, rho=0.319438
DEBUG: bound: at document #0
INFO: -5.633 per-word bound, 49.6 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 7, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.036*"type" + 0.035*"args" + 0.035*"tuple" + 0.026*"argument" + 0.021*"programming" + 0.020*"body" + 0.019*"list" + 0.019*"multiple" + 0.019*"solution" + 0.019*"element"
INFO: topic #1 (1.000): 0.198*"function" + 0.080*"argument" + 0.039*"order" + 0.039*"high" + 0.038*"example" + 0.025*"decorator" + 0.023*"way" + 0.020*"value" + 0.019*"name" + 0.019*"call"
INFO: topic #2 (1.000): 0.058*"function" + 0.041*"return" + 0.036*"new" + 0.031*"class" + 0.030*"html_tag" + 0.028*"time" + 0.025*"first" + 0.024*"second" + 0.018*"version" + 0.018*"hof"
INFO: topic diff=0.240471, rho=0.319438
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 39.16020316181694
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -7.919827069564384
DEBUG: bound: at document #0
INFO: -5.146 per-word bound, 35.4 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 8, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.043*"type" + 0.041*"args" + 0.041*"tuple" + 0.029*"argument" + 0.023*"programming" + 0.023*"body" + 0.022*"list" + 0.022*"solution" + 0.022*"element" + 0.022*"https://docs.python.org/3/library/typing.html#callable"
INFO: topic #1 (1.000): 0.190*"function" + 0.079*"argument" + 0.038*"order" + 0.038*"high" + 0.029*"decorator" + 0.027*"example" + 0.024*"name" + 0.021*"call" + 0.020*"way" + 0.015*"value"
INFO: topic #2 (1.000): 0.056*"function" + 0.042*"return" + 0.034*"new" + 0.030*"class" + 0.028*"html_tag" + 0.027*"time" + 0.026*"first" + 0.023*"second" + 0.017*"version" + 0.017*"hof"
INFO: topic diff=0.238778, rho=0.304290
DEBUG: bound: at document #0
INFO: -5.625 per-word bound, 49.3 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 8, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.037*"type" + 0.035*"args" + 0.035*"tuple" + 0.026*"argument" + 0.021*"programming" + 0.021*"body" + 0.019*"multiple" + 0.019*"list" + 0.019*"solution" + 0.019*"element"
INFO: topic #1 (1.000): 0.196*"function" + 0.081*"argument" + 0.039*"order" + 0.039*"high" + 0.038*"example" + 0.026*"decorator" + 0.023*"way" + 0.020*"value" + 0.020*"name" + 0.019*"call"
INFO: topic #2 (1.000): 0.061*"function" + 0.042*"return" + 0.035*"new" + 0.034*"class" + 0.029*"html_tag" + 0.028*"time" + 0.025*"first" + 0.024*"second" + 0.018*"hof" + 0.018*"version"
INFO: topic diff=0.228242, rho=0.304290
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 39.066993185689476
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -7.922830514809628
DEBUG: bound: at document #0
INFO: -5.139 per-word bound, 35.2 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 9, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.043*"type" + 0.042*"args" + 0.042*"tuple" + 0.029*"argument" + 0.023*"programming" + 0.023*"body" + 0.022*"list" + 0.022*"solution" + 0.022*"element" + 0.022*"https://docs.python.org/3/library/typing.html#callable"
INFO: topic #1 (1.000): 0.189*"function" + 0.080*"argument" + 0.038*"order" + 0.038*"high" + 0.029*"decorator" + 0.027*"example" + 0.024*"name" + 0.021*"call" + 0.020*"way" + 0.015*"value"
INFO: topic #2 (1.000): 0.059*"function" + 0.043*"return" + 0.034*"new" + 0.033*"class" + 0.028*"html_tag" + 0.027*"time" + 0.027*"first" + 0.023*"second" + 0.017*"version" + 0.017*"hof"
INFO: topic diff=0.224313, rho=0.291111
DEBUG: bound: at document #0
INFO: -5.618 per-word bound, 49.1 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 9, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.037*"type" + 0.036*"args" + 0.036*"tuple" + 0.026*"argument" + 0.021*"programming" + 0.021*"body" + 0.019*"multiple" + 0.019*"list" + 0.019*"solution" + 0.019*"element"
INFO: topic #1 (1.000): 0.195*"function" + 0.081*"argument" + 0.040*"order" + 0.039*"high" + 0.038*"example" + 0.026*"decorator" + 0.023*"way" + 0.020*"value" + 0.020*"name" + 0.019*"call"
INFO: topic #2 (1.000): 0.064*"function" + 0.042*"return" + 0.036*"class" + 0.035*"new" + 0.029*"html_tag" + 0.028*"time" + 0.025*"first" + 0.023*"second" + 0.018*"version" + 0.018*"hof"
INFO: topic diff=0.217648, rho=0.291111
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 38.99555242292675
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -7.922830514809628
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5> in 0.13s', 'datetime': '2023-03-20T16:52:57.261778', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/questions/9/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-20T16:52:57.261943', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/questions/9/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/9/model.state
DEBUG: {'uri': 'model/questions/9/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/questions/9/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-20T16:52:57.264262', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/questions/9/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/questions/9/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/9/model
INFO: topic #0 (1.000): 0.037*"type" + 0.036*"args" + 0.036*"tuple" + 0.026*"argument" + 0.021*"programming" + 0.021*"body" + 0.019*"multiple" + 0.019*"list" + 0.019*"solution" + 0.019*"element"
INFO: topic #1 (1.000): 0.195*"function" + 0.081*"argument" + 0.040*"order" + 0.039*"high" + 0.038*"example" + 0.026*"decorator" + 0.023*"way" + 0.020*"value" + 0.020*"name" + 0.019*"call"
INFO: topic #2 (1.000): 0.064*"function" + 0.042*"return" + 0.036*"class" + 0.035*"new" + 0.029*"html_tag" + 0.028*"time" + 0.025*"first" + 0.023*"second" + 0.018*"version" + 0.018*"hof"
INFO: Question Similarity: [0.10462534427642822, 0.14560920000076294, 0.2888372540473938, 0.4489741325378418, 0.05246710777282715, 0.3915720582008362, 0.4021875858306885, 0.14681553840637207, 0.5099236369132996, 0.15382105112075806]
INFO: 72341442: -0.08051170608675288
INFO: 72341776: -0.08069089132427644
INFO: 72341506: -0.08638533831140095
INFO: 62328793: -0.1646680300294181
INFO: 62328997: -0.16735485326430224
INFO: 74854675: -0.22573194475346145
INFO: 50623708: -0.33417447374430115
INFO: 65901747: -0.3453062262536581
INFO: 74483521: -0.5962469556500588
INFO: 74483522: -0.6967476640484113
INFO: 70168888: -0.7953821875105548
INFO: 70168821: -0.8639813164502662
INFO: 70168970: -0.8798813606493603
INFO: 70170703: -0.9126563099743137
INFO: 61810300: -1.0099533279880981
INFO: 70170666: -1.0145512592421264
INFO: 61810249: -1.0984295645303548
INFO: 61810298: -1.1439733874929703
INFO: Recommended Keywords
INFO: first score: -0.8546732
INFO: possible score: -0.85346246
INFO: example score: -0.8398758
INFO: time score: -0.8395551
INFO: order score: -0.8106762
INFO: element score: -0.8070449
INFO: give score: -0.79927605
INFO: reason score: -0.78348964
INFO: second score: -0.78112465
INFO: change score: -0.7804322
INFO: case score: -0.76500225
INFO: new score: -0.7519959
INFO: choice score: -0.74868876
INFO: way score: -0.7485424
INFO: type score: -0.745052
INFO: pre score: -0.74125594
INFO: simple score: -0.7231045
INFO: multiple score: -0.7135776
INFO: solution score: -0.70991534
INFO: convenient score: -0.70023894
INFO: function score: -0.6580394
INFO: invoke score: -0.6576008
INFO: result score: -0.6512078
INFO: run score: -0.6490019
INFO: object score: -0.64553696
INFO: note score: -0.6408038
INFO: argument score: -0.6385723
INFO: extra score: -0.63117546
INFO: individual score: -0.6191291
INFO: call score: -0.6061971
INFO: positional score: -0.5766313
INFO: advantage score: -0.5752581
INFO: expression score: -0.569919
INFO: shorthand score: -0.5664216
INFO: key score: -0.56589806
INFO: benefit score: -0.5657186
INFO: single score: -0.5627621
INFO: refer score: -0.561143
INFO: link score: -0.5607839
INFO: step score: -0.5595098
INFO: class score: -0.5591576
INFO: statement score: -0.55785596
INFO: additional score: -0.5503374
INFO: tuple score: -0.5388488
INFO: instance score: -0.532487
INFO: available score: -0.5247606
INFO: high score: -0.51840895
INFO: helper score: -0.51713616
INFO: real score: -0.49618873
INFO: body score: -0.49267742
INFO: guess score: -0.49252445
INFO: signature score: -0.4843983
INFO: name score: -0.48318535
INFO: mind score: -0.47760364
INFO: memory score: -0.47723958
INFO: difference score: -0.47664356
INFO: equivalent score: -0.47543755
INFO: version score: -0.46981084
INFO: code score: -0.46214214
INFO: phrase score: -0.4590042
INFO: programming score: -0.45405436
INFO: detail score: -0.44643718
INFO: return score: -0.4445108
INFO: need score: -0.44337964
INFO: default score: -0.4408173
INFO: redundant score: -0.43309313
INFO: args score: -0.43018243
INFO: resource score: -0.42506352
INFO: different score: -0.42278782
INFO: debate score: -0.41981596
INFO: reference score: -0.41514796
INFO: operation score: -0.40796018
INFO: block score: -0.40202495
INFO: list score: -0.3905002
INFO: execute score: -0.3744886
INFO: problem score: -0.37222743
INFO: f score: -0.36803886
INFO: conditional score: -0.36234406
INFO: sum score: -0.35675296
INFO: state score: -0.34901175
INFO: unnamed score: -0.34507498
INFO: later score: -0.3357565
INFO: parameter score: -0.3326092
INFO: string score: -0.32005715
INFO: core score: -0.31956375
INFO: mode score: -0.30829614
INFO: pointer score: -0.30261263
INFO: attribute score: -0.30109522
INFO: ref score: -0.29700398
INFO: syntactic score: -0.29391065
INFO: talk score: -0.28639582
INFO: syntax score: -0.28404188
INFO: efficient score: -0.27540275
INFO: callable score: -0.26881507
INFO: print score: -0.2559481
INFO: define score: -0.25435102
INFO: learn score: -0.2379037
INFO: value score: -0.2300332
INFO: functional score: -0.22464362
INFO: relevant score: -0.20693216
INFO: research score: -0.2044883
INFO: online score: -0.20012611
INFO: hof score: -0.18447936
INFO: lot score: -0.18250667
INFO: func score: -0.18234327
INFO: variable score: -0.16976956
INFO: wiil score: -0.16071086
INFO: lambda score: -0.1590146
INFO: maximal score: -0.1520336
INFO: lst score: -0.14649075
INFO: last score: -0.11594664
INFO: decorator score: -0.096371055
INFO: datum score: -0.09563393
INFO: x score: -0.08524982
INFO: homework score: -0.07226952
INFO: panda score: -0.05547113
INFO: g score: -0.04327812
INFO: weird score: -0.0141124595
INFO: fnc score: -0.0
INFO: fnc(*args score: -0.0
INFO: https://docs.python.org/3/library/typing.html#callable score: -0.0
INFO: make_function_print_arg score: -0.0
INFO: f(x score: -0.0
INFO: html_tag score: -0.0
INFO: print_h1 score: -0.0
INFO: def score: 0.050540056
INFO: ============================================================
INFO: --------------------
INFO: How do I copy an object in Python?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<147 unique tokens: ['assignment', 'batchelder', 'case', 'copy', 'copy.deepcopy']...> from 10 documents (total 393 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<147 unique tokens: ['assignment', 'batchelder', 'case', 'copy', 'copy.deepcopy']...> from 10 documents (total 393 corpus positions)", 'datetime': '2023-03-20T16:52:59.318901', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.440 per-word bound, 173.6 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.053*"copy" + 0.052*"deepcopy" + 0.047*"object" + 0.029*"reference" + 0.020*"lots_of_data" + 0.020*"dictionary" + 0.020*"new" + 0.018*"name" + 0.017*"df" + 0.016*"foo"
INFO: topic #1 (1.000): 0.085*"object" + 0.061*"deepcopy" + 0.054*"copy" + 0.029*"df" + 0.026*"instance" + 0.026*"reference" + 0.025*"dictionary" + 0.020*"name" + 0.020*"answer" + 0.018*"new"
INFO: topic #2 (1.000): 0.068*"object" + 0.050*"copy" + 0.043*"reference" + 0.039*"new" + 0.038*"name" + 0.032*"instance" + 0.031*"list" + 0.029*"df" + 0.027*"deepcopy" + 0.026*"variable"
INFO: topic diff=4.799085, rho=1.000000
DEBUG: bound: at document #0
INFO: -9.431 per-word bound, 690.4 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.158*"copy" + 0.082*"object" + 0.039*"deep" + 0.033*"method" + 0.029*"deepcopy" + 0.027*"shallow" + 0.022*"change" + 0.021*"immutable" + 0.019*"interior" + 0.016*"mutable"
INFO: topic #1 (1.000): 0.136*"object" + 0.135*"copy" + 0.053*"class" + 0.050*"deepcopy" + 0.049*"shallow" + 0.021*"new" + 0.019*"instance" + 0.018*"value" + 0.016*"reference" + 0.015*"answer"
INFO: topic #2 (1.000): 0.136*"copy" + 0.097*"object" + 0.067*"list" + 0.056*"new" + 0.042*"original" + 0.041*"shallow" + 0.032*"reference" + 0.020*"memory" + 0.019*"deep" + 0.017*"case"
INFO: topic diff=4.714206, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 43.111126735859095
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -1.5870907682449484
DEBUG: bound: at document #0
INFO: -6.668 per-word bound, 101.7 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.148*"copy" + 0.078*"object" + 0.036*"deep" + 0.030*"method" + 0.029*"deepcopy" + 0.025*"shallow" + 0.021*"change" + 0.019*"immutable" + 0.018*"interior" + 0.015*"mutable"
INFO: topic #1 (1.000): 0.108*"object" + 0.101*"copy" + 0.073*"deepcopy" + 0.034*"class" + 0.032*"shallow" + 0.024*"dictionary" + 0.022*"answer" + 0.020*"memo" + 0.017*"instance" + 0.017*"lots_of_data"
INFO: topic #2 (1.000): 0.084*"copy" + 0.082*"object" + 0.054*"new" + 0.052*"list" + 0.047*"reference" + 0.032*"name" + 0.028*"instance" + 0.027*"df" + 0.026*"original" + 0.026*"shallow"
INFO: topic diff=1.223133, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.072 per-word bound, 33.6 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.164*"copy" + 0.101*"object" + 0.042*"deep" + 0.041*"shallow" + 0.037*"method" + 0.024*"change" + 0.022*"deepcopy" + 0.022*"immutable" + 0.021*"class" + 0.020*"interior"
INFO: topic #1 (1.000): 0.108*"object" + 0.094*"copy" + 0.079*"deepcopy" + 0.048*"class" + 0.030*"shallow" + 0.024*"value" + 0.023*"memo" + 0.022*"instance" + 0.019*"way" + 0.018*"dictionary"
INFO: topic #2 (1.000): 0.100*"copy" + 0.077*"object" + 0.075*"list" + 0.070*"new" + 0.049*"reference" + 0.037*"original" + 0.029*"content" + 0.027*"memory" + 0.027*"shallow" + 0.022*"instance"
INFO: topic diff=1.207972, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 32.09424249917176
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -2.7803252971557306
DEBUG: bound: at document #0
INFO: -5.844 per-word bound, 57.4 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.158*"copy" + 0.098*"object" + 0.040*"deep" + 0.040*"shallow" + 0.036*"method" + 0.023*"change" + 0.022*"deepcopy" + 0.021*"immutable" + 0.021*"class" + 0.019*"interior"
INFO: topic #1 (1.000): 0.094*"deepcopy" + 0.091*"object" + 0.082*"copy" + 0.032*"class" + 0.027*"memo" + 0.025*"dictionary" + 0.024*"answer" + 0.023*"shallow" + 0.022*"lots_of_data" + 0.022*"foo"
INFO: topic #2 (1.000): 0.074*"object" + 0.067*"copy" + 0.059*"new" + 0.055*"list" + 0.055*"reference" + 0.036*"instance" + 0.035*"name" + 0.033*"df" + 0.026*"variable" + 0.026*"memory"
INFO: topic diff=0.913267, rho=0.447214
DEBUG: bound: at document #0
INFO: -4.743 per-word bound, 26.8 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.167*"copy" + 0.106*"object" + 0.045*"shallow" + 0.042*"deep" + 0.037*"method" + 0.027*"class" + 0.024*"change" + 0.022*"immutable" + 0.020*"deepcopy" + 0.019*"interior"
INFO: topic #1 (1.000): 0.102*"deepcopy" + 0.090*"object" + 0.075*"copy" + 0.032*"class" + 0.031*"memo" + 0.027*"value" + 0.024*"way" + 0.020*"dictionary" + 0.019*"answer" + 0.019*"shallow"
INFO: topic #2 (1.000): 0.080*"copy" + 0.076*"new" + 0.075*"list" + 0.070*"object" + 0.058*"reference" + 0.034*"instance" + 0.032*"content" + 0.031*"original" + 0.030*"memory" + 0.023*"name"
INFO: topic diff=0.712072, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 29.163701834366556
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -2.7341991444266416
DEBUG: bound: at document #0
INFO: -5.547 per-word bound, 46.7 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.163*"copy" + 0.105*"object" + 0.044*"shallow" + 0.041*"deep" + 0.036*"method" + 0.026*"class" + 0.023*"change" + 0.021*"immutable" + 0.020*"deepcopy" + 0.018*"interior"
INFO: topic #1 (1.000): 0.106*"deepcopy" + 0.081*"object" + 0.072*"copy" + 0.032*"memo" + 0.027*"dictionary" + 0.026*"answer" + 0.025*"lots_of_data" + 0.025*"foo" + 0.024*"class" + 0.021*"value"
INFO: topic #2 (1.000): 0.070*"object" + 0.062*"new" + 0.059*"reference" + 0.059*"copy" + 0.056*"list" + 0.041*"instance" + 0.036*"name" + 0.035*"df" + 0.028*"memory" + 0.027*"variable"
INFO: topic diff=0.593429, rho=0.408248
DEBUG: bound: at document #0
INFO: -4.663 per-word bound, 25.3 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.169*"copy" + 0.108*"object" + 0.047*"shallow" + 0.043*"deep" + 0.037*"method" + 0.030*"class" + 0.023*"change" + 0.022*"immutable" + 0.019*"deepcopy" + 0.019*"interior"
INFO: topic #1 (1.000): 0.114*"deepcopy" + 0.081*"object" + 0.066*"copy" + 0.035*"memo" + 0.028*"value" + 0.027*"way" + 0.022*"class" + 0.022*"dictionary" + 0.021*"module" + 0.021*"answer"
INFO: topic #2 (1.000): 0.078*"new" + 0.074*"list" + 0.068*"copy" + 0.067*"object" + 0.062*"reference" + 0.042*"instance" + 0.033*"content" + 0.033*"memory" + 0.028*"original" + 0.025*"name"
INFO: topic diff=0.401625, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 28.32841815305479
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -3.1366682479819787
DEBUG: bound: at document #0
INFO: -5.448 per-word bound, 43.6 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.166*"copy" + 0.107*"object" + 0.046*"shallow" + 0.041*"deep" + 0.035*"method" + 0.029*"class" + 0.022*"change" + 0.022*"immutable" + 0.019*"deepcopy" + 0.018*"interior"
INFO: topic #1 (1.000): 0.112*"deepcopy" + 0.076*"object" + 0.067*"copy" + 0.034*"memo" + 0.027*"dictionary" + 0.026*"answer" + 0.026*"lots_of_data" + 0.026*"foo" + 0.022*"value" + 0.022*"way"
INFO: topic #2 (1.000): 0.069*"object" + 0.064*"new" + 0.062*"reference" + 0.057*"list" + 0.053*"copy" + 0.045*"instance" + 0.036*"name" + 0.036*"df" + 0.029*"memory" + 0.027*"variable"
INFO: topic diff=0.422674, rho=0.377964
DEBUG: bound: at document #0
INFO: -4.634 per-word bound, 24.8 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.171*"copy" + 0.109*"object" + 0.048*"shallow" + 0.044*"deep" + 0.036*"method" + 0.030*"class" + 0.023*"change" + 0.022*"immutable" + 0.018*"deepcopy" + 0.018*"interior"
INFO: topic #1 (1.000): 0.119*"deepcopy" + 0.076*"object" + 0.062*"copy" + 0.037*"memo" + 0.028*"value" + 0.028*"way" + 0.022*"dictionary" + 0.022*"module" + 0.022*"answer" + 0.021*"lots_of_data"
INFO: topic #2 (1.000): 0.079*"new" + 0.073*"list" + 0.066*"object" + 0.064*"reference" + 0.061*"copy" + 0.046*"instance" + 0.034*"memory" + 0.033*"content" + 0.027*"name" + 0.026*"df"
INFO: topic diff=0.282845, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 28.008004829193204
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -3.9671602250798337
DEBUG: bound: at document #0
INFO: -5.404 per-word bound, 42.3 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.168*"copy" + 0.108*"object" + 0.047*"shallow" + 0.042*"deep" + 0.035*"method" + 0.030*"class" + 0.022*"change" + 0.022*"immutable" + 0.018*"deepcopy" + 0.018*"interior"
INFO: topic #1 (1.000): 0.115*"deepcopy" + 0.073*"object" + 0.064*"copy" + 0.035*"memo" + 0.027*"dictionary" + 0.026*"answer" + 0.026*"lots_of_data" + 0.026*"foo" + 0.023*"value" + 0.022*"way"
INFO: topic #2 (1.000): 0.068*"object" + 0.066*"new" + 0.063*"reference" + 0.057*"list" + 0.050*"copy" + 0.047*"instance" + 0.036*"name" + 0.036*"df" + 0.030*"memory" + 0.027*"variable"
INFO: topic diff=0.332463, rho=0.353553
DEBUG: bound: at document #0
INFO: -4.621 per-word bound, 24.6 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.172*"copy" + 0.109*"object" + 0.048*"shallow" + 0.044*"deep" + 0.036*"method" + 0.031*"class" + 0.023*"change" + 0.023*"immutable" + 0.018*"interior" + 0.018*"mutable"
INFO: topic #1 (1.000): 0.122*"deepcopy" + 0.074*"object" + 0.060*"copy" + 0.038*"memo" + 0.028*"value" + 0.028*"way" + 0.023*"module" + 0.023*"dictionary" + 0.022*"answer" + 0.022*"lots_of_data"
INFO: topic #2 (1.000): 0.079*"new" + 0.073*"list" + 0.066*"object" + 0.066*"reference" + 0.056*"copy" + 0.048*"instance" + 0.035*"memory" + 0.033*"content" + 0.027*"name" + 0.027*"df"
INFO: topic diff=0.247607, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 27.85743121085499
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -3.9750287039278747
DEBUG: bound: at document #0
INFO: -5.379 per-word bound, 41.6 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.170*"copy" + 0.108*"object" + 0.048*"shallow" + 0.043*"deep" + 0.035*"method" + 0.030*"class" + 0.022*"change" + 0.022*"immutable" + 0.018*"deepcopy" + 0.018*"interior"
INFO: topic #1 (1.000): 0.117*"deepcopy" + 0.072*"object" + 0.062*"copy" + 0.035*"memo" + 0.027*"dictionary" + 0.027*"lots_of_data" + 0.027*"foo" + 0.026*"answer" + 0.023*"value" + 0.023*"way"
INFO: topic #2 (1.000): 0.068*"object" + 0.067*"new" + 0.064*"reference" + 0.058*"list" + 0.048*"instance" + 0.047*"copy" + 0.036*"name" + 0.036*"df" + 0.031*"memory" + 0.028*"variable"
INFO: topic diff=0.281444, rho=0.333333
DEBUG: bound: at document #0
INFO: -4.613 per-word bound, 24.5 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.173*"copy" + 0.110*"object" + 0.049*"shallow" + 0.044*"deep" + 0.036*"method" + 0.031*"class" + 0.023*"change" + 0.023*"immutable" + 0.018*"interior" + 0.018*"mutable"
INFO: topic #1 (1.000): 0.123*"deepcopy" + 0.072*"object" + 0.059*"copy" + 0.038*"memo" + 0.028*"value" + 0.028*"way" + 0.024*"module" + 0.023*"dictionary" + 0.022*"answer" + 0.022*"lots_of_data"
INFO: topic #2 (1.000): 0.079*"new" + 0.072*"list" + 0.066*"reference" + 0.066*"object" + 0.052*"copy" + 0.049*"instance" + 0.036*"memory" + 0.032*"content" + 0.028*"name" + 0.028*"df"
INFO: topic diff=0.233755, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 27.781142426022864
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -3.969021813437383
DEBUG: bound: at document #0
INFO: -5.364 per-word bound, 41.2 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.171*"copy" + 0.109*"object" + 0.049*"shallow" + 0.043*"deep" + 0.035*"method" + 0.031*"class" + 0.022*"change" + 0.022*"immutable" + 0.018*"interior" + 0.018*"mutable"
INFO: topic #1 (1.000): 0.118*"deepcopy" + 0.071*"object" + 0.061*"copy" + 0.036*"memo" + 0.027*"dictionary" + 0.027*"lots_of_data" + 0.027*"foo" + 0.026*"answer" + 0.023*"value" + 0.023*"way"
INFO: topic #2 (1.000): 0.068*"object" + 0.067*"new" + 0.064*"reference" + 0.058*"list" + 0.049*"instance" + 0.045*"copy" + 0.036*"name" + 0.036*"df" + 0.031*"memory" + 0.028*"variable"
INFO: topic diff=0.249264, rho=0.316228
DEBUG: bound: at document #0
INFO: -4.608 per-word bound, 24.4 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.173*"copy" + 0.110*"object" + 0.049*"shallow" + 0.044*"deep" + 0.036*"method" + 0.031*"class" + 0.023*"change" + 0.023*"immutable" + 0.018*"interior" + 0.018*"mutable"
INFO: topic #1 (1.000): 0.124*"deepcopy" + 0.072*"object" + 0.058*"copy" + 0.038*"memo" + 0.028*"value" + 0.028*"way" + 0.025*"module" + 0.023*"dictionary" + 0.023*"answer" + 0.022*"lots_of_data"
INFO: topic #2 (1.000): 0.079*"new" + 0.072*"list" + 0.067*"reference" + 0.066*"object" + 0.050*"copy" + 0.049*"instance" + 0.036*"memory" + 0.032*"content" + 0.029*"name" + 0.029*"df"
INFO: topic diff=0.221940, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 27.737697644165582
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -3.969021813437383
DEBUG: bound: at document #0
INFO: -5.353 per-word bound, 40.9 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.172*"copy" + 0.109*"object" + 0.049*"shallow" + 0.043*"deep" + 0.035*"method" + 0.031*"class" + 0.022*"change" + 0.022*"immutable" + 0.018*"interior" + 0.018*"mutable"
INFO: topic #1 (1.000): 0.118*"deepcopy" + 0.071*"object" + 0.061*"copy" + 0.036*"memo" + 0.027*"dictionary" + 0.027*"lots_of_data" + 0.027*"foo" + 0.026*"answer" + 0.023*"value" + 0.023*"way"
INFO: topic #2 (1.000): 0.068*"object" + 0.067*"new" + 0.065*"reference" + 0.058*"list" + 0.049*"instance" + 0.044*"copy" + 0.036*"name" + 0.036*"df" + 0.032*"memory" + 0.027*"variable"
INFO: topic diff=0.227400, rho=0.301511
DEBUG: bound: at document #0
INFO: -4.604 per-word bound, 24.3 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.174*"copy" + 0.110*"object" + 0.049*"shallow" + 0.044*"deep" + 0.036*"method" + 0.031*"class" + 0.022*"change" + 0.022*"immutable" + 0.018*"interior" + 0.018*"mutable"
INFO: topic #1 (1.000): 0.124*"deepcopy" + 0.071*"object" + 0.058*"copy" + 0.038*"memo" + 0.028*"value" + 0.028*"way" + 0.026*"module" + 0.023*"dictionary" + 0.023*"answer" + 0.023*"lots_of_data"
INFO: topic #2 (1.000): 0.079*"new" + 0.071*"list" + 0.067*"reference" + 0.066*"object" + 0.049*"instance" + 0.048*"copy" + 0.036*"memory" + 0.032*"content" + 0.029*"name" + 0.029*"df"
INFO: topic diff=0.210465, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 27.708786589350428
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -3.9578804993871888
DEBUG: bound: at document #0
INFO: -5.345 per-word bound, 40.6 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.172*"copy" + 0.109*"object" + 0.050*"shallow" + 0.043*"deep" + 0.035*"method" + 0.031*"class" + 0.022*"change" + 0.022*"immutable" + 0.018*"interior" + 0.018*"mutable"
INFO: topic #1 (1.000): 0.119*"deepcopy" + 0.071*"object" + 0.060*"copy" + 0.036*"memo" + 0.027*"dictionary" + 0.027*"lots_of_data" + 0.027*"foo" + 0.026*"answer" + 0.023*"value" + 0.023*"way"
INFO: topic #2 (1.000): 0.068*"object" + 0.068*"new" + 0.065*"reference" + 0.059*"list" + 0.049*"instance" + 0.043*"copy" + 0.036*"name" + 0.036*"df" + 0.032*"memory" + 0.027*"variable"
INFO: topic diff=0.211825, rho=0.288675
DEBUG: bound: at document #0
INFO: -4.601 per-word bound, 24.3 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.174*"copy" + 0.110*"object" + 0.050*"shallow" + 0.044*"deep" + 0.036*"method" + 0.031*"class" + 0.022*"change" + 0.022*"immutable" + 0.018*"interior" + 0.018*"mutable"
INFO: topic #1 (1.000): 0.124*"deepcopy" + 0.071*"object" + 0.058*"copy" + 0.038*"memo" + 0.028*"value" + 0.027*"way" + 0.027*"module" + 0.024*"dictionary" + 0.023*"answer" + 0.023*"lots_of_data"
INFO: topic #2 (1.000): 0.078*"new" + 0.071*"list" + 0.067*"reference" + 0.066*"object" + 0.050*"instance" + 0.047*"copy" + 0.036*"memory" + 0.031*"content" + 0.029*"name" + 0.029*"df"
INFO: topic diff=0.200736, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 27.688089939386707
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -3.9578804993871888
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5> in 0.13s', 'datetime': '2023-03-20T16:52:59.451425', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/questions/10/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-20T16:52:59.451580', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/questions/10/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/10/model.state
DEBUG: {'uri': 'model/questions/10/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/questions/10/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-20T16:52:59.454113', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/questions/10/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/questions/10/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/10/model
INFO: topic #0 (1.000): 0.174*"copy" + 0.110*"object" + 0.050*"shallow" + 0.044*"deep" + 0.036*"method" + 0.031*"class" + 0.022*"change" + 0.022*"immutable" + 0.018*"interior" + 0.018*"mutable"
INFO: topic #1 (1.000): 0.124*"deepcopy" + 0.071*"object" + 0.058*"copy" + 0.038*"memo" + 0.028*"value" + 0.027*"way" + 0.027*"module" + 0.024*"dictionary" + 0.023*"answer" + 0.023*"lots_of_data"
INFO: topic #2 (1.000): 0.078*"new" + 0.071*"list" + 0.067*"reference" + 0.066*"object" + 0.050*"instance" + 0.047*"copy" + 0.036*"memory" + 0.031*"content" + 0.029*"name" + 0.029*"df"
INFO: Question Similarity: [0.1959053874015808, 0.17413294315338135, 0.0930936336517334, 0.1420188546180725, 0.09221601486206055, 0.1343625783920288, 0.044537901878356934, 0.1096653938293457, 0.12416106462478638, 0.30900347232818604]
INFO: 46939443: -0.0803072357658576
INFO: 4794254: -0.08319458801923593
INFO: 52160051: -0.08608067341600685
INFO: 65637038: -0.21944453308535303
INFO: 72220352: -0.2225511254367927
INFO: 29398459: -0.23263468384464708
INFO: 42143502: -0.2649349346379972
INFO: 56478412: -0.26712789240117985
INFO: 23581063: -0.32219735920632386
INFO: 68746763: -0.34270696498908887
INFO: 73328910: -0.430964433175601
INFO: 68737463: -0.4786364090569007
INFO: 26014778: -0.6873249831790464
INFO: Recommended Keywords
INFO: reference score: -0.8410426
INFO: instance score: -0.83776826
INFO: copy score: -0.73615247
INFO: object score: -0.72962564
INFO: source score: -0.7291584
INFO: information score: -0.7174537
INFO: change score: -0.70128906
INFO: method score: -0.6870629
INFO: attribute score: -0.681203
INFO: function score: -0.6721455
INFO: need score: -0.6653924
INFO: answer score: -0.6649327
INFO: element score: -0.66392255
INFO: mutable score: -0.661024
INFO: difference score: -0.6547532
INFO: item score: -0.65134734
INFO: original score: -0.6445258
INFO: case score: -0.6436414
INFO: different score: -0.6404282
INFO: exact score: -0.64004433
INFO: immutable score: -0.63359255
INFO: content score: -0.61528665
INFO: memory score: -0.60171425
INFO: name score: -0.59876704
INFO: value score: -0.59797
INFO: explanation score: -0.5905499
INFO: address score: -0.58334595
INFO: detail score: -0.57275236
INFO: solution score: -0.57260233
INFO: deep score: -0.57222164
INFO: individual score: -0.5662072
INFO: produce score: -0.54844767
INFO: related score: -0.54522943
INFO: way score: -0.5440219
INFO: basic score: -0.53185505
INFO: memo score: -0.5308052
INFO: dictionary score: -0.53011096
INFO: doubt score: -0.52787876
INFO: list score: -0.5038757
INFO: copying score: -0.503787
INFO: override score: -0.50185007
INFO: point score: -0.49689835
INFO: look score: -0.49437144
INFO: module score: -0.49070042
INFO: whole score: -0.49051905
INFO: avoid score: -0.4900632
INFO: test score: -0.48191565
INFO: new score: -0.47593704
INFO: slice score: -0.46684894
INFO: interior score: -0.46587214
INFO: many score: -0.46575168
INFO: classed score: -0.46216992
INFO: implement score: -0.46003276
INFO: print score: -0.4575891
INFO: class score: -0.4478311
INFO: question score: -0.44065103
INFO: independent score: -0.4356737
INFO: help score: -0.425378
INFO: general score: -0.42206004
INFO: variable score: -0.42189038
INFO: nested score: -0.4217295
INFO: recursive score: -0.4105868
INFO: shallow score: -0.41053283
INFO: documentation score: -0.3999688
INFO: container score: -0.39410257
INFO: time score: -0.39124122
INFO: customize score: -0.37271485
INFO: work score: -0.3612787
INFO: right score: -0.35941485
INFO: datum score: -0.35707387
INFO: selection score: -0.34856176
INFO: foo score: -0.34051666
INFO: multiple score: -0.33412158
INFO: assignment score: -0.33230442
INFO: pointer score: -0.33199197
INFO: string score: -0.33071244
INFO: field score: -0.31096148
INFO: tuple score: -0.31045988
INFO: course score: -0.31021985
INFO: mutate score: -0.30040166
INFO: library score: -0.29210654
INFO: import score: -0.29061142
INFO: args score: -0.2857244
INFO: board score: -0.27927214
INFO: b score: -0.2483668
INFO: nice score: -0.2433398
INFO: hook score: -0.22819598
INFO: outer score: -0.22744787
INFO: df score: -0.17396092
INFO: place score: -0.17289829
INFO: = score: -0.1670311
INFO: story score: -0.1503216
INFO: member score: -0.13752422
INFO: replica score: -0.12051624
INFO: eq score: -0.11630672
INFO: several score: -0.0886173
INFO: dict_b score: -0.0
INFO: deepcopy score: -0.0
INFO: foo(5 score: -0.0
INFO: lots_of_data score: -0.0
INFO: ============================================================
INFO: --------------------
INFO: How can I find the methods or attributes of an object?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<448 unique tokens: ["'", 'a.', 'a.__class__.__getattribute__(a', 'a.m', 'addmethod']...> from 9 documents (total 1382 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<448 unique tokens: ["\'", \'a.\', \'a.__class__.__getattribute__(a\', \'a.m\', \'addmethod\']...> from 9 documents (total 1382 corpus positions)', 'datetime': '2023-03-20T16:53:01.475422', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 9 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.409 per-word bound, 170.0 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 0, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.100*"method" + 0.052*"class" + 0.027*"list" + 0.022*"instance" + 0.018*"function" + 0.017*"object" + 0.011*"output" + 0.011*"name" + 0.011*"attribute" + 0.010*"return"
INFO: topic #1 (1.000): 0.112*"method" + 0.058*"class" + 0.045*"function" + 0.041*"object" + 0.040*"instance" + 0.021*"attribute" + 0.017*"list" + 0.015*"code" + 0.012*"return" + 0.011*"dir"
INFO: topic #2 (1.000): 0.091*"method" + 0.053*"class" + 0.032*"object" + 0.031*"instance" + 0.027*"function" + 0.022*"list" + 0.017*"attribute" + 0.013*"code" + 0.011*"dir" + 0.009*"descriptor"
INFO: topic diff=2.816457, rho=1.000000
DEBUG: bound: at document #0
INFO: -9.050 per-word bound, 530.0 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 0, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.079*"method" + 0.043*"class" + 0.017*"instance" + 0.017*"list" + 0.015*"function" + 0.012*"object" + 0.012*"module" + 0.010*"attribute" + 0.009*"return" + 0.007*"type"
INFO: topic #1 (1.000): 0.131*"method" + 0.066*"class" + 0.059*"function" + 0.059*"instance" + 0.057*"object" + 0.030*"attribute" + 0.018*"self" + 0.014*"first" + 0.012*"unbound" + 0.012*"descriptor"
INFO: topic #2 (1.000): 0.076*"method" + 0.046*"class" + 0.027*"instance" + 0.026*"object" + 0.025*"function" + 0.016*"attribute" + 0.015*"list" + 0.009*"code" + 0.009*"descriptor" + 0.008*"module"
INFO: topic diff=2.269597, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 62.77594676711059
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.651999787754342
DEBUG: bound: at document #0
INFO: -5.917 per-word bound, 60.4 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 1, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.064*"method" + 0.031*"class" + 0.013*"list" + 0.013*"instance" + 0.012*"store" + 0.012*"local" + 0.011*"function" + 0.009*"object" + 0.009*"module" + 0.009*"attribute"
INFO: topic #1 (1.000): 0.117*"method" + 0.061*"class" + 0.047*"function" + 0.045*"instance" + 0.044*"object" + 0.023*"attribute" + 0.017*"list" + 0.013*"code" + 0.012*"return" + 0.010*"argument"
INFO: topic #2 (1.000): 0.060*"method" + 0.035*"class" + 0.020*"instance" + 0.020*"object" + 0.019*"function" + 0.014*"attribute" + 0.012*"list" + 0.007*"code" + 0.007*"descriptor" + 0.006*"module"
INFO: topic diff=1.134804, rho=0.512989
DEBUG: bound: at document #0
INFO: -6.979 per-word bound, 126.1 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 1, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.048*"method" + 0.023*"class" + 0.015*"restriction" + 0.014*"block" + 0.014*"look" + 0.014*"statement" + 0.014*"stack" + 0.014*"peek" + 0.012*"module" + 0.008*"function"
INFO: topic #1 (1.000): 0.121*"method" + 0.062*"class" + 0.052*"function" + 0.052*"instance" + 0.051*"object" + 0.027*"attribute" + 0.015*"self" + 0.012*"first" + 0.012*"list" + 0.011*"return"
INFO: topic #2 (1.000): 0.042*"method" + 0.026*"class" + 0.015*"instance" + 0.014*"object" + 0.014*"function" + 0.011*"attribute" + 0.009*"list" + 0.006*"module" + 0.005*"code" + 0.005*"descriptor"
INFO: topic diff=1.200066, rho=0.512989
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 53.175619414069764
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -2.9858437577873578
DEBUG: bound: at document #0
INFO: -5.807 per-word bound, 56.0 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 2, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.039*"method" + 0.017*"class" + 0.016*"store" + 0.016*"local" + 0.011*"restriction" + 0.010*"statement" + 0.010*"block" + 0.010*"peek" + 0.010*"stack" + 0.010*"look"
INFO: topic #1 (1.000): 0.116*"method" + 0.060*"class" + 0.046*"function" + 0.044*"instance" + 0.044*"object" + 0.023*"attribute" + 0.017*"list" + 0.013*"code" + 0.012*"return" + 0.010*"argument"
INFO: topic #2 (1.000): 0.030*"method" + 0.018*"class" + 0.011*"instance" + 0.010*"object" + 0.010*"function" + 0.008*"attribute" + 0.006*"list" + 0.004*"module" + 0.004*"code" + 0.004*"descriptor"
INFO: topic diff=0.622392, rho=0.456435
DEBUG: bound: at document #0
INFO: -5.990 per-word bound, 63.6 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 2, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.033*"method" + 0.025*"restriction" + 0.016*"block" + 0.016*"stack" + 0.016*"peek" + 0.016*"look" + 0.016*"statement" + 0.013*"suit" + 0.013*"instance.functionname" + 0.013*"guido"
INFO: topic #1 (1.000): 0.120*"method" + 0.062*"class" + 0.051*"function" + 0.051*"instance" + 0.050*"object" + 0.027*"attribute" + 0.014*"self" + 0.013*"list" + 0.012*"first" + 0.011*"return"
INFO: topic #2 (1.000): 0.020*"method" + 0.013*"class" + 0.007*"instance" + 0.007*"object" + 0.007*"function" + 0.006*"attribute" + 0.005*"list" + 0.004*"module" + 0.003*"code" + 0.003*"descriptor"
INFO: topic diff=0.604825, rho=0.456435
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 51.06940940199813
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -5.376434384473973
DEBUG: bound: at document #0
INFO: -5.754 per-word bound, 54.0 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 3, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.028*"method" + 0.019*"restriction" + 0.016*"store" + 0.016*"local" + 0.012*"stack" + 0.012*"peek" + 0.012*"block" + 0.012*"statement" + 0.012*"look" + 0.010*"guido"
INFO: topic #1 (1.000): 0.116*"method" + 0.061*"class" + 0.046*"function" + 0.044*"instance" + 0.044*"object" + 0.023*"attribute" + 0.016*"list" + 0.013*"code" + 0.012*"return" + 0.010*"argument"
INFO: topic #2 (1.000): 0.014*"method" + 0.009*"class" + 0.005*"instance" + 0.005*"object" + 0.005*"function" + 0.005*"attribute" + 0.004*"list" + 0.003*"module" + 0.003*"code" + 0.003*"descriptor"
INFO: topic diff=0.374709, rho=0.415227
DEBUG: bound: at document #0
INFO: -5.826 per-word bound, 56.7 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 3, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.029*"restriction" + 0.024*"method" + 0.016*"block" + 0.016*"stack" + 0.016*"peek" + 0.016*"look" + 0.016*"statement" + 0.015*"series" + 0.015*"instance.functionname" + 0.015*"guido"
INFO: topic #1 (1.000): 0.120*"method" + 0.062*"class" + 0.051*"function" + 0.050*"instance" + 0.049*"object" + 0.026*"attribute" + 0.013*"list" + 0.013*"self" + 0.012*"first" + 0.011*"return"
INFO: topic #2 (1.000): 0.010*"method" + 0.006*"class" + 0.004*"instance" + 0.004*"function" + 0.004*"object" + 0.004*"attribute" + 0.003*"list" + 0.003*"module" + 0.003*"descriptor" + 0.003*"code"
INFO: topic diff=0.384446, rho=0.415227
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 50.260939969183966
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -5.362020235221713
DEBUG: bound: at document #0
INFO: -5.726 per-word bound, 52.9 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 4, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.023*"restriction" + 0.021*"method" + 0.015*"store" + 0.015*"local" + 0.013*"block" + 0.013*"peek" + 0.013*"statement" + 0.013*"stack" + 0.013*"look" + 0.012*"series"
INFO: topic #1 (1.000): 0.116*"method" + 0.061*"class" + 0.046*"function" + 0.044*"instance" + 0.044*"object" + 0.023*"attribute" + 0.016*"list" + 0.013*"code" + 0.012*"return" + 0.010*"argument"
INFO: topic #2 (1.000): 0.007*"method" + 0.005*"class" + 0.003*"instance" + 0.003*"function" + 0.003*"object" + 0.003*"attribute" + 0.003*"list" + 0.003*"module" + 0.003*"descriptor" + 0.003*"code"
INFO: topic diff=0.284661, rho=0.383482
DEBUG: bound: at document #0
INFO: -5.775 per-word bound, 54.8 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 4, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.030*"restriction" + 0.018*"method" + 0.016*"peek" + 0.016*"block" + 0.016*"look" + 0.016*"stack" + 0.016*"statement" + 0.016*"concept" + 0.016*"creator" + 0.016*"duck"
INFO: topic #1 (1.000): 0.120*"method" + 0.063*"class" + 0.050*"function" + 0.050*"instance" + 0.049*"object" + 0.026*"attribute" + 0.013*"list" + 0.013*"self" + 0.011*"first" + 0.011*"return"
INFO: topic #2 (1.000): 0.005*"method" + 0.004*"class" + 0.003*"instance" + 0.003*"function" + 0.003*"object" + 0.003*"attribute" + 0.003*"list" + 0.002*"module" + 0.002*"descriptor" + 0.002*"code"
INFO: topic diff=0.280013, rho=0.383482
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 49.905399568721386
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -5.362020235221713
DEBUG: bound: at document #0
INFO: -5.710 per-word bound, 52.3 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 5, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.024*"restriction" + 0.016*"method" + 0.015*"store" + 0.015*"local" + 0.013*"statement" + 0.013*"look" + 0.013*"peek" + 0.013*"stack" + 0.013*"block" + 0.013*"x.f"
INFO: topic #1 (1.000): 0.117*"method" + 0.061*"class" + 0.046*"function" + 0.045*"instance" + 0.044*"object" + 0.023*"attribute" + 0.016*"list" + 0.013*"code" + 0.012*"return" + 0.010*"argument"
INFO: topic #2 (1.000): 0.004*"method" + 0.003*"class" + 0.003*"instance" + 0.003*"function" + 0.003*"object" + 0.003*"attribute" + 0.002*"list" + 0.002*"module" + 0.002*"descriptor" + 0.002*"code"
INFO: topic diff=0.236698, rho=0.358057
DEBUG: bound: at document #0
INFO: -5.752 per-word bound, 53.9 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 5, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.031*"restriction" + 0.016*"peek" + 0.016*"statement" + 0.016*"stack" + 0.016*"look" + 0.016*"block" + 0.016*"creator" + 0.016*"design" + 0.016*"rossum" + 0.016*"concept"
INFO: topic #1 (1.000): 0.120*"method" + 0.062*"class" + 0.050*"function" + 0.050*"instance" + 0.048*"object" + 0.026*"attribute" + 0.014*"list" + 0.012*"self" + 0.011*"first" + 0.011*"return"
INFO: topic #2 (1.000): 0.004*"method" + 0.003*"class" + 0.003*"instance" + 0.003*"function" + 0.003*"object" + 0.002*"attribute" + 0.002*"list" + 0.002*"module" + 0.002*"descriptor" + 0.002*"code"
INFO: topic diff=0.223831, rho=0.358057
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 49.719021875963556
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -5.238794069788834
DEBUG: bound: at document #0
INFO: -5.699 per-word bound, 51.9 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 6, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.025*"restriction" + 0.015*"store" + 0.015*"local" + 0.013*"peek" + 0.013*"block" + 0.013*"look" + 0.013*"stack" + 0.013*"statement" + 0.013*"creator" + 0.013*"concept"
INFO: topic #1 (1.000): 0.117*"method" + 0.061*"class" + 0.046*"function" + 0.045*"instance" + 0.044*"object" + 0.023*"attribute" + 0.016*"list" + 0.013*"code" + 0.012*"return" + 0.010*"argument"
INFO: topic #2 (1.000): 0.003*"method" + 0.003*"class" + 0.002*"instance" + 0.002*"function" + 0.002*"object" + 0.002*"attribute" + 0.002*"list" + 0.002*"module" + 0.002*"descriptor" + 0.002*"code"
INFO: topic diff=0.205655, rho=0.337100
DEBUG: bound: at document #0
INFO: -5.739 per-word bound, 53.4 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 6, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.031*"restriction" + 0.016*"statement" + 0.016*"look" + 0.016*"peek" + 0.016*"stack" + 0.016*"block" + 0.016*"tutorial" + 0.016*"duck" + 0.016*"creator" + 0.016*"class.functionname"
INFO: topic #1 (1.000): 0.121*"method" + 0.062*"class" + 0.050*"function" + 0.049*"instance" + 0.048*"object" + 0.026*"attribute" + 0.014*"list" + 0.012*"self" + 0.011*"return" + 0.011*"first"
INFO: topic #2 (1.000): 0.003*"method" + 0.003*"class" + 0.002*"instance" + 0.002*"function" + 0.002*"object" + 0.002*"attribute" + 0.002*"list" + 0.002*"module" + 0.002*"descriptor" + 0.002*"code"
INFO: topic diff=0.191927, rho=0.337100
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 49.59826904914766
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -5.240144599839159
DEBUG: bound: at document #0
INFO: -5.691 per-word bound, 51.7 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 7, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.025*"restriction" + 0.015*"store" + 0.015*"local" + 0.013*"look" + 0.013*"block" + 0.013*"peek" + 0.013*"statement" + 0.013*"stack" + 0.013*"guido" + 0.013*"rossum"
INFO: topic #1 (1.000): 0.117*"method" + 0.061*"class" + 0.046*"function" + 0.045*"instance" + 0.044*"object" + 0.023*"attribute" + 0.016*"list" + 0.013*"code" + 0.012*"return" + 0.010*"argument"
INFO: topic #2 (1.000): 0.003*"method" + 0.002*"class" + 0.002*"instance" + 0.002*"function" + 0.002*"object" + 0.002*"attribute" + 0.002*"list" + 0.002*"module" + 0.002*"descriptor" + 0.002*"code"
INFO: topic diff=0.185249, rho=0.319438
DEBUG: bound: at document #0
INFO: -5.730 per-word bound, 53.1 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 7, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.031*"restriction" + 0.016*"statement" + 0.016*"look" + 0.016*"peek" + 0.016*"block" + 0.016*"stack" + 0.016*"pre" + 0.016*"ready" + 0.016*"filling" + 0.016*"suit"
INFO: topic #1 (1.000): 0.121*"method" + 0.062*"class" + 0.050*"function" + 0.049*"instance" + 0.048*"object" + 0.026*"attribute" + 0.014*"list" + 0.012*"self" + 0.011*"return" + 0.011*"first"
INFO: topic #2 (1.000): 0.003*"method" + 0.002*"class" + 0.002*"instance" + 0.002*"function" + 0.002*"object" + 0.002*"attribute" + 0.002*"list" + 0.002*"module" + 0.002*"descriptor" + 0.002*"code"
INFO: topic diff=0.175337, rho=0.319438
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 49.50884898342373
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -5.240144599839159
DEBUG: bound: at document #0
INFO: -5.685 per-word bound, 51.4 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 8, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.026*"restriction" + 0.015*"store" + 0.015*"local" + 0.013*"look" + 0.013*"peek" + 0.013*"statement" + 0.013*"block" + 0.013*"stack" + 0.013*"suit" + 0.013*"creator"
INFO: topic #1 (1.000): 0.117*"method" + 0.061*"class" + 0.046*"function" + 0.045*"instance" + 0.044*"object" + 0.023*"attribute" + 0.016*"list" + 0.012*"code" + 0.012*"return" + 0.010*"argument"
INFO: topic #2 (1.000): 0.002*"method" + 0.002*"class" + 0.002*"instance" + 0.002*"function" + 0.002*"object" + 0.002*"attribute" + 0.002*"list" + 0.002*"module" + 0.002*"descriptor" + 0.002*"code"
INFO: topic diff=0.171256, rho=0.304290
DEBUG: bound: at document #0
INFO: -5.722 per-word bound, 52.8 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 8, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.031*"restriction" + 0.016*"look" + 0.016*"peek" + 0.016*"statement" + 0.016*"stack" + 0.016*"block" + 0.016*"pre" + 0.016*"foo.bar" + 0.016*"filling" + 0.016*"van"
INFO: topic #1 (1.000): 0.121*"method" + 0.062*"class" + 0.050*"function" + 0.049*"instance" + 0.048*"object" + 0.026*"attribute" + 0.014*"list" + 0.012*"self" + 0.011*"return" + 0.011*"first"
INFO: topic #2 (1.000): 0.002*"method" + 0.002*"class" + 0.002*"instance" + 0.002*"function" + 0.002*"object" + 0.002*"attribute" + 0.002*"list" + 0.002*"module" + 0.002*"descriptor" + 0.002*"code"
INFO: topic diff=0.164169, rho=0.304290
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 49.43889185701374
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -5.240144599839159
DEBUG: bound: at document #0
INFO: -5.679 per-word bound, 51.2 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 9, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.026*"restriction" + 0.015*"store" + 0.015*"local" + 0.014*"stack" + 0.014*"look" + 0.014*"block" + 0.014*"statement" + 0.014*"peek" + 0.014*"duck" + 0.014*"explanation"
INFO: topic #1 (1.000): 0.117*"method" + 0.061*"class" + 0.046*"function" + 0.045*"instance" + 0.044*"object" + 0.024*"attribute" + 0.016*"list" + 0.012*"code" + 0.012*"return" + 0.010*"argument"
INFO: topic #2 (1.000): 0.002*"method" + 0.002*"class" + 0.002*"instance" + 0.002*"function" + 0.002*"object" + 0.002*"attribute" + 0.002*"list" + 0.002*"module" + 0.002*"descriptor" + 0.002*"code"
INFO: topic diff=0.160722, rho=0.291111
DEBUG: bound: at document #0
INFO: -5.715 per-word bound, 52.5 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 9, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.031*"restriction" + 0.016*"statement" + 0.016*"stack" + 0.016*"peek" + 0.016*"look" + 0.016*"block" + 0.016*"history" + 0.016*"full" + 0.016*"pre" + 0.016*"x.f"
INFO: topic #1 (1.000): 0.121*"method" + 0.062*"class" + 0.050*"function" + 0.049*"instance" + 0.048*"object" + 0.026*"attribute" + 0.014*"list" + 0.012*"self" + 0.011*"return" + 0.011*"first"
INFO: topic #2 (1.000): 0.002*"method" + 0.002*"class" + 0.002*"instance" + 0.002*"function" + 0.002*"object" + 0.002*"attribute" + 0.002*"list" + 0.002*"module" + 0.002*"descriptor" + 0.002*"code"
INFO: topic diff=0.155232, rho=0.291111
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 49.38254723498686
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -5.240144599839159
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5> in 0.17s', 'datetime': '2023-03-20T16:53:01.645444', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/questions/11/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-20T16:53:01.645604', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/questions/11/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/11/model.state
DEBUG: {'uri': 'model/questions/11/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/questions/11/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-20T16:53:01.649149', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/questions/11/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/questions/11/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/11/model
INFO: topic #0 (1.000): 0.031*"restriction" + 0.016*"statement" + 0.016*"stack" + 0.016*"peek" + 0.016*"look" + 0.016*"block" + 0.016*"history" + 0.016*"full" + 0.016*"pre" + 0.016*"x.f"
INFO: topic #1 (1.000): 0.121*"method" + 0.062*"class" + 0.050*"function" + 0.049*"instance" + 0.048*"object" + 0.026*"attribute" + 0.014*"list" + 0.012*"self" + 0.011*"return" + 0.011*"first"
INFO: topic #2 (1.000): 0.002*"method" + 0.002*"class" + 0.002*"instance" + 0.002*"function" + 0.002*"object" + 0.002*"attribute" + 0.002*"list" + 0.002*"module" + 0.002*"descriptor" + 0.002*"code"
INFO: Question Similarity: [0.10374921560287476, 0.08703142404556274, 0.09539961814880371, 0.08364278078079224, 0.12477689981460571, 0.1220749020576477, 0.06367868185043335, 0.05145597457885742, 0.2589115500450134, 0.29363518953323364]
INFO: 54045798: -0.08384174933748459
INFO: 54045993: -0.0901872261986984
INFO: 37396464: -0.10374504832601851
INFO: 56587904: -0.10397717036348711
INFO: 74315537: -0.13657608335144952
INFO: 61200307: -0.13714697960942857
INFO: 1911313: -0.1396264079822562
INFO: 68575686: -0.14040307751016937
INFO: 1911287: -0.14071732276858367
INFO: 61490721: -0.1407177054160482
INFO: 7478804: -0.1414633604988988
INFO: 28060251: -0.14161184049868014
INFO: 8961717: -0.1416891284102298
INFO: 50179469: -0.1430037689785191
INFO: 34404761: -0.14311202816689098
INFO: 2982: -0.14311216456286882
INFO: 32076685: -0.14336982189564773
INFO: 54326058: -0.14368207829414723
INFO: 982: -0.14485591281533064
INFO: 9041763: -0.14506038440201602
INFO: 61957218: -0.1454366808709415
INFO: 53608586: -0.14543887954080814
INFO: 24748849: -0.1457961153270851
INFO: 959064: -0.14609008940355095
INFO: 73486831: -0.14609078441320297
INFO: 43703054: -0.14678474558997776
INFO: 16240409: -0.1471954123919522
INFO: 24795848: -0.14804384884000546
INFO: 39061905: -0.1480442915162553
INFO: 68804677: -0.1523053727532593
INFO: 65571791: -0.15230898352670852
INFO: 22525: -0.15253935144169187
INFO: 29333454: -0.1556624248984283
INFO: 24865663: -0.15595509341363756
INFO: 63620684: -0.15737055149811793
INFO: 37464502: -0.15774829952963745
INFO: 9636303: -0.1584795468200776
INFO: 27380776: -0.15900798018595488
INFO: 32608298: -0.15981244062232888
INFO: 34452: -0.16013960568615065
INFO: 64315050: -0.16056792623253338
INFO: 1911291: -0.1605708300413957
INFO: 57149907: -0.1605809056233665
INFO: 34467: -0.1608968187110859
INFO: 34481: -0.1613493414079034
INFO: 4600: -0.16196041365036126
INFO: 15640132: -0.16243703483246452
INFO: 28220562: -0.16243896908899305
INFO: 50050651: -0.16310255316636518
INFO: 47317075: -0.16310632455336568
INFO: 68474764: -0.16387753734426175
INFO: 45341362: -0.16708662720874623
INFO: 61189861: -0.16720445096771192
INFO: 29851741: -0.16720591955898978
INFO: 20100900: -0.16720830824689856
INFO: 65186594: -0.16720963984076795
INFO: 24715094: -0.16856772014636895
INFO: 49194581: -0.1709554711662241
INFO: 48284803: -0.1737164966327845
INFO: 34472: -0.18314940541682267
INFO: 70662971: -0.19122757937443854
INFO: 58987382: -0.1922293471765188
INFO: 73990545: -0.2040808264944887
INFO: 73990556: -0.20671209590571354
INFO: 68418526: -0.23436224686073442
INFO: 68418456: -0.26822596871027327
INFO: 52331202: -0.48970068518967586
INFO: 14298870: -0.5315685367580006
INFO: 14298889: -0.5663501477382548
INFO: Recommended Keywords
INFO: instance score: -0.8567142
INFO: particular score: -0.8401845
INFO: possible score: -0.82926375
INFO: example score: -0.8163868
INFO: order score: -0.7759071
INFO: difference score: -0.7648796
INFO: usual score: -0.7514504
INFO: direct score: -0.74377966
INFO: result score: -0.7436005
INFO: fact score: -0.7362986
INFO: attribute score: -0.73358154
INFO: change score: -0.72678596
INFO: correct score: -0.72318333
INFO: true score: -0.72165567
INFO: process score: -0.7183624
INFO: simple score: -0.7124313
INFO: key score: -0.7103158
INFO: case score: -0.7032463
INFO: least score: -0.7025381
INFO: useful score: -0.69762284
INFO: reason score: -0.6961011
INFO: representation score: -0.6947313
INFO: see score: -0.6940035
INFO: non score: -0.6932663
INFO: object score: -0.6910505
INFO: method score: -0.6893931
INFO: need score: -0.68604916
INFO: specific score: -0.6834111
INFO: equivalent score: -0.6801211
INFO: clear score: -0.67889386
INFO: function score: -0.6784248
INFO: normal score: -0.6767966
INFO: problem score: -0.67605406
INFO: approach score: -0.6612787
INFO: reference score: -0.6563482
INFO: definition score: -0.6505101
INFO: whole score: -0.6484605
INFO: other score: -0.6433358
INFO: self score: -0.6428852
INFO: condition score: -0.63912654
INFO: way score: -0.6389448
INFO: distinguish score: -0.6386715
INFO: different score: -0.6380562
INFO: incorrect score: -0.62874466
INFO: point score: -0.6251756
INFO: identical score: -0.6249953
INFO: type score: -0.62450016
INFO: valid score: -0.62324893
INFO: error score: -0.6181488
INFO: restriction score: -0.6159807
INFO: exception score: -0.61443484
INFO: model score: -0.60903764
INFO: create score: -0.60714465
INFO: time score: -0.600099
INFO: note score: -0.599079
INFO: reliable score: -0.5972174
INFO: observe score: -0.59614515
INFO: well score: -0.5921924
INFO: source score: -0.5919368
INFO: solution score: -0.5918963
INFO: assure score: -0.5886838
INFO: convenient score: -0.58707875
INFO: important score: -0.5868396
INFO: argument score: -0.58057064
INFO: test score: -0.5788567
INFO: external score: -0.57718724
INFO: person score: -0.5769557
INFO: question score: -0.57144994
INFO: erroneous score: -0.57121646
INFO: remove score: -0.5698804
INFO: easy score: -0.5662179
INFO: behaviour score: -0.5637247
INFO: confuse score: -0.56361794
INFO: class score: -0.56135535
INFO: cycle score: -0.559932
INFO: guide score: -0.5598736
INFO: separate score: -0.55826443
INFO: execute score: -0.5558021
INFO: information score: -0.5551094
INFO: persistent score: -0.5545537
INFO: due score: -0.5535762
INFO: mechanism score: -0.552493
INFO: statement score: -0.55209005
INFO: observation score: -0.5482586
INFO: good score: -0.5445177
INFO: provide score: -0.54408616
INFO: current score: -0.54352105
INFO: completeness score: -0.5364167
INFO: scope score: -0.53570074
INFO: value score: -0.5346727
INFO: many score: -0.5304468
INFO: descriptor score: -0.52922153
INFO: overridden score: -0.5259041
INFO: open score: -0.5250607
INFO: distinct score: -0.5246003
INFO: signature score: -0.52386594
INFO: detail score: -0.523018
INFO: item score: -0.5224775
INFO: attach score: -0.52217734
INFO: little score: -0.51943713
INFO: generalized score: -0.51881415
INFO: level score: -0.5170127
INFO: static score: -0.5152812
INFO: believe score: -0.5116156
INFO: abstract score: -0.5013296
INFO: interesting score: -0.49903572
INFO: link score: -0.49725425
INFO: write score: -0.49643892
INFO: regular score: -0.49572268
INFO: parenthesis score: -0.4955967
INFO: descriptive score: -0.49433202
INFO: new score: -0.48713386
INFO: field score: -0.48710376
INFO: empty score: -0.4867996
INFO: work score: -0.48521847
INFO: call score: -0.48511228
INFO: code score: -0.48472458
INFO: variable score: -0.47828078
INFO: first score: -0.47815973
INFO: single score: -0.47654375
INFO: unbound score: -0.47521645
INFO: list score: -0.47445157
INFO: operation score: -0.47303241
INFO: virtual score: -0.4707424
INFO: in score: -0.46707052
INFO: none score: -0.46451664
INFO: post score: -0.46261853
INFO: notice score: -0.4620697
INFO: original score: -0.4573512
INFO: simulate score: -0.4568881
INFO: recent score: -0.45441338
INFO: sure score: -0.45418382
INFO: wrong score: -0.45364505
INFO: look score: -0.4524724
INFO: interested score: -0.45173067
INFO: sub score: -0.44924548
INFO: display score: -0.44353276
INFO: comprehension score: -0.44345826
INFO: base score: -0.4433219
INFO: force score: -0.43837392
INFO: right score: -0.43669763
INFO: addendum score: -0.43629804
INFO: extensions score: -0.4338708
INFO: answer score: -0.4299328
INFO: poor score: -0.42904082
INFO: paragraph score: -0.42542952
INFO: directive score: -0.42528784
INFO: return score: -0.42229006
INFO: available score: -0.42006066
INFO: block score: -0.41919628
INFO: bind score: -0.41887957
INFO: output score: -0.41706884
INFO: issue score: -0.41550845
INFO: data score: -0.4147737
INFO: know score: -0.41365612
INFO: documentation score: -0.41201824
INFO: low score: -0.40678424
INFO: module score: -0.40645397
INFO: string score: -0.39443713
INFO: encode score: -0.39168507
INFO: comment score: -0.39124918
INFO: place score: -0.38761228
INFO: parameter score: -0.3872984
INFO: excellent score: -0.38386136
INFO: name score: -0.37741745
INFO: protocol score: -0.37547964
INFO: user score: -0.37442267
INFO: second score: -0.3739683
INFO: property score: -0.35797632
INFO: pointer score: -0.35567734
INFO: version score: -0.3553612
INFO: wrapping score: -0.34728134
INFO: stack score: -0.34192798
INFO: design score: -0.34083557
INFO: language score: -0.33162525
INFO: import score: -0.3314745
INFO: runtime score: -0.33006647
INFO: file score: -0.3288548
INFO: local score: -0.3281626
INFO: c score: -0.3237696
INFO: compiler score: -0.3185444
INFO: inspect score: -0.31729123
INFO: leave score: -0.3140985
INFO: intolerant score: -0.31213608
INFO: introspection score: -0.31155762
INFO: page score: -0.30478626
INFO: access score: -0.30287766
INFO: tuple score: -0.30240726
INFO: global score: -0.3012458
INFO: workaround score: -0.29884043
INFO: wrap score: -0.29822955
INFO: overwrite score: -0.29679883
INFO: callable score: -0.28769073
INFO: style score: -0.27880257
INFO: hack score: -0.27811226
INFO: enum score: -0.27647108
INFO: builtin score: -0.2753701
INFO: dictionary score: -0.27255487
INFO: patch score: -0.27215233
INFO: edit score: -0.27118456
INFO: line score: -0.26962766
INFO: ubuntu score: -0.26946315
INFO: collection score: -0.26864505
INFO: care score: -0.26779586
INFO: print score: -0.2651614
INFO: permission score: -0.25827587
INFO: reachable score: -0.2579036
INFO: tutorial score: -0.25747055
INFO: magic score: -0.25742823
INFO: directory score: -0.24777599
INFO: speak score: -0.24669385
INFO: needle score: -0.2434527
INFO: tab score: -0.24226224
INFO: strange score: -0.24203432
INFO: press score: -0.24096866
INFO: people score: -0.23707792
INFO: autocompletion score: -0.23493981
INFO: old score: -0.233875
INFO: year score: -0.2328816
INFO: trick score: -0.22790892
INFO: foo score: -0.22773656
INFO: dot score: -0.22328782
INFO: member score: -0.21923617
INFO: goal score: -0.21915968
INFO: bash score: -0.2166319
INFO: howto score: -0.21547483
INFO: javascript score: -0.21519484
INFO: age score: -0.21269934
INFO: command score: -0.21246094
INFO: func score: -0.2082857
INFO: obj score: -0.20412752
INFO: job score: -0.20023513
INFO: top score: -0.19480015
INFO: nice score: -0.18931979
INFO: shell score: -0.1876272
INFO: f score: -0.18099909
INFO: dict score: -0.17627373
INFO: str1 score: -0.17158106
INFO: garbage score: -0.16183281
INFO: thank score: -0.1587014
INFO: binder score: -0.15659416
INFO: lambda score: -0.15623473
INFO: library score: -0.15107901
INFO: wiki score: -0.14264224
INFO: forgiveness score: -0.13350637
INFO: faq score: -0.12926175
INFO: peek score: -0.11998189
INFO: int score: -0.11597181
INFO: store score: -0.10195361
INFO: community score: -0.096764885
INFO: bar score: -0.08618347
INFO: liner score: -0.08610942
INFO: str score: -0.065599
INFO: doc score: -0.062467113
INFO: vote score: -0.056944676
INFO: track score: -0.056892205
INFO: repr score: -0.054987505
INFO: monkey score: -0.041909795
INFO: jeff score: -0.002446704
INFO: arturo score: -0.0
INFO: zope score: -0.0
INFO: atwood score: -0.0
INFO: ipython score: -0.0
INFO: a. score: -0.0
INFO: types.functiontype score: -0.0
INFO: guineapig score: -0.0
INFO: types.methodtype score: -0.0
INFO: http://docs.python.org/library/new.html score: -0.0
INFO: patch_me score: -0.0
INFO: modifie score: -0.0
INFO: addmethod score: -0.0
INFO: setattr score: -0.0
INFO: hasattr(module_name score: -0.0
INFO: diveintopython.net score: -0.0
INFO: attributeerror score: -0.0
INFO: dir(objectname score: -0.0
INFO: print_name score: -0.0
INFO: get_object_function score: -0.0
INFO: help(dir score: -0.0
INFO: getattr score: -0.0
INFO: getattribute score: -0.0
INFO: pythonic score: -0.0
INFO: pydoc score: -0.0
INFO: repl score: -0.0
INFO: list(filter(lambda score: -0.0
INFO: callable(getattr(obj score: -0.0
INFO: inspect.ismethod score: -0.0
INFO: cython score: -0.0
INFO: getattrs score: -0.0
INFO: pytest score: -0.0
INFO: print(dir(class score: -0.0
INFO: print(help(classname score: -0.0
INFO: staticmethod score: -0.0
INFO: classmethod score: -0.0
INFO: names¹. score: -0.0
INFO: getmember score: -0.0
INFO: 3.x score: -0.0
INFO: dunder score: -0.0
INFO: functiontype score: -0.0
INFO: class.__dict score: -0.0
INFO: dir(theobject score: -0.0
INFO: codeape score: -0.0
INFO: inspect.getmember score: -0.0
INFO: person.full_name score: -0.0
INFO: person.__dict__['full_name'].__get__(none score: -0.0
INFO: @mgilson score: -0.0
INFO: wombatz score: -0.0
INFO: c.function score: -0.0
INFO: myclass.f score: -0.0
INFO: x.f score: -0.0
INFO: class.functionname score: -0.0
INFO: instance.functionname score: -0.0
INFO: foo.bar score: -0.0
INFO: decorator score: 0.012097511
INFO: pratt score: 0.015412375
INFO: ahh score: 0.022572786
INFO: var score: 0.0336973
INFO: gorilla score: 0.03615889
INFO: jason score: 0.04020433
INFO: route score: 0.09362066
INFO: dir score: 0.107343964
INFO: ============================================================
INFO: --------------------
INFO: How can my code discover the name of an object?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<599 unique tokens: ['=', '@aivar', '@juan', '@mherzog)-', '@scohe001']...> from 10 documents (total 2018 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<599 unique tokens: ['=', '@aivar', '@juan', '@mherzog)-', '@scohe001']...> from 10 documents (total 2018 corpus positions)", 'datetime': '2023-03-20T16:53:04.575549', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.571 per-word bound, 190.2 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.075*"name" + 0.051*"variable" + 0.048*"function" + 0.031*"object" + 0.023*"value" + 0.022*"code" + 0.017*"class" + 0.017*"list" + 0.016*"string" + 0.011*"frame"
INFO: topic #1 (1.000): 0.079*"name" + 0.050*"variable" + 0.047*"object" + 0.044*"function" + 0.020*"code" + 0.019*"value" + 0.014*"list" + 0.012*"string" + 0.012*"frame" + 0.011*"global"
INFO: topic #2 (1.000): 0.083*"name" + 0.052*"variable" + 0.045*"function" + 0.028*"object" + 0.019*"code" + 0.018*"value" + 0.017*"string" + 0.013*"class" + 0.012*"global" + 0.012*"list"
INFO: topic diff=2.655170, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.435 per-word bound, 1384.2 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"name" + 0.047*"class" + 0.038*"variable" + 0.038*"function" + 0.038*"object" + 0.030*"instance" + 0.027*"code" + 0.017*"value" + 0.014*"list" + 0.012*"example"
INFO: topic #1 (1.000): 0.082*"name" + 0.074*"object" + 0.053*"variable" + 0.035*"function" + 0.023*"value" + 0.020*"reference" + 0.019*"code" + 0.016*"way" + 0.015*"instance" + 0.015*"class"
INFO: topic #2 (1.000): 0.072*"name" + 0.043*"variable" + 0.037*"function" + 0.028*"object" + 0.017*"code" + 0.017*"class" + 0.015*"value" + 0.013*"string" + 0.012*"instance" + 0.009*"global"
INFO: topic diff=1.992905, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 89.32584125031907
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.26187316598874183
DEBUG: bound: at document #0
INFO: -6.278 per-word bound, 77.6 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.065*"name" + 0.059*"variable" + 0.042*"function" + 0.026*"code" + 0.025*"class" + 0.023*"object" + 0.023*"value" + 0.020*"list" + 0.015*"string" + 0.014*"instance"
INFO: topic #1 (1.000): 0.091*"name" + 0.063*"object" + 0.045*"function" + 0.041*"variable" + 0.018*"value" + 0.017*"code" + 0.013*"string" + 0.013*"way" + 0.011*"class" + 0.011*"global"
INFO: topic #2 (1.000): 0.061*"name" + 0.035*"variable" + 0.031*"function" + 0.023*"object" + 0.014*"class" + 0.014*"code" + 0.013*"value" + 0.011*"string" + 0.010*"instance" + 0.009*"global"
INFO: topic diff=1.250214, rho=0.500000
DEBUG: bound: at document #0
INFO: -8.213 per-word bound, 296.8 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"name" + 0.044*"variable" + 0.040*"class" + 0.033*"function" + 0.029*"instance" + 0.028*"object" + 0.027*"code" + 0.017*"value" + 0.016*"list" + 0.013*"example"
INFO: topic #1 (1.000): 0.087*"name" + 0.073*"object" + 0.046*"variable" + 0.038*"function" + 0.021*"value" + 0.018*"reference" + 0.016*"way" + 0.015*"code" + 0.013*"dictionary" + 0.012*"string"
INFO: topic #2 (1.000): 0.047*"name" + 0.027*"function" + 0.026*"variable" + 0.018*"object" + 0.014*"class" + 0.012*"code" + 0.010*"instance" + 0.010*"value" + 0.008*"string" + 0.007*"hack"
INFO: topic diff=1.188632, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 66.29167046315878
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -0.7694078656414844
DEBUG: bound: at document #0
INFO: -5.970 per-word bound, 62.7 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.063*"name" + 0.062*"variable" + 0.040*"function" + 0.026*"code" + 0.024*"class" + 0.023*"value" + 0.022*"object" + 0.020*"list" + 0.015*"instance" + 0.014*"string"
INFO: topic #1 (1.000): 0.093*"name" + 0.066*"object" + 0.045*"function" + 0.033*"variable" + 0.017*"value" + 0.015*"code" + 0.014*"way" + 0.013*"string" + 0.012*"global" + 0.011*"class"
INFO: topic #2 (1.000): 0.035*"name" + 0.020*"function" + 0.019*"variable" + 0.013*"object" + 0.011*"class" + 0.009*"code" + 0.008*"instance" + 0.008*"value" + 0.006*"string" + 0.006*"hack"
INFO: topic diff=0.937507, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.999 per-word bound, 127.9 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.058*"name" + 0.049*"variable" + 0.036*"class" + 0.034*"function" + 0.027*"instance" + 0.027*"code" + 0.026*"object" + 0.018*"value" + 0.017*"list" + 0.014*"example"
INFO: topic #1 (1.000): 0.089*"name" + 0.075*"object" + 0.039*"variable" + 0.039*"function" + 0.020*"value" + 0.018*"reference" + 0.017*"way" + 0.014*"code" + 0.013*"dictionary" + 0.012*"string"
INFO: topic #2 (1.000): 0.025*"name" + 0.017*"function" + 0.015*"hack" + 0.014*"a.__name" + 0.014*"a().__class__.__name" + 0.014*"post" + 0.013*"variable" + 0.011*"class" + 0.009*"object" + 0.008*"quick"
INFO: topic diff=0.652701, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 61.88241734660529
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -1.5294853983025736
DEBUG: bound: at document #0
INFO: -5.859 per-word bound, 58.0 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.063*"variable" + 0.062*"name" + 0.039*"function" + 0.026*"code" + 0.024*"class" + 0.023*"value" + 0.022*"object" + 0.020*"list" + 0.015*"instance" + 0.014*"string"
INFO: topic #1 (1.000): 0.094*"name" + 0.068*"object" + 0.045*"function" + 0.031*"variable" + 0.016*"value" + 0.015*"code" + 0.014*"way" + 0.013*"string" + 0.012*"global" + 0.012*"reference"
INFO: topic #2 (1.000): 0.018*"name" + 0.012*"function" + 0.011*"hack" + 0.010*"a.__name" + 0.010*"a().__class__.__name" + 0.010*"post" + 0.009*"variable" + 0.008*"class" + 0.007*"object" + 0.006*"quick"
INFO: topic diff=0.606059, rho=0.408248
DEBUG: bound: at document #0
INFO: -6.851 per-word bound, 115.5 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"name" + 0.052*"variable" + 0.034*"class" + 0.034*"function" + 0.026*"code" + 0.026*"instance" + 0.026*"object" + 0.018*"value" + 0.017*"list" + 0.014*"example"
INFO: topic #1 (1.000): 0.090*"name" + 0.075*"object" + 0.040*"function" + 0.037*"variable" + 0.019*"value" + 0.018*"reference" + 0.017*"way" + 0.013*"code" + 0.013*"dictionary" + 0.012*"string"
INFO: topic #2 (1.000): 0.020*"hack" + 0.018*"a.__name" + 0.018*"a().__class__.__name" + 0.018*"post" + 0.013*"name" + 0.012*"quick" + 0.010*"function" + 0.007*"class" + 0.006*"variable" + 0.005*"object"
INFO: topic diff=0.395204, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 60.69981143423721
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -1.385917073343079
DEBUG: bound: at document #0
INFO: -5.819 per-word bound, 56.4 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.063*"variable" + 0.062*"name" + 0.039*"function" + 0.026*"code" + 0.024*"class" + 0.022*"value" + 0.022*"object" + 0.020*"list" + 0.016*"instance" + 0.013*"string"
INFO: topic #1 (1.000): 0.094*"name" + 0.069*"object" + 0.045*"function" + 0.030*"variable" + 0.016*"value" + 0.015*"code" + 0.014*"way" + 0.013*"string" + 0.012*"reference" + 0.012*"global"
INFO: topic #2 (1.000): 0.014*"hack" + 0.012*"a.__name" + 0.012*"a().__class__.__name" + 0.012*"post" + 0.009*"name" + 0.008*"quick" + 0.007*"function" + 0.005*"class" + 0.005*"variable" + 0.004*"object"
INFO: topic diff=0.403802, rho=0.377964
DEBUG: bound: at document #0
INFO: -6.804 per-word bound, 111.8 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"name" + 0.053*"variable" + 0.034*"function" + 0.033*"class" + 0.026*"code" + 0.025*"object" + 0.025*"instance" + 0.019*"value" + 0.017*"list" + 0.014*"example"
INFO: topic #1 (1.000): 0.091*"name" + 0.075*"object" + 0.040*"function" + 0.036*"variable" + 0.019*"value" + 0.018*"reference" + 0.017*"way" + 0.013*"code" + 0.013*"dictionary" + 0.012*"string"
INFO: topic #2 (1.000): 0.023*"hack" + 0.019*"post" + 0.019*"a.__name" + 0.019*"a().__class__.__name" + 0.015*"quick" + 0.007*"name" + 0.005*"function" + 0.004*"class" + 0.003*"variable" + 0.003*"object"
INFO: topic diff=0.276603, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 60.271087409161616
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -1.3760096348471496
DEBUG: bound: at document #0
INFO: -5.799 per-word bound, 55.7 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.063*"variable" + 0.062*"name" + 0.039*"function" + 0.026*"code" + 0.024*"class" + 0.022*"object" + 0.022*"value" + 0.019*"list" + 0.016*"instance" + 0.013*"example"
INFO: topic #1 (1.000): 0.094*"name" + 0.069*"object" + 0.045*"function" + 0.029*"variable" + 0.016*"value" + 0.014*"code" + 0.014*"way" + 0.013*"string" + 0.012*"reference" + 0.012*"global"
INFO: topic #2 (1.000): 0.016*"hack" + 0.014*"post" + 0.014*"a.__name" + 0.014*"a().__class__.__name" + 0.011*"quick" + 0.005*"name" + 0.004*"function" + 0.004*"class" + 0.003*"variable" + 0.002*"object"
INFO: topic diff=0.302473, rho=0.353553
DEBUG: bound: at document #0
INFO: -6.781 per-word bound, 109.9 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"name" + 0.054*"variable" + 0.035*"function" + 0.033*"class" + 0.026*"code" + 0.025*"object" + 0.025*"instance" + 0.019*"value" + 0.017*"list" + 0.014*"example"
INFO: topic #1 (1.000): 0.091*"name" + 0.075*"object" + 0.041*"function" + 0.035*"variable" + 0.019*"value" + 0.017*"reference" + 0.016*"way" + 0.013*"code" + 0.013*"dictionary" + 0.012*"string"
INFO: topic #2 (1.000): 0.026*"hack" + 0.019*"post" + 0.019*"a.__name" + 0.019*"a().__class__.__name" + 0.018*"quick" + 0.004*"name" + 0.003*"function" + 0.003*"class" + 0.002*"variable" + 0.002*"object"
INFO: topic diff=0.240274, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 60.0593407899501
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -1.3760096348471496
DEBUG: bound: at document #0
INFO: -5.786 per-word bound, 55.2 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.063*"variable" + 0.062*"name" + 0.039*"function" + 0.026*"code" + 0.024*"class" + 0.022*"object" + 0.022*"value" + 0.019*"list" + 0.016*"instance" + 0.013*"example"
INFO: topic #1 (1.000): 0.094*"name" + 0.069*"object" + 0.045*"function" + 0.029*"variable" + 0.016*"value" + 0.014*"code" + 0.014*"way" + 0.013*"string" + 0.012*"reference" + 0.012*"global"
INFO: topic #2 (1.000): 0.018*"hack" + 0.014*"post" + 0.014*"a.__name" + 0.014*"a().__class__.__name" + 0.013*"quick" + 0.003*"name" + 0.003*"function" + 0.002*"class" + 0.002*"variable" + 0.002*"object"
INFO: topic diff=0.252863, rho=0.333333
DEBUG: bound: at document #0
INFO: -6.764 per-word bound, 108.7 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"name" + 0.054*"variable" + 0.035*"function" + 0.032*"class" + 0.026*"code" + 0.025*"object" + 0.024*"instance" + 0.019*"value" + 0.017*"list" + 0.014*"example"
INFO: topic #1 (1.000): 0.091*"name" + 0.075*"object" + 0.041*"function" + 0.034*"variable" + 0.019*"value" + 0.017*"reference" + 0.016*"way" + 0.013*"code" + 0.013*"dictionary" + 0.012*"string"
INFO: topic #2 (1.000): 0.028*"hack" + 0.022*"quick" + 0.019*"post" + 0.019*"a.__name" + 0.019*"a().__class__.__name" + 0.003*"name" + 0.002*"function" + 0.002*"class" + 0.002*"variable" + 0.002*"object"
INFO: topic diff=0.223958, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 59.930728198252226
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -1.4004232412619964
DEBUG: bound: at document #0
INFO: -5.777 per-word bound, 54.8 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.063*"variable" + 0.062*"name" + 0.039*"function" + 0.026*"code" + 0.024*"class" + 0.023*"object" + 0.022*"value" + 0.019*"list" + 0.016*"instance" + 0.013*"example"
INFO: topic #1 (1.000): 0.094*"name" + 0.069*"object" + 0.045*"function" + 0.029*"variable" + 0.016*"value" + 0.014*"code" + 0.014*"way" + 0.013*"string" + 0.012*"reference" + 0.012*"global"
INFO: topic #2 (1.000): 0.021*"hack" + 0.016*"quick" + 0.014*"post" + 0.014*"a.__name" + 0.014*"a().__class__.__name" + 0.002*"name" + 0.002*"function" + 0.002*"class" + 0.002*"variable" + 0.002*"object"
INFO: topic diff=0.225734, rho=0.316228
DEBUG: bound: at document #0
INFO: -6.752 per-word bound, 107.8 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"name" + 0.054*"variable" + 0.035*"function" + 0.032*"class" + 0.026*"code" + 0.025*"object" + 0.024*"instance" + 0.019*"value" + 0.017*"list" + 0.014*"example"
INFO: topic #1 (1.000): 0.091*"name" + 0.075*"object" + 0.041*"function" + 0.034*"variable" + 0.019*"value" + 0.017*"reference" + 0.016*"way" + 0.013*"code" + 0.012*"dictionary" + 0.012*"string"
INFO: topic #2 (1.000): 0.031*"hack" + 0.025*"quick" + 0.019*"post" + 0.019*"a.__name" + 0.019*"a().__class__.__name" + 0.002*"name" + 0.002*"function" + 0.002*"class" + 0.002*"variable" + 0.002*"object"
INFO: topic diff=0.210909, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 59.840271282245126
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -1.4004232412619964
DEBUG: bound: at document #0
INFO: -5.770 per-word bound, 54.6 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.063*"variable" + 0.062*"name" + 0.039*"function" + 0.026*"code" + 0.024*"class" + 0.023*"object" + 0.022*"value" + 0.019*"list" + 0.017*"instance" + 0.013*"example"
INFO: topic #1 (1.000): 0.094*"name" + 0.069*"object" + 0.045*"function" + 0.029*"variable" + 0.016*"value" + 0.014*"way" + 0.014*"code" + 0.013*"string" + 0.012*"reference" + 0.011*"global"
INFO: topic #2 (1.000): 0.023*"hack" + 0.018*"quick" + 0.014*"post" + 0.014*"a.__name" + 0.014*"a().__class__.__name" + 0.002*"name" + 0.002*"function" + 0.002*"class" + 0.002*"variable" + 0.002*"object"
INFO: topic diff=0.208558, rho=0.301511
DEBUG: bound: at document #0
INFO: -6.742 per-word bound, 107.0 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"name" + 0.055*"variable" + 0.035*"function" + 0.032*"class" + 0.026*"code" + 0.025*"object" + 0.024*"instance" + 0.019*"value" + 0.018*"list" + 0.014*"example"
INFO: topic #1 (1.000): 0.092*"name" + 0.075*"object" + 0.041*"function" + 0.034*"variable" + 0.018*"value" + 0.017*"reference" + 0.016*"way" + 0.013*"code" + 0.012*"string" + 0.012*"dictionary"
INFO: topic #2 (1.000): 0.033*"hack" + 0.028*"quick" + 0.019*"post" + 0.019*"a.__name" + 0.019*"a().__class__.__name" + 0.002*"name" + 0.002*"function" + 0.002*"class" + 0.002*"variable" + 0.002*"object"
INFO: topic diff=0.199392, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 59.76967527441319
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -1.4004232412619964
DEBUG: bound: at document #0
INFO: -5.764 per-word bound, 54.3 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.062*"variable" + 0.062*"name" + 0.039*"function" + 0.026*"code" + 0.025*"class" + 0.023*"object" + 0.022*"value" + 0.019*"list" + 0.017*"instance" + 0.013*"example"
INFO: topic #1 (1.000): 0.094*"name" + 0.069*"object" + 0.045*"function" + 0.030*"variable" + 0.016*"value" + 0.014*"way" + 0.014*"code" + 0.013*"string" + 0.013*"reference" + 0.011*"global"
INFO: topic #2 (1.000): 0.024*"hack" + 0.021*"quick" + 0.014*"post" + 0.014*"a.__name" + 0.014*"a().__class__.__name" + 0.002*"name" + 0.002*"function" + 0.002*"class" + 0.002*"variable" + 0.002*"object"
INFO: topic diff=0.196173, rho=0.288675
DEBUG: bound: at document #0
INFO: -6.732 per-word bound, 106.3 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"name" + 0.055*"variable" + 0.035*"function" + 0.031*"class" + 0.026*"code" + 0.025*"object" + 0.023*"instance" + 0.019*"value" + 0.018*"list" + 0.014*"example"
INFO: topic #1 (1.000): 0.092*"name" + 0.074*"object" + 0.041*"function" + 0.034*"variable" + 0.018*"value" + 0.017*"reference" + 0.016*"way" + 0.014*"code" + 0.012*"string" + 0.012*"dictionary"
INFO: topic #2 (1.000): 0.034*"hack" + 0.031*"quick" + 0.019*"post" + 0.019*"a.__name" + 0.019*"a().__class__.__name" + 0.002*"name" + 0.002*"function" + 0.002*"class" + 0.002*"variable" + 0.002*"object"
INFO: topic diff=0.189390, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 59.71252332896668
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.4004232412619964
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5> in 0.30s', 'datetime': '2023-03-20T16:53:04.881970', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/questions/12/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-20T16:53:04.882205', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/questions/12/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/12/model.state
DEBUG: {'uri': 'model/questions/12/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/questions/12/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-20T16:53:04.886695', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/questions/12/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/questions/12/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/12/model
INFO: topic #0 (1.000): 0.060*"name" + 0.055*"variable" + 0.035*"function" + 0.031*"class" + 0.026*"code" + 0.025*"object" + 0.023*"instance" + 0.019*"value" + 0.018*"list" + 0.014*"example"
INFO: topic #1 (1.000): 0.092*"name" + 0.074*"object" + 0.041*"function" + 0.034*"variable" + 0.018*"value" + 0.017*"reference" + 0.016*"way" + 0.014*"code" + 0.012*"string" + 0.012*"dictionary"
INFO: topic #2 (1.000): 0.034*"hack" + 0.031*"quick" + 0.019*"post" + 0.019*"a.__name" + 0.019*"a().__class__.__name" + 0.002*"name" + 0.002*"function" + 0.002*"class" + 0.002*"variable" + 0.002*"object"
INFO: Question Similarity: [0.1509883999824524, 0.04883831739425659, 0.10391420125961304, 0.128229022026062, 0.10648477077484131, 0.09669965505599976, 0.3102548122406006, 0.10299235582351685, 0.09972989559173584, 0.1045263409614563]
INFO: 30019630: -0.0881212583694295
INFO: 54349277: -0.08855810539411678
INFO: 23258737: -0.0890358624522289
INFO: 1539517: -0.08943788455086553
INFO: 1538380: -0.09034230556437045
INFO: 21339843: -0.09047006182322027
INFO: 39240374: -0.09067595017650604
INFO: 1538772: -0.09079856698089595
INFO: 1539174: -0.0910695922805302
INFO: 1539112: -0.09212775818477151
INFO: 30019808: -0.09213791244374267
INFO: 1538466: -0.0922632666351321
INFO: 68743685: -0.0931642634043814
INFO: 1538399: -0.09375248132480167
INFO: 1539123: -0.0963707032338788
INFO: 16139159: -0.09646056239144231
INFO: 64053336: -0.10506460475856017
INFO: 57648972: -0.175109668474388
INFO: 57649418: -0.1754583956357035
INFO: 57648979: -0.17551138176664516
INFO: 17200177: -0.18370583095109724
INFO: 17200322: -0.18745766456469257
INFO: 71791073: -0.18940597456300323
INFO: 8875330: -0.1920953536674968
INFO: 41586688: -0.19291771622088627
INFO: 8875313: -0.19477928826077717
INFO: 17200188: -0.19492442968496432
INFO: 8875258: -0.1975964645591097
INFO: 63661634: -0.207799520594172
INFO: 59914969: -0.20899839347125743
INFO: 33912052: -0.2116426150615799
INFO: 19156516: -0.2230524806410087
INFO: 18983693: -0.2249525071180745
INFO: 18983795: -0.22505964830962177
INFO: 18983535: -0.22560923558173426
INFO: 18983610: -0.22582652987790233
INFO: 18983557: -0.22629733357480622
INFO: 18983728: -0.2267370695242451
INFO: 17196512: -0.22834604707206727
INFO: 17196943: -0.2431459676798338
INFO: 67092322: -0.267466135525128
INFO: 67092520: -0.2804181307174374
INFO: 57503767: -0.30712214790276676
INFO: 54423514: -0.30861200773375225
INFO: 54999371: -0.31133121463909735
INFO: 67419557: -0.3140781614952575
INFO: 40536047: -0.3167645456279411
INFO: 71962669: -0.3190423440757006
INFO: 18425275: -0.31926224399148057
INFO: 18425285: -0.31928154303502665
INFO: 63171710: -0.3203881980596701
INFO: 60826880: -0.32081336159183205
INFO: 65678960: -0.32428147113675715
INFO: 66833271: -0.32429925226616685
INFO: 59721785: -0.3257926182030794
INFO: 46471018: -0.3259653121507559
INFO: 59079732: -0.32602403883017506
INFO: 72890920: -0.3263852698263455
INFO: 18425336: -0.3275615398357447
INFO: 59804094: -0.3276804028298638
INFO: 58451182: -0.3288508378557115
INFO: 53684586: -0.3289219938230479
INFO: 73495512: -0.3296128238169263
INFO: 51347986: -0.3297039663411152
INFO: 30922184: -0.329873617661693
INFO: 18425312: -0.3300141682270634
INFO: 69496355: -0.33033500681467326
INFO: 18425523: -0.3305947465177306
INFO: 69960020: -0.330885098238596
INFO: 54033089: -0.3310544284281967
INFO: 71712672: -0.3313668410508934
INFO: 75046191: -0.3317554205217379
INFO: 19201952: -0.3317554205217379
INFO: 59364138: -0.3341099173678762
INFO: 49331805: -0.6518479880421135
INFO: 38599084: -0.6561605989858186
INFO: 38599196: -0.6733477831474005
INFO: Recommended Keywords
INFO: example score: -0.8966918
INFO: instance score: -0.8810488
INFO: specific score: -0.8024551
INFO: function score: -0.7983081
INFO: type score: -0.79448223
INFO: define score: -0.7805101
INFO: element score: -0.78037256
INFO: defining score: -0.77720183
INFO: possible score: -0.77569336
INFO: equivalent score: -0.7638515
INFO: reference score: -0.76123714
INFO: simple score: -0.76086175
INFO: attribute score: -0.7533677
INFO: relation score: -0.74607676
INFO: denote score: -0.7373797
INFO: exact score: -0.73451006
INFO: certain score: -0.7131715
INFO: eg score: -0.7052645
INFO: useful score: -0.7006029
INFO: object score: -0.69795203
INFO: arbitrary score: -0.6949063
INFO: usage score: -0.68897575
INFO: equal score: -0.68727905
INFO: source score: -0.68694615
INFO: variable score: -0.68487495
INFO: common score: -0.6839179
INFO: case score: -0.68350446
INFO: method score: -0.6800819
INFO: form score: -0.6785124
INFO: true score: -0.6723201
INFO: mean score: -0.66810584
INFO: consider score: -0.6658223
INFO: code score: -0.6632553
INFO: variation score: -0.6565871
INFO: multiple score: -0.65439606
INFO: process score: -0.6471995
INFO: convenient score: -0.644288
INFO: value score: -0.64251584
INFO: determine score: -0.63928
INFO: order score: -0.6364672
INFO: problem score: -0.63440007
INFO: word score: -0.63021857
INFO: fact score: -0.6276042
INFO: reverse score: -0.62750876
INFO: principle score: -0.6271244
INFO: solution score: -0.62584895
INFO: input score: -0.6257172
INFO: result score: -0.6204826
INFO: application score: -0.61853325
INFO: key score: -0.61479336
INFO: note score: -0.6086822
INFO: requirement score: -0.6075919
INFO: drawback score: -0.60367537
INFO: item score: -0.6007079
INFO: need score: -0.59876037
INFO: approach score: -0.5968947
INFO: insert score: -0.59184885
INFO: complete score: -0.5895339
INFO: contain score: -0.5861952
INFO: reason score: -0.58326125
INFO: clear score: -0.58317834
INFO: choice score: -0.5800465
INFO: procedure score: -0.5795544
INFO: keyword score: -0.57670945
INFO: map score: -0.57643354
INFO: error score: -0.57584107
INFO: pointing score: -0.5754391
INFO: subject score: -0.574006
INFO: important score: -0.5698799
INFO: canonical score: -0.56745464
INFO: weak score: -0.5628433
INFO: kind score: -0.56067044
INFO: purpose score: -0.5599452
INFO: effective score: -0.5582813
INFO: iterate score: -0.556035
INFO: impossible score: -0.553702
INFO: information score: -0.553308
INFO: easy score: -0.55252564
INFO: content score: -0.5480969
INFO: whole score: -0.5477588
INFO: prefix score: -0.5475434
INFO: least score: -0.5463254
INFO: efficient score: -0.54508483
INFO: dimension score: -0.5444595
INFO: index score: -0.5441277
INFO: create score: -0.5422614
INFO: theory score: -0.5418316
INFO: mapping score: -0.5403817
INFO: current score: -0.5395365
INFO: identity score: -0.5389783
INFO: unusual score: -0.536178
INFO: parameter score: -0.5256504
INFO: frame score: -0.523339
INFO: schema score: -0.52327615
INFO: logic score: -0.5221493
INFO: technique score: -0.5207407
INFO: output score: -0.5192736
INFO: point score: -0.5179001
INFO: superset score: -0.5176946
INFO: class score: -0.51584566
INFO: argument score: -0.5155256
INFO: environment score: -0.5125465
INFO: other score: -0.51162314
INFO: scope score: -0.5115295
INFO: available score: -0.50530916
INFO: parent score: -0.5046042
INFO: difficult score: -0.50383264
INFO: well score: -0.50378335
INFO: memory score: -0.502559
INFO: generalize score: -0.5011112
INFO: glance score: -0.4957986
INFO: namespace score: -0.4929822
INFO: separate score: -0.49244037
INFO: search score: -0.49058515
INFO: dictionary score: -0.48920012
INFO: question score: -0.48663566
INFO: database score: -0.48620227
INFO: stack score: -0.48451036
INFO: parse score: -0.48430464
INFO: many score: -0.47860262
INFO: module score: -0.47568172
INFO: node score: -0.4746563
INFO: pointer score: -0.47300568
INFO: nodes score: -0.47159642
INFO: original score: -0.46743876
INFO: documentation score: -0.4672884
INFO: self score: -0.46426538
INFO: person score: -0.46286157
INFO: hash score: -0.46103084
INFO: language score: -0.45857614
INFO: file score: -0.45339608
INFO: datum score: -0.4518177
INFO: way score: -0.4513526
INFO: filter score: -0.44565308
INFO: detail score: -0.44321343
INFO: integer score: -0.44244042
INFO: list score: -0.44230077
INFO: implementation score: -0.43968108
INFO: name score: -0.43859854
INFO: unicode score: -0.43780315
INFO: general score: -0.4371666
INFO: long score: -0.4352009
INFO: number score: -0.43165293
INFO: iterator score: -0.42844355
INFO: constructor score: -0.42743343
INFO: call score: -0.4272873
INFO: extra score: -0.42167976
INFO: enough score: -0.41628227
INFO: handling score: -0.41574034
INFO: package score: -0.4138437
INFO: idea score: -0.40835258
INFO: builtin score: -0.4078814
INFO: instant score: -0.4076978
INFO: interpreter score: -0.40745047
INFO: base score: -0.40704238
INFO: consist score: -0.40678024
INFO: hold score: -0.40324998
INFO: loop score: -0.40321958
INFO: level score: -0.39746547
INFO: single score: -0.39579457
INFO: moment score: -0.3955542
INFO: init score: -0.39478254
INFO: pause score: -0.39370584
INFO: patch score: -0.39142635
INFO: location score: -0.39112073
INFO: ids score: -0.3873881
INFO: able score: -0.38425025
INFO: page score: -0.3841577
INFO: wrapper score: -0.3832432
INFO: property score: -0.38214356
INFO: large score: -0.375497
INFO: good score: -0.37390572
INFO: thing score: -0.37367168
INFO: print score: -0.371999
INFO: lambdas score: -0.37151176
INFO: write score: -0.36995292
INFO: design score: -0.36755303
INFO: wish score: -0.3667496
INFO: debugging score: -0.3634918
INFO: access score: -0.36084783
INFO: look score: -0.35892925
INFO: part score: -0.35573643
INFO: c score: -0.3545043
INFO: string score: -0.35089818
INFO: assignment score: -0.3478888
INFO: version score: -0.34720868
INFO: main score: -0.34583807
INFO: count score: -0.3455712
INFO: dict score: -0.3425584
INFO: time score: -0.34176815
INFO: outer score: -0.34163478
INFO: caller score: -0.34028193
INFO: foo score: -0.33738825
INFO: several score: -0.33709943
INFO: work score: -0.3356417
INFO: lifetime score: -0.33448926
INFO: hack score: -0.33197695
INFO: bug score: -0.33099052
INFO: my_list score: -0.32992953
INFO: json score: -0.3289388
INFO: global score: -0.32798326
INFO: new score: -0.32724205
INFO: none score: -0.3256019
INFO: tree score: -0.3251191
INFO: comprehensive score: -0.32141456
INFO: f score: -0.32098615
INFO: text score: -0.3194889
INFO: g score: -0.31893256
INFO: answer score: -0.31636998
INFO: script score: -0.31635618
INFO: quick score: -0.31187394
INFO: close score: -0.31083113
INFO: previous score: -0.3089178
INFO: obj score: -0.30669945
INFO: retrieve score: -0.30555183
INFO: local score: -0.29855895
INFO: trustworthy score: -0.29432473
INFO: tricky score: -0.29129243
INFO: inspect score: -0.2891253
INFO: want score: -0.2859674
INFO: z score: -0.28556144
INFO: issue score: -0.27703458
INFO: post score: -0.2709529
INFO: alert score: -0.26949018
INFO: len score: -0.2676723
INFO: lambda score: -0.2675889
INFO: = score: -0.2658342
INFO: succ score: -0.26542723
INFO: collection score: -0.2645974
INFO: pass score: -0.25955075
INFO: line score: -0.2546133
INFO: situation score: -0.25330222
INFO: var1 score: -0.25010902
INFO: whatis score: -0.24877875
INFO: f2 score: -0.24875313
INFO: frontend score: -0.24501367
INFO: format score: -0.24132456
INFO: cmd score: -0.24076454
INFO: comment score: -0.24064343
INFO: performance score: -0.2379377
INFO: program score: -0.23691614
INFO: magic score: -0.22753388
INFO: warning score: -0.22745149
INFO: first score: -0.22511005
INFO: lead score: -0.21545918
INFO: help score: -0.21293555
INFO: course score: -0.20651425
INFO: str score: -0.20178263
INFO: chance score: -0.20098996
INFO: place score: -0.19731596
INFO: store score: -0.19373094
INFO: library score: -0.18357065
INFO: willing score: -0.16606076
INFO: garbage score: -0.16550079
INFO: hope score: -0.16473293
INFO: exec score: -0.16419956
INFO: orm score: -0.16351752
INFO: worth score: -0.16173993
INFO: area score: -0.15725267
INFO: repr score: -0.15585928
INFO: live score: -0.1447038
INFO: command score: -0.14283736
INFO: snippet score: -0.13982412
INFO: return score: -0.13126051
INFO: grab score: -0.12788114
INFO: monkey score: -0.11262631
INFO: liner score: -0.10982347
INFO: late score: -0.10693745
INFO: try score: -0.10654919
INFO: var score: -0.10263872
INFO: fancy score: -0.09641141
INFO: cleans score: -0.089595556
INFO: private score: -0.08695523
INFO: wealth score: -0.08368782
INFO: fun score: -0.07714448
INFO: amr score: -0.07387364
INFO: wonderful score: -0.07167387
INFO: goal score: -0.061738104
INFO: insanity score: -0.04316127
INFO: ex score: -0.040024526
INFO: stores score: -0.03647596
INFO: cann score: -0.02728381
INFO: sorcery score: -0.02334545
INFO: bla score: -0.017126754
INFO: vol score: -0.009293524
INFO: vel score: -0.007285553
INFO: track score: -0.0013910148
INFO: dataframe score: -0.0
INFO: kwargs score: -0.0
INFO: slatkin score: -0.0
INFO: dunder score: -0.0
INFO: set_name score: -0.0
INFO: varname score: -0.0
INFO: var_1 score: -0.0
INFO: var_2 score: -0.0
INFO: idilip score: -0.0
INFO: var2 score: -0.0
INFO: myvar score: -0.0
INFO: @mherzog)- score: -0.0
INFO: sharaki score: -0.0
INFO: cann't score: -0.0
INFO: a[1 score: -0.0
INFO: b.val score: -0.0
INFO: python3 score: -0.0
INFO: autodict score: -0.0
INFO: hashmap score: -0.0
INFO: globals().item score: -0.0
INFO: except_word score: -0.0
INFO: each_item score: -0.0
INFO: self.name score: -0.0
INFO: test_function score: -0.0
INFO: dill.source.getname score: -0.0
INFO: getattr score: -0.0
INFO: p3.name score: -0.0
INFO: get_players_at_seat score: -0.0
INFO: atribute score: -0.0
INFO: driax score: -0.0
INFO: assignent score: -0.0
INFO: cpython score: -0.0
INFO: nameof score: -0.0
INFO: https://stackoverflow.com/a/49331683/7386061 score: -0.0
INFO: collector(gc score: -0.0
INFO: weakref score: -0.0
INFO: gc.get_object score: -0.0
INFO: myclass score: -0.0
INFO: some_object score: -0.0
INFO: object1 score: -0.0
INFO: identifier(or score: -0.0
INFO: a.__name score: -0.0
INFO: a().__class__.__name score: -0.0
INFO: astounded score: 0.011188151
INFO: brett score: 0.016912263
INFO: def score: 0.018433508
INFO: player score: 0.024128683
INFO: dill score: 0.034412332
INFO: round score: 0.03529577
INFO: garden score: 0.06273452
INFO: match score: 0.07773286
INFO: ============================================================
INFO: --------------------
INFO: Is it possible to write obfuscated one-liners in Python?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<389 unique tokens: ['2.20s', '3.10s', '9.76s', '=', '\\n']...> from 10 documents (total 845 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<389 unique tokens: ['2.20s', '3.10s', '9.76s', '=', '\\\\n']...> from 10 documents (total 845 corpus positions)", 'datetime': '2023-03-20T16:53:08.001964', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.538 per-word bound, 185.8 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.044*"line" + 0.029*"print" + 0.022*"file" + 0.021*"function" + 0.019*"\n" + 0.012*"context" + 0.012*"way" + 0.012*"newline" + 0.012*"list" + 0.012*"manager"
INFO: topic #1 (1.000): 0.039*"line" + 0.022*"function" + 0.017*"print" + 0.016*"write" + 0.015*"code" + 0.014*"useful" + 0.013*"command" + 0.012*"thing" + 0.012*"time" + 0.011*"lambda"
INFO: topic #2 (1.000): 0.038*"line" + 0.022*"print" + 0.018*"\n" + 0.018*"function" + 0.017*"file" + 0.015*"way" + 0.014*"character" + 0.014*"list" + 0.014*"newline" + 0.013*"method"
INFO: topic diff=2.707263, rho=1.000000
DEBUG: bound: at document #0
INFO: -13.196 per-word bound, 9381.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.049*"line" + 0.021*"print" + 0.018*"function" + 0.017*"\n" + 0.016*"file" + 0.016*"string" + 0.012*"way" + 0.012*"list" + 0.010*"code" + 0.009*"long"
INFO: topic #1 (1.000): 0.081*"line" + 0.035*"operator" + 0.024*"string" + 0.023*"code" + 0.020*"statement" + 0.016*"style" + 0.016*"bracket" + 0.014*"way" + 0.012*"work" + 0.012*"number"
INFO: topic #2 (1.000): 0.054*"line" + 0.028*"long" + 0.022*"string" + 0.020*"way" + 0.016*"number" + 0.015*"list" + 0.014*"function" + 0.013*"\n" + 0.013*"print" + 0.012*"operator"
INFO: topic diff=2.595973, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 124.60265519705146
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -1.8595334958398133
DEBUG: bound: at document #0
INFO: -6.774 per-word bound, 109.5 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.041*"line" + 0.031*"print" + 0.025*"file" + 0.024*"\n" + 0.021*"function" + 0.017*"way" + 0.016*"newline" + 0.014*"context" + 0.014*"character" + 0.014*"manager"
INFO: topic #1 (1.000): 0.060*"line" + 0.020*"code" + 0.017*"function" + 0.017*"operator" + 0.016*"command" + 0.016*"liner" + 0.015*"write" + 0.015*"statement" + 0.014*"work" + 0.014*"lambda"
INFO: topic #2 (1.000): 0.042*"line" + 0.025*"list" + 0.022*"long" + 0.017*"string" + 0.016*"way" + 0.014*"split" + 0.013*"number" + 0.013*"function" + 0.011*"print" + 0.010*"\n"
INFO: topic diff=1.531121, rho=0.500000
DEBUG: bound: at document #0
INFO: -8.768 per-word bound, 435.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.039*"line" + 0.028*"print" + 0.025*"\n" + 0.023*"file" + 0.020*"function" + 0.016*"way" + 0.015*"newline" + 0.013*"context" + 0.013*"character" + 0.013*"manager"
INFO: topic #1 (1.000): 0.078*"line" + 0.029*"operator" + 0.023*"string" + 0.021*"code" + 0.017*"continuation" + 0.017*"statement" + 0.016*"long" + 0.013*"way" + 0.012*"style" + 0.012*"bracket"
INFO: topic #2 (1.000): 0.026*"line" + 0.026*"result" + 0.024*"long" + 0.023*"number" + 0.021*"list" + 0.019*"string" + 0.018*"correct" + 0.017*"work" + 0.017*"expression" + 0.016*"operation"
INFO: topic diff=1.174739, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 81.11748868431033
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.87898666335382
DEBUG: bound: at document #0
INFO: -6.251 per-word bound, 76.2 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.039*"line" + 0.032*"print" + 0.027*"file" + 0.026*"\n" + 0.021*"function" + 0.017*"way" + 0.017*"newline" + 0.015*"character" + 0.015*"manager" + 0.015*"method"
INFO: topic #1 (1.000): 0.063*"line" + 0.020*"code" + 0.018*"operator" + 0.015*"command" + 0.015*"liner" + 0.015*"function" + 0.014*"statement" + 0.014*"write" + 0.013*"lambda" + 0.013*"string"
INFO: topic #2 (1.000): 0.035*"list" + 0.025*"result" + 0.022*"split" + 0.019*"line" + 0.017*"long" + 0.017*"number" + 0.014*"work" + 0.014*"string" + 0.014*"solution" + 0.013*"correct"
INFO: topic diff=0.978005, rho=0.447214
DEBUG: bound: at document #0
INFO: -7.388 per-word bound, 167.5 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.038*"line" + 0.030*"print" + 0.027*"\n" + 0.025*"file" + 0.020*"function" + 0.016*"way" + 0.016*"newline" + 0.014*"character" + 0.014*"manager" + 0.014*"method"
INFO: topic #1 (1.000): 0.078*"line" + 0.028*"operator" + 0.023*"string" + 0.021*"code" + 0.020*"long" + 0.018*"continuation" + 0.016*"statement" + 0.014*"way" + 0.012*"binary" + 0.011*"command"
INFO: topic #2 (1.000): 0.037*"result" + 0.026*"list" + 0.025*"number" + 0.023*"work" + 0.022*"correct" + 0.022*"expression" + 0.022*"operation" + 0.015*"solution" + 0.015*"string" + 0.013*"ternary"
INFO: topic diff=0.686416, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 74.31702955354783
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -2.809988554988307
DEBUG: bound: at document #0
INFO: -6.129 per-word bound, 70.0 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.039*"line" + 0.033*"print" + 0.027*"file" + 0.026*"\n" + 0.021*"function" + 0.018*"way" + 0.017*"newline" + 0.016*"character" + 0.015*"manager" + 0.015*"method"
INFO: topic #1 (1.000): 0.065*"line" + 0.020*"code" + 0.019*"operator" + 0.015*"command" + 0.015*"liner" + 0.014*"function" + 0.014*"string" + 0.014*"statement" + 0.013*"write" + 0.013*"lambda"
INFO: topic #2 (1.000): 0.039*"list" + 0.033*"result" + 0.025*"split" + 0.020*"ternary" + 0.020*"work" + 0.019*"number" + 0.019*"solution" + 0.016*"correct" + 0.015*"expression" + 0.015*"pythonic"
INFO: topic diff=0.595337, rho=0.408248
DEBUG: bound: at document #0
INFO: -7.149 per-word bound, 141.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.037*"line" + 0.031*"print" + 0.027*"\n" + 0.026*"file" + 0.020*"function" + 0.017*"way" + 0.016*"newline" + 0.015*"character" + 0.014*"manager" + 0.014*"method"
INFO: topic #1 (1.000): 0.077*"line" + 0.027*"operator" + 0.023*"string" + 0.021*"code" + 0.020*"long" + 0.018*"continuation" + 0.015*"statement" + 0.014*"way" + 0.012*"binary" + 0.012*"command"
INFO: topic #2 (1.000): 0.040*"result" + 0.029*"list" + 0.026*"number" + 0.025*"work" + 0.024*"expression" + 0.024*"correct" + 0.023*"operation" + 0.018*"ternary" + 0.018*"solution" + 0.016*"pythonic"
INFO: topic diff=0.423997, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 72.49087326468013
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -2.630986442298316
DEBUG: bound: at document #0
INFO: -6.086 per-word bound, 67.9 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.038*"line" + 0.033*"print" + 0.027*"file" + 0.026*"\n" + 0.021*"function" + 0.018*"way" + 0.017*"newline" + 0.016*"character" + 0.015*"manager" + 0.015*"method"
INFO: topic #1 (1.000): 0.065*"line" + 0.020*"code" + 0.019*"operator" + 0.015*"command" + 0.015*"liner" + 0.015*"string" + 0.014*"function" + 0.014*"statement" + 0.013*"write" + 0.013*"lambda"
INFO: topic #2 (1.000): 0.041*"list" + 0.036*"result" + 0.026*"ternary" + 0.025*"split" + 0.022*"work" + 0.020*"solution" + 0.020*"number" + 0.019*"pythonic" + 0.017*"correct" + 0.017*"expression"
INFO: topic diff=0.382628, rho=0.377964
DEBUG: bound: at document #0
INFO: -7.066 per-word bound, 134.0 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.037*"line" + 0.031*"print" + 0.027*"\n" + 0.026*"file" + 0.020*"function" + 0.017*"way" + 0.017*"newline" + 0.015*"character" + 0.014*"manager" + 0.014*"method"
INFO: topic #1 (1.000): 0.077*"line" + 0.027*"operator" + 0.022*"string" + 0.021*"code" + 0.020*"long" + 0.018*"continuation" + 0.015*"statement" + 0.013*"way" + 0.012*"command" + 0.012*"liner"
INFO: topic #2 (1.000): 0.041*"result" + 0.031*"list" + 0.027*"work" + 0.026*"number" + 0.024*"expression" + 0.024*"correct" + 0.023*"operation" + 0.022*"ternary" + 0.019*"solution" + 0.018*"pythonic"
INFO: topic diff=0.315429, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 71.83781459324962
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -3.013009870281747
DEBUG: bound: at document #0
INFO: -6.063 per-word bound, 66.9 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.038*"line" + 0.033*"print" + 0.027*"file" + 0.027*"\n" + 0.021*"function" + 0.018*"way" + 0.018*"newline" + 0.016*"character" + 0.015*"manager" + 0.015*"method"
INFO: topic #1 (1.000): 0.066*"line" + 0.020*"code" + 0.019*"operator" + 0.015*"string" + 0.015*"command" + 0.015*"liner" + 0.014*"function" + 0.013*"statement" + 0.013*"lambda" + 0.013*"write"
INFO: topic #2 (1.000): 0.042*"list" + 0.037*"result" + 0.030*"ternary" + 0.025*"split" + 0.023*"work" + 0.021*"solution" + 0.020*"number" + 0.020*"pythonic" + 0.017*"correct" + 0.017*"expression"
INFO: topic diff=0.289346, rho=0.353553
DEBUG: bound: at document #0
INFO: -7.028 per-word bound, 130.5 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.037*"line" + 0.031*"print" + 0.027*"\n" + 0.026*"file" + 0.020*"function" + 0.017*"way" + 0.017*"newline" + 0.015*"character" + 0.015*"manager" + 0.015*"method"
INFO: topic #1 (1.000): 0.077*"line" + 0.027*"operator" + 0.022*"string" + 0.021*"code" + 0.020*"long" + 0.017*"continuation" + 0.014*"statement" + 0.013*"way" + 0.012*"command" + 0.012*"liner"
INFO: topic #2 (1.000): 0.042*"result" + 0.032*"list" + 0.027*"work" + 0.026*"number" + 0.024*"ternary" + 0.024*"expression" + 0.023*"correct" + 0.023*"operation" + 0.019*"solution" + 0.019*"pythonic"
INFO: topic diff=0.269099, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 71.52020308762921
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -3.015140848596205
DEBUG: bound: at document #0
INFO: -6.049 per-word bound, 66.2 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.038*"line" + 0.033*"print" + 0.027*"file" + 0.027*"\n" + 0.021*"function" + 0.018*"way" + 0.018*"newline" + 0.016*"character" + 0.015*"manager" + 0.015*"method"
INFO: topic #1 (1.000): 0.066*"line" + 0.020*"code" + 0.020*"operator" + 0.015*"string" + 0.015*"command" + 0.015*"liner" + 0.013*"statement" + 0.013*"function" + 0.013*"lambda" + 0.013*"write"
INFO: topic #2 (1.000): 0.042*"list" + 0.038*"result" + 0.031*"ternary" + 0.024*"split" + 0.024*"work" + 0.021*"solution" + 0.021*"number" + 0.020*"pythonic" + 0.018*"correct" + 0.017*"expression"
INFO: topic diff=0.251729, rho=0.333333
DEBUG: bound: at document #0
INFO: -7.005 per-word bound, 128.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.037*"line" + 0.031*"print" + 0.027*"\n" + 0.026*"file" + 0.020*"function" + 0.017*"way" + 0.017*"newline" + 0.015*"character" + 0.015*"manager" + 0.015*"method"
INFO: topic #1 (1.000): 0.076*"line" + 0.026*"operator" + 0.022*"string" + 0.021*"code" + 0.020*"long" + 0.017*"continuation" + 0.014*"statement" + 0.013*"way" + 0.012*"command" + 0.012*"liner"
INFO: topic #2 (1.000): 0.042*"result" + 0.032*"list" + 0.027*"work" + 0.026*"number" + 0.025*"ternary" + 0.023*"expression" + 0.023*"correct" + 0.023*"operation" + 0.019*"solution" + 0.019*"pythonic"
INFO: topic diff=0.242405, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 71.33306732127083
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -3.015140848596205
DEBUG: bound: at document #0
INFO: -6.038 per-word bound, 65.7 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.038*"line" + 0.033*"print" + 0.027*"file" + 0.027*"\n" + 0.020*"function" + 0.018*"way" + 0.017*"newline" + 0.016*"character" + 0.015*"manager" + 0.015*"method"
INFO: topic #1 (1.000): 0.067*"line" + 0.020*"code" + 0.020*"operator" + 0.015*"string" + 0.015*"command" + 0.015*"liner" + 0.013*"statement" + 0.013*"function" + 0.013*"lambda" + 0.013*"write"
INFO: topic #2 (1.000): 0.042*"list" + 0.038*"result" + 0.032*"ternary" + 0.024*"work" + 0.024*"split" + 0.021*"number" + 0.021*"solution" + 0.021*"pythonic" + 0.018*"correct" + 0.018*"expression"
INFO: topic diff=0.230037, rho=0.316228
DEBUG: bound: at document #0
INFO: -6.988 per-word bound, 126.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.037*"line" + 0.031*"print" + 0.027*"\n" + 0.026*"file" + 0.020*"function" + 0.017*"way" + 0.017*"newline" + 0.015*"character" + 0.015*"manager" + 0.015*"method"
INFO: topic #1 (1.000): 0.076*"line" + 0.026*"operator" + 0.022*"string" + 0.021*"code" + 0.020*"long" + 0.017*"continuation" + 0.014*"statement" + 0.013*"way" + 0.012*"command" + 0.012*"liner"
INFO: topic #2 (1.000): 0.042*"result" + 0.033*"list" + 0.028*"work" + 0.026*"number" + 0.026*"ternary" + 0.023*"expression" + 0.023*"correct" + 0.023*"operation" + 0.019*"solution" + 0.019*"pythonic"
INFO: topic diff=0.223413, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 71.20959269723345
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -3.015140848596205
DEBUG: bound: at document #0
INFO: -6.029 per-word bound, 65.3 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.038*"line" + 0.033*"print" + 0.027*"file" + 0.027*"\n" + 0.020*"function" + 0.018*"way" + 0.017*"newline" + 0.016*"character" + 0.015*"manager" + 0.015*"method"
INFO: topic #1 (1.000): 0.067*"line" + 0.020*"code" + 0.020*"operator" + 0.016*"string" + 0.015*"command" + 0.015*"liner" + 0.013*"statement" + 0.013*"function" + 0.013*"long" + 0.013*"lambda"
INFO: topic #2 (1.000): 0.042*"list" + 0.038*"result" + 0.032*"ternary" + 0.025*"work" + 0.024*"split" + 0.021*"number" + 0.021*"solution" + 0.021*"pythonic" + 0.018*"correct" + 0.018*"expression"
INFO: topic diff=0.214417, rho=0.301511
DEBUG: bound: at document #0
INFO: -6.975 per-word bound, 125.8 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.037*"line" + 0.031*"print" + 0.027*"\n" + 0.026*"file" + 0.020*"function" + 0.017*"way" + 0.017*"newline" + 0.015*"character" + 0.015*"manager" + 0.015*"method"
INFO: topic #1 (1.000): 0.076*"line" + 0.026*"operator" + 0.022*"string" + 0.021*"code" + 0.020*"long" + 0.017*"continuation" + 0.014*"statement" + 0.013*"way" + 0.012*"command" + 0.012*"liner"
INFO: topic #2 (1.000): 0.041*"result" + 0.033*"list" + 0.028*"work" + 0.026*"ternary" + 0.026*"number" + 0.023*"expression" + 0.023*"correct" + 0.023*"operation" + 0.019*"solution" + 0.019*"pythonic"
INFO: topic diff=0.208814, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 71.11915895804796
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -3.0100064250365013
DEBUG: bound: at document #0
INFO: -6.022 per-word bound, 65.0 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.038*"line" + 0.033*"print" + 0.027*"file" + 0.027*"\n" + 0.020*"function" + 0.018*"way" + 0.017*"newline" + 0.016*"character" + 0.015*"manager" + 0.015*"method"
INFO: topic #1 (1.000): 0.067*"line" + 0.020*"code" + 0.020*"operator" + 0.016*"string" + 0.015*"command" + 0.015*"liner" + 0.013*"statement" + 0.013*"long" + 0.013*"function" + 0.013*"lambda"
INFO: topic #2 (1.000): 0.042*"list" + 0.038*"result" + 0.032*"ternary" + 0.025*"work" + 0.024*"split" + 0.022*"number" + 0.021*"solution" + 0.021*"pythonic" + 0.018*"correct" + 0.018*"expression"
INFO: topic diff=0.201884, rho=0.288675
DEBUG: bound: at document #0
INFO: -6.964 per-word bound, 124.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.038*"line" + 0.031*"print" + 0.027*"\n" + 0.026*"file" + 0.020*"function" + 0.017*"way" + 0.017*"newline" + 0.015*"character" + 0.015*"manager" + 0.015*"method"
INFO: topic #1 (1.000): 0.075*"line" + 0.026*"operator" + 0.021*"string" + 0.021*"code" + 0.019*"long" + 0.017*"continuation" + 0.014*"statement" + 0.013*"way" + 0.012*"command" + 0.012*"liner"
INFO: topic #2 (1.000): 0.041*"result" + 0.034*"list" + 0.027*"work" + 0.027*"ternary" + 0.026*"number" + 0.023*"expression" + 0.023*"correct" + 0.023*"operation" + 0.019*"solution" + 0.019*"pythonic"
INFO: topic diff=0.197072, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 71.04654259439504
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -3.0100064250365013
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5> in 0.17s', 'datetime': '2023-03-20T16:53:08.175789', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/questions/13/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-20T16:53:08.175941', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/questions/13/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/13/model.state
DEBUG: {'uri': 'model/questions/13/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/questions/13/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-20T16:53:08.179049', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/questions/13/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/questions/13/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/13/model
INFO: topic #0 (1.000): 0.038*"line" + 0.031*"print" + 0.027*"\n" + 0.026*"file" + 0.020*"function" + 0.017*"way" + 0.017*"newline" + 0.015*"character" + 0.015*"manager" + 0.015*"method"
INFO: topic #1 (1.000): 0.075*"line" + 0.026*"operator" + 0.021*"string" + 0.021*"code" + 0.019*"long" + 0.017*"continuation" + 0.014*"statement" + 0.013*"way" + 0.012*"command" + 0.012*"liner"
INFO: topic #2 (1.000): 0.041*"result" + 0.034*"list" + 0.027*"work" + 0.027*"ternary" + 0.026*"number" + 0.023*"expression" + 0.023*"correct" + 0.023*"operation" + 0.019*"solution" + 0.019*"pythonic"
INFO: Question Similarity: [0.10190123319625854, 0.022274792194366455, 0.09113484621047974, 0.09393662214279175, 0.19111818075180054, 0.13491439819335938, 0.24958574771881104, 0.11726987361907959, 0.21989881992340088, 0.18629783391952515]
INFO: 4006112: -0.03644713899121145
INFO: 4006000: -0.03811994958192427
INFO: 4039268: -0.03824205429048765
INFO: 4005967: -0.038883415466214294
INFO: 4006001: -0.04004147986335284
INFO: 4039302: -0.04285357857231339
INFO: 4005957: -0.04894272020067842
INFO: 69960088: -0.1615561802402177
INFO: 69960026: -0.1689106303322919
INFO: 69960072: -0.17481308178762744
INFO: 4172465: -0.22127627397208852
INFO: 70051452: -0.22411578971692983
INFO: 4172487: -0.22550310957085265
INFO: 70051424: -0.22940769662085536
INFO: 4172475: -0.22967145413225187
INFO: 46326379: -0.2311507943872262
INFO: 52080154: -0.2362692219797837
INFO: 38224926: -0.23643326952358754
INFO: 75427193: -0.24109768368219833
INFO: 36882925: -0.24124592028448794
INFO: 59444846: -0.2459040934001731
INFO: 66576132: -0.2459993208220457
INFO: 6159915: -0.24959622538020315
INFO: 6159910: -0.25154739364751566
INFO: 42309842: -0.25766824500203944
INFO: 6160082: -0.25934578929640245
INFO: 56594378: -0.26112788191907693
INFO: 56901429: -0.2632836524508524
INFO: 52290101: -0.26480317494036587
INFO: 39168994: -0.2657632790448197
INFO: 12871858: -0.2657709790036974
INFO: 63796747: -0.26940934427777435
INFO: 6159912: -0.2697905510402108
INFO: 6165711: -0.2704974596241263
INFO: 39474750: -0.2732146778390262
INFO: 42309840: -0.2950377835516895
INFO: 4172466: -0.2964372275262121
INFO: 42309846: -0.3027923986915325
INFO: 67349311: -0.36632049170831055
INFO: 67347936: -0.3702461752170732
INFO: 41772854: -0.3936322203426092
INFO: 67347879: -0.41992955822787653
INFO: 39068229: -0.4278301317919626
INFO: 39067866: -0.43049914545162105
INFO: 58550900: -0.4359540293180909
INFO: 58550959: -0.4561840892662161
INFO: 39067798: -0.47441118298086443
INFO: Recommended Keywords
INFO: example score: -0.8380702
INFO: result score: -0.77973795
INFO: correct score: -0.7305613
INFO: key score: -0.7297016
INFO: case score: -0.7143558
INFO: possible score: -0.71160585
INFO: solution score: -0.70337105
INFO: continuation score: -0.7021986
INFO: other score: -0.66532844
INFO: set score: -0.66206414
INFO: equal score: -0.66187805
INFO: reason score: -0.66002107
INFO: condition score: -0.65986484
INFO: latter score: -0.65766174
INFO: simple score: -0.6533161
INFO: object score: -0.65056956
INFO: unique score: -0.6496206
INFO: end score: -0.6468288
INFO: expression score: -0.6443446
INFO: file score: -0.627768
INFO: current score: -0.62421155
INFO: one score: -0.62068933
INFO: error score: -0.61961025
INFO: insert score: -0.6194343
INFO: yield score: -0.61902803
INFO: method score: -0.61741775
INFO: keyword score: -0.6155408
INFO: newline score: -0.6134025
INFO: code score: -0.6118495
INFO: time score: -0.61057657
INFO: default score: -0.6095943
INFO: long score: -0.6095383
INFO: way score: -0.6061275
INFO: necessary score: -0.60521483
INFO: write score: -0.6047926
INFO: convert score: -0.60446304
INFO: note score: -0.5970579
INFO: operation score: -0.59230393
INFO: context score: -0.5922342
INFO: much score: -0.591661
INFO: continuous score: -0.5911029
INFO: difference score: -0.58583224
INFO: useful score: -0.58562446
INFO: easy score: -0.5823668
INFO: approach score: -0.58197784
INFO: function score: -0.5780178
INFO: break score: -0.5770849
INFO: similar score: -0.57555324
INFO: item score: -0.56684506
INFO: least score: -0.5638664
INFO: short score: -0.56233716
INFO: create score: -0.56130016
INFO: point score: -0.5604435
INFO: creation score: -0.55788344
INFO: update score: -0.5572843
INFO: extra score: -0.55709296
INFO: effect score: -0.5547853
INFO: advantage score: -0.55369806
INFO: counter score: -0.5439323
INFO: append score: -0.5437783
INFO: mode score: -0.5435524
INFO: basic score: -0.5365592
INFO: exact score: -0.53526247
INFO: print score: -0.5334863
INFO: concept score: -0.5312542
INFO: purpose score: -0.5301788
INFO: special score: -0.5298203
INFO: quick score: -0.5286759
INFO: ternary score: -0.5285319
INFO: idea score: -0.5266229
INFO: system score: -0.5254136
INFO: space score: -0.5227677
INFO: side score: -0.5209538
INFO: delimiter score: -0.5201573
INFO: value score: -0.51964587
INFO: equivalent score: -0.51733196
INFO: source score: -0.5172918
INFO: enough score: -0.51510596
INFO: argument score: -0.51433724
INFO: alternative score: -0.5114704
INFO: work score: -0.5107506
INFO: important score: -0.50613135
INFO: cursor score: -0.50211626
INFO: loop score: -0.50191057
INFO: drop score: -0.4995689
INFO: guide score: -0.4987719
INFO: data score: -0.49390593
INFO: statement score: -0.49076912
INFO: careful score: -0.48983547
INFO: reading score: -0.48908213
INFO: return score: -0.4890587
INFO: single score: -0.48860288
INFO: multiple score: -0.4882206
INFO: list score: -0.48395213
INFO: operator score: -0.48383662
INFO: info score: -0.47835204
INFO: output score: -0.47821411
INFO: question score: -0.47742993
INFO: pair score: -0.47662124
INFO: compact score: -0.47361964
INFO: dependency score: -0.4708184
INFO: outcome score: -0.4684636
INFO: open score: -0.46471205
INFO: look score: -0.46259806
INFO: interpret score: -0.46250707
INFO: character score: -0.4618529
INFO: block score: -0.46125615
INFO: feature score: -0.46058786
INFO: init score: -0.4572412
INFO: option score: -0.45662338
INFO: false score: -0.4559587
INFO: number score: -0.45587176
INFO: documentation score: -0.45436296
INFO: new score: -0.4523387
INFO: iterable score: -0.45222223
INFO: good score: -0.45162532
INFO: string score: -0.4509497
INFO: variable score: -0.44976485
INFO: letter score: -0.44562677
INFO: dealing score: -0.4455843
INFO: comment score: -0.44267166
INFO: format score: -0.43772602
INFO: implicit score: -0.4369898
INFO: instant score: -0.43683776
INFO: parenthesis score: -0.43318108
INFO: module score: -0.43177867
INFO: exception score: -0.43045923
INFO: practice score: -0.4296254
INFO: many score: -0.42816943
INFO: negative score: -0.42784256
INFO: install score: -0.42675826
INFO: information score: -0.42452776
INFO: available score: -0.4236014
INFO: split score: -0.42257187
INFO: interpreter score: -0.42224422
INFO: small score: -0.42015064
INFO: class score: -0.41956052
INFO: related score: -0.41859463
INFO: benefit score: -0.41488436
INFO: writing score: -0.41157058
INFO: support score: -0.4098888
INFO: common score: -0.40629685
INFO: triple score: -0.39674917
INFO: count score: -0.3965626
INFO: import score: -0.39596504
INFO: command score: -0.39372456
INFO: terminator score: -0.3898904
INFO: test score: -0.38958973
INFO: today score: -0.38630664
INFO: performance score: -0.38322157
INFO: total score: -0.38246176
INFO: window score: -0.37975362
INFO: line score: -0.37922668
INFO: mind score: -0.3718524
INFO: thing score: -0.3699052
INFO: text score: -0.36813727
INFO: indent score: -0.36693394
INFO: bit score: -0.36588687
INFO: datum score: -0.3641345
INFO: digits score: -0.3621307
INFO: multi score: -0.35994646
INFO: word score: -0.35941997
INFO: first score: -0.35688272
INFO: lot score: -0.35497716
INFO: right score: -0.35488415
INFO: filter score: -0.35159752
INFO: concern score: -0.35101253
INFO: snippet score: -0.3494374
INFO: generator score: -0.3493122
INFO: integer score: -0.343908
INFO: article score: -0.3410773
INFO: quoting score: -0.3364227
INFO: pass score: -0.33505672
INFO: none score: -0.33306178
INFO: eye score: -0.33267525
INFO: boolean score: -0.33261862
INFO: quote score: -0.32939628
INFO: handy score: -0.32816106
INFO: suite score: -0.3241265
INFO: stream score: -0.32285714
INFO: speed score: -0.31472415
INFO: awkward score: -0.31392866
INFO: bracket score: -0.31173608
INFO: unpack score: -0.31152967
INFO: readable score: -0.3107721
INFO: analysis score: -0.3080562
INFO: unedited score: -0.30363667
INFO: whitespace score: -0.3036145
INFO: multiline score: -0.30357903
INFO: section score: -0.2990597
INFO: comma score: -0.29726654
INFO: style score: -0.29696012
INFO: liner score: -0.29624623
INFO: close score: -0.2958476
INFO: button score: -0.2888373
INFO: binary score: -0.28630129
INFO: indentation score: -0.28497568
INFO: edit score: -0.27583516
INFO: evaluation score: -0.27260095
INFO: encourage score: -0.27167156
INFO: session score: -0.27150404
INFO: last score: -0.2712603
INFO: heredoc score: -0.27007484
INFO: commas score: -0.26468325
INFO: query score: -0.25965294
INFO: bash score: -0.25364366
INFO: decimal score: -0.24540646
INFO: second score: -0.24525672
INFO: backslash score: -0.24081755
INFO: nice score: -0.23664759
INFO: server score: -0.23214912
INFO: shell score: -0.2317984
INFO: division score: -0.22959654
INFO: directory score: -0.22605394
INFO: w score: -0.22142108
INFO: grep score: -0.21844
INFO: doc score: -0.21499002
INFO: web score: -0.20530863
INFO: tuple score: -0.20524794
INFO: pip score: -0.20511529
INFO: trick score: -0.20417002
INFO: indented score: -0.20304729
INFO: lambda score: -0.20271404
INFO: brace score: -0.20188121
INFO: program score: -0.19515821
INFO: lazy score: -0.19498096
INFO: pronounced score: -0.1946892
INFO: stuff score: -0.19113828
INFO: flask score: -0.1862886
INFO: bourne score: -0.18369295
INFO: manager score: -0.18006954
INFO: syntactic score: -0.17881444
INFO: str score: -0.175936
INFO: evening score: -0.16404748
INFO: serialized score: -0.16364963
INFO: = score: -0.16291419
INFO: op score: -0.16083698
INFO: port score: -0.14090988
INFO: top score: -0.1375648
INFO: len score: -0.123438016
INFO: giant score: -0.1182301
INFO: lexical score: -0.11800061
INFO: toady score: -0.10857539
INFO: average score: -0.10246934
INFO: funny score: -0.092690304
INFO: ts score: -0.068670556
INFO: tim score: -0.040122055
INFO: f.write('\n score: -0.0
INFO: \n score: -0.0
INFO: os.linesep score: -0.0
INFO: writeline score: -0.0
INFO: pathlib score: -0.0
INFO: path.write_text(data score: -0.0
INFO: docs.python.org score: -0.0
INFO: georgy score: -0.0
INFO: filewriter score: -0.0
INFO: my_file.txt score: -0.0
INFO: f.write score: -0.0
INFO: there\r\n score: -0.0
INFO: there\n score: -0.0
INFO: tkinter score: -0.0
INFO: stmt1 score: -0.0
INFO: stmt2 score: -0.0
INFO: expr1][2 score: -0.0
INFO: boolexpr score: -0.0
INFO: line.count("t score: -0.0
INFO: len(line score: -0.0
INFO: t"s score: -0.0
INFO: @kaya3 score: -0.0
INFO: ts[0 score: -0.0
INFO: pythonic score: -0.0
INFO: acgtyrant score: -0.0
INFO: pep8 score: -0.0
INFO: pep score: 0.021341437
INFO: demo score: 0.034880187
INFO: pov score: 0.042306546
INFO: memoriam score: 0.073528
INFO: ============================================================
INFO: --------------------
INFO: What does the slash(/) in the parameter list of a function mean?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<416 unique tokens: ['\\n', "\\n'.join", 'actual', 'alternative', 'answer']...> from 10 documents (total 1124 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<416 unique tokens: [\'\\\\n\', "\\\\n\'.join", \'actual\', \'alternative\', \'answer\']...> from 10 documents (total 1124 corpus positions)', 'datetime': '2023-03-20T16:53:11.538326', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.649 per-word bound, 200.7 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.053*"argument" + 0.052*"positional" + 0.046*"parameter" + 0.032*"function" + 0.027*"keyword" + 0.020*"name" + 0.014*"string" + 0.013*"example" + 0.012*"new" + 0.011*"case"
INFO: topic #1 (1.000): 0.079*"parameter" + 0.070*"argument" + 0.062*"positional" + 0.041*"function" + 0.023*"keyword" + 0.021*"name" + 0.021*"f" + 0.017*"string" + 0.014*"pep" + 0.013*"example"
INFO: topic #2 (1.000): 0.036*"string" + 0.027*"argument" + 0.026*"f" + 0.024*"parameter" + 0.021*"code" + 0.019*"positional" + 0.016*"function" + 0.016*"os.sep" + 0.014*"path" + 0.013*"name"
INFO: topic diff=4.062468, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.934 per-word bound, 1956.1 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.039*"argument" + 0.038*"positional" + 0.033*"parameter" + 0.025*"function" + 0.019*"keyword" + 0.015*"string" + 0.015*"example" + 0.014*"name" + 0.013*"path" + 0.010*"case"
INFO: topic #1 (1.000): 0.106*"parameter" + 0.081*"positional" + 0.068*"argument" + 0.061*"function" + 0.030*"syntax" + 0.022*"keyword" + 0.021*"list" + 0.021*"pep" + 0.017*"example" + 0.016*"name"
INFO: topic #2 (1.000): 0.078*"string" + 0.052*"path" + 0.023*"file" + 0.022*"example" + 0.022*"slash" + 0.017*"character" + 0.016*"code" + 0.016*"directory" + 0.013*"literal" + 0.013*"list"
INFO: topic diff=3.073327, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 70.67552699796848
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -2.004306577700286
DEBUG: bound: at document #0
INFO: -6.182 per-word bound, 72.6 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.031*"argument" + 0.030*"positional" + 0.026*"parameter" + 0.020*"function" + 0.016*"keyword" + 0.012*"example" + 0.012*"name" + 0.012*"string" + 0.011*"path" + 0.009*"case"
INFO: topic #1 (1.000): 0.091*"parameter" + 0.076*"argument" + 0.074*"positional" + 0.052*"function" + 0.026*"keyword" + 0.020*"name" + 0.019*"syntax" + 0.018*"pep" + 0.016*"f" + 0.014*"example"
INFO: topic #2 (1.000): 0.071*"string" + 0.038*"path" + 0.022*"code" + 0.021*"file" + 0.018*"directory" + 0.017*"example" + 0.016*"f" + 0.015*"os.sep" + 0.013*"slash" + 0.012*"print"
INFO: topic diff=1.255731, rho=0.500000
DEBUG: bound: at document #0
INFO: -6.822 per-word bound, 113.1 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.024*"argument" + 0.022*"positional" + 0.020*"parameter" + 0.016*"function" + 0.012*"keyword" + 0.010*"example" + 0.009*"name" + 0.009*"string" + 0.008*"path" + 0.007*"case"
INFO: topic #1 (1.000): 0.102*"parameter" + 0.081*"positional" + 0.072*"argument" + 0.060*"function" + 0.027*"syntax" + 0.025*"keyword" + 0.021*"pep" + 0.017*"list" + 0.017*"name" + 0.015*"example"
INFO: topic #2 (1.000): 0.065*"string" + 0.041*"path" + 0.020*"file" + 0.018*"example" + 0.017*"slash" + 0.015*"absolute" + 0.015*"component" + 0.015*"directory" + 0.014*"code" + 0.014*"character"
INFO: topic diff=1.169995, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 57.884676326985755
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.844491629198319
DEBUG: bound: at document #0
INFO: -5.995 per-word bound, 63.8 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.017*"argument" + 0.016*"positional" + 0.014*"parameter" + 0.012*"function" + 0.009*"keyword" + 0.007*"example" + 0.007*"name" + 0.007*"string" + 0.006*"path" + 0.006*"case"
INFO: topic #1 (1.000): 0.090*"parameter" + 0.075*"argument" + 0.073*"positional" + 0.051*"function" + 0.027*"keyword" + 0.020*"name" + 0.019*"syntax" + 0.018*"pep" + 0.018*"f" + 0.014*"example"
INFO: topic #2 (1.000): 0.067*"string" + 0.036*"path" + 0.020*"file" + 0.019*"code" + 0.017*"directory" + 0.016*"example" + 0.014*"os.sep" + 0.013*"slash" + 0.011*"print" + 0.011*"output"
INFO: topic diff=0.728306, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.078 per-word bound, 67.5 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.012*"argument" + 0.011*"positional" + 0.010*"parameter" + 0.009*"function" + 0.007*"keyword" + 0.006*"example" + 0.005*"name" + 0.005*"string" + 0.005*"path" + 0.005*"case"
INFO: topic #1 (1.000): 0.100*"parameter" + 0.080*"positional" + 0.072*"argument" + 0.058*"function" + 0.026*"syntax" + 0.025*"keyword" + 0.021*"pep" + 0.017*"name" + 0.016*"list" + 0.014*"example"
INFO: topic #2 (1.000): 0.064*"string" + 0.040*"path" + 0.019*"file" + 0.017*"example" + 0.016*"component" + 0.016*"absolute" + 0.016*"slash" + 0.015*"directory" + 0.014*"code" + 0.014*"sequence"
INFO: topic diff=0.620614, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 55.08192762667291
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -2.035952590800811
DEBUG: bound: at document #0
INFO: -5.904 per-word bound, 59.9 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.009*"argument" + 0.008*"positional" + 0.008*"parameter" + 0.006*"function" + 0.005*"keyword" + 0.005*"example" + 0.004*"name" + 0.004*"string" + 0.004*"path" + 0.004*"case"
INFO: topic #1 (1.000): 0.089*"parameter" + 0.075*"argument" + 0.073*"positional" + 0.051*"function" + 0.026*"keyword" + 0.020*"name" + 0.019*"f" + 0.019*"syntax" + 0.018*"pep" + 0.014*"example"
INFO: topic #2 (1.000): 0.068*"string" + 0.036*"path" + 0.020*"file" + 0.019*"code" + 0.017*"directory" + 0.016*"example" + 0.013*"os.sep" + 0.013*"slash" + 0.012*"print" + 0.011*"absolute"
INFO: topic diff=0.470685, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.959 per-word bound, 62.2 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.006*"argument" + 0.006*"positional" + 0.006*"parameter" + 0.005*"function" + 0.004*"keyword" + 0.004*"example" + 0.004*"name" + 0.004*"string" + 0.003*"path" + 0.003*"case"
INFO: topic #1 (1.000): 0.098*"parameter" + 0.078*"positional" + 0.072*"argument" + 0.058*"function" + 0.025*"syntax" + 0.025*"keyword" + 0.020*"pep" + 0.017*"name" + 0.015*"list" + 0.015*"f"
INFO: topic #2 (1.000): 0.064*"string" + 0.039*"path" + 0.019*"file" + 0.017*"example" + 0.016*"component" + 0.016*"absolute" + 0.016*"slash" + 0.015*"directory" + 0.014*"code" + 0.014*"sequence"
INFO: topic diff=0.408592, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 53.95725046354011
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -2.712194527732906
DEBUG: bound: at document #0
INFO: -5.856 per-word bound, 57.9 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.005*"argument" + 0.005*"positional" + 0.004*"parameter" + 0.004*"function" + 0.003*"keyword" + 0.003*"example" + 0.003*"name" + 0.003*"string" + 0.003*"path" + 0.003*"case"
INFO: topic #1 (1.000): 0.089*"parameter" + 0.074*"argument" + 0.072*"positional" + 0.051*"function" + 0.026*"keyword" + 0.020*"f" + 0.019*"name" + 0.019*"syntax" + 0.018*"pep" + 0.014*"example"
INFO: topic #2 (1.000): 0.069*"string" + 0.036*"path" + 0.020*"file" + 0.018*"code" + 0.017*"directory" + 0.016*"example" + 0.013*"slash" + 0.013*"os.sep" + 0.012*"print" + 0.012*"absolute"
INFO: topic diff=0.337594, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.917 per-word bound, 60.4 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.004*"argument" + 0.004*"positional" + 0.004*"parameter" + 0.003*"function" + 0.003*"keyword" + 0.003*"example" + 0.003*"name" + 0.003*"string" + 0.003*"path" + 0.003*"case"
INFO: topic #1 (1.000): 0.098*"parameter" + 0.078*"positional" + 0.073*"argument" + 0.057*"function" + 0.025*"keyword" + 0.025*"syntax" + 0.020*"pep" + 0.018*"name" + 0.016*"f" + 0.015*"list"
INFO: topic #2 (1.000): 0.065*"string" + 0.039*"path" + 0.019*"file" + 0.017*"example" + 0.016*"component" + 0.016*"absolute" + 0.016*"slash" + 0.015*"directory" + 0.014*"code" + 0.014*"tab"
INFO: topic diff=0.302629, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 53.48344084246034
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -2.701925680613499
DEBUG: bound: at document #0
INFO: -5.830 per-word bound, 56.9 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.004*"argument" + 0.003*"positional" + 0.003*"parameter" + 0.003*"function" + 0.003*"keyword" + 0.003*"example" + 0.003*"name" + 0.003*"string" + 0.003*"path" + 0.003*"case"
INFO: topic #1 (1.000): 0.089*"parameter" + 0.074*"argument" + 0.072*"positional" + 0.051*"function" + 0.026*"keyword" + 0.021*"f" + 0.020*"syntax" + 0.019*"name" + 0.018*"pep" + 0.014*"example"
INFO: topic #2 (1.000): 0.070*"string" + 0.037*"path" + 0.020*"file" + 0.018*"code" + 0.017*"directory" + 0.016*"example" + 0.013*"slash" + 0.013*"os.sep" + 0.012*"absolute" + 0.012*"component"
INFO: topic diff=0.261827, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.896 per-word bound, 59.6 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.003*"argument" + 0.003*"positional" + 0.003*"parameter" + 0.003*"function" + 0.003*"keyword" + 0.003*"example" + 0.003*"name" + 0.003*"string" + 0.003*"path" + 0.003*"case"
INFO: topic #1 (1.000): 0.097*"parameter" + 0.077*"positional" + 0.073*"argument" + 0.057*"function" + 0.025*"keyword" + 0.024*"syntax" + 0.020*"pep" + 0.018*"name" + 0.017*"f" + 0.014*"list"
INFO: topic #2 (1.000): 0.066*"string" + 0.039*"path" + 0.020*"file" + 0.017*"example" + 0.016*"component" + 0.016*"absolute" + 0.016*"slash" + 0.015*"directory" + 0.014*"code" + 0.014*"tab"
INFO: topic diff=0.243554, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 53.2484741853041
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -2.701925680613499
DEBUG: bound: at document #0
INFO: -5.813 per-word bound, 56.2 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.003*"argument" + 0.003*"positional" + 0.003*"parameter" + 0.003*"function" + 0.003*"keyword" + 0.003*"example" + 0.003*"name" + 0.003*"string" + 0.003*"path" + 0.003*"case"
INFO: topic #1 (1.000): 0.089*"parameter" + 0.074*"argument" + 0.072*"positional" + 0.052*"function" + 0.026*"keyword" + 0.021*"f" + 0.020*"syntax" + 0.019*"name" + 0.018*"pep" + 0.014*"example"
INFO: topic #2 (1.000): 0.070*"string" + 0.037*"path" + 0.020*"file" + 0.018*"code" + 0.017*"directory" + 0.016*"example" + 0.013*"slash" + 0.013*"os.sep" + 0.012*"print" + 0.012*"absolute"
INFO: topic diff=0.218550, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.884 per-word bound, 59.0 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.003*"argument" + 0.003*"positional" + 0.003*"parameter" + 0.003*"function" + 0.003*"keyword" + 0.003*"example" + 0.002*"name" + 0.002*"string" + 0.002*"path" + 0.002*"case"
INFO: topic #1 (1.000): 0.097*"parameter" + 0.077*"positional" + 0.073*"argument" + 0.057*"function" + 0.025*"keyword" + 0.024*"syntax" + 0.020*"pep" + 0.018*"name" + 0.017*"f" + 0.014*"example"
INFO: topic #2 (1.000): 0.067*"string" + 0.039*"path" + 0.020*"file" + 0.017*"example" + 0.016*"component" + 0.016*"absolute" + 0.015*"slash" + 0.015*"directory" + 0.014*"code" + 0.014*"tab"
INFO: topic diff=0.210745, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 53.10033260391788
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -2.682526757485409
DEBUG: bound: at document #0
INFO: -5.801 per-word bound, 55.8 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.003*"argument" + 0.003*"positional" + 0.003*"parameter" + 0.003*"function" + 0.002*"keyword" + 0.002*"example" + 0.002*"name" + 0.002*"string" + 0.002*"path" + 0.002*"case"
INFO: topic #1 (1.000): 0.090*"parameter" + 0.074*"argument" + 0.072*"positional" + 0.052*"function" + 0.026*"keyword" + 0.021*"f" + 0.020*"syntax" + 0.019*"name" + 0.018*"pep" + 0.014*"example"
INFO: topic #2 (1.000): 0.071*"string" + 0.037*"path" + 0.020*"file" + 0.018*"code" + 0.017*"directory" + 0.016*"example" + 0.013*"slash" + 0.012*"print" + 0.012*"os.sep" + 0.012*"absolute"
INFO: topic diff=0.194625, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.874 per-word bound, 58.7 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.003*"argument" + 0.003*"positional" + 0.003*"parameter" + 0.002*"function" + 0.002*"keyword" + 0.002*"example" + 0.002*"name" + 0.002*"string" + 0.002*"path" + 0.002*"case"
INFO: topic #1 (1.000): 0.097*"parameter" + 0.077*"positional" + 0.073*"argument" + 0.057*"function" + 0.025*"keyword" + 0.024*"syntax" + 0.020*"pep" + 0.018*"name" + 0.017*"f" + 0.014*"example"
INFO: topic #2 (1.000): 0.067*"string" + 0.039*"path" + 0.020*"file" + 0.017*"example" + 0.016*"absolute" + 0.016*"component" + 0.015*"slash" + 0.015*"directory" + 0.014*"code" + 0.014*"sequence"
INFO: topic diff=0.191024, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 52.99397100638872
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -2.682526757485409
DEBUG: bound: at document #0
INFO: -5.791 per-word bound, 55.4 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.003*"argument" + 0.002*"positional" + 0.002*"parameter" + 0.002*"function" + 0.002*"keyword" + 0.002*"example" + 0.002*"name" + 0.002*"string" + 0.002*"path" + 0.002*"case"
INFO: topic #1 (1.000): 0.090*"parameter" + 0.074*"argument" + 0.072*"positional" + 0.052*"function" + 0.026*"keyword" + 0.022*"f" + 0.020*"syntax" + 0.019*"name" + 0.018*"pep" + 0.014*"example"
INFO: topic #2 (1.000): 0.071*"string" + 0.037*"path" + 0.020*"file" + 0.018*"code" + 0.017*"directory" + 0.016*"example" + 0.013*"slash" + 0.013*"print" + 0.012*"component" + 0.012*"absolute"
INFO: topic diff=0.180143, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.867 per-word bound, 58.3 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.002*"argument" + 0.002*"positional" + 0.002*"parameter" + 0.002*"function" + 0.002*"keyword" + 0.002*"example" + 0.002*"name" + 0.002*"string" + 0.002*"path" + 0.002*"case"
INFO: topic #1 (1.000): 0.096*"parameter" + 0.076*"positional" + 0.073*"argument" + 0.057*"function" + 0.025*"keyword" + 0.024*"syntax" + 0.019*"pep" + 0.018*"name" + 0.018*"f" + 0.014*"example"
INFO: topic #2 (1.000): 0.067*"string" + 0.039*"path" + 0.020*"file" + 0.017*"example" + 0.016*"absolute" + 0.016*"component" + 0.015*"slash" + 0.015*"directory" + 0.015*"code" + 0.014*"sequence"
INFO: topic diff=0.177295, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 52.91577574159
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -2.682526757485409
DEBUG: bound: at document #0
INFO: -5.784 per-word bound, 55.1 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.002*"argument" + 0.002*"positional" + 0.002*"parameter" + 0.002*"function" + 0.002*"keyword" + 0.002*"example" + 0.002*"name" + 0.002*"string" + 0.002*"path" + 0.002*"case"
INFO: topic #1 (1.000): 0.090*"parameter" + 0.074*"argument" + 0.072*"positional" + 0.052*"function" + 0.026*"keyword" + 0.022*"f" + 0.020*"syntax" + 0.019*"name" + 0.018*"pep" + 0.014*"example"
INFO: topic #2 (1.000): 0.071*"string" + 0.037*"path" + 0.020*"file" + 0.018*"code" + 0.017*"directory" + 0.016*"example" + 0.013*"slash" + 0.013*"print" + 0.013*"component" + 0.013*"absolute"
INFO: topic diff=0.169811, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.861 per-word bound, 58.1 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.002*"argument" + 0.002*"positional" + 0.002*"parameter" + 0.002*"function" + 0.002*"keyword" + 0.002*"example" + 0.002*"name" + 0.002*"string" + 0.002*"path" + 0.002*"case"
INFO: topic #1 (1.000): 0.096*"parameter" + 0.076*"positional" + 0.073*"argument" + 0.057*"function" + 0.025*"keyword" + 0.024*"syntax" + 0.019*"pep" + 0.018*"f" + 0.018*"name" + 0.014*"example"
INFO: topic #2 (1.000): 0.068*"string" + 0.039*"path" + 0.020*"file" + 0.017*"example" + 0.016*"absolute" + 0.016*"component" + 0.015*"slash" + 0.015*"directory" + 0.015*"code" + 0.014*"sequence"
INFO: topic diff=0.166541, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 52.85803328223725
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -2.6681126082331477
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5> in 0.18s', 'datetime': '2023-03-20T16:53:11.715740', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/questions/14/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-20T16:53:11.715972', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/questions/14/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/14/model.state
DEBUG: {'uri': 'model/questions/14/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/questions/14/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-20T16:53:11.719122', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/questions/14/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/questions/14/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/questions/14/model
INFO: topic #0 (1.000): 0.002*"argument" + 0.002*"positional" + 0.002*"parameter" + 0.002*"function" + 0.002*"keyword" + 0.002*"example" + 0.002*"name" + 0.002*"string" + 0.002*"path" + 0.002*"case"
INFO: topic #1 (1.000): 0.096*"parameter" + 0.076*"positional" + 0.073*"argument" + 0.057*"function" + 0.025*"keyword" + 0.024*"syntax" + 0.019*"pep" + 0.018*"f" + 0.018*"name" + 0.014*"example"
INFO: topic #2 (1.000): 0.068*"string" + 0.039*"path" + 0.020*"file" + 0.017*"example" + 0.016*"absolute" + 0.016*"component" + 0.015*"slash" + 0.015*"directory" + 0.015*"code" + 0.014*"sequence"
INFO: Question Similarity: [0.12553083896636963, 0.10954254865646362, 0.6439432203769684, 0.1365172266960144, 0.12598299980163574, 0.18281638622283936, 0.0537380576133728, 0.18379920721054077, 0.026678740978240967, 0.25701236724853516]
INFO: 63490944: -0.039622502675324286
INFO: 63490955: -0.040377965554181536
INFO: 28243933: -0.08306140153757303
INFO: 59642921: -0.16101163230285834
INFO: 24735582: -0.1612209948263364
INFO: 56212520: -0.16358052045877255
INFO: 59661137: -0.18524473552162604
INFO: 59661122: -0.18757458145347974
INFO: 44780467: -0.2058490772630691
INFO: 69762290: -0.2128248872773215
INFO: 44781006: -0.21452423624099454
INFO: 44781133: -0.22151384784682693
INFO: 68678495: -0.22795919404829681
INFO: 75404785: -0.23348488627523956
INFO: 44780840: -0.23564026386898104
INFO: 16011098: -0.31237253842884366
INFO: 50522959: -0.319539364078225
INFO: 16011057: -0.319539364078225
INFO: 16011031: -0.319539364078225
INFO: 44189631: -0.33279222771960915
INFO: 16011039: -0.3327946029431517
INFO: 16011123: -0.33524407962145997
INFO: 16011083: -0.33964540135051624
INFO: 67585662: -0.3554548638226723
INFO: 38923690: -0.3777222247479856
INFO: 56514307: -0.3790874311962459
INFO: 25559273: -0.38190101415044064
INFO: 67751005: -0.38325859536311824
INFO: 1945936: -0.4279062248758468
INFO: 58588281: -0.4279087552286958
INFO: 1946192: -0.43641835037751686
INFO: 57826848: -0.4431790049579366
INFO: 4488585: -0.4480564094797475
INFO: 65945746: -0.4679964694551047
INFO: 60416293: -0.46831429856535384
INFO: 49961041: -0.47188675085135945
INFO: 74229426: -0.47409351437880626
INFO: 1945939: -0.47600948132066134
INFO: 14962135: -0.476009788118103
INFO: 4488596: -0.4887855123920584
INFO: 1945935: -0.49016163006439756
INFO: 47363488: -0.4927965476117637
INFO: 24296743: -0.49923879075301686
INFO: 4488586: -0.49945925301608374
INFO: 1948595: -0.5024029924504605
INFO: 37556617: -0.5085549479622418
INFO: 69469685: -0.5133002065320011
INFO: 62445955: -0.5284291928387854
INFO: 1945930: -0.5294127389658527
INFO: 43390891: -0.5338125375152178
INFO: 74845836: -1.825184901259614
INFO: Recommended Keywords
INFO: function score: -0.8157434
INFO: example score: -0.7992194
INFO: define score: -0.7798785
INFO: component score: -0.7340807
INFO: code score: -0.729469
INFO: specific score: -0.7262269
INFO: parameter score: -0.7241014
INFO: sequence score: -0.71558553
INFO: simple score: -0.7060551
INFO: definition score: -0.70063406
INFO: notation score: -0.6881142
INFO: method score: -0.6868276
INFO: variable score: -0.6804637
INFO: application score: -0.6702902
INFO: binary score: -0.66962343
INFO: positional score: -0.66900086
INFO: error score: -0.66788256
INFO: keyword score: -0.6650358
INFO: useful score: -0.65898496
INFO: syntax score: -0.653655
INFO: expression score: -0.6372338
INFO: file score: -0.6236895
INFO: problem score: -0.6232152
INFO: case score: -0.621637
INFO: valid score: -0.62093496
INFO: root score: -0.6189112
INFO: similar score: -0.61345595
INFO: interface score: -0.61274385
INFO: relevant score: -0.60843784
INFO: relative score: -0.6059492
INFO: value score: -0.60129964
INFO: actual score: -0.599612
INFO: reference score: -0.591418
INFO: redundant score: -0.5888483
INFO: whitespace score: -0.5862611
INFO: need score: -0.5858961
INFO: append score: -0.58037895
INFO: space score: -0.57516694
INFO: readability score: -0.5740677
INFO: factor score: -0.5735403
INFO: reset score: -0.5719866
INFO: module score: -0.5687465
INFO: argument score: -0.56734216
INFO: backward score: -0.56676507
INFO: consider score: -0.56567866
INFO: update score: -0.56327677
INFO: output score: -0.56103075
INFO: item score: -0.55765533
INFO: newline score: -0.55616987
INFO: approach score: -0.5530783
INFO: default score: -0.5513045
INFO: convert score: -0.5497878
INFO: remove score: -0.54896015
INFO: filename score: -0.5476822
INFO: absolute score: -0.5441167
INFO: path score: -0.5431972
INFO: literal score: -0.54288596
INFO: link score: -0.54179054
INFO: key score: -0.53921986
INFO: extension score: -0.5380949
INFO: slash score: -0.534344
INFO: note score: -0.5342667
INFO: point score: -0.5311307
INFO: form score: -0.5284065
INFO: conjunction score: -0.5267369
INFO: pathname score: -0.5264967
INFO: separator score: -0.52580583
INFO: directory score: -0.52574784
INFO: see score: -0.5252266
INFO: f score: -0.5201014
INFO: readable score: -0.5109456
INFO: choice score: -0.50631106
INFO: folder score: -0.50605
INFO: special score: -0.50603133
INFO: pure score: -0.5050754
INFO: sense score: -0.50111806
INFO: config score: -0.49611846
INFO: client score: -0.49424973
INFO: rationale score: -0.49045932
INFO: punctuation score: -0.48954502
INFO: tab score: -0.4884723
INFO: workaround score: -0.48486543
INFO: alternative score: -0.47849208
INFO: extra score: -0.4778231
INFO: question score: -0.47612894
INFO: test score: -0.47139704
INFO: kind score: -0.46715665
INFO: manual score: -0.4615637
INFO: sub score: -0.45643952
INFO: cross score: -0.45640668
INFO: prevent score: -0.45282823
INFO: implementation score: -0.4502294
INFO: current score: -0.44839743
INFO: allow score: -0.4477853
INFO: statement score: -0.4460623
INFO: result score: -0.44559816
INFO: length score: -0.4447635
INFO: behavior score: -0.4406699
INFO: foo score: -0.43739155
INFO: parent score: -0.435068
INFO: priority score: -0.43468326
INFO: least score: -0.4319999
INFO: dot score: -0.42955315
INFO: uninstall score: -0.42647997
INFO: usable score: -0.41966558
INFO: reading score: -0.4164864
INFO: full score: -0.41047966
INFO: string score: -0.4088307
INFO: answer score: -0.40062532
INFO: tabulation score: -0.40049562
INFO: raw score: -0.40044877
INFO: enable score: -0.39948192
INFO: horizontal score: -0.39941657
INFO: self score: -0.39850405
INFO: optional score: -0.39600375
INFO: natural score: -0.39530984
INFO: idea score: -0.39286965
INFO: sandbox score: -0.38641715
INFO: understanding score: -0.38371247
INFO: well score: -0.382248
INFO: install score: -0.37955022
INFO: documentation score: -0.37887058
INFO: linux score: -0.37319636
INFO: way score: -0.37220392
INFO: option score: -0.36889642
INFO: char score: -0.3664293
INFO: call score: -0.36466482
INFO: tree score: -0.36320707
INFO: other score: -0.36100927
INFO: formatter score: -0.36062527
INFO: field score: -0.35795507
INFO: hello score: -0.3543306
INFO: text score: -0.35328755
INFO: replace score: -0.34897855
INFO: version score: -0.34820077
INFO: platform score: -0.34609616
INFO: global score: -0.34366366
INFO: len score: -0.3432791
INFO: b score: -0.34274423
INFO: split score: -0.33723578
INFO: foobar score: -0.33667505
INFO: drive score: -0.3363892
INFO: right score: -0.33605704
INFO: c score: -0.33429787
INFO: list score: -0.32957605
INFO: latter score: -0.32186633
INFO: util score: -0.32182702
INFO: separate score: -0.319762
INFO: format score: -0.31811062
INFO: property score: -0.31029508
INFO: py score: -0.3095293
INFO: character score: -0.3008393
INFO: snippet score: -0.2968471
INFO: build score: -0.29501113
INFO: comment score: -0.294759
INFO: recent score: -0.29383382
INFO: letter score: -0.29370734
INFO: edit score: -0.29243305
INFO: new score: -0.2899856
INFO: program score: -0.2798647
INFO: entry score: -0.27697897
INFO: window score: -0.27288604
INFO: one score: -0.2727936
INFO: = score: -0.26725695
INFO: forward score: -0.26151657
INFO: print score: -0.26127326
INFO: name score: -0.26104003
INFO: previous score: -0.256154
INFO: line score: -0.25128028
INFO: surprising score: -0.24915408
INFO: speed score: -0.24887118
INFO: exotic score: -0.24845174
INFO: sep score: -0.24751242
INFO: issue score: -0.23761964
INFO: work score: -0.23617753
INFO: thing score: -0.23564714
INFO: entire score: -0.23087083
INFO: front score: -0.22140202
INFO: portable score: -0.21964866
INFO: script score: -0.21912132
INFO: none score: -0.21575168
INFO: cord score: -0.21368113
INFO: opposite score: -0.21069373
INFO: end score: -0.21018144
INFO: align score: -0.20849437
INFO: strip score: -0.20803784
INFO: faq score: -0.20615707
INFO: guido score: -0.20343669
INFO: position score: -0.20173597
INFO: curly score: -0.20144352
INFO: future score: -0.2006912
INFO: pip score: -0.19391215
INFO: course score: -0.19077672
INFO: library score: -0.19055435
INFO: bite score: -0.1898299
INFO: api score: -0.18949583
INFO: strange score: -0.18837135
INFO: companion score: -0.18602599
INFO: help score: -0.18451169
INFO: doc score: -0.182987
INFO: lash score: -0.18005182
INFO: mark score: -0.17736806
INFO: op score: -0.1706103
INFO: combo score: -0.16584572
INFO: proposal score: -0.16280621
INFO: raise score: -0.16034886
INFO: heh score: -0.15726636
INFO: uplevel score: -0.15134571
INFO: pep score: -0.13873541
INFO: portion score: -0.13738123
INFO: escape score: -0.1351557
INFO: return score: -0.12801558
INFO: command score: -0.12648316
INFO: windows score: -0.106966674
INFO: discord score: -0.103195965
INFO: rest score: -0.09359967
INFO: event score: -0.089076504
INFO: hope score: -0.0849612
INFO: recap score: -0.08082161
INFO: rick score: -0.07899865
INFO: next score: -0.074550495
INFO: brace score: -0.054736897
INFO: throw score: -0.041313615
INFO: author score: -0.032286298
INFO: join score: -0.019493664
INFO: ruin score: -0.0047912193
INFO: alex score: -0.004636816
INFO: syntaxerror score: -0.0
INFO: \n score: -0.0
INFO: str.join()/str.format score: -0.0
INFO: backslashe score: -0.0
INFO: os.linesep score: -0.0
INFO: typeerror score: -0.0
INFO: python3.8 score: -0.0
INFO: signifie score: -0.0
INFO: discord.ext score: -0.0
INFO: pycord score: -0.0
INFO: https://guide.pycord.dev/installation score: -0.0
INFO: os.sep score: -0.0
INFO: \utils\properties.ini score: -0.0
INFO: pathlib score: -0.0
INFO: pathlib.os.sep score: -0.0
INFO: os.path.normpath(pathname score: -0.0
INFO: foo/ score: -0.0
INFO: a/./b score: -0.0
INFO: b. score: -0.0
INFO: os.path score: -0.0
INFO: larry score: -0.0
INFO: os.path.join(a score: -0.0
INFO: path(__file__).resolve().parent score: -0.0
INFO: split("/ score: -0.0
INFO: http://docs.python.org/library/os.path.html#os.path.join score: -0.0
INFO: os.environ['home score: -0.0
INFO: os.path.dirname(__file score: -0.0
INFO: os.path.sep score: -0.0
INFO: foobar.jpg score: -0.0
INFO: new_sandbox score: -0.0
INFO: myapp.conf score: -0.0
INFO: foo.conf score: -0.0
INFO: myapp score: -0.0
INFO: /some score: -0.0
INFO: /new_sandbox/ score: -0.0
INFO: eq__(self score: -0.0
INFO: file.write("hello\talex score: -0.0
INFO: hello\n{tab}alex score: -0.0
INFO: tabulation}alex score: -0.0
INFO: hello\n{ht}alex score: -0.0
INFO: hello\n{character score: -0.0
INFO: hello\n{horizontal score: -0.0
INFO: hello\x09alex score: -0.0
INFO: hello\u0009alex score: -0.0
INFO: hello\u00000009alex score: -0.0
INFO: \t score: -0.0
INFO: hello\talex score: -0.0
INFO: hello--->alex score: -0.0
INFO: slash(/ score: -0.0
INFO: divmod score: -0.0
INFO: cpython score: -0.0
INFO: top score: 0.003989149
INFO: clinic score: 0.007766165
INFO: fortunate score: 0.032104313
INFO: terrible score: 0.043735113
INFO: home score: 0.1343576
INFO: ============================================================
