INFO: --------------------
INFO: What is the difference between arguments and parameters?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<397 unique tokens: ['1st', '2nd', '=', 'able', 'absolute']...> from 10 documents (total 1569 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<397 unique tokens: ['1st', '2nd', '=', 'able', 'absolute']...> from 10 documents (total 1569 corpus positions)", 'datetime': '2023-04-25T15:14:04.688861', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<397 unique tokens: ['1st', '2nd', '=', 'able', 'absolute']...> from 10 documents (total 1569 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<397 unique tokens: ['1st', '2nd', '=', 'able', 'absolute']...> from 10 documents (total 1569 corpus positions)", 'datetime': '2023-04-25T15:14:05.117644', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: generating 5 topic models using 1 workers
INFO: using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 5 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.022 per-word bound, 130.0 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
WARNING: updated prior is not positive
INFO: optimized alpha [0.2, 0.2, 0.2, 0.2, 0.2]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.200): 0.003*"parameter" + 0.003*"function" + 0.003*"argument" + 0.003*"variable" + 0.003*"type" + 0.003*"value" + 0.003*"object" + 0.003*"c++" + 0.003*"actual" + 0.003*"call"
INFO: topic #1 (0.200): 0.094*"argument" + 0.093*"parameter" + 0.074*"function" + 0.040*"value" + 0.027*"variable" + 0.022*"actual" + 0.022*"method" + 0.017*"formal" + 0.016*"name" + 0.015*"definition"
INFO: topic #2 (0.200): 0.099*"parameter" + 0.056*"argument" + 0.029*"function" + 0.021*"method" + 0.021*"value" + 0.020*"actual" + 0.017*"call" + 0.017*"variable" + 0.015*"formal" + 0.015*"name"
INFO: topic #3 (0.200): 0.003*"parameter" + 0.003*"argument" + 0.003*"function" + 0.003*"variable" + 0.003*"type" + 0.003*"value" + 0.003*"actual" + 0.003*"program" + 0.003*"object" + 0.003*"call"
INFO: topic #4 (0.200): 0.003*"function" + 0.003*"parameter" + 0.003*"argument" + 0.003*"variable" + 0.003*"value" + 0.003*"actual" + 0.003*"type" + 0.003*"program" + 0.003*"object" + 0.003*"c++"
INFO: topic diff=2.657265, rho=1.000000
DEBUG: bound: at document #0
INFO: -6.579 per-word bound, 95.6 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0729647, 0.3046404, 0.07247235, 0.11420732, 0.16264214]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.073): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"question" + 0.003*"c." + 0.003*"argument" + 0.003*"positional" + 0.003*"def" + 0.003*"arg"
INFO: topic #1 (0.305): 0.104*"parameter" + 0.102*"argument" + 0.092*"function" + 0.052*"value" + 0.032*"definition" + 0.025*"variable" + 0.024*"call" + 0.021*"name" + 0.021*"actual" + 0.021*"method"
INFO: topic #2 (0.072): 0.060*"parameter" + 0.034*"argument" + 0.018*"function" + 0.014*"method" + 0.013*"value" + 0.013*"actual" + 0.011*"call" + 0.011*"variable" + 0.010*"formal" + 0.010*"name"
INFO: topic #3 (0.114): 0.028*"f" + 0.028*"question" + 0.015*"def" + 0.015*"arg" + 0.015*"correct" + 0.015*"print(arg" + 0.015*"big" + 0.015*"look" + 0.015*"distinguishing" + 0.015*"n’t"
INFO: topic #4 (0.163): 0.112*"default" + 0.046*"positional" + 0.031*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"p" + 0.016*"error" + 0.016*"f2" + 0.015*"c." + 0.009*"def"
INFO: topic diff=0.700561, rho=0.707107
DEBUG: bound: at document #0
INFO: -5.183 per-word bound, 36.3 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.056841843, 0.38570535, 0.056564827, 0.07511403, 0.0846514]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.057): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"question" + 0.003*"c." + 0.003*"argument" + 0.003*"positional" + 0.003*"def" + 0.003*"arg"
INFO: topic #1 (0.386): 0.099*"parameter" + 0.095*"argument" + 0.078*"function" + 0.043*"value" + 0.026*"variable" + 0.022*"actual" + 0.022*"method" + 0.021*"definition" + 0.018*"call" + 0.018*"name"
INFO: topic #2 (0.057): 0.039*"parameter" + 0.023*"argument" + 0.013*"function" + 0.010*"method" + 0.009*"value" + 0.009*"actual" + 0.008*"call" + 0.008*"variable" + 0.007*"formal" + 0.007*"name"
INFO: topic #3 (0.075): 0.017*"f" + 0.017*"question" + 0.009*"def" + 0.009*"arg" + 0.009*"correct" + 0.009*"print(arg" + 0.009*"big" + 0.009*"look" + 0.009*"distinguishing" + 0.009*"n’t"
INFO: topic #4 (0.085): 0.077*"default" + 0.032*"positional" + 0.022*"keyword" + 0.017*"non" + 0.017*"f2(x" + 0.012*"p" + 0.012*"error" + 0.012*"f2" + 0.011*"c." + 0.007*"def"
INFO: topic diff=0.301002, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.150 per-word bound, 35.5 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.049884915, 0.5024299, 0.049675237, 0.072168544, 0.09139806]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.050): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"question" + 0.003*"c." + 0.003*"argument" + 0.003*"positional" + 0.003*"def" + 0.003*"arg"
INFO: topic #1 (0.502): 0.105*"parameter" + 0.101*"argument" + 0.089*"function" + 0.050*"value" + 0.030*"definition" + 0.025*"variable" + 0.023*"call" + 0.021*"actual" + 0.021*"method" + 0.020*"name"
INFO: topic #2 (0.050): 0.023*"parameter" + 0.014*"argument" + 0.008*"function" + 0.007*"method" + 0.006*"value" + 0.006*"actual" + 0.006*"call" + 0.006*"variable" + 0.005*"formal" + 0.005*"name"
INFO: topic #3 (0.072): 0.029*"question" + 0.028*"f" + 0.015*"n’t" + 0.015*"print(arg" + 0.015*"look" + 0.015*"fun(arg" + 0.015*"distinguishing" + 0.015*"correct" + 0.015*"big" + 0.015*"min"
INFO: topic #4 (0.091): 0.113*"default" + 0.046*"positional" + 0.031*"keyword" + 0.024*"non" + 0.024*"f2(x" + 0.016*"f2" + 0.016*"error" + 0.016*"p" + 0.016*"c." + 0.009*"f3"
INFO: topic diff=0.230537, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.118 per-word bound, 34.7 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.044113826, 0.62466896, 0.043952387, 0.060137115, 0.072184116]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.044): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"question" + 0.003*"c." + 0.003*"argument" + 0.003*"positional" + 0.003*"def" + 0.003*"arg"
INFO: topic #1 (0.625): 0.100*"parameter" + 0.096*"argument" + 0.078*"function" + 0.043*"value" + 0.026*"variable" + 0.022*"actual" + 0.022*"method" + 0.021*"definition" + 0.018*"call" + 0.018*"name"
INFO: topic #2 (0.044): 0.015*"parameter" + 0.009*"argument" + 0.006*"function" + 0.005*"method" + 0.005*"value" + 0.005*"actual" + 0.004*"call" + 0.004*"variable" + 0.004*"formal" + 0.004*"name"
INFO: topic #3 (0.060): 0.018*"question" + 0.018*"f" + 0.010*"n’t" + 0.010*"print(arg" + 0.010*"look" + 0.010*"fun(arg" + 0.010*"distinguishing" + 0.010*"correct" + 0.010*"big" + 0.010*"min"
INFO: topic #4 (0.072): 0.083*"default" + 0.034*"positional" + 0.023*"keyword" + 0.018*"non" + 0.018*"f2(x" + 0.013*"f2" + 0.013*"error" + 0.013*"p" + 0.012*"c." + 0.007*"f3"
INFO: topic diff=0.210303, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.104 per-word bound, 34.4 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.040778767, 0.768083, 0.04064163, 0.060296398, 0.07962051]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.041): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"question" + 0.003*"c." + 0.003*"argument" + 0.003*"positional" + 0.003*"def" + 0.003*"arg"
INFO: topic #1 (0.768): 0.105*"parameter" + 0.101*"argument" + 0.088*"function" + 0.050*"value" + 0.029*"definition" + 0.025*"variable" + 0.023*"call" + 0.021*"actual" + 0.021*"method" + 0.020*"name"
INFO: topic #2 (0.041): 0.010*"parameter" + 0.006*"argument" + 0.005*"function" + 0.004*"method" + 0.004*"value" + 0.004*"actual" + 0.004*"call" + 0.004*"variable" + 0.003*"formal" + 0.003*"name"
INFO: topic #3 (0.060): 0.029*"question" + 0.027*"f" + 0.015*"n’t" + 0.015*"print(arg" + 0.015*"look" + 0.015*"fun(arg" + 0.015*"distinguishing" + 0.015*"correct" + 0.015*"big" + 0.015*"min"
INFO: topic #4 (0.080): 0.113*"default" + 0.046*"positional" + 0.031*"keyword" + 0.024*"non" + 0.024*"f2(x" + 0.016*"f2" + 0.016*"error" + 0.016*"p" + 0.016*"c." + 0.009*"f3"
INFO: topic diff=0.168966, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.095 per-word bound, 34.2 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.037689675, 0.9472538, 0.037573226, 0.0535622, 0.067922905]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.038): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"question" + 0.003*"c." + 0.003*"argument" + 0.003*"positional" + 0.003*"def" + 0.003*"arg"
INFO: topic #1 (0.947): 0.100*"parameter" + 0.096*"argument" + 0.078*"function" + 0.043*"value" + 0.026*"variable" + 0.022*"actual" + 0.022*"method" + 0.021*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #2 (0.038): 0.007*"parameter" + 0.005*"argument" + 0.004*"function" + 0.003*"method" + 0.003*"value" + 0.003*"actual" + 0.003*"call" + 0.003*"variable" + 0.003*"formal" + 0.003*"name"
INFO: topic #3 (0.054): 0.019*"question" + 0.018*"f" + 0.011*"n’t" + 0.011*"print(arg" + 0.011*"look" + 0.011*"fun(arg" + 0.011*"distinguishing" + 0.011*"correct" + 0.011*"big" + 0.011*"min"
INFO: topic #4 (0.068): 0.086*"default" + 0.035*"positional" + 0.024*"keyword" + 0.018*"non" + 0.018*"f2(x" + 0.013*"f2" + 0.013*"error" + 0.013*"p" + 0.013*"c." + 0.007*"f3"
INFO: topic diff=0.162137, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.086 per-word bound, 34.0 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.035620894, 1.0824499, 0.03551718, 0.054469053, 0.07509809]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.036): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"question" + 0.003*"c." + 0.003*"argument" + 0.003*"positional" + 0.003*"def" + 0.003*"arg"
INFO: topic #1 (1.082): 0.105*"parameter" + 0.100*"argument" + 0.087*"function" + 0.049*"value" + 0.028*"definition" + 0.025*"variable" + 0.022*"call" + 0.021*"method" + 0.021*"actual" + 0.020*"name"
INFO: topic #2 (0.036): 0.005*"parameter" + 0.004*"argument" + 0.003*"function" + 0.003*"method" + 0.003*"value" + 0.003*"actual" + 0.003*"call" + 0.003*"variable" + 0.003*"formal" + 0.003*"name"
INFO: topic #3 (0.054): 0.028*"question" + 0.027*"f" + 0.015*"big" + 0.015*"print(arg" + 0.015*"n’t" + 0.015*"min" + 0.015*"look" + 0.015*"fun(arg" + 0.015*"distinguishing" + 0.015*"correct"
INFO: topic #4 (0.075): 0.112*"default" + 0.046*"positional" + 0.031*"keyword" + 0.023*"f2(x" + 0.023*"non" + 0.016*"error" + 0.016*"f2" + 0.016*"p" + 0.016*"c." + 0.009*"f4"
INFO: topic diff=0.139857, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.083 per-word bound, 33.9 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.03366518, 1.331028, 0.03357282, 0.04990766, 0.06646034]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.034): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"question" + 0.003*"c." + 0.003*"argument" + 0.003*"positional" + 0.003*"arg" + 0.003*"def"
INFO: topic #1 (1.331): 0.100*"parameter" + 0.096*"argument" + 0.078*"function" + 0.044*"value" + 0.026*"variable" + 0.022*"method" + 0.022*"actual" + 0.021*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #2 (0.034): 0.004*"parameter" + 0.003*"argument" + 0.003*"function" + 0.003*"method" + 0.003*"value" + 0.003*"actual" + 0.003*"call" + 0.003*"variable" + 0.003*"formal" + 0.003*"name"
INFO: topic #3 (0.050): 0.020*"question" + 0.019*"f" + 0.011*"n’t" + 0.011*"print(arg" + 0.011*"look" + 0.011*"fun(arg" + 0.011*"distinguishing" + 0.011*"correct" + 0.011*"big" + 0.011*"min"
INFO: topic #4 (0.066): 0.088*"default" + 0.036*"positional" + 0.025*"keyword" + 0.019*"non" + 0.019*"f2(x" + 0.013*"f2" + 0.013*"error" + 0.013*"p" + 0.013*"c." + 0.007*"f3"
INFO: topic diff=0.135897, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.076 per-word bound, 33.7 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.032159455, 1.3757737, 0.032075323, 0.05094499, 0.07312847]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.032): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"question" + 0.003*"c." + 0.003*"argument" + 0.003*"positional" + 0.003*"arg" + 0.003*"def"
INFO: topic #1 (1.376): 0.105*"parameter" + 0.100*"argument" + 0.086*"function" + 0.049*"value" + 0.028*"definition" + 0.025*"variable" + 0.022*"call" + 0.022*"method" + 0.022*"actual" + 0.020*"name"
INFO: topic #2 (0.032): 0.004*"parameter" + 0.003*"argument" + 0.003*"function" + 0.003*"method" + 0.003*"value" + 0.003*"actual" + 0.003*"call" + 0.003*"variable" + 0.003*"formal" + 0.003*"name"
INFO: topic #3 (0.051): 0.028*"question" + 0.026*"f" + 0.015*"big" + 0.015*"print(arg" + 0.015*"n’t" + 0.015*"min" + 0.015*"look" + 0.015*"fun(arg" + 0.015*"distinguishing" + 0.015*"correct"
INFO: topic #4 (0.073): 0.111*"default" + 0.045*"positional" + 0.031*"keyword" + 0.023*"f2(x" + 0.023*"non" + 0.016*"error" + 0.016*"f2" + 0.016*"p" + 0.016*"c." + 0.009*"f4"
INFO: topic diff=0.123143, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.076 per-word bound, 33.7 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.030782038, 1.685527, 0.030705096, 0.047496464, 0.066050805]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.031): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"question" + 0.003*"c." + 0.003*"argument" + 0.003*"positional" + 0.003*"def" + 0.003*"arg"
INFO: topic #1 (1.686): 0.100*"parameter" + 0.096*"argument" + 0.079*"function" + 0.044*"value" + 0.026*"variable" + 0.022*"method" + 0.022*"actual" + 0.022*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #2 (0.031): 0.003*"parameter" + 0.003*"argument" + 0.003*"function" + 0.003*"method" + 0.003*"value" + 0.003*"actual" + 0.003*"call" + 0.003*"variable" + 0.003*"formal" + 0.003*"name"
INFO: topic #3 (0.047): 0.020*"question" + 0.019*"f" + 0.011*"distinguishing" + 0.011*"fun(arg" + 0.011*"look" + 0.011*"correct" + 0.011*"min" + 0.011*"big" + 0.011*"n’t" + 0.011*"print(arg"
INFO: topic #4 (0.066): 0.089*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"f2(x" + 0.019*"non" + 0.013*"error" + 0.013*"p" + 0.013*"f2" + 0.013*"c." + 0.007*"f3"
INFO: topic diff=0.120010, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.069 per-word bound, 33.6 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.02957341, 1.5637162, 0.029502494, 0.048464827, 0.0721291]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.030): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"question" + 0.003*"c." + 0.003*"argument" + 0.003*"positional" + 0.003*"def" + 0.003*"arg"
INFO: topic #1 (1.564): 0.104*"parameter" + 0.100*"argument" + 0.086*"function" + 0.048*"value" + 0.027*"definition" + 0.025*"variable" + 0.022*"call" + 0.022*"method" + 0.022*"actual" + 0.020*"name"
INFO: topic #2 (0.030): 0.003*"parameter" + 0.003*"argument" + 0.003*"function" + 0.003*"method" + 0.003*"value" + 0.003*"actual" + 0.003*"call" + 0.003*"variable" + 0.003*"formal" + 0.003*"name"
INFO: topic #3 (0.048): 0.028*"question" + 0.026*"f" + 0.015*"n’t" + 0.015*"print(arg" + 0.015*"look" + 0.015*"fun(arg" + 0.015*"distinguishing" + 0.015*"correct" + 0.015*"big" + 0.015*"min"
INFO: topic #4 (0.072): 0.110*"default" + 0.045*"positional" + 0.030*"keyword" + 0.023*"f2(x" + 0.023*"non" + 0.016*"p" + 0.016*"f2" + 0.016*"error" + 0.016*"c." + 0.008*"associated"
INFO: topic diff=0.111908, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.070 per-word bound, 33.6 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.028521992, 1.9041433, 0.028456105, 0.045647353, 0.065914065]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.029): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"argument" + 0.003*"positional" + 0.003*"def" + 0.003*"arg"
INFO: topic #1 (1.904): 0.100*"parameter" + 0.096*"argument" + 0.079*"function" + 0.044*"value" + 0.026*"variable" + 0.022*"method" + 0.022*"actual" + 0.022*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #2 (0.028): 0.003*"parameter" + 0.003*"argument" + 0.003*"function" + 0.003*"method" + 0.003*"value" + 0.003*"actual" + 0.003*"call" + 0.003*"variable" + 0.003*"formal" + 0.003*"name"
INFO: topic #3 (0.046): 0.020*"question" + 0.019*"f" + 0.011*"n’t" + 0.011*"print(arg" + 0.011*"look" + 0.011*"fun(arg" + 0.011*"distinguishing" + 0.011*"correct" + 0.011*"big" + 0.011*"min"
INFO: topic #4 (0.066): 0.090*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"f2(x" + 0.019*"non" + 0.013*"error" + 0.013*"f2" + 0.013*"p" + 0.013*"c." + 0.007*"f4"
INFO: topic diff=0.109241, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.063 per-word bound, 33.4 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.027511455, 1.6387198, 0.027450224, 0.046527453, 0.07146943]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.028): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"argument" + 0.003*"positional" + 0.003*"arg" + 0.003*"def"
INFO: topic #1 (1.639): 0.104*"parameter" + 0.099*"argument" + 0.085*"function" + 0.048*"value" + 0.027*"definition" + 0.025*"variable" + 0.022*"call" + 0.022*"method" + 0.022*"actual" + 0.020*"name"
INFO: topic #2 (0.027): 0.003*"parameter" + 0.003*"argument" + 0.003*"function" + 0.003*"method" + 0.003*"value" + 0.003*"actual" + 0.003*"call" + 0.003*"variable" + 0.003*"formal" + 0.003*"name"
INFO: topic #3 (0.047): 0.027*"question" + 0.026*"f" + 0.015*"n’t" + 0.015*"look" + 0.015*"print(arg" + 0.015*"min" + 0.015*"fun(arg" + 0.015*"distinguishing" + 0.015*"correct" + 0.015*"big"
INFO: topic #4 (0.071): 0.110*"default" + 0.045*"positional" + 0.030*"keyword" + 0.023*"f2(x" + 0.023*"non" + 0.016*"p" + 0.016*"f2" + 0.016*"error" + 0.016*"c." + 0.008*"associated"
INFO: topic diff=0.103628, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.066 per-word bound, 33.5 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.02666211, 1.9804626, 0.02660465, 0.04410335, 0.06577398]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.027): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"question" + 0.003*"c." + 0.003*"argument" + 0.003*"positional" + 0.003*"def" + 0.003*"arg"
INFO: topic #1 (1.980): 0.101*"parameter" + 0.096*"argument" + 0.079*"function" + 0.044*"value" + 0.026*"variable" + 0.022*"method" + 0.022*"actual" + 0.022*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #2 (0.027): 0.003*"parameter" + 0.003*"argument" + 0.003*"function" + 0.003*"method" + 0.003*"value" + 0.003*"actual" + 0.003*"call" + 0.003*"variable" + 0.003*"formal" + 0.003*"name"
INFO: topic #3 (0.044): 0.020*"question" + 0.019*"f" + 0.011*"min" + 0.011*"print(arg" + 0.011*"distinguishing" + 0.011*"correct" + 0.011*"fun(arg" + 0.011*"look" + 0.011*"n’t" + 0.011*"big"
INFO: topic #4 (0.066): 0.091*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"f2(x" + 0.019*"non" + 0.013*"p" + 0.013*"f2" + 0.013*"error" + 0.013*"c." + 0.007*"sure"
INFO: topic diff=0.101257, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.058 per-word bound, 33.3 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.025806693, 1.6549745, 0.025752915, 0.044929303, 0.07093361]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.026): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"argument" + 0.003*"positional" + 0.003*"arg" + 0.003*"def"
INFO: topic #1 (1.655): 0.104*"parameter" + 0.099*"argument" + 0.085*"function" + 0.048*"value" + 0.027*"definition" + 0.025*"variable" + 0.022*"method" + 0.022*"actual" + 0.022*"call" + 0.020*"name"
INFO: topic #2 (0.026): 0.003*"parameter" + 0.003*"argument" + 0.003*"function" + 0.003*"method" + 0.003*"value" + 0.003*"actual" + 0.003*"call" + 0.003*"variable" + 0.003*"formal" + 0.003*"name"
INFO: topic #3 (0.045): 0.027*"question" + 0.025*"f" + 0.015*"correct" + 0.015*"distinguishing" + 0.015*"fun(arg" + 0.015*"look" + 0.015*"min" + 0.015*"n’t" + 0.015*"print(arg" + 0.015*"big"
INFO: topic #4 (0.071): 0.109*"default" + 0.044*"positional" + 0.030*"keyword" + 0.023*"f2(x" + 0.023*"non" + 0.016*"error" + 0.016*"p" + 0.016*"f2" + 0.016*"c." + 0.008*"f3"
INFO: topic diff=0.097064, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.062 per-word bound, 33.4 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.025096605, 1.9849195, 0.025045779, 0.0427814, 0.06560312]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.025): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"question" + 0.003*"c." + 0.003*"argument" + 0.003*"positional" + 0.003*"def" + 0.003*"arg"
INFO: topic #1 (1.985): 0.101*"parameter" + 0.096*"argument" + 0.079*"function" + 0.044*"value" + 0.026*"variable" + 0.022*"method" + 0.022*"actual" + 0.022*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #2 (0.025): 0.003*"parameter" + 0.003*"argument" + 0.003*"function" + 0.003*"method" + 0.003*"value" + 0.003*"actual" + 0.003*"call" + 0.003*"variable" + 0.003*"formal" + 0.003*"name"
INFO: topic #3 (0.043): 0.021*"question" + 0.019*"f" + 0.011*"correct" + 0.011*"big" + 0.011*"distinguishing" + 0.011*"fun(arg" + 0.011*"look" + 0.011*"print(arg" + 0.011*"min" + 0.011*"n’t"
INFO: topic #4 (0.066): 0.091*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"f2(x" + 0.019*"non" + 0.013*"error" + 0.013*"p" + 0.013*"f2" + 0.013*"c." + 0.007*"f3"
INFO: topic diff=0.094945, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.054 per-word bound, 33.2 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.024365246, 1.6513656, 0.024317376, 0.043574832, 0.07045941]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.024): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"question" + 0.003*"c." + 0.003*"argument" + 0.003*"positional" + 0.003*"arg" + 0.003*"def"
INFO: topic #1 (1.651): 0.104*"parameter" + 0.099*"argument" + 0.085*"function" + 0.048*"value" + 0.027*"definition" + 0.025*"variable" + 0.022*"method" + 0.022*"actual" + 0.021*"call" + 0.020*"name"
INFO: topic #2 (0.024): 0.003*"parameter" + 0.003*"argument" + 0.003*"function" + 0.003*"method" + 0.003*"value" + 0.003*"actual" + 0.003*"call" + 0.003*"variable" + 0.003*"formal" + 0.003*"name"
INFO: topic #3 (0.044): 0.027*"question" + 0.025*"f" + 0.014*"big" + 0.014*"look" + 0.014*"min" + 0.014*"n’t" + 0.014*"print(arg" + 0.014*"distinguishing" + 0.014*"correct" + 0.014*"fun(arg"
INFO: topic #4 (0.070): 0.109*"default" + 0.044*"positional" + 0.030*"keyword" + 0.023*"f2(x" + 0.023*"non" + 0.016*"p" + 0.016*"error" + 0.016*"f2" + 0.016*"c." + 0.008*"f3(b=100"
INFO: topic diff=0.091652, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.059 per-word bound, 33.3 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.023758786, 1.9666474, 0.023713294, 0.041638993, 0.06542038]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.024): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"argument" + 0.003*"positional" + 0.003*"arg" + 0.003*"def"
INFO: topic #1 (1.967): 0.101*"parameter" + 0.096*"argument" + 0.079*"function" + 0.044*"value" + 0.026*"variable" + 0.022*"method" + 0.022*"actual" + 0.022*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #2 (0.024): 0.003*"parameter" + 0.003*"argument" + 0.003*"function" + 0.003*"method" + 0.003*"value" + 0.003*"actual" + 0.003*"call" + 0.003*"variable" + 0.003*"formal" + 0.003*"name"
INFO: topic #3 (0.042): 0.021*"question" + 0.019*"f" + 0.011*"n’t" + 0.011*"print(arg" + 0.011*"look" + 0.011*"fun(arg" + 0.011*"distinguishing" + 0.011*"correct" + 0.011*"big" + 0.011*"min"
INFO: topic #4 (0.065): 0.091*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"f2(x" + 0.019*"non" + 0.013*"f2" + 0.013*"error" + 0.013*"p" + 0.013*"c." + 0.007*"f3"
INFO: topic diff=0.089736, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.050 per-word bound, 33.1 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0231261, 1.6421826, 0.023083026, 0.042407382, 0.07002739]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.023): 0.003*"f" + 0.003*"default" + 0.003*"parameter" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"argument" + 0.003*"positional" + 0.003*"arg" + 0.003*"variable"
INFO: topic #1 (1.642): 0.104*"parameter" + 0.099*"argument" + 0.085*"function" + 0.048*"value" + 0.026*"definition" + 0.025*"variable" + 0.022*"method" + 0.022*"actual" + 0.021*"call" + 0.019*"name"
INFO: topic #2 (0.023): 0.003*"parameter" + 0.003*"argument" + 0.003*"function" + 0.003*"method" + 0.003*"value" + 0.003*"actual" + 0.003*"call" + 0.003*"variable" + 0.003*"formal" + 0.003*"name"
INFO: topic #3 (0.042): 0.027*"question" + 0.025*"f" + 0.014*"distinguishing" + 0.014*"n’t" + 0.014*"min" + 0.014*"look" + 0.014*"fun(arg" + 0.014*"correct" + 0.014*"big" + 0.014*"print(arg"
INFO: topic #4 (0.070): 0.108*"default" + 0.044*"positional" + 0.030*"keyword" + 0.023*"f2(x" + 0.023*"non" + 0.015*"p" + 0.015*"error" + 0.015*"f2" + 0.015*"c." + 0.008*"f1(x"
INFO: topic diff=0.087073, rho=0.288675
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=397, num_topics=5, decay=0.5, chunksize=5> in 0.17s', 'datetime': '2023-04-25T15:14:05.288056', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 5 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.002 per-word bound, 128.2 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
WARNING: updated prior is not positive
INFO: optimized alpha [0.2, 0.2, 0.2, 0.2, 0.2]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.200): 0.099*"parameter" + 0.094*"argument" + 0.072*"function" + 0.039*"value" + 0.026*"variable" + 0.023*"method" + 0.023*"actual" + 0.018*"formal" + 0.017*"name" + 0.016*"definition"
INFO: topic #1 (0.200): 0.003*"function" + 0.003*"argument" + 0.003*"parameter" + 0.003*"variable" + 0.003*"value" + 0.003*"type" + 0.003*"actual" + 0.003*"object" + 0.003*"program" + 0.003*"part"
INFO: topic #2 (0.200): 0.003*"function" + 0.003*"parameter" + 0.003*"argument" + 0.003*"variable" + 0.003*"value" + 0.003*"program" + 0.003*"type" + 0.003*"actual" + 0.003*"part" + 0.003*"object"
INFO: topic #3 (0.200): 0.065*"program" + 0.039*"address" + 0.039*"output" + 0.039*"c++" + 0.027*"function" + 0.027*"variable" + 0.027*"object" + 0.027*"int" + 0.027*"copy" + 0.027*"equivalent"
INFO: topic #4 (0.200): 0.003*"function" + 0.003*"parameter" + 0.003*"argument" + 0.003*"value" + 0.003*"variable" + 0.003*"actual" + 0.003*"program" + 0.003*"type" + 0.003*"object" + 0.003*"call"
INFO: topic diff=3.006858, rho=1.000000
DEBUG: bound: at document #0
INFO: -6.535 per-word bound, 92.7 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.31014842, 0.11997905, 0.1663771, 0.14933069, 0.079250656]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.310): 0.108*"parameter" + 0.103*"argument" + 0.090*"function" + 0.052*"value" + 0.032*"definition" + 0.024*"call" + 0.024*"variable" + 0.022*"method" + 0.021*"name" + 0.021*"actual"
INFO: topic #1 (0.120): 0.027*"f" + 0.027*"question" + 0.014*"arg" + 0.014*"def" + 0.014*"print(arg" + 0.014*"fun(arg" + 0.014*"min" + 0.014*"n’t" + 0.014*"distinguishing" + 0.014*"look"
INFO: topic #2 (0.166): 0.117*"default" + 0.048*"positional" + 0.032*"keyword" + 0.024*"non" + 0.024*"f2(x" + 0.017*"p" + 0.017*"error" + 0.017*"f2" + 0.010*"c." + 0.009*"def"
INFO: topic #3 (0.149): 0.062*"program" + 0.025*"c++" + 0.018*"function" + 0.017*"address" + 0.017*"output" + 0.012*"declaration" + 0.012*"variable" + 0.012*"object" + 0.012*"int" + 0.012*"copy"
INFO: topic #4 (0.079): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"arg" + 0.003*"argument"
INFO: topic diff=0.615217, rho=0.707107
DEBUG: bound: at document #0
INFO: -5.114 per-word bound, 34.6 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.37226987, 0.07734957, 0.085710905, 0.10697729, 0.060449705]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.372): 0.102*"parameter" + 0.097*"argument" + 0.078*"function" + 0.043*"value" + 0.026*"variable" + 0.023*"method" + 0.022*"actual" + 0.021*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #1 (0.077): 0.016*"f" + 0.016*"question" + 0.009*"arg" + 0.009*"def" + 0.009*"print(arg" + 0.009*"fun(arg" + 0.009*"min" + 0.009*"n’t" + 0.009*"distinguishing" + 0.009*"look"
INFO: topic #2 (0.086): 0.080*"default" + 0.033*"positional" + 0.022*"keyword" + 0.017*"non" + 0.017*"f2(x" + 0.012*"p" + 0.012*"error" + 0.012*"f2" + 0.008*"c." + 0.007*"def"
INFO: topic #3 (0.107): 0.065*"program" + 0.034*"c++" + 0.030*"address" + 0.030*"output" + 0.021*"equivalent" + 0.021*"separate" + 0.021*"int" + 0.021*"copy" + 0.020*"object" + 0.018*"function"
INFO: topic #4 (0.060): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"arg" + 0.003*"argument"
INFO: topic diff=0.254300, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.222 per-word bound, 37.3 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.4954979, 0.07439883, 0.09273584, 0.10689342, 0.05283251]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.495): 0.108*"parameter" + 0.103*"argument" + 0.090*"function" + 0.051*"value" + 0.030*"definition" + 0.025*"variable" + 0.024*"call" + 0.022*"method" + 0.021*"actual" + 0.021*"name"
INFO: topic #1 (0.074): 0.028*"question" + 0.027*"f" + 0.015*"fun(arg" + 0.015*"min" + 0.015*"n’t" + 0.015*"distinguishing" + 0.015*"print(arg" + 0.015*"look" + 0.015*"correct" + 0.015*"big"
INFO: topic #2 (0.093): 0.116*"default" + 0.047*"positional" + 0.032*"keyword" + 0.024*"non" + 0.024*"f2(x" + 0.017*"f2" + 0.017*"error" + 0.017*"p" + 0.012*"c." + 0.009*"a=200"
INFO: topic #3 (0.107): 0.066*"program" + 0.026*"c++" + 0.019*"address" + 0.019*"output" + 0.013*"equivalent" + 0.013*"separate" + 0.013*"int" + 0.013*"copy" + 0.013*"object" + 0.013*"function"
INFO: topic #4 (0.053): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"arg" + 0.003*"argument"
INFO: topic diff=0.221793, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.078 per-word bound, 33.8 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.558292, 0.060957767, 0.07194015, 0.09272063, 0.04602784]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.558): 0.102*"parameter" + 0.098*"argument" + 0.079*"function" + 0.044*"value" + 0.026*"variable" + 0.023*"method" + 0.022*"actual" + 0.021*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #1 (0.061): 0.018*"question" + 0.017*"f" + 0.010*"fun(arg" + 0.010*"min" + 0.010*"n’t" + 0.010*"distinguishing" + 0.010*"print(arg" + 0.010*"look" + 0.010*"correct" + 0.010*"big"
INFO: topic #2 (0.072): 0.085*"default" + 0.035*"positional" + 0.024*"keyword" + 0.018*"non" + 0.018*"f2(x" + 0.013*"p" + 0.013*"f2" + 0.013*"error" + 0.010*"c." + 0.007*"associated"
INFO: topic #3 (0.093): 0.068*"program" + 0.034*"c++" + 0.031*"address" + 0.031*"output" + 0.021*"equivalent" + 0.021*"separate" + 0.021*"int" + 0.021*"copy" + 0.020*"object" + 0.015*"variable"
INFO: topic #4 (0.046): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"arg" + 0.003*"argument"
INFO: topic diff=0.211350, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.174 per-word bound, 36.1 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7075537, 0.061123528, 0.07945531, 0.095812894, 0.04244158]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.708): 0.107*"parameter" + 0.103*"argument" + 0.089*"function" + 0.050*"value" + 0.029*"definition" + 0.025*"variable" + 0.023*"call" + 0.022*"method" + 0.021*"actual" + 0.021*"name"
INFO: topic #1 (0.061): 0.028*"question" + 0.027*"f" + 0.015*"fun(arg" + 0.015*"min" + 0.015*"n’t" + 0.015*"distinguishing" + 0.015*"print(arg" + 0.015*"look" + 0.015*"correct" + 0.015*"big"
INFO: topic #2 (0.079): 0.114*"default" + 0.046*"positional" + 0.031*"keyword" + 0.024*"f2(x" + 0.024*"non" + 0.016*"p" + 0.016*"f2" + 0.016*"error" + 0.014*"c." + 0.009*"sure"
INFO: topic #3 (0.096): 0.068*"program" + 0.026*"c++" + 0.021*"address" + 0.021*"output" + 0.014*"equivalent" + 0.014*"separate" + 0.014*"int" + 0.014*"copy" + 0.014*"object" + 0.011*"variable"
INFO: topic #4 (0.042): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"argument" + 0.003*"arg"
INFO: topic diff=0.185046, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.059 per-word bound, 33.3 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.74496835, 0.053261805, 0.06621891, 0.087248, 0.038640417]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.745): 0.103*"parameter" + 0.098*"argument" + 0.080*"function" + 0.044*"value" + 0.026*"variable" + 0.023*"method" + 0.022*"actual" + 0.022*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #1 (0.053): 0.019*"question" + 0.018*"f" + 0.011*"fun(arg" + 0.011*"min" + 0.011*"n’t" + 0.011*"distinguishing" + 0.011*"print(arg" + 0.011*"look" + 0.011*"correct" + 0.011*"big"
INFO: topic #2 (0.066): 0.087*"default" + 0.036*"positional" + 0.024*"keyword" + 0.019*"non" + 0.019*"f2(x" + 0.013*"p" + 0.013*"f2" + 0.013*"error" + 0.012*"c." + 0.007*"associated"
INFO: topic #3 (0.087): 0.069*"program" + 0.034*"c++" + 0.031*"address" + 0.031*"output" + 0.021*"equivalent" + 0.021*"separate" + 0.021*"int" + 0.021*"copy" + 0.020*"object" + 0.014*"variable"
INFO: topic #4 (0.039): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"argument" + 0.003*"arg"
INFO: topic diff=0.181163, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.149 per-word bound, 35.5 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.9041419, 0.054188773, 0.07331704, 0.09112267, 0.03646909]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.904): 0.107*"parameter" + 0.102*"argument" + 0.088*"function" + 0.050*"value" + 0.029*"definition" + 0.025*"variable" + 0.023*"call" + 0.022*"method" + 0.022*"actual" + 0.020*"name"
INFO: topic #1 (0.054): 0.028*"question" + 0.027*"f" + 0.015*"fun(arg" + 0.015*"min" + 0.015*"n’t" + 0.015*"distinguishing" + 0.015*"print(arg" + 0.015*"look" + 0.015*"correct" + 0.015*"big"
INFO: topic #2 (0.073): 0.113*"default" + 0.046*"positional" + 0.031*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"f2" + 0.016*"error" + 0.016*"p" + 0.015*"c." + 0.009*"a=200"
INFO: topic #3 (0.091): 0.070*"program" + 0.026*"c++" + 0.022*"address" + 0.022*"output" + 0.015*"equivalent" + 0.015*"separate" + 0.015*"int" + 0.015*"copy" + 0.014*"object" + 0.010*"variable"
INFO: topic #4 (0.036): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"argument" + 0.003*"arg"
INFO: topic diff=0.163240, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.048 per-word bound, 33.1 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.89233387, 0.04858249, 0.06308994, 0.08460521, 0.03392376]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.892): 0.103*"parameter" + 0.098*"argument" + 0.080*"function" + 0.045*"value" + 0.026*"variable" + 0.023*"method" + 0.022*"actual" + 0.022*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #1 (0.049): 0.020*"question" + 0.019*"f" + 0.011*"fun(arg" + 0.011*"min" + 0.011*"n’t" + 0.011*"distinguishing" + 0.011*"print(arg" + 0.011*"look" + 0.011*"correct" + 0.011*"big"
INFO: topic #2 (0.063): 0.088*"default" + 0.036*"positional" + 0.025*"keyword" + 0.019*"non" + 0.019*"f2(x" + 0.013*"f2" + 0.013*"error" + 0.013*"p" + 0.012*"c." + 0.007*"a=200"
INFO: topic #3 (0.085): 0.070*"program" + 0.033*"c++" + 0.031*"address" + 0.031*"output" + 0.021*"equivalent" + 0.021*"separate" + 0.021*"int" + 0.021*"copy" + 0.020*"object" + 0.012*"variable"
INFO: topic #4 (0.034): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"argument" + 0.003*"arg"
INFO: topic diff=0.159279, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.135 per-word bound, 35.1 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0439228, 0.04970928, 0.06966227, 0.08859414, 0.032417223]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.044): 0.107*"parameter" + 0.102*"argument" + 0.088*"function" + 0.050*"value" + 0.028*"definition" + 0.025*"variable" + 0.023*"call" + 0.022*"method" + 0.022*"actual" + 0.020*"name"
INFO: topic #1 (0.050): 0.028*"question" + 0.026*"f" + 0.015*"fun(arg" + 0.015*"min" + 0.015*"distinguishing" + 0.015*"n’t" + 0.015*"big" + 0.015*"correct" + 0.015*"print(arg" + 0.015*"look"
INFO: topic #2 (0.070): 0.111*"default" + 0.045*"positional" + 0.031*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"error" + 0.016*"f2" + 0.016*"p" + 0.016*"c." + 0.009*"associated"
INFO: topic #3 (0.089): 0.071*"program" + 0.026*"c++" + 0.023*"address" + 0.023*"output" + 0.016*"equivalent" + 0.016*"separate" + 0.016*"int" + 0.016*"copy" + 0.015*"object" + 0.009*"variable"
INFO: topic #4 (0.032): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"argument" + 0.003*"arg"
INFO: topic diff=0.146750, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.040 per-word bound, 32.9 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.9826356, 0.04530654, 0.061045345, 0.08303576, 0.03054082]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.983): 0.103*"parameter" + 0.098*"argument" + 0.080*"function" + 0.045*"value" + 0.026*"variable" + 0.023*"method" + 0.022*"actual" + 0.022*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #1 (0.045): 0.020*"question" + 0.019*"f" + 0.011*"n’t" + 0.011*"min" + 0.011*"look" + 0.011*"print(arg" + 0.011*"distinguishing" + 0.011*"big" + 0.011*"fun(arg" + 0.011*"correct"
INFO: topic #2 (0.061): 0.089*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"non" + 0.019*"f2(x" + 0.013*"p" + 0.013*"error" + 0.013*"f2" + 0.013*"c." + 0.007*"sure"
INFO: topic #3 (0.083): 0.071*"program" + 0.033*"c++" + 0.031*"address" + 0.031*"output" + 0.021*"equivalent" + 0.021*"separate" + 0.021*"int" + 0.021*"copy" + 0.020*"object" + 0.012*"dosomething(int"
INFO: topic #4 (0.031): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"argument" + 0.003*"arg"
INFO: topic diff=0.143385, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.126 per-word bound, 34.9 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.119459, 0.04646211, 0.06712425, 0.08690715, 0.029408466]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.119): 0.107*"parameter" + 0.102*"argument" + 0.087*"function" + 0.049*"value" + 0.028*"definition" + 0.025*"variable" + 0.022*"call" + 0.022*"method" + 0.022*"actual" + 0.020*"name"
INFO: topic #1 (0.046): 0.027*"question" + 0.026*"f" + 0.015*"fun(arg" + 0.015*"min" + 0.015*"n’t" + 0.015*"distinguishing" + 0.015*"print(arg" + 0.015*"look" + 0.015*"correct" + 0.015*"big"
INFO: topic #2 (0.067): 0.111*"default" + 0.045*"positional" + 0.030*"keyword" + 0.023*"f2(x" + 0.023*"non" + 0.016*"p" + 0.016*"error" + 0.016*"f2" + 0.016*"c." + 0.008*"f1(x"
INFO: topic #3 (0.087): 0.071*"program" + 0.026*"c++" + 0.023*"address" + 0.023*"output" + 0.016*"separate" + 0.016*"equivalent" + 0.016*"int" + 0.016*"copy" + 0.015*"object" + 0.009*"dosomething(int"
INFO: topic #4 (0.029): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"argument" + 0.003*"arg"
INFO: topic diff=0.134550, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.035 per-word bound, 32.8 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0273689, 0.04282205, 0.059552573, 0.081926264, 0.027947279]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.027): 0.103*"parameter" + 0.098*"argument" + 0.081*"function" + 0.045*"value" + 0.026*"variable" + 0.023*"method" + 0.022*"actual" + 0.022*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #1 (0.043): 0.020*"question" + 0.019*"f" + 0.011*"min" + 0.011*"n’t" + 0.011*"look" + 0.011*"fun(arg" + 0.011*"distinguishing" + 0.011*"print(arg" + 0.011*"correct" + 0.011*"big"
INFO: topic #2 (0.060): 0.090*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"f2(x" + 0.019*"non" + 0.013*"error" + 0.013*"p" + 0.013*"f2" + 0.013*"c." + 0.007*"f3"
INFO: topic #3 (0.082): 0.071*"program" + 0.033*"c++" + 0.031*"address" + 0.031*"output" + 0.021*"equivalent" + 0.021*"separate" + 0.021*"int" + 0.021*"copy" + 0.020*"object" + 0.012*"dosomething(int"
INFO: topic #4 (0.028): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"arg" + 0.003*"argument" + 0.003*"def"
INFO: topic diff=0.131581, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.119 per-word bound, 34.8 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.1503984, 0.043953016, 0.065204285, 0.08562082, 0.027053444]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.150): 0.106*"parameter" + 0.102*"argument" + 0.087*"function" + 0.049*"value" + 0.028*"definition" + 0.025*"variable" + 0.022*"call" + 0.022*"method" + 0.022*"actual" + 0.020*"name"
INFO: topic #1 (0.044): 0.027*"question" + 0.026*"f" + 0.015*"fun(arg" + 0.015*"distinguishing" + 0.015*"min" + 0.015*"look" + 0.015*"print(arg" + 0.015*"n’t" + 0.015*"big" + 0.015*"correct"
INFO: topic #2 (0.065): 0.110*"default" + 0.045*"positional" + 0.030*"keyword" + 0.023*"f2(x" + 0.023*"non" + 0.016*"p" + 0.016*"f2" + 0.016*"error" + 0.016*"c." + 0.008*"associated"
INFO: topic #3 (0.086): 0.071*"program" + 0.026*"c++" + 0.024*"address" + 0.024*"output" + 0.016*"equivalent" + 0.016*"separate" + 0.016*"int" + 0.016*"copy" + 0.015*"object" + 0.009*"dosomething(int"
INFO: topic #4 (0.027): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"arg" + 0.003*"argument"
INFO: topic diff=0.125309, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.030 per-word bound, 32.7 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0455114, 0.040847756, 0.058393374, 0.08105826, 0.025874864]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.046): 0.103*"parameter" + 0.098*"argument" + 0.081*"function" + 0.045*"value" + 0.026*"variable" + 0.023*"method" + 0.023*"actual" + 0.022*"definition" + 0.019*"call" + 0.019*"name"
INFO: topic #1 (0.041): 0.020*"question" + 0.019*"f" + 0.011*"distinguishing" + 0.011*"n’t" + 0.011*"min" + 0.011*"look" + 0.011*"fun(arg" + 0.011*"print(arg" + 0.011*"big" + 0.011*"correct"
INFO: topic #2 (0.058): 0.091*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"non" + 0.019*"f2(x" + 0.013*"f2" + 0.013*"error" + 0.013*"p" + 0.013*"c." + 0.007*"associated"
INFO: topic #3 (0.081): 0.072*"program" + 0.033*"c++" + 0.031*"address" + 0.031*"output" + 0.021*"separate" + 0.021*"equivalent" + 0.021*"int" + 0.021*"copy" + 0.020*"object" + 0.012*"dosomething(int"
INFO: topic #4 (0.026): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"argument" + 0.003*"def" + 0.003*"arg"
INFO: topic diff=0.122429, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.114 per-word bound, 34.6 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.1577085, 0.04193851, 0.06368331, 0.084574945, 0.02514591]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.158): 0.106*"parameter" + 0.101*"argument" + 0.087*"function" + 0.049*"value" + 0.027*"definition" + 0.025*"variable" + 0.022*"method" + 0.022*"call" + 0.022*"actual" + 0.020*"name"
INFO: topic #1 (0.042): 0.027*"question" + 0.025*"f" + 0.015*"fun(arg" + 0.015*"distinguishing" + 0.015*"min" + 0.015*"look" + 0.015*"print(arg" + 0.015*"n’t" + 0.015*"big" + 0.015*"correct"
INFO: topic #2 (0.064): 0.109*"default" + 0.044*"positional" + 0.030*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"p" + 0.016*"f2" + 0.016*"error" + 0.016*"c." + 0.008*"a=200"
INFO: topic #3 (0.085): 0.071*"program" + 0.027*"c++" + 0.024*"address" + 0.024*"output" + 0.017*"separate" + 0.017*"equivalent" + 0.016*"int" + 0.016*"copy" + 0.015*"object" + 0.009*"possible"
INFO: topic #4 (0.025): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"argument" + 0.003*"arg"
INFO: topic diff=0.117670, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.027 per-word bound, 32.6 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0502998, 0.039230656, 0.057460427, 0.08034316, 0.02417074]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.050): 0.103*"parameter" + 0.098*"argument" + 0.081*"function" + 0.045*"value" + 0.026*"variable" + 0.023*"method" + 0.023*"actual" + 0.022*"definition" + 0.019*"call" + 0.019*"name"
INFO: topic #1 (0.039): 0.021*"question" + 0.019*"f" + 0.011*"look" + 0.011*"distinguishing" + 0.011*"correct" + 0.011*"big" + 0.011*"fun(arg" + 0.011*"print(arg" + 0.011*"n’t" + 0.011*"min"
INFO: topic #2 (0.057): 0.091*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"non" + 0.019*"f2(x" + 0.013*"p" + 0.013*"error" + 0.013*"f2" + 0.013*"c." + 0.007*"f4"
INFO: topic #3 (0.080): 0.072*"program" + 0.032*"c++" + 0.031*"address" + 0.031*"output" + 0.021*"equivalent" + 0.021*"separate" + 0.021*"int" + 0.021*"copy" + 0.020*"object" + 0.012*"dosomething(int"
INFO: topic #4 (0.024): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"argument" + 0.003*"arg"
INFO: topic diff=0.114995, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.109 per-word bound, 34.5 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.1541431, 0.04027804, 0.062443573, 0.083696574, 0.02356198]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.154): 0.106*"parameter" + 0.101*"argument" + 0.087*"function" + 0.049*"value" + 0.027*"definition" + 0.025*"variable" + 0.022*"method" + 0.022*"actual" + 0.022*"call" + 0.020*"name"
INFO: topic #1 (0.040): 0.027*"question" + 0.025*"f" + 0.014*"min" + 0.014*"correct" + 0.014*"fun(arg" + 0.014*"big" + 0.014*"distinguishing" + 0.014*"look" + 0.014*"n’t" + 0.014*"print(arg"
INFO: topic #2 (0.062): 0.109*"default" + 0.044*"positional" + 0.030*"keyword" + 0.023*"f2(x" + 0.023*"non" + 0.016*"error" + 0.016*"f2" + 0.016*"p" + 0.016*"c." + 0.008*"f4"
INFO: topic #3 (0.084): 0.072*"program" + 0.027*"c++" + 0.024*"address" + 0.024*"output" + 0.017*"equivalent" + 0.017*"separate" + 0.017*"int" + 0.017*"copy" + 0.016*"object" + 0.009*"dosomething(int"
INFO: topic #4 (0.024): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"argument" + 0.003*"arg"
INFO: topic diff=0.111164, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.024 per-word bound, 32.5 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0488805, 0.037876967, 0.056691915, 0.07973738, 0.022738975]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.049): 0.103*"parameter" + 0.098*"argument" + 0.081*"function" + 0.045*"value" + 0.026*"variable" + 0.023*"method" + 0.023*"actual" + 0.022*"definition" + 0.019*"call" + 0.019*"name"
INFO: topic #1 (0.038): 0.021*"question" + 0.019*"f" + 0.011*"min" + 0.011*"correct" + 0.011*"look" + 0.011*"fun(arg" + 0.011*"distinguishing" + 0.011*"print(arg" + 0.011*"big" + 0.011*"n’t"
INFO: topic #2 (0.057): 0.092*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"non" + 0.019*"f2(x" + 0.013*"p" + 0.013*"f2" + 0.013*"error" + 0.013*"c." + 0.007*"sure"
INFO: topic #3 (0.080): 0.072*"program" + 0.032*"c++" + 0.031*"address" + 0.031*"output" + 0.021*"separate" + 0.021*"equivalent" + 0.021*"int" + 0.021*"copy" + 0.020*"object" + 0.011*"void"
INFO: topic #4 (0.023): 0.003*"f" + 0.003*"default" + 0.003*"c." + 0.003*"function" + 0.003*"parameter" + 0.003*"question" + 0.003*"positional" + 0.003*"def" + 0.003*"argument" + 0.003*"arg"
INFO: topic diff=0.108766, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.105 per-word bound, 34.4 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.1460963, 0.038882073, 0.06141255, 0.08294453, 0.022221174]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.146): 0.106*"parameter" + 0.101*"argument" + 0.086*"function" + 0.049*"value" + 0.027*"definition" + 0.026*"variable" + 0.022*"method" + 0.022*"actual" + 0.022*"call" + 0.020*"name"
INFO: topic #1 (0.039): 0.027*"question" + 0.025*"f" + 0.014*"min" + 0.014*"n’t" + 0.014*"print(arg" + 0.014*"fun(arg" + 0.014*"distinguishing" + 0.014*"correct" + 0.014*"big" + 0.014*"look"
INFO: topic #2 (0.061): 0.108*"default" + 0.044*"positional" + 0.030*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.015*"p" + 0.015*"f2" + 0.015*"error" + 0.015*"c." + 0.008*"sure"
INFO: topic #3 (0.083): 0.072*"program" + 0.027*"c++" + 0.024*"address" + 0.024*"output" + 0.017*"separate" + 0.017*"equivalent" + 0.017*"int" + 0.017*"copy" + 0.016*"object" + 0.009*"demo"
INFO: topic #4 (0.022): 0.003*"f" + 0.003*"default" + 0.003*"function" + 0.003*"c." + 0.003*"question" + 0.003*"parameter" + 0.003*"positional" + 0.003*"def" + 0.003*"arg" + 0.003*"argument"
INFO: topic diff=0.105583, rho=0.288675
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=397, num_topics=5, decay=0.5, chunksize=5> in 0.13s', 'datetime': '2023-04-25T15:14:05.416419', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 5 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.034 per-word bound, 131.0 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
WARNING: updated prior is not positive
INFO: optimized alpha [0.2, 0.2, 0.2, 0.2, 0.2]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.200): 0.003*"parameter" + 0.003*"function" + 0.003*"argument" + 0.003*"variable" + 0.003*"value" + 0.003*"type" + 0.003*"program" + 0.003*"output" + 0.003*"object" + 0.003*"call"
INFO: topic #1 (0.200): 0.092*"argument" + 0.081*"parameter" + 0.066*"function" + 0.044*"value" + 0.035*"variable" + 0.025*"method" + 0.022*"actual" + 0.016*"formal" + 0.016*"call" + 0.015*"name"
INFO: topic #2 (0.200): 0.003*"function" + 0.003*"parameter" + 0.003*"argument" + 0.003*"variable" + 0.003*"value" + 0.003*"type" + 0.003*"program" + 0.003*"int" + 0.003*"output" + 0.003*"actual"
INFO: topic #3 (0.200): 0.112*"parameter" + 0.087*"argument" + 0.069*"function" + 0.030*"value" + 0.023*"actual" + 0.021*"example" + 0.019*"type" + 0.019*"formal" + 0.018*"method" + 0.018*"name"
INFO: topic #4 (0.200): 0.062*"function" + 0.047*"parameter" + 0.032*"message" + 0.032*"part" + 0.017*"variable" + 0.017*"argument" + 0.017*"object" + 0.017*"process" + 0.017*"information" + 0.017*"first"
INFO: topic diff=2.761824, rho=1.000000
DEBUG: bound: at document #0
INFO: -6.801 per-word bound, 111.5 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1741428, 0.3002516, 0.12503874, 0.23215666, 0.11878554]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.174): 0.103*"default" + 0.042*"positional" + 0.028*"keyword" + 0.022*"non" + 0.022*"f2(x" + 0.016*"f" + 0.015*"question" + 0.015*"def" + 0.015*"arg" + 0.015*"f2"
INFO: topic #1 (0.300): 0.095*"argument" + 0.083*"parameter" + 0.070*"function" + 0.049*"value" + 0.033*"variable" + 0.029*"method" + 0.023*"definition" + 0.021*"actual" + 0.019*"call" + 0.015*"name"
INFO: topic #2 (0.125): 0.022*"c." + 0.012*"z" + 0.012*"thesis" + 0.012*"community" + 0.012*"convention" + 0.012*"alternative" + 0.012*"view" + 0.012*"sqrt" + 0.012*"inside" + 0.012*"prototype"
INFO: topic #3 (0.232): 0.114*"parameter" + 0.095*"function" + 0.094*"argument" + 0.047*"value" + 0.036*"definition" + 0.030*"b" + 0.026*"call" + 0.024*"name" + 0.019*"key" + 0.019*"actual"
INFO: topic #4 (0.119): 0.026*"function" + 0.024*"part" + 0.023*"parameter" + 0.018*"signature" + 0.014*"code" + 0.014*"message" + 0.012*"f" + 0.009*"variable" + 0.009*"argument" + 0.008*"first"
INFO: topic diff=0.830101, rho=0.707107
DEBUG: bound: at document #0
INFO: -5.218 per-word bound, 37.2 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.082767606, 0.2597315, 0.07709648, 0.15562516, 0.091676384]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.083): 0.070*"default" + 0.029*"positional" + 0.020*"keyword" + 0.015*"non" + 0.015*"f2(x" + 0.011*"f" + 0.011*"question" + 0.011*"def" + 0.011*"arg" + 0.011*"f2"
INFO: topic #1 (0.260): 0.093*"argument" + 0.091*"parameter" + 0.065*"function" + 0.043*"value" + 0.030*"variable" + 0.026*"method" + 0.023*"actual" + 0.018*"formal" + 0.017*"definition" + 0.016*"call"
INFO: topic #2 (0.077): 0.013*"c." + 0.008*"z" + 0.008*"thesis" + 0.008*"community" + 0.008*"convention" + 0.008*"alternative" + 0.008*"view" + 0.008*"sqrt" + 0.008*"inside" + 0.008*"prototype"
INFO: topic #3 (0.156): 0.108*"parameter" + 0.099*"function" + 0.090*"argument" + 0.038*"value" + 0.028*"definition" + 0.022*"b" + 0.021*"type" + 0.021*"example" + 0.021*"call" + 0.021*"name"
INFO: topic #4 (0.092): 0.030*"part" + 0.027*"function" + 0.026*"message" + 0.020*"parameter" + 0.018*"signature" + 0.016*"code" + 0.014*"self" + 0.014*"dot" + 0.014*"similar" + 0.014*"second"
INFO: topic diff=0.383474, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.293 per-word bound, 39.2 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.08772094, 0.2742055, 0.07224704, 0.17103006, 0.08162448]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.088): 0.103*"default" + 0.043*"positional" + 0.029*"keyword" + 0.022*"non" + 0.022*"f2(x" + 0.016*"question" + 0.016*"f" + 0.016*"def" + 0.016*"arg" + 0.015*"f2"
INFO: topic #1 (0.274): 0.095*"parameter" + 0.095*"argument" + 0.064*"function" + 0.041*"value" + 0.029*"method" + 0.027*"variable" + 0.024*"actual" + 0.020*"formal" + 0.017*"definition" + 0.014*"call"
INFO: topic #2 (0.072): 0.027*"c." + 0.014*"z" + 0.014*"thesis" + 0.014*"community" + 0.014*"convention" + 0.014*"alternative" + 0.014*"view" + 0.014*"sqrt" + 0.014*"inside" + 0.014*"prototype"
INFO: topic #3 (0.171): 0.114*"function" + 0.105*"parameter" + 0.095*"argument" + 0.059*"value" + 0.047*"definition" + 0.040*"b" + 0.035*"call" + 0.029*"name" + 0.027*"key" + 0.023*"case"
INFO: topic #4 (0.082): 0.024*"part" + 0.018*"signature" + 0.016*"function" + 0.016*"message" + 0.014*"f" + 0.013*"code" + 0.013*"parameter" + 0.009*"self" + 0.009*"dot" + 0.009*"similar"
INFO: topic diff=0.328460, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.100 per-word bound, 34.3 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.06512878, 0.23707208, 0.056869924, 0.13625973, 0.071179874]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.065): 0.075*"default" + 0.031*"positional" + 0.022*"keyword" + 0.017*"non" + 0.017*"f2(x" + 0.012*"question" + 0.012*"f" + 0.012*"def" + 0.012*"arg" + 0.012*"f2"
INFO: topic #1 (0.237): 0.094*"parameter" + 0.093*"argument" + 0.064*"function" + 0.041*"value" + 0.028*"variable" + 0.027*"method" + 0.024*"actual" + 0.020*"formal" + 0.016*"definition" + 0.016*"name"
INFO: topic #2 (0.057): 0.017*"c." + 0.010*"z" + 0.010*"thesis" + 0.010*"community" + 0.010*"convention" + 0.010*"alternative" + 0.010*"view" + 0.010*"sqrt" + 0.010*"inside" + 0.010*"prototype"
INFO: topic #3 (0.136): 0.113*"function" + 0.103*"parameter" + 0.091*"argument" + 0.045*"value" + 0.035*"definition" + 0.028*"b" + 0.027*"call" + 0.023*"name" + 0.022*"type" + 0.021*"example"
INFO: topic #4 (0.071): 0.030*"part" + 0.026*"message" + 0.018*"signature" + 0.016*"code" + 0.014*"function" + 0.014*"self" + 0.014*"dot" + 0.014*"similar" + 0.014*"second" + 0.014*"notation"
INFO: topic diff=0.259284, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.170 per-word bound, 36.0 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.06986188, 0.24780723, 0.055442747, 0.14775112, 0.06651345]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.070): 0.101*"default" + 0.043*"positional" + 0.029*"keyword" + 0.023*"f2(x" + 0.023*"non" + 0.016*"question" + 0.016*"f" + 0.016*"arg" + 0.016*"def" + 0.016*"error"
INFO: topic #1 (0.248): 0.098*"parameter" + 0.095*"argument" + 0.063*"function" + 0.039*"value" + 0.028*"method" + 0.026*"variable" + 0.025*"actual" + 0.021*"formal" + 0.016*"definition" + 0.014*"name"
INFO: topic #2 (0.055): 0.028*"c." + 0.015*"z" + 0.015*"thesis" + 0.015*"community" + 0.015*"convention" + 0.015*"alternative" + 0.015*"view" + 0.015*"sqrt" + 0.015*"inside" + 0.015*"prototype"
INFO: topic #3 (0.148): 0.121*"function" + 0.102*"parameter" + 0.096*"argument" + 0.063*"value" + 0.050*"definition" + 0.043*"b" + 0.038*"call" + 0.030*"name" + 0.029*"key" + 0.025*"case"
INFO: topic #4 (0.067): 0.025*"part" + 0.018*"signature" + 0.017*"message" + 0.015*"f" + 0.013*"code" + 0.010*"function" + 0.009*"self" + 0.009*"dot" + 0.009*"similar" + 0.009*"second"
INFO: topic diff=0.242087, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.077 per-word bound, 33.7 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.056158476, 0.21812358, 0.046789847, 0.124691665, 0.060630683]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.056): 0.076*"default" + 0.033*"positional" + 0.023*"keyword" + 0.018*"f2(x" + 0.018*"non" + 0.013*"question" + 0.013*"f" + 0.013*"arg" + 0.013*"def" + 0.012*"error"
INFO: topic #1 (0.218): 0.095*"parameter" + 0.093*"argument" + 0.064*"function" + 0.040*"value" + 0.028*"variable" + 0.027*"method" + 0.024*"actual" + 0.020*"formal" + 0.016*"definition" + 0.015*"name"
INFO: topic #2 (0.047): 0.019*"c." + 0.010*"z" + 0.010*"thesis" + 0.010*"community" + 0.010*"convention" + 0.010*"alternative" + 0.010*"view" + 0.010*"sqrt" + 0.010*"inside" + 0.010*"prototype"
INFO: topic #3 (0.125): 0.118*"function" + 0.101*"parameter" + 0.091*"argument" + 0.048*"value" + 0.038*"definition" + 0.031*"b" + 0.030*"call" + 0.024*"name" + 0.022*"type" + 0.020*"example"
INFO: topic #4 (0.061): 0.031*"part" + 0.026*"message" + 0.018*"signature" + 0.015*"code" + 0.014*"self" + 0.014*"dot" + 0.014*"similar" + 0.014*"second" + 0.014*"notation" + 0.014*"index"
INFO: topic diff=0.191958, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.133 per-word bound, 35.1 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.06039139, 0.22825131, 0.04640797, 0.13424255, 0.057961952]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.060): 0.100*"default" + 0.043*"positional" + 0.030*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"question" + 0.016*"f" + 0.016*"def" + 0.016*"arg" + 0.016*"f2"
INFO: topic #1 (0.228): 0.098*"parameter" + 0.095*"argument" + 0.063*"function" + 0.039*"value" + 0.028*"method" + 0.026*"variable" + 0.025*"actual" + 0.021*"formal" + 0.016*"definition" + 0.014*"name"
INFO: topic #2 (0.046): 0.028*"c." + 0.015*"prototype" + 0.015*"arguments" + 0.015*"text" + 0.015*"sqrt" + 0.015*"view" + 0.015*"alternative" + 0.015*"community" + 0.015*"inside" + 0.015*"convention"
INFO: topic #3 (0.134): 0.124*"function" + 0.102*"parameter" + 0.096*"argument" + 0.064*"value" + 0.051*"definition" + 0.043*"b" + 0.039*"call" + 0.030*"name" + 0.030*"key" + 0.026*"case"
INFO: topic #4 (0.058): 0.025*"part" + 0.018*"signature" + 0.017*"message" + 0.015*"f" + 0.013*"code" + 0.010*"self" + 0.010*"dot" + 0.010*"similar" + 0.010*"second" + 0.010*"notation"
INFO: topic diff=0.192389, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.066 per-word bound, 33.5 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.050585017, 0.20421843, 0.04060445, 0.11690613, 0.054091744]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.051): 0.078*"default" + 0.033*"positional" + 0.023*"keyword" + 0.018*"non" + 0.018*"f2(x" + 0.013*"question" + 0.013*"f" + 0.013*"arg" + 0.013*"def" + 0.013*"p"
INFO: topic #1 (0.204): 0.096*"parameter" + 0.093*"argument" + 0.063*"function" + 0.040*"value" + 0.028*"variable" + 0.027*"method" + 0.024*"actual" + 0.020*"formal" + 0.016*"definition" + 0.015*"name"
INFO: topic #2 (0.041): 0.019*"c." + 0.011*"view" + 0.011*"text" + 0.011*"community" + 0.011*"z" + 0.011*"alternative" + 0.011*"thesis" + 0.011*"prototype" + 0.011*"convention" + 0.011*"opposite"
INFO: topic #3 (0.117): 0.120*"function" + 0.101*"parameter" + 0.091*"argument" + 0.050*"value" + 0.039*"definition" + 0.032*"b" + 0.031*"call" + 0.025*"name" + 0.022*"type" + 0.021*"key"
INFO: topic #4 (0.054): 0.031*"part" + 0.026*"message" + 0.018*"signature" + 0.015*"code" + 0.014*"self" + 0.014*"dot" + 0.014*"similar" + 0.014*"second" + 0.014*"notation" + 0.014*"index"
INFO: topic diff=0.165034, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.113 per-word bound, 34.6 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0541842, 0.21093525, 0.040526826, 0.11488304, 0.05216533]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.054): 0.099*"default" + 0.043*"positional" + 0.030*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"question" + 0.016*"f" + 0.016*"def" + 0.016*"arg" + 0.016*"error"
INFO: topic #1 (0.211): 0.099*"parameter" + 0.095*"argument" + 0.063*"function" + 0.039*"value" + 0.028*"method" + 0.026*"variable" + 0.025*"actual" + 0.021*"formal" + 0.016*"definition" + 0.014*"name"
INFO: topic #2 (0.041): 0.027*"c." + 0.015*"z" + 0.015*"thesis" + 0.015*"community" + 0.015*"convention" + 0.015*"alternative" + 0.015*"view" + 0.015*"sqrt" + 0.015*"inside" + 0.015*"prototype"
INFO: topic #3 (0.115): 0.125*"function" + 0.101*"parameter" + 0.096*"argument" + 0.064*"value" + 0.051*"definition" + 0.043*"b" + 0.039*"call" + 0.031*"name" + 0.030*"key" + 0.026*"case"
INFO: topic #4 (0.052): 0.026*"part" + 0.018*"message" + 0.017*"signature" + 0.015*"f" + 0.013*"code" + 0.010*"self" + 0.010*"dot" + 0.010*"similar" + 0.010*"second" + 0.010*"notation"
INFO: topic diff=0.166089, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.059 per-word bound, 33.3 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.04654701, 0.19116454, 0.03624621, 0.10418051, 0.049369678]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.047): 0.078*"default" + 0.034*"positional" + 0.024*"keyword" + 0.019*"non" + 0.019*"f2(x" + 0.013*"question" + 0.013*"f" + 0.013*"def" + 0.013*"arg" + 0.013*"f2"
INFO: topic #1 (0.191): 0.096*"parameter" + 0.093*"argument" + 0.064*"function" + 0.040*"value" + 0.028*"variable" + 0.027*"method" + 0.024*"actual" + 0.020*"formal" + 0.016*"definition" + 0.015*"name"
INFO: topic #2 (0.036): 0.020*"c." + 0.011*"prototype" + 0.011*"arguments" + 0.011*"text" + 0.011*"sqrt" + 0.011*"view" + 0.011*"alternative" + 0.011*"community" + 0.011*"inside" + 0.011*"convention"
INFO: topic #3 (0.104): 0.121*"function" + 0.101*"parameter" + 0.091*"argument" + 0.051*"value" + 0.040*"definition" + 0.033*"b" + 0.031*"call" + 0.025*"name" + 0.022*"type" + 0.021*"key"
INFO: topic #4 (0.049): 0.031*"part" + 0.026*"message" + 0.018*"signature" + 0.015*"code" + 0.014*"self" + 0.014*"similar" + 0.014*"dot" + 0.014*"second" + 0.014*"notation" + 0.014*"index"
INFO: topic diff=0.151009, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.097 per-word bound, 34.2 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.049793612, 0.1978716, 0.03638289, 0.10360787, 0.048021026]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.050): 0.098*"default" + 0.043*"positional" + 0.030*"keyword" + 0.023*"f2(x" + 0.023*"non" + 0.016*"question" + 0.016*"f" + 0.016*"def" + 0.016*"arg" + 0.016*"error"
INFO: topic #1 (0.198): 0.099*"parameter" + 0.095*"argument" + 0.063*"function" + 0.039*"value" + 0.028*"method" + 0.026*"variable" + 0.025*"actual" + 0.021*"formal" + 0.016*"definition" + 0.014*"name"
INFO: topic #2 (0.036): 0.027*"c." + 0.015*"view" + 0.015*"text" + 0.015*"community" + 0.015*"z" + 0.015*"alternative" + 0.015*"thesis" + 0.015*"opposite" + 0.015*"prototype" + 0.015*"inside"
INFO: topic #3 (0.104): 0.125*"function" + 0.101*"parameter" + 0.096*"argument" + 0.064*"value" + 0.051*"definition" + 0.043*"b" + 0.039*"call" + 0.030*"name" + 0.030*"key" + 0.026*"case"
INFO: topic #4 (0.048): 0.026*"part" + 0.018*"message" + 0.017*"signature" + 0.015*"f" + 0.013*"code" + 0.010*"similar" + 0.010*"dot" + 0.010*"self" + 0.010*"second" + 0.010*"notation"
INFO: topic diff=0.147561, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.054 per-word bound, 33.2 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.043548465, 0.18126298, 0.033042938, 0.09604359, 0.0458906]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.044): 0.079*"default" + 0.035*"positional" + 0.025*"keyword" + 0.019*"f2(x" + 0.019*"non" + 0.013*"question" + 0.013*"f" + 0.013*"def" + 0.013*"arg" + 0.013*"error"
INFO: topic #1 (0.181): 0.096*"parameter" + 0.093*"argument" + 0.064*"function" + 0.040*"value" + 0.028*"variable" + 0.027*"method" + 0.025*"actual" + 0.020*"formal" + 0.016*"definition" + 0.015*"name"
INFO: topic #2 (0.033): 0.020*"c." + 0.011*"view" + 0.011*"prototype" + 0.011*"opposite" + 0.011*"inside" + 0.011*"convention" + 0.011*"community" + 0.011*"arguments" + 0.011*"alternative" + 0.011*"sqrt"
INFO: topic #3 (0.096): 0.122*"function" + 0.101*"parameter" + 0.092*"argument" + 0.051*"value" + 0.040*"definition" + 0.033*"b" + 0.032*"call" + 0.026*"name" + 0.022*"type" + 0.022*"key"
INFO: topic #4 (0.046): 0.030*"part" + 0.026*"message" + 0.018*"signature" + 0.015*"code" + 0.014*"self" + 0.014*"dot" + 0.014*"similar" + 0.014*"second" + 0.014*"notation" + 0.014*"index"
INFO: topic diff=0.139964, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.089 per-word bound, 34.0 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.046513543, 0.18785755, 0.033292737, 0.09614831, 0.04490586]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.047): 0.097*"default" + 0.043*"positional" + 0.030*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"question" + 0.016*"f" + 0.016*"def" + 0.016*"arg" + 0.016*"f2"
INFO: topic #1 (0.188): 0.099*"parameter" + 0.095*"argument" + 0.063*"function" + 0.039*"value" + 0.028*"method" + 0.026*"variable" + 0.025*"actual" + 0.021*"formal" + 0.016*"definition" + 0.014*"name"
INFO: topic #2 (0.033): 0.027*"c." + 0.014*"prototype" + 0.014*"text" + 0.014*"alternative" + 0.014*"community" + 0.014*"sqrt" + 0.014*"arguments" + 0.014*"convention" + 0.014*"inside" + 0.014*"opposite"
INFO: topic #3 (0.096): 0.125*"function" + 0.101*"parameter" + 0.096*"argument" + 0.063*"value" + 0.051*"definition" + 0.043*"b" + 0.039*"call" + 0.030*"name" + 0.029*"key" + 0.026*"case"
INFO: topic #4 (0.045): 0.026*"part" + 0.019*"message" + 0.017*"signature" + 0.015*"f" + 0.013*"code" + 0.010*"self" + 0.010*"second" + 0.010*"dot" + 0.010*"similar" + 0.010*"index"
INFO: topic diff=0.135148, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.050 per-word bound, 33.1 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.041230343, 0.17358312, 0.030581748, 0.090362206, 0.043218244]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.041): 0.080*"default" + 0.036*"positional" + 0.025*"keyword" + 0.019*"non" + 0.019*"f2(x" + 0.014*"question" + 0.014*"f" + 0.013*"arg" + 0.013*"def" + 0.013*"p"
INFO: topic #1 (0.174): 0.096*"parameter" + 0.093*"argument" + 0.064*"function" + 0.040*"value" + 0.028*"variable" + 0.027*"method" + 0.025*"actual" + 0.020*"formal" + 0.016*"definition" + 0.015*"name"
INFO: topic #2 (0.031): 0.020*"c." + 0.011*"inside" + 0.011*"prototype" + 0.011*"community" + 0.011*"convention" + 0.011*"alternative" + 0.011*"opposite" + 0.011*"thesis" + 0.011*"text" + 0.011*"view"
INFO: topic #3 (0.090): 0.122*"function" + 0.101*"parameter" + 0.092*"argument" + 0.052*"value" + 0.041*"definition" + 0.033*"b" + 0.032*"call" + 0.026*"name" + 0.022*"key" + 0.022*"type"
INFO: topic #4 (0.043): 0.030*"part" + 0.026*"message" + 0.018*"signature" + 0.015*"code" + 0.014*"self" + 0.014*"dot" + 0.014*"similar" + 0.014*"second" + 0.014*"notation" + 0.014*"index"
INFO: topic diff=0.130607, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.083 per-word bound, 33.9 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.043966368, 0.18001589, 0.030893434, 0.09082092, 0.042477254]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.044): 0.097*"default" + 0.044*"positional" + 0.030*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"question" + 0.016*"f" + 0.016*"arg" + 0.016*"def" + 0.016*"p"
INFO: topic #1 (0.180): 0.098*"parameter" + 0.095*"argument" + 0.063*"function" + 0.039*"value" + 0.028*"method" + 0.026*"variable" + 0.025*"actual" + 0.021*"formal" + 0.016*"definition" + 0.014*"name"
INFO: topic #2 (0.031): 0.027*"c." + 0.014*"inside" + 0.014*"opposite" + 0.014*"arguments" + 0.014*"community" + 0.014*"convention" + 0.014*"alternative" + 0.014*"z" + 0.014*"view" + 0.014*"sqrt"
INFO: topic #3 (0.091): 0.126*"function" + 0.101*"parameter" + 0.096*"argument" + 0.063*"value" + 0.050*"definition" + 0.043*"b" + 0.039*"call" + 0.030*"name" + 0.029*"key" + 0.025*"case"
INFO: topic #4 (0.042): 0.026*"part" + 0.019*"message" + 0.017*"signature" + 0.015*"f" + 0.013*"code" + 0.011*"similar" + 0.011*"second" + 0.011*"self" + 0.011*"dot" + 0.011*"index"
INFO: topic diff=0.125890, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.046 per-word bound, 33.0 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.039383452, 0.16747646, 0.028627347, 0.08615785, 0.041100185]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.039): 0.081*"default" + 0.036*"positional" + 0.025*"keyword" + 0.019*"non" + 0.019*"f2(x" + 0.014*"question" + 0.014*"f" + 0.014*"arg" + 0.014*"def" + 0.014*"error"
INFO: topic #1 (0.167): 0.096*"parameter" + 0.093*"argument" + 0.064*"function" + 0.040*"value" + 0.028*"variable" + 0.027*"method" + 0.025*"actual" + 0.020*"formal" + 0.016*"definition" + 0.015*"name"
INFO: topic #2 (0.029): 0.020*"c." + 0.011*"alternative" + 0.011*"text" + 0.011*"sqrt" + 0.011*"prototype" + 0.011*"opposite" + 0.011*"inside" + 0.011*"convention" + 0.011*"community" + 0.011*"arguments"
INFO: topic #3 (0.086): 0.122*"function" + 0.101*"parameter" + 0.092*"argument" + 0.052*"value" + 0.041*"definition" + 0.034*"b" + 0.032*"call" + 0.026*"name" + 0.022*"key" + 0.021*"type"
INFO: topic #4 (0.041): 0.030*"part" + 0.025*"message" + 0.018*"signature" + 0.015*"code" + 0.014*"second" + 0.014*"dot" + 0.014*"self" + 0.014*"similar" + 0.014*"index" + 0.014*"notation"
INFO: topic diff=0.122737, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.078 per-word bound, 33.8 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.04192951, 0.17371656, 0.028972836, 0.0868131, 0.04052997]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.042): 0.097*"default" + 0.044*"positional" + 0.030*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"question" + 0.016*"f" + 0.016*"def" + 0.016*"arg" + 0.016*"error"
INFO: topic #1 (0.174): 0.098*"parameter" + 0.095*"argument" + 0.063*"function" + 0.039*"value" + 0.028*"method" + 0.026*"variable" + 0.025*"actual" + 0.021*"formal" + 0.016*"definition" + 0.014*"name"
INFO: topic #2 (0.029): 0.026*"c." + 0.014*"community" + 0.014*"opposite" + 0.014*"prototype" + 0.014*"inside" + 0.014*"convention" + 0.014*"sqrt" + 0.014*"view" + 0.014*"alternative" + 0.014*"z"
INFO: topic #3 (0.087): 0.126*"function" + 0.101*"parameter" + 0.095*"argument" + 0.063*"value" + 0.050*"definition" + 0.042*"b" + 0.039*"call" + 0.030*"name" + 0.029*"key" + 0.025*"case"
INFO: topic #4 (0.041): 0.026*"part" + 0.019*"message" + 0.017*"signature" + 0.015*"f" + 0.013*"code" + 0.011*"self" + 0.011*"second" + 0.011*"similar" + 0.011*"dot" + 0.011*"index"
INFO: topic diff=0.118525, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.044 per-word bound, 33.0 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.037877187, 0.16251665, 0.027035285, 0.08291471, 0.03937992]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.038): 0.081*"default" + 0.037*"positional" + 0.026*"keyword" + 0.020*"non" + 0.020*"f2(x" + 0.014*"question" + 0.014*"f" + 0.014*"def" + 0.014*"arg" + 0.014*"p"
INFO: topic #1 (0.163): 0.096*"parameter" + 0.093*"argument" + 0.064*"function" + 0.040*"value" + 0.028*"variable" + 0.027*"method" + 0.025*"actual" + 0.020*"formal" + 0.016*"definition" + 0.015*"name"
INFO: topic #2 (0.027): 0.020*"c." + 0.011*"inside" + 0.011*"opposite" + 0.011*"arguments" + 0.011*"community" + 0.011*"convention" + 0.011*"alternative" + 0.011*"z" + 0.011*"view" + 0.011*"sqrt"
INFO: topic #3 (0.083): 0.122*"function" + 0.101*"parameter" + 0.092*"argument" + 0.052*"value" + 0.041*"definition" + 0.034*"b" + 0.032*"call" + 0.026*"name" + 0.022*"key" + 0.021*"type"
INFO: topic #4 (0.039): 0.030*"part" + 0.025*"message" + 0.018*"signature" + 0.015*"code" + 0.014*"dot" + 0.014*"similar" + 0.014*"self" + 0.014*"notation" + 0.014*"index" + 0.014*"second"
INFO: topic diff=0.116066, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.073 per-word bound, 33.7 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.0402632, 0.16855405, 0.02739844, 0.08368297, 0.038933787]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.040): 0.097*"default" + 0.044*"positional" + 0.030*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"question" + 0.016*"f" + 0.016*"def" + 0.016*"arg" + 0.016*"error"
INFO: topic #1 (0.169): 0.098*"parameter" + 0.094*"argument" + 0.063*"function" + 0.039*"value" + 0.028*"method" + 0.026*"variable" + 0.025*"actual" + 0.021*"formal" + 0.016*"definition" + 0.014*"name"
INFO: topic #2 (0.027): 0.026*"c." + 0.014*"arguments" + 0.014*"thesis" + 0.014*"text" + 0.014*"sqrt" + 0.014*"prototype" + 0.014*"opposite" + 0.014*"inside" + 0.014*"convention" + 0.014*"community"
INFO: topic #3 (0.084): 0.126*"function" + 0.102*"parameter" + 0.095*"argument" + 0.063*"value" + 0.050*"definition" + 0.042*"b" + 0.038*"call" + 0.030*"name" + 0.029*"key" + 0.025*"case"
INFO: topic #4 (0.039): 0.027*"part" + 0.019*"message" + 0.017*"signature" + 0.014*"f" + 0.013*"code" + 0.011*"self" + 0.011*"notation" + 0.011*"similar" + 0.011*"index" + 0.011*"dot"
INFO: topic diff=0.112432, rho=0.288675
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=397, num_topics=5, decay=0.5, chunksize=5> in 0.19s', 'datetime': '2023-04-25T15:14:05.605206', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 5 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.011 per-word bound, 129.0 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
WARNING: updated prior is not positive
INFO: optimized alpha [0.2, 0.2, 0.2, 0.2, 0.2]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.200): 0.096*"parameter" + 0.090*"argument" + 0.079*"function" + 0.040*"value" + 0.027*"variable" + 0.023*"method" + 0.023*"actual" + 0.017*"name" + 0.016*"type" + 0.016*"definition"
INFO: topic #1 (0.200): 0.003*"function" + 0.003*"parameter" + 0.003*"argument" + 0.003*"value" + 0.003*"variable" + 0.003*"type" + 0.003*"program" + 0.003*"message" + 0.003*"object" + 0.003*"part"
INFO: topic #2 (0.200): 0.065*"program" + 0.039*"output" + 0.039*"address" + 0.039*"c++" + 0.027*"function" + 0.027*"variable" + 0.027*"object" + 0.027*"int" + 0.027*"separate" + 0.027*"copy"
INFO: topic #3 (0.200): 0.003*"parameter" + 0.003*"argument" + 0.003*"function" + 0.003*"program" + 0.003*"variable" + 0.003*"value" + 0.003*"type" + 0.003*"object" + 0.003*"part" + 0.003*"c++"
INFO: topic #4 (0.200): 0.095*"argument" + 0.094*"parameter" + 0.041*"function" + 0.034*"value" + 0.025*"formal" + 0.023*"method" + 0.020*"actual" + 0.019*"variable" + 0.016*"term" + 0.015*"call"
INFO: topic diff=2.770252, rho=1.000000
DEBUG: bound: at document #0
INFO: -6.758 per-word bound, 108.2 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.26984465, 0.120011896, 0.15139578, 0.12819731, 0.16306287]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.270): 0.103*"parameter" + 0.098*"argument" + 0.098*"function" + 0.054*"value" + 0.033*"definition" + 0.026*"call" + 0.026*"variable" + 0.023*"name" + 0.022*"b" + 0.019*"actual"
INFO: topic #1 (0.120): 0.026*"f" + 0.026*"question" + 0.014*"def" + 0.014*"arg" + 0.014*"big" + 0.014*"fun(arg" + 0.014*"distinguishing" + 0.014*"look" + 0.014*"n’t" + 0.014*"min"
INFO: topic #2 (0.151): 0.060*"program" + 0.024*"c++" + 0.019*"function" + 0.016*"output" + 0.016*"address" + 0.014*"c." + 0.013*"declaration" + 0.011*"variable" + 0.011*"object" + 0.011*"int"
INFO: topic #3 (0.128): 0.123*"default" + 0.050*"positional" + 0.034*"keyword" + 0.026*"non" + 0.026*"f2(x" + 0.018*"p" + 0.018*"error" + 0.018*"f2" + 0.009*"def" + 0.009*"arg"
INFO: topic #4 (0.163): 0.090*"parameter" + 0.087*"argument" + 0.036*"function" + 0.028*"formal" + 0.027*"value" + 0.025*"method" + 0.020*"actual" + 0.017*"definition" + 0.013*"term" + 0.012*"variable"
INFO: topic diff=0.802251, rho=0.707107
DEBUG: bound: at document #0
INFO: -5.225 per-word bound, 37.4 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.33042854, 0.07648763, 0.10634071, 0.07865963, 0.084324405]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.330): 0.100*"parameter" + 0.096*"argument" + 0.080*"function" + 0.044*"value" + 0.026*"variable" + 0.022*"method" + 0.022*"actual" + 0.021*"definition" + 0.019*"call" + 0.019*"name"
INFO: topic #1 (0.076): 0.015*"f" + 0.015*"question" + 0.009*"def" + 0.009*"arg" + 0.009*"big" + 0.009*"fun(arg" + 0.009*"distinguishing" + 0.009*"look" + 0.009*"n’t" + 0.009*"min"
INFO: topic #2 (0.106): 0.064*"program" + 0.033*"c++" + 0.030*"address" + 0.030*"output" + 0.020*"separate" + 0.020*"equivalent" + 0.020*"copy" + 0.020*"int" + 0.020*"object" + 0.019*"function"
INFO: topic #3 (0.079): 0.081*"default" + 0.034*"positional" + 0.023*"keyword" + 0.018*"non" + 0.018*"f2(x" + 0.012*"p" + 0.012*"error" + 0.012*"f2" + 0.007*"def" + 0.007*"arg"
INFO: topic #4 (0.084): 0.071*"parameter" + 0.069*"argument" + 0.029*"function" + 0.022*"formal" + 0.022*"value" + 0.020*"method" + 0.016*"actual" + 0.014*"definition" + 0.010*"term" + 0.010*"variable"
INFO: topic diff=0.367530, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.258 per-word bound, 38.3 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.38275173, 0.07213279, 0.104786865, 0.074722886, 0.07766443]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.383): 0.107*"parameter" + 0.102*"argument" + 0.092*"function" + 0.052*"value" + 0.030*"definition" + 0.025*"variable" + 0.024*"call" + 0.021*"name" + 0.021*"actual" + 0.020*"method"
INFO: topic #1 (0.072): 0.028*"question" + 0.027*"f" + 0.015*"look" + 0.015*"fun(arg" + 0.015*"correct" + 0.015*"big" + 0.015*"distinguishing" + 0.015*"n’t" + 0.015*"print(arg" + 0.015*"min"
INFO: topic #2 (0.105): 0.058*"program" + 0.025*"c++" + 0.020*"c." + 0.017*"address" + 0.017*"output" + 0.014*"function" + 0.014*"declaration" + 0.012*"separate" + 0.012*"equivalent" + 0.012*"copy"
INFO: topic #3 (0.075): 0.126*"default" + 0.051*"positional" + 0.035*"keyword" + 0.026*"f2(x" + 0.026*"non" + 0.018*"f2" + 0.018*"p" + 0.018*"error" + 0.010*"f3(b=100" + 0.010*"f3"
INFO: topic #4 (0.078): 0.054*"parameter" + 0.053*"argument" + 0.028*"method" + 0.020*"function" + 0.017*"definition" + 0.015*"formal" + 0.015*"value" + 0.013*"instance" + 0.012*"runtime" + 0.012*"actual"
INFO: topic diff=0.291495, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.103 per-word bound, 34.4 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.44517443, 0.058850616, 0.0900193, 0.06047731, 0.062284976]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.445): 0.102*"parameter" + 0.097*"argument" + 0.080*"function" + 0.044*"value" + 0.026*"variable" + 0.022*"method" + 0.022*"actual" + 0.021*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #1 (0.059): 0.018*"question" + 0.017*"f" + 0.010*"look" + 0.010*"fun(arg" + 0.010*"correct" + 0.010*"big" + 0.010*"distinguishing" + 0.010*"n’t" + 0.010*"print(arg" + 0.010*"min"
INFO: topic #2 (0.090): 0.063*"program" + 0.033*"c++" + 0.029*"address" + 0.029*"output" + 0.020*"separate" + 0.020*"equivalent" + 0.020*"copy" + 0.020*"int" + 0.019*"object" + 0.014*"variable"
INFO: topic #3 (0.060): 0.089*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"f2(x" + 0.019*"non" + 0.013*"f2" + 0.013*"p" + 0.013*"error" + 0.008*"f3(b=100" + 0.008*"f3"
INFO: topic #4 (0.062): 0.038*"parameter" + 0.037*"argument" + 0.020*"method" + 0.014*"function" + 0.012*"definition" + 0.011*"formal" + 0.011*"value" + 0.010*"instance" + 0.009*"runtime" + 0.009*"actual"
INFO: topic diff=0.252940, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.154 per-word bound, 35.6 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.55566883, 0.058659814, 0.09353169, 0.060600374, 0.06107953]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.556): 0.107*"parameter" + 0.102*"argument" + 0.089*"function" + 0.051*"value" + 0.029*"definition" + 0.025*"variable" + 0.023*"call" + 0.021*"actual" + 0.021*"method" + 0.021*"name"
INFO: topic #1 (0.059): 0.028*"question" + 0.027*"f" + 0.015*"look" + 0.015*"fun(arg" + 0.015*"correct" + 0.015*"big" + 0.015*"distinguishing" + 0.015*"n’t" + 0.015*"print(arg" + 0.015*"min"
INFO: topic #2 (0.094): 0.058*"program" + 0.026*"c++" + 0.021*"c." + 0.018*"address" + 0.018*"output" + 0.014*"declaration" + 0.012*"separate" + 0.012*"equivalent" + 0.012*"copy" + 0.012*"int"
INFO: topic #3 (0.061): 0.125*"default" + 0.051*"positional" + 0.035*"keyword" + 0.026*"f2(x" + 0.026*"non" + 0.018*"f2" + 0.018*"p" + 0.018*"error" + 0.010*"f3(b=100" + 0.010*"f3"
INFO: topic #4 (0.061): 0.026*"parameter" + 0.025*"argument" + 0.018*"method" + 0.013*"runtime" + 0.013*"instance" + 0.010*"definition" + 0.010*"function" + 0.008*"formal" + 0.008*"value" + 0.006*"actual"
INFO: topic diff=0.206771, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.069 per-word bound, 33.6 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.6081352, 0.051128216, 0.08483741, 0.052564904, 0.05291718]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.608): 0.102*"parameter" + 0.098*"argument" + 0.080*"function" + 0.044*"value" + 0.026*"variable" + 0.022*"method" + 0.022*"actual" + 0.022*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #1 (0.051): 0.019*"question" + 0.018*"f" + 0.011*"distinguishing" + 0.011*"look" + 0.011*"min" + 0.011*"correct" + 0.011*"big" + 0.011*"print(arg" + 0.011*"fun(arg" + 0.011*"n’t"
INFO: topic #2 (0.085): 0.063*"program" + 0.033*"c++" + 0.028*"address" + 0.028*"output" + 0.019*"separate" + 0.019*"equivalent" + 0.019*"copy" + 0.019*"int" + 0.019*"object" + 0.014*"declaration"
INFO: topic #3 (0.053): 0.093*"default" + 0.038*"positional" + 0.026*"keyword" + 0.020*"f2(x" + 0.020*"non" + 0.014*"p" + 0.014*"f2" + 0.014*"error" + 0.008*"associated" + 0.008*"f3(b=100"
INFO: topic #4 (0.053): 0.017*"parameter" + 0.017*"argument" + 0.012*"method" + 0.010*"runtime" + 0.009*"instance" + 0.007*"definition" + 0.007*"function" + 0.006*"formal" + 0.006*"value" + 0.005*"actual"
INFO: topic diff=0.189979, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.115 per-word bound, 34.7 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.737624, 0.051860888, 0.089320324, 0.053546283, 0.048543423]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.738): 0.107*"parameter" + 0.102*"argument" + 0.088*"function" + 0.050*"value" + 0.029*"definition" + 0.025*"variable" + 0.023*"call" + 0.022*"method" + 0.021*"actual" + 0.021*"name"
INFO: topic #1 (0.052): 0.028*"question" + 0.026*"f" + 0.015*"min" + 0.015*"correct" + 0.015*"look" + 0.015*"distinguishing" + 0.015*"n’t" + 0.015*"print(arg" + 0.015*"fun(arg" + 0.015*"big"
INFO: topic #2 (0.089): 0.059*"program" + 0.026*"c++" + 0.021*"c." + 0.018*"address" + 0.018*"output" + 0.014*"declaration" + 0.013*"separate" + 0.013*"equivalent" + 0.013*"copy" + 0.013*"int"
INFO: topic #3 (0.054): 0.125*"default" + 0.051*"positional" + 0.034*"keyword" + 0.026*"f2(x" + 0.026*"non" + 0.018*"f2" + 0.018*"p" + 0.018*"error" + 0.010*"f3(b=100" + 0.010*"f3"
INFO: topic #4 (0.049): 0.012*"parameter" + 0.012*"argument" + 0.009*"method" + 0.007*"runtime" + 0.007*"instance" + 0.005*"definition" + 0.005*"function" + 0.005*"formal" + 0.005*"value" + 0.004*"actual"
INFO: topic diff=0.164901, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.053 per-word bound, 33.2 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.7572008, 0.046576034, 0.08276801, 0.04791382, 0.0439108]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.757): 0.103*"parameter" + 0.098*"argument" + 0.080*"function" + 0.045*"value" + 0.026*"variable" + 0.023*"method" + 0.022*"actual" + 0.022*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #1 (0.047): 0.020*"question" + 0.019*"f" + 0.011*"min" + 0.011*"correct" + 0.011*"look" + 0.011*"distinguishing" + 0.011*"n’t" + 0.011*"print(arg" + 0.011*"fun(arg" + 0.011*"big"
INFO: topic #2 (0.083): 0.064*"program" + 0.033*"c++" + 0.028*"address" + 0.028*"output" + 0.019*"separate" + 0.019*"equivalent" + 0.019*"copy" + 0.019*"int" + 0.018*"object" + 0.014*"declaration"
INFO: topic #3 (0.048): 0.096*"default" + 0.039*"positional" + 0.027*"keyword" + 0.020*"f2(x" + 0.020*"non" + 0.014*"f2" + 0.014*"p" + 0.014*"error" + 0.008*"f3(b=100" + 0.008*"f3"
INFO: topic #4 (0.044): 0.008*"parameter" + 0.008*"argument" + 0.006*"method" + 0.005*"runtime" + 0.005*"instance" + 0.004*"definition" + 0.004*"function" + 0.004*"formal" + 0.004*"value" + 0.003*"actual"
INFO: topic diff=0.156556, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.096 per-word bound, 34.2 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.88553447, 0.047581635, 0.08741274, 0.049126226, 0.041233372]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.886): 0.107*"parameter" + 0.102*"argument" + 0.088*"function" + 0.050*"value" + 0.028*"definition" + 0.025*"variable" + 0.023*"call" + 0.022*"method" + 0.021*"actual" + 0.020*"name"
INFO: topic #1 (0.048): 0.028*"question" + 0.026*"f" + 0.015*"distinguishing" + 0.015*"look" + 0.015*"min" + 0.015*"correct" + 0.015*"big" + 0.015*"print(arg" + 0.015*"fun(arg" + 0.015*"n’t"
INFO: topic #2 (0.087): 0.060*"program" + 0.027*"c++" + 0.021*"c." + 0.019*"address" + 0.019*"output" + 0.014*"declaration" + 0.013*"separate" + 0.013*"equivalent" + 0.013*"copy" + 0.013*"int"
INFO: topic #3 (0.049): 0.124*"default" + 0.050*"positional" + 0.034*"keyword" + 0.026*"f2(x" + 0.026*"non" + 0.018*"f2" + 0.018*"p" + 0.018*"error" + 0.009*"f3(b=100" + 0.009*"f3"
INFO: topic #4 (0.041): 0.006*"parameter" + 0.006*"argument" + 0.005*"method" + 0.004*"runtime" + 0.004*"instance" + 0.004*"definition" + 0.004*"function" + 0.003*"formal" + 0.003*"value" + 0.003*"actual"
INFO: topic diff=0.142620, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.045 per-word bound, 33.0 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.8603877, 0.04344984, 0.08177225, 0.044722795, 0.038127933]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.860): 0.103*"parameter" + 0.098*"argument" + 0.080*"function" + 0.045*"value" + 0.026*"variable" + 0.023*"method" + 0.022*"actual" + 0.022*"definition" + 0.019*"call" + 0.018*"name"
INFO: topic #1 (0.043): 0.020*"question" + 0.019*"f" + 0.011*"big" + 0.011*"print(arg" + 0.011*"min" + 0.011*"look" + 0.011*"fun(arg" + 0.011*"distinguishing" + 0.011*"correct" + 0.011*"n’t"
INFO: topic #2 (0.082): 0.064*"program" + 0.033*"c++" + 0.028*"address" + 0.028*"output" + 0.019*"separate" + 0.019*"equivalent" + 0.019*"copy" + 0.019*"int" + 0.018*"object" + 0.014*"declaration"
INFO: topic #3 (0.045): 0.097*"default" + 0.040*"positional" + 0.027*"keyword" + 0.021*"f2(x" + 0.021*"non" + 0.014*"f2" + 0.014*"p" + 0.014*"error" + 0.008*"f3(b=100" + 0.008*"f3"
INFO: topic #4 (0.038): 0.005*"parameter" + 0.005*"argument" + 0.004*"method" + 0.004*"runtime" + 0.004*"instance" + 0.003*"definition" + 0.003*"function" + 0.003*"formal" + 0.003*"value" + 0.003*"actual"
INFO: topic diff=0.136395, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.086 per-word bound, 34.0 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.9775111, 0.04451476, 0.086282976, 0.045964196, 0.036268882]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.978): 0.107*"parameter" + 0.102*"argument" + 0.087*"function" + 0.050*"value" + 0.028*"definition" + 0.025*"variable" + 0.022*"call" + 0.022*"method" + 0.021*"actual" + 0.020*"name"
INFO: topic #1 (0.045): 0.027*"question" + 0.026*"f" + 0.015*"n’t" + 0.015*"min" + 0.015*"look" + 0.015*"fun(arg" + 0.015*"print(arg" + 0.015*"big" + 0.015*"distinguishing" + 0.015*"correct"
INFO: topic #2 (0.086): 0.060*"program" + 0.027*"c++" + 0.021*"c." + 0.020*"address" + 0.019*"output" + 0.014*"separate" + 0.014*"equivalent" + 0.013*"declaration" + 0.013*"copy" + 0.013*"int"
INFO: topic #3 (0.046): 0.123*"default" + 0.050*"positional" + 0.034*"keyword" + 0.026*"f2(x" + 0.026*"non" + 0.018*"p" + 0.018*"f2" + 0.018*"error" + 0.009*"associated" + 0.009*"f3"
INFO: topic #4 (0.036): 0.004*"parameter" + 0.004*"argument" + 0.004*"method" + 0.003*"runtime" + 0.003*"instance" + 0.003*"definition" + 0.003*"function" + 0.003*"formal" + 0.003*"value" + 0.003*"actual"
INFO: topic diff=0.127728, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.039 per-word bound, 32.9 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.91663384, 0.041094396, 0.081134625, 0.04231818, 0.03399605]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.917): 0.103*"parameter" + 0.098*"argument" + 0.081*"function" + 0.045*"value" + 0.026*"variable" + 0.023*"method" + 0.022*"definition" + 0.022*"actual" + 0.019*"call" + 0.019*"name"
INFO: topic #1 (0.041): 0.020*"question" + 0.019*"f" + 0.011*"correct" + 0.011*"look" + 0.011*"fun(arg" + 0.011*"n’t" + 0.011*"print(arg" + 0.011*"big" + 0.011*"min" + 0.011*"distinguishing"
INFO: topic #2 (0.081): 0.064*"program" + 0.033*"c++" + 0.028*"address" + 0.028*"output" + 0.019*"separate" + 0.019*"equivalent" + 0.019*"copy" + 0.019*"int" + 0.018*"object" + 0.014*"c."
INFO: topic #3 (0.042): 0.098*"default" + 0.040*"positional" + 0.027*"keyword" + 0.021*"f2(x" + 0.021*"non" + 0.014*"p" + 0.014*"f2" + 0.014*"error" + 0.008*"associated" + 0.008*"f3"
INFO: topic #4 (0.034): 0.004*"parameter" + 0.004*"argument" + 0.003*"method" + 0.003*"runtime" + 0.003*"instance" + 0.003*"definition" + 0.003*"function" + 0.003*"formal" + 0.003*"value" + 0.003*"actual"
INFO: topic diff=0.122751, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.079 per-word bound, 33.8 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0209707, 0.042147603, 0.08542416, 0.043525077, 0.032606293]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.021): 0.107*"parameter" + 0.102*"argument" + 0.087*"function" + 0.049*"value" + 0.028*"definition" + 0.025*"variable" + 0.022*"call" + 0.022*"method" + 0.022*"actual" + 0.020*"name"
INFO: topic #1 (0.042): 0.027*"question" + 0.026*"f" + 0.015*"distinguishing" + 0.015*"n’t" + 0.015*"min" + 0.015*"look" + 0.015*"fun(arg" + 0.015*"correct" + 0.015*"big" + 0.015*"print(arg"
INFO: topic #2 (0.085): 0.060*"program" + 0.027*"c++" + 0.020*"c." + 0.020*"address" + 0.020*"output" + 0.014*"separate" + 0.014*"equivalent" + 0.014*"copy" + 0.014*"int" + 0.013*"declaration"
INFO: topic #3 (0.044): 0.122*"default" + 0.050*"positional" + 0.034*"keyword" + 0.025*"f2(x" + 0.025*"non" + 0.017*"f2" + 0.017*"p" + 0.017*"error" + 0.009*"f3(b=100" + 0.009*"f3"
INFO: topic #4 (0.033): 0.003*"parameter" + 0.003*"argument" + 0.003*"method" + 0.003*"runtime" + 0.003*"instance" + 0.003*"definition" + 0.003*"function" + 0.003*"formal" + 0.003*"value" + 0.003*"actual"
INFO: topic diff=0.116979, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.034 per-word bound, 32.8 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.94142175, 0.039222725, 0.08062474, 0.040406443, 0.030853888]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.941): 0.103*"parameter" + 0.099*"argument" + 0.081*"function" + 0.045*"value" + 0.026*"variable" + 0.023*"method" + 0.022*"definition" + 0.022*"actual" + 0.019*"call" + 0.019*"name"
INFO: topic #1 (0.039): 0.020*"question" + 0.019*"f" + 0.011*"distinguishing" + 0.011*"n’t" + 0.011*"min" + 0.011*"look" + 0.011*"fun(arg" + 0.011*"correct" + 0.011*"big" + 0.011*"print(arg"
INFO: topic #2 (0.081): 0.064*"program" + 0.033*"c++" + 0.028*"address" + 0.028*"output" + 0.019*"separate" + 0.019*"equivalent" + 0.019*"copy" + 0.019*"int" + 0.018*"object" + 0.014*"c."
INFO: topic #3 (0.040): 0.099*"default" + 0.040*"positional" + 0.027*"keyword" + 0.021*"f2(x" + 0.021*"non" + 0.014*"p" + 0.014*"f2" + 0.014*"error" + 0.008*"a=200" + 0.008*"specify"
INFO: topic #4 (0.031): 0.003*"parameter" + 0.003*"argument" + 0.003*"method" + 0.003*"runtime" + 0.003*"instance" + 0.003*"definition" + 0.003*"function" + 0.003*"formal" + 0.003*"value" + 0.003*"actual"
INFO: topic diff=0.112843, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.073 per-word bound, 33.7 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.0351214, 0.040241975, 0.08468572, 0.04156197, 0.02976498]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.035): 0.106*"parameter" + 0.102*"argument" + 0.087*"function" + 0.049*"value" + 0.027*"definition" + 0.026*"variable" + 0.022*"method" + 0.022*"call" + 0.022*"actual" + 0.020*"name"
INFO: topic #1 (0.040): 0.027*"question" + 0.025*"f" + 0.015*"big" + 0.015*"n’t" + 0.015*"min" + 0.015*"look" + 0.015*"fun(arg" + 0.015*"distinguishing" + 0.015*"correct" + 0.015*"print(arg"
INFO: topic #2 (0.085): 0.061*"program" + 0.028*"c++" + 0.020*"address" + 0.020*"c." + 0.020*"output" + 0.014*"separate" + 0.014*"equivalent" + 0.014*"copy" + 0.014*"int" + 0.013*"declaration"
INFO: topic #3 (0.042): 0.121*"default" + 0.049*"positional" + 0.033*"keyword" + 0.025*"f2(x" + 0.025*"non" + 0.017*"p" + 0.017*"f2" + 0.017*"error" + 0.009*"f1(x" + 0.009*"f3(b=100"
INFO: topic #4 (0.030): 0.003*"parameter" + 0.003*"argument" + 0.003*"method" + 0.003*"runtime" + 0.003*"instance" + 0.003*"definition" + 0.003*"function" + 0.003*"formal" + 0.003*"value" + 0.003*"actual"
INFO: topic diff=0.108832, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.031 per-word bound, 32.7 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.9493662, 0.037686408, 0.08017367, 0.038836442, 0.02836531]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.949): 0.103*"parameter" + 0.099*"argument" + 0.081*"function" + 0.045*"value" + 0.026*"variable" + 0.023*"method" + 0.022*"definition" + 0.022*"actual" + 0.019*"call" + 0.019*"name"
INFO: topic #1 (0.038): 0.021*"question" + 0.019*"f" + 0.011*"print(arg" + 0.011*"min" + 0.011*"look" + 0.011*"fun(arg" + 0.011*"distinguishing" + 0.011*"correct" + 0.011*"big" + 0.011*"n’t"
INFO: topic #2 (0.080): 0.064*"program" + 0.033*"c++" + 0.028*"address" + 0.028*"output" + 0.019*"separate" + 0.019*"equivalent" + 0.019*"copy" + 0.019*"int" + 0.018*"object" + 0.014*"c."
INFO: topic #3 (0.039): 0.099*"default" + 0.041*"positional" + 0.028*"keyword" + 0.021*"f2(x" + 0.021*"non" + 0.015*"p" + 0.015*"f2" + 0.015*"error" + 0.008*"sure" + 0.008*"specify"
INFO: topic #4 (0.028): 0.003*"parameter" + 0.003*"argument" + 0.003*"method" + 0.003*"runtime" + 0.003*"instance" + 0.003*"definition" + 0.003*"function" + 0.003*"formal" + 0.003*"value" + 0.003*"actual"
INFO: topic diff=0.105295, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.067 per-word bound, 33.5 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.034697, 0.038665894, 0.08402284, 0.039938755, 0.027483705]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.035): 0.106*"parameter" + 0.102*"argument" + 0.087*"function" + 0.049*"value" + 0.027*"definition" + 0.026*"variable" + 0.022*"method" + 0.022*"call" + 0.022*"actual" + 0.020*"name"
INFO: topic #1 (0.039): 0.027*"question" + 0.025*"f" + 0.014*"print(arg" + 0.014*"correct" + 0.014*"min" + 0.014*"look" + 0.014*"fun(arg" + 0.014*"distinguishing" + 0.014*"n’t" + 0.014*"big"
INFO: topic #2 (0.084): 0.061*"program" + 0.028*"c++" + 0.021*"address" + 0.020*"output" + 0.020*"c." + 0.014*"separate" + 0.014*"equivalent" + 0.014*"copy" + 0.014*"int" + 0.013*"declaration"
INFO: topic #3 (0.040): 0.120*"default" + 0.049*"positional" + 0.033*"keyword" + 0.025*"f2(x" + 0.025*"non" + 0.017*"p" + 0.017*"f2" + 0.017*"error" + 0.009*"associated" + 0.009*"specify"
INFO: topic #4 (0.027): 0.003*"parameter" + 0.003*"argument" + 0.003*"method" + 0.003*"runtime" + 0.003*"instance" + 0.003*"definition" + 0.003*"function" + 0.003*"formal" + 0.003*"value" + 0.003*"actual"
INFO: topic diff=0.102462, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.028 per-word bound, 32.6 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.9491406, 0.036396705, 0.07975941, 0.03751807, 0.02633593]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.949): 0.103*"parameter" + 0.099*"argument" + 0.081*"function" + 0.045*"value" + 0.026*"variable" + 0.023*"method" + 0.022*"definition" + 0.022*"actual" + 0.019*"call" + 0.019*"name"
INFO: topic #1 (0.036): 0.021*"question" + 0.019*"f" + 0.011*"print(arg" + 0.011*"min" + 0.011*"look" + 0.011*"fun(arg" + 0.011*"distinguishing" + 0.011*"correct" + 0.011*"big" + 0.011*"n’t"
INFO: topic #2 (0.080): 0.064*"program" + 0.032*"c++" + 0.028*"address" + 0.028*"output" + 0.019*"separate" + 0.019*"equivalent" + 0.019*"copy" + 0.019*"int" + 0.018*"object" + 0.014*"c."
INFO: topic #3 (0.038): 0.099*"default" + 0.041*"positional" + 0.028*"keyword" + 0.021*"f2(x" + 0.021*"non" + 0.015*"p" + 0.015*"f2" + 0.015*"error" + 0.008*"specify" + 0.008*"f3"
INFO: topic #4 (0.026): 0.003*"parameter" + 0.003*"argument" + 0.003*"method" + 0.003*"runtime" + 0.003*"instance" + 0.003*"definition" + 0.003*"function" + 0.003*"formal" + 0.003*"value" + 0.003*"actual"
INFO: topic diff=0.099277, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.062 per-word bound, 33.4 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [1.027601, 0.03733606, 0.08341703, 0.038569853, 0.025604315]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.028): 0.106*"parameter" + 0.102*"argument" + 0.087*"function" + 0.049*"value" + 0.027*"definition" + 0.026*"variable" + 0.022*"method" + 0.022*"call" + 0.022*"actual" + 0.020*"name"
INFO: topic #1 (0.037): 0.027*"question" + 0.025*"f" + 0.014*"correct" + 0.014*"print(arg" + 0.014*"n’t" + 0.014*"min" + 0.014*"look" + 0.014*"distinguishing" + 0.014*"fun(arg" + 0.014*"big"
INFO: topic #2 (0.083): 0.061*"program" + 0.028*"c++" + 0.021*"address" + 0.021*"output" + 0.020*"c." + 0.014*"equivalent" + 0.014*"separate" + 0.014*"copy" + 0.014*"int" + 0.013*"object"
INFO: topic #3 (0.039): 0.119*"default" + 0.049*"positional" + 0.033*"keyword" + 0.025*"non" + 0.025*"f2(x" + 0.017*"f2" + 0.017*"error" + 0.017*"p" + 0.011*"key" + 0.009*"associated"
INFO: topic #4 (0.026): 0.003*"parameter" + 0.003*"argument" + 0.003*"method" + 0.003*"runtime" + 0.003*"instance" + 0.003*"definition" + 0.003*"function" + 0.003*"formal" + 0.003*"value" + 0.003*"actual"
INFO: topic diff=0.097363, rho=0.288675
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=397, num_topics=5, decay=0.5, chunksize=5> in 0.18s', 'datetime': '2023-04-25T15:14:05.785228', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 5 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.034 per-word bound, 131.0 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
WARNING: updated prior is not positive
INFO: optimized alpha [0.2, 0.2, 0.2, 0.2, 0.2]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.200): 0.099*"parameter" + 0.087*"argument" + 0.046*"function" + 0.036*"value" + 0.025*"method" + 0.024*"variable" + 0.023*"actual" + 0.019*"name" + 0.018*"formal" + 0.016*"definition"
INFO: topic #1 (0.200): 0.003*"function" + 0.003*"parameter" + 0.003*"argument" + 0.003*"variable" + 0.003*"value" + 0.003*"type" + 0.003*"part" + 0.003*"object" + 0.003*"program" + 0.003*"copy"
INFO: topic #2 (0.200): 0.003*"function" + 0.003*"parameter" + 0.003*"argument" + 0.003*"variable" + 0.003*"value" + 0.003*"call" + 0.003*"program" + 0.003*"part" + 0.003*"object" + 0.003*"type"
INFO: topic #3 (0.200): 0.092*"argument" + 0.091*"parameter" + 0.080*"function" + 0.032*"value" + 0.022*"method" + 0.021*"actual" + 0.018*"call" + 0.018*"variable" + 0.018*"formal" + 0.018*"example"
INFO: topic #4 (0.200): 0.078*"function" + 0.071*"variable" + 0.063*"value" + 0.055*"parameter" + 0.055*"argument" + 0.040*"foo" + 0.032*"type" + 0.032*"point" + 0.016*"actual" + 0.016*"string"
INFO: topic diff=2.859026, rho=1.000000
DEBUG: bound: at document #0
INFO: -6.875 per-word bound, 117.4 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.20637158, 0.12411705, 0.17237301, 0.27244002, 0.1621975]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.206): 0.099*"parameter" + 0.086*"argument" + 0.044*"function" + 0.032*"value" + 0.025*"actual" + 0.024*"method" + 0.021*"formal" + 0.018*"program" + 0.018*"definition" + 0.017*"variable"
INFO: topic #1 (0.124): 0.020*"c." + 0.011*"sqrt" + 0.011*"convention" + 0.011*"community" + 0.011*"arguments" + 0.011*"opposite" + 0.011*"prototype" + 0.011*"alternative" + 0.011*"inside" + 0.011*"view"
INFO: topic #2 (0.172): 0.111*"default" + 0.045*"positional" + 0.031*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"p" + 0.016*"error" + 0.016*"f2" + 0.013*"arg" + 0.013*"def"
INFO: topic #3 (0.272): 0.098*"parameter" + 0.098*"argument" + 0.096*"function" + 0.050*"value" + 0.036*"definition" + 0.030*"call" + 0.026*"b" + 0.023*"name" + 0.022*"variable" + 0.018*"key"
INFO: topic #4 (0.162): 0.074*"function" + 0.048*"value" + 0.044*"parameter" + 0.044*"argument" + 0.035*"variable" + 0.020*"foo" + 0.018*"datum" + 0.016*"point" + 0.016*"type" + 0.014*"sense"
INFO: topic diff=0.861515, rho=0.707107
DEBUG: bound: at document #0
INFO: -5.284 per-word bound, 39.0 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.16522133, 0.07853474, 0.0859506, 0.28412154, 0.1133441]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.165): 0.090*"parameter" + 0.080*"argument" + 0.037*"function" + 0.028*"value" + 0.027*"actual" + 0.027*"method" + 0.024*"formal" + 0.019*"variable" + 0.017*"term" + 0.014*"program"
INFO: topic #1 (0.079): 0.012*"c." + 0.007*"text" + 0.007*"sqrt" + 0.007*"convention" + 0.007*"community" + 0.007*"arguments" + 0.007*"alternative" + 0.007*"prototype" + 0.007*"opposite" + 0.007*"thesis"
INFO: topic #2 (0.086): 0.075*"default" + 0.031*"positional" + 0.021*"keyword" + 0.016*"non" + 0.016*"f2(x" + 0.011*"p" + 0.011*"error" + 0.011*"f2" + 0.010*"arg" + 0.010*"def"
INFO: topic #3 (0.284): 0.099*"parameter" + 0.098*"argument" + 0.089*"function" + 0.043*"value" + 0.025*"definition" + 0.024*"call" + 0.021*"name" + 0.021*"variable" + 0.020*"method" + 0.018*"actual"
INFO: topic #4 (0.113): 0.074*"function" + 0.057*"variable" + 0.056*"value" + 0.047*"parameter" + 0.047*"argument" + 0.033*"foo" + 0.026*"point" + 0.026*"type" + 0.014*"actual" + 0.014*"number"
INFO: topic diff=0.409391, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.415 per-word bound, 42.7 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.17142795, 0.07411168, 0.09166184, 0.3340194, 0.0961105]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.171): 0.092*"parameter" + 0.079*"argument" + 0.036*"function" + 0.029*"actual" + 0.026*"method" + 0.026*"formal" + 0.026*"value" + 0.018*"program" + 0.015*"variable" + 0.015*"term"
INFO: topic #1 (0.074): 0.025*"c." + 0.014*"text" + 0.014*"prototype" + 0.014*"opposite" + 0.014*"inside" + 0.014*"convention" + 0.014*"community" + 0.014*"arguments" + 0.014*"alternative" + 0.014*"z"
INFO: topic #2 (0.092): 0.111*"default" + 0.046*"positional" + 0.031*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"p" + 0.016*"error" + 0.016*"f2" + 0.016*"arg" + 0.016*"def"
INFO: topic #3 (0.334): 0.104*"parameter" + 0.103*"argument" + 0.102*"function" + 0.054*"value" + 0.036*"definition" + 0.030*"call" + 0.025*"name" + 0.024*"b" + 0.023*"variable" + 0.018*"method"
INFO: topic #4 (0.096): 0.054*"function" + 0.041*"variable" + 0.041*"value" + 0.035*"parameter" + 0.034*"argument" + 0.024*"foo" + 0.019*"point" + 0.019*"type" + 0.014*"sense" + 0.011*"actual"
INFO: topic diff=0.373840, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.229 per-word bound, 37.5 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.15078211, 0.059433483, 0.06929815, 0.33369717, 0.083819956]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.151): 0.084*"parameter" + 0.074*"argument" + 0.031*"function" + 0.030*"actual" + 0.029*"formal" + 0.028*"method" + 0.023*"value" + 0.019*"term" + 0.017*"variable" + 0.014*"program"
INFO: topic #1 (0.059): 0.016*"c." + 0.009*"text" + 0.009*"prototype" + 0.009*"opposite" + 0.009*"inside" + 0.009*"convention" + 0.009*"community" + 0.009*"arguments" + 0.009*"alternative" + 0.009*"z"
INFO: topic #2 (0.069): 0.081*"default" + 0.034*"positional" + 0.023*"keyword" + 0.018*"non" + 0.018*"f2(x" + 0.012*"p" + 0.012*"error" + 0.012*"f2" + 0.012*"arg" + 0.012*"def"
INFO: topic #3 (0.334): 0.105*"parameter" + 0.103*"argument" + 0.095*"function" + 0.048*"value" + 0.027*"definition" + 0.026*"call" + 0.023*"name" + 0.023*"variable" + 0.019*"method" + 0.017*"actual"
INFO: topic #4 (0.084): 0.058*"variable" + 0.056*"function" + 0.047*"value" + 0.037*"foo" + 0.034*"parameter" + 0.034*"argument" + 0.028*"point" + 0.027*"type" + 0.015*"number" + 0.015*"string"
INFO: topic diff=0.340216, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.306 per-word bound, 39.6 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.15779497, 0.058440655, 0.07497445, 0.37699077, 0.0694453]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.158): 0.084*"parameter" + 0.074*"argument" + 0.031*"actual" + 0.031*"function" + 0.030*"formal" + 0.028*"method" + 0.021*"value" + 0.018*"program" + 0.017*"term" + 0.014*"variable"
INFO: topic #1 (0.058): 0.027*"c." + 0.014*"sqrt" + 0.014*"prototype" + 0.014*"arguments" + 0.014*"convention" + 0.014*"inside" + 0.014*"opposite" + 0.014*"alternative" + 0.014*"community" + 0.014*"view"
INFO: topic #2 (0.075): 0.112*"default" + 0.046*"positional" + 0.031*"keyword" + 0.024*"non" + 0.024*"f2(x" + 0.016*"p" + 0.016*"error" + 0.016*"f2" + 0.016*"arg" + 0.016*"def"
INFO: topic #3 (0.377): 0.108*"parameter" + 0.106*"argument" + 0.105*"function" + 0.056*"value" + 0.036*"definition" + 0.031*"call" + 0.026*"name" + 0.023*"variable" + 0.023*"b" + 0.018*"method"
INFO: topic #4 (0.069): 0.043*"variable" + 0.042*"function" + 0.035*"value" + 0.028*"foo" + 0.025*"parameter" + 0.025*"argument" + 0.021*"point" + 0.020*"type" + 0.012*"number" + 0.011*"string"
INFO: topic diff=0.304292, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.200 per-word bound, 36.7 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14355192, 0.05002863, 0.061172623, 0.3629716, 0.06498712]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.144): 0.079*"parameter" + 0.071*"argument" + 0.032*"formal" + 0.031*"actual" + 0.029*"method" + 0.027*"function" + 0.021*"term" + 0.020*"value" + 0.016*"variable" + 0.014*"program"
INFO: topic #1 (0.050): 0.018*"c." + 0.010*"sqrt" + 0.010*"prototype" + 0.010*"arguments" + 0.010*"convention" + 0.010*"inside" + 0.010*"opposite" + 0.010*"alternative" + 0.010*"community" + 0.010*"view"
INFO: topic #2 (0.061): 0.085*"default" + 0.035*"positional" + 0.024*"keyword" + 0.018*"non" + 0.018*"f2(x" + 0.013*"p" + 0.013*"error" + 0.013*"f2" + 0.013*"arg" + 0.013*"def"
INFO: topic #3 (0.363): 0.109*"parameter" + 0.107*"argument" + 0.101*"function" + 0.052*"value" + 0.029*"definition" + 0.028*"call" + 0.025*"name" + 0.024*"variable" + 0.018*"method" + 0.017*"example"
INFO: topic #4 (0.065): 0.057*"variable" + 0.042*"function" + 0.040*"foo" + 0.039*"value" + 0.029*"point" + 0.026*"type" + 0.023*"argument" + 0.023*"parameter" + 0.016*"number" + 0.015*"string"
INFO: topic diff=0.282703, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.243 per-word bound, 37.9 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.15189637, 0.050209295, 0.06664689, 0.42140287, 0.057355378]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.152): 0.079*"parameter" + 0.070*"argument" + 0.033*"formal" + 0.032*"actual" + 0.029*"method" + 0.027*"function" + 0.019*"term" + 0.019*"value" + 0.017*"program" + 0.014*"different"
INFO: topic #1 (0.050): 0.027*"c." + 0.015*"arguments" + 0.015*"prototype" + 0.015*"view" + 0.015*"thesis" + 0.015*"text" + 0.015*"community" + 0.015*"alternative" + 0.015*"sqrt" + 0.015*"convention"
INFO: topic #2 (0.067): 0.112*"default" + 0.046*"positional" + 0.031*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"p" + 0.016*"f2" + 0.016*"error" + 0.016*"def" + 0.016*"arg"
INFO: topic #3 (0.421): 0.111*"parameter" + 0.109*"argument" + 0.109*"function" + 0.059*"value" + 0.037*"definition" + 0.031*"call" + 0.027*"name" + 0.024*"variable" + 0.022*"b" + 0.018*"case"
INFO: topic #4 (0.057): 0.043*"variable" + 0.032*"function" + 0.030*"foo" + 0.030*"value" + 0.022*"point" + 0.020*"type" + 0.018*"argument" + 0.018*"parameter" + 0.012*"number" + 0.012*"string"
INFO: topic diff=0.260917, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.174 per-word bound, 36.1 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14051434, 0.04442656, 0.0564863, 0.39104518, 0.055223282]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.141): 0.076*"parameter" + 0.069*"argument" + 0.033*"formal" + 0.031*"actual" + 0.030*"method" + 0.025*"function" + 0.022*"term" + 0.018*"value" + 0.016*"variable" + 0.013*"reference"
INFO: topic #1 (0.044): 0.019*"c." + 0.011*"arguments" + 0.011*"prototype" + 0.011*"view" + 0.011*"thesis" + 0.011*"text" + 0.011*"community" + 0.011*"alternative" + 0.011*"sqrt" + 0.011*"convention"
INFO: topic #2 (0.056): 0.087*"default" + 0.036*"positional" + 0.025*"keyword" + 0.019*"non" + 0.019*"f2(x" + 0.013*"p" + 0.013*"f2" + 0.013*"error" + 0.013*"def" + 0.013*"arg"
INFO: topic #3 (0.391): 0.113*"parameter" + 0.110*"argument" + 0.108*"function" + 0.056*"value" + 0.031*"definition" + 0.029*"call" + 0.027*"name" + 0.025*"variable" + 0.018*"example" + 0.017*"method"
INFO: topic #4 (0.055): 0.056*"variable" + 0.042*"foo" + 0.032*"value" + 0.031*"function" + 0.030*"point" + 0.025*"type" + 0.016*"number" + 0.015*"string" + 0.015*"argument" + 0.015*"parameter"
INFO: topic diff=0.235012, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.197 per-word bound, 36.7 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14889538, 0.045006346, 0.061580427, 0.4531515, 0.05022174]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.149): 0.076*"parameter" + 0.069*"argument" + 0.034*"formal" + 0.032*"actual" + 0.029*"method" + 0.025*"function" + 0.021*"term" + 0.017*"value" + 0.015*"program" + 0.014*"variable"
INFO: topic #1 (0.045): 0.027*"c." + 0.015*"prototype" + 0.015*"opposite" + 0.015*"thesis" + 0.015*"text" + 0.015*"sqrt" + 0.015*"alternative" + 0.015*"z" + 0.015*"inside" + 0.015*"convention"
INFO: topic #2 (0.062): 0.111*"default" + 0.045*"positional" + 0.031*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"p" + 0.016*"error" + 0.016*"f2" + 0.016*"def" + 0.016*"arg"
INFO: topic #3 (0.453): 0.115*"parameter" + 0.114*"function" + 0.112*"argument" + 0.061*"value" + 0.039*"definition" + 0.033*"call" + 0.028*"name" + 0.025*"variable" + 0.023*"b" + 0.018*"case"
INFO: topic #4 (0.050): 0.042*"variable" + 0.032*"foo" + 0.024*"value" + 0.024*"function" + 0.023*"point" + 0.020*"type" + 0.013*"number" + 0.012*"string" + 0.012*"argument" + 0.012*"parameter"
INFO: topic diff=0.234467, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.144 per-word bound, 35.4 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13893467, 0.04062687, 0.053402588, 0.40954182, 0.04907787]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.139): 0.075*"parameter" + 0.069*"argument" + 0.032*"formal" + 0.031*"actual" + 0.030*"method" + 0.024*"function" + 0.022*"term" + 0.017*"value" + 0.016*"variable" + 0.012*"declaration"
INFO: topic #1 (0.041): 0.020*"c." + 0.011*"prototype" + 0.011*"inside" + 0.011*"thesis" + 0.011*"text" + 0.011*"sqrt" + 0.011*"arguments" + 0.011*"z" + 0.011*"opposite" + 0.011*"alternative"
INFO: topic #2 (0.053): 0.089*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"non" + 0.019*"f2(x" + 0.013*"p" + 0.013*"error" + 0.013*"f2" + 0.013*"arg" + 0.013*"def"
INFO: topic #3 (0.410): 0.116*"parameter" + 0.115*"function" + 0.113*"argument" + 0.060*"value" + 0.033*"definition" + 0.032*"call" + 0.028*"name" + 0.026*"variable" + 0.019*"example" + 0.017*"type"
INFO: topic #4 (0.049): 0.053*"variable" + 0.044*"foo" + 0.030*"point" + 0.025*"value" + 0.024*"type" + 0.022*"function" + 0.017*"number" + 0.015*"string" + 0.010*"sense" + 0.010*"stop"
INFO: topic diff=0.206021, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.155 per-word bound, 35.6 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.14678259, 0.041341964, 0.058103472, 0.46900046, 0.045401674]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.147): 0.075*"parameter" + 0.069*"argument" + 0.034*"formal" + 0.031*"actual" + 0.030*"method" + 0.024*"function" + 0.021*"term" + 0.016*"value" + 0.015*"variable" + 0.014*"program"
INFO: topic #1 (0.041): 0.027*"c." + 0.014*"convention" + 0.014*"community" + 0.014*"text" + 0.014*"sqrt" + 0.014*"prototype" + 0.014*"opposite" + 0.014*"view" + 0.014*"alternative" + 0.014*"arguments"
INFO: topic #2 (0.058): 0.111*"default" + 0.045*"positional" + 0.030*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"p" + 0.016*"f2" + 0.016*"error" + 0.016*"def" + 0.016*"arg"
INFO: topic #3 (0.469): 0.119*"function" + 0.117*"parameter" + 0.114*"argument" + 0.064*"value" + 0.040*"definition" + 0.034*"call" + 0.029*"name" + 0.026*"variable" + 0.023*"b" + 0.019*"case"
INFO: topic #4 (0.045): 0.041*"variable" + 0.034*"foo" + 0.023*"point" + 0.020*"value" + 0.019*"type" + 0.017*"function" + 0.013*"number" + 0.012*"string" + 0.008*"sense" + 0.008*"stop"
INFO: topic diff=0.213104, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.116 per-word bound, 34.7 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.13767162, 0.037826747, 0.051177073, 0.41797522, 0.04476446]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.138): 0.076*"parameter" + 0.070*"argument" + 0.032*"formal" + 0.030*"method" + 0.030*"actual" + 0.024*"function" + 0.022*"term" + 0.017*"value" + 0.017*"variable" + 0.012*"c"
INFO: topic #1 (0.038): 0.020*"c." + 0.011*"convention" + 0.011*"view" + 0.011*"prototype" + 0.011*"opposite" + 0.011*"inside" + 0.011*"text" + 0.011*"community" + 0.011*"alternative" + 0.011*"arguments"
INFO: topic #2 (0.051): 0.090*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"non" + 0.019*"f2(x" + 0.013*"p" + 0.013*"f2" + 0.013*"error" + 0.013*"def" + 0.013*"arg"
INFO: topic #3 (0.418): 0.121*"function" + 0.118*"parameter" + 0.115*"argument" + 0.063*"value" + 0.036*"definition" + 0.034*"call" + 0.030*"name" + 0.026*"variable" + 0.019*"example" + 0.018*"type"
INFO: topic #4 (0.045): 0.051*"variable" + 0.045*"foo" + 0.030*"point" + 0.022*"type" + 0.020*"value" + 0.017*"number" + 0.015*"function" + 0.015*"string" + 0.010*"sense" + 0.010*"mutable"
INFO: topic diff=0.190970, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.119 per-word bound, 34.7 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1352564, 0.038511783, 0.055408023, 0.4662126, 0.041776396]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.135): 0.076*"parameter" + 0.070*"argument" + 0.033*"formal" + 0.031*"actual" + 0.030*"method" + 0.024*"function" + 0.021*"term" + 0.016*"value" + 0.015*"variable" + 0.013*"declaration"
INFO: topic #1 (0.039): 0.027*"c." + 0.014*"inside" + 0.014*"prototype" + 0.014*"community" + 0.014*"convention" + 0.014*"alternative" + 0.014*"opposite" + 0.014*"thesis" + 0.014*"text" + 0.014*"view"
INFO: topic #2 (0.055): 0.110*"default" + 0.045*"positional" + 0.030*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"def" + 0.016*"arg" + 0.016*"question" + 0.016*"p" + 0.016*"f2"
INFO: topic #3 (0.466): 0.124*"function" + 0.119*"parameter" + 0.115*"argument" + 0.067*"value" + 0.042*"definition" + 0.036*"call" + 0.030*"name" + 0.026*"variable" + 0.024*"b" + 0.020*"case"
INFO: topic #4 (0.042): 0.040*"variable" + 0.035*"foo" + 0.024*"point" + 0.018*"type" + 0.016*"value" + 0.014*"number" + 0.012*"function" + 0.012*"string" + 0.009*"sense" + 0.009*"caller"
INFO: topic diff=0.193817, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.092 per-word bound, 34.1 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.12872984, 0.03557219, 0.049337544, 0.4133977, 0.041416798]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.129): 0.076*"parameter" + 0.072*"argument" + 0.031*"formal" + 0.031*"method" + 0.030*"actual" + 0.024*"function" + 0.022*"term" + 0.017*"variable" + 0.017*"value" + 0.012*"c"
INFO: topic #1 (0.036): 0.020*"c." + 0.011*"opposite" + 0.011*"convention" + 0.011*"community" + 0.011*"arguments" + 0.011*"alternative" + 0.011*"prototype" + 0.011*"sqrt" + 0.011*"inside" + 0.011*"view"
INFO: topic #2 (0.049): 0.091*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"non" + 0.019*"f2(x" + 0.013*"arg" + 0.013*"def" + 0.013*"question" + 0.013*"f2" + 0.013*"error"
INFO: topic #3 (0.413): 0.126*"function" + 0.120*"parameter" + 0.116*"argument" + 0.066*"value" + 0.038*"definition" + 0.035*"call" + 0.031*"name" + 0.027*"variable" + 0.020*"example" + 0.019*"type"
INFO: topic #4 (0.041): 0.048*"variable" + 0.045*"foo" + 0.029*"point" + 0.020*"type" + 0.018*"number" + 0.015*"value" + 0.015*"string" + 0.011*"function" + 0.011*"sense" + 0.011*"scope"
INFO: topic diff=0.178479, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.091 per-word bound, 34.1 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.1275094, 0.036265682, 0.053263735, 0.45790082, 0.038968164]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.128): 0.076*"parameter" + 0.071*"argument" + 0.033*"formal" + 0.030*"actual" + 0.030*"method" + 0.024*"function" + 0.021*"term" + 0.016*"value" + 0.016*"variable" + 0.013*"declaration"
INFO: topic #1 (0.036): 0.027*"c." + 0.014*"sqrt" + 0.014*"opposite" + 0.014*"view" + 0.014*"thesis" + 0.014*"text" + 0.014*"alternative" + 0.014*"z" + 0.014*"prototype" + 0.014*"inside"
INFO: topic #2 (0.053): 0.109*"default" + 0.044*"positional" + 0.030*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"question" + 0.016*"arg" + 0.016*"def" + 0.016*"p" + 0.016*"error"
INFO: topic #3 (0.458): 0.128*"function" + 0.120*"parameter" + 0.116*"argument" + 0.069*"value" + 0.043*"definition" + 0.037*"call" + 0.031*"name" + 0.026*"variable" + 0.024*"b" + 0.020*"case"
INFO: topic #4 (0.039): 0.038*"variable" + 0.036*"foo" + 0.023*"point" + 0.016*"type" + 0.014*"number" + 0.012*"value" + 0.012*"string" + 0.009*"function" + 0.009*"sense" + 0.009*"some_value"
INFO: topic diff=0.172508, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.076 per-word bound, 33.7 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.122463256, 0.033746663, 0.04784224, 0.4064271, 0.038786177]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.122): 0.077*"parameter" + 0.073*"argument" + 0.031*"formal" + 0.031*"method" + 0.029*"actual" + 0.024*"function" + 0.022*"term" + 0.018*"variable" + 0.017*"value" + 0.012*"c"
INFO: topic #1 (0.034): 0.020*"c." + 0.011*"alternative" + 0.011*"thesis" + 0.011*"text" + 0.011*"sqrt" + 0.011*"prototype" + 0.011*"opposite" + 0.011*"inside" + 0.011*"convention" + 0.011*"community"
INFO: topic #2 (0.048): 0.091*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"non" + 0.019*"f2(x" + 0.013*"question" + 0.013*"arg" + 0.013*"def" + 0.013*"p" + 0.013*"error"
INFO: topic #3 (0.406): 0.129*"function" + 0.120*"parameter" + 0.116*"argument" + 0.067*"value" + 0.039*"definition" + 0.036*"call" + 0.032*"name" + 0.027*"variable" + 0.020*"type" + 0.020*"example"
INFO: topic #4 (0.039): 0.046*"variable" + 0.046*"foo" + 0.029*"point" + 0.018*"number" + 0.018*"type" + 0.014*"string" + 0.011*"value" + 0.011*"sense" + 0.011*"replace" + 0.011*"note"
INFO: topic diff=0.165545, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.075 per-word bound, 33.7 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.121951856, 0.03443286, 0.05151059, 0.4478603, 0.03672024]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.122): 0.077*"parameter" + 0.072*"argument" + 0.033*"formal" + 0.030*"method" + 0.030*"actual" + 0.024*"function" + 0.021*"term" + 0.017*"value" + 0.016*"variable" + 0.012*"declaration"
INFO: topic #1 (0.034): 0.026*"c." + 0.014*"prototype" + 0.014*"inside" + 0.014*"thesis" + 0.014*"text" + 0.014*"sqrt" + 0.014*"z" + 0.014*"community" + 0.014*"convention" + 0.014*"opposite"
INFO: topic #2 (0.052): 0.109*"default" + 0.044*"positional" + 0.030*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"question" + 0.016*"def" + 0.016*"arg" + 0.016*"f2" + 0.016*"error"
INFO: topic #3 (0.448): 0.130*"function" + 0.120*"parameter" + 0.116*"argument" + 0.070*"value" + 0.044*"definition" + 0.038*"call" + 0.032*"name" + 0.027*"variable" + 0.024*"b" + 0.021*"case"
INFO: topic #4 (0.037): 0.037*"variable" + 0.037*"foo" + 0.023*"point" + 0.015*"number" + 0.015*"type" + 0.012*"string" + 0.010*"value" + 0.009*"sense" + 0.009*"interpreter" + 0.009*"caller"
INFO: topic diff=0.153565, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.065 per-word bound, 33.5 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.117849216, 0.032234058, 0.046600603, 0.39907378, 0.036658186]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.118): 0.077*"parameter" + 0.074*"argument" + 0.031*"formal" + 0.031*"method" + 0.029*"actual" + 0.025*"function" + 0.022*"term" + 0.018*"variable" + 0.017*"value" + 0.012*"c"
INFO: topic #1 (0.032): 0.020*"c." + 0.011*"prototype" + 0.011*"sqrt" + 0.011*"inside" + 0.011*"z" + 0.011*"opposite" + 0.011*"community" + 0.011*"view" + 0.011*"arguments" + 0.011*"alternative"
INFO: topic #2 (0.047): 0.092*"default" + 0.037*"positional" + 0.025*"keyword" + 0.019*"f2(x" + 0.019*"non" + 0.013*"question" + 0.013*"def" + 0.013*"arg" + 0.013*"error" + 0.013*"f2"
INFO: topic #3 (0.399): 0.131*"function" + 0.121*"parameter" + 0.115*"argument" + 0.069*"value" + 0.040*"definition" + 0.037*"call" + 0.032*"name" + 0.027*"variable" + 0.021*"type" + 0.020*"example"
INFO: topic #4 (0.037): 0.046*"foo" + 0.044*"variable" + 0.029*"point" + 0.019*"number" + 0.016*"type" + 0.014*"string" + 0.011*"sense" + 0.011*"interpreter" + 0.011*"course" + 0.011*"stop"
INFO: topic diff=0.152429, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.066 per-word bound, 33.5 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
INFO: optimized alpha [0.11776621, 0.032905854, 0.050049596, 0.43793762, 0.03487648]
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (0.118): 0.077*"parameter" + 0.073*"argument" + 0.032*"formal" + 0.030*"method" + 0.030*"actual" + 0.024*"function" + 0.021*"term" + 0.017*"value" + 0.017*"variable" + 0.012*"declaration"
INFO: topic #1 (0.033): 0.026*"c." + 0.014*"opposite" + 0.014*"sqrt" + 0.014*"arguments" + 0.014*"community" + 0.014*"convention" + 0.014*"inside" + 0.014*"alternative" + 0.014*"prototype" + 0.014*"thesis"
INFO: topic #2 (0.050): 0.108*"default" + 0.044*"positional" + 0.030*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.015*"question" + 0.015*"arg" + 0.015*"def" + 0.015*"error" + 0.015*"f2"
INFO: topic #3 (0.438): 0.132*"function" + 0.120*"parameter" + 0.116*"argument" + 0.071*"value" + 0.045*"definition" + 0.038*"call" + 0.032*"name" + 0.027*"variable" + 0.025*"b" + 0.021*"case"
INFO: topic #4 (0.035): 0.037*"foo" + 0.036*"variable" + 0.023*"point" + 0.015*"number" + 0.013*"type" + 0.012*"string" + 0.009*"sense" + 0.009*"caller" + 0.009*"course" + 0.009*"note"
INFO: topic diff=0.137423, rho=0.288675
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=397, num_topics=5, decay=0.5, chunksize=5> in 0.37s', 'datetime': '2023-04-25T15:14:06.155913', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: generating a 25 x 25 asymmetric distance matrix...
INFO: the given threshold of None covered on average 91.4% of tokens
INFO: fitting the clustering model, using 2 for min_samples
INFO: generating stable topics, using 2 for min_cores
INFO: found 4 clusters
INFO: found 4 stable topics
INFO: generating classic gensim model representation based on results from the ensemble
INFO: using autotuned alpha, starting with [0.25, 0.25, 0.25, 0.25]
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 4 topics, 0 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
WARNING: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=397, num_topics=4, decay=0.5, chunksize=5> in 0.00s', 'datetime': '2023-04-25T15:14:06.193761', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: Setting topics to those of the model: <gensim.models.ensemblelda.EnsembleLda object at 0x1308e6b50>
INFO: measuring u_mass...
INFO: Coherence u_mass: -0.2933
INFO: Coherence u_mass per-topic: [-0.6036729745449805, -0.12322616542287915, 9.888889707050057e-12, -0.4461040681703666]
DEBUG: starting a new internal lifecycle event log for EnsembleLda
INFO: EnsembleLda lifecycle event {'fname_or_handle': 'model/elda/7/model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset({'topic_model_class'}), 'datetime': '2023-04-25T15:14:06.197052', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: not storing attribute topic_model_class
DEBUG: {'uri': 'model/elda/7/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/elda/7/model
INFO: topic #0 (0.250): 0.003*"parameter" + 0.003*"argument" + 0.003*"method" + 0.003*"runtime" + 0.003*"instance" + 0.003*"function" + 0.003*"definition" + 0.003*"value" + 0.003*"formal" + 0.003*"actual"
INFO: topic #1 (0.250): 0.027*"question" + 0.025*"f" + 0.014*"look" + 0.014*"big" + 0.014*"distinguishing" + 0.014*"fun(arg" + 0.014*"correct" + 0.014*"min" + 0.014*"print(arg" + 0.014*"n’t"
INFO: topic #2 (0.250): 0.108*"default" + 0.045*"positional" + 0.030*"keyword" + 0.023*"non" + 0.023*"f2(x" + 0.016*"error" + 0.016*"f2" + 0.016*"p" + 0.011*"def" + 0.011*"arg"
INFO: topic #3 (0.250): 0.106*"parameter" + 0.101*"argument" + 0.096*"function" + 0.053*"value" + 0.032*"definition" + 0.026*"call" + 0.025*"variable" + 0.023*"name" + 0.019*"actual" + 0.018*"method"
INFO: Question Similarity: [0.03763139247894287, 0.27221667766571045, 0.7087501883506775, 0.17243289947509766, 0.05437415838241577, 0.6915662586688995, 0.12265866994857788, 0.10482025146484375, 0.03931593894958496, 0.07596439123153687]
INFO: 51054544: -0.17246542898990253
INFO: 3176321: -0.1754883604619232
INFO: 51054593: -0.18095851032626079
INFO: 3176327: -0.18989161622885625
INFO: 4905833: -0.1949585052293828
INFO: 3176323: -0.21690620383329084
INFO: 69118816: -0.3023530651113216
INFO: 72422146: -0.6078843537094899
INFO: 47169062: -0.9426407544775031
INFO: 70921285: -0.9501312560280302
INFO: 69273218: -0.9651334549095428
INFO: 1788926: -0.9818661084674193
INFO: 67754922: -0.9905501286202546
INFO: Recommended Keywords
INFO: difference score: -0.82512105
INFO: instance score: -0.8158242
INFO: definition score: -0.8145172
INFO: correct score: -0.81251764
INFO: function score: -0.8102616
INFO: example score: -0.80279034
INFO: define score: -0.80116934
INFO: particular score: -0.7939565
INFO: actual score: -0.78644335
INFO: method score: -0.78041446
INFO: simple score: -0.77900505
INFO: exact score: -0.7701779
INFO: certain score: -0.769688
INFO: object score: -0.7466314
INFO: determine score: -0.74383026
INFO: mean score: -0.7340254
INFO: specific score: -0.73140526
INFO: absolute score: -0.7289288
INFO: case score: -0.72888863
INFO: calculate score: -0.7196462
INFO: value score: -0.71079755
INFO: equate score: -0.70234126
INFO: variable score: -0.6956084
INFO: process score: -0.6876474
INFO: real score: -0.68618274
INFO: reference score: -0.6842827
INFO: equivalent score: -0.6808301
INFO: variables score: -0.669706
INFO: parameter score: -0.6673616
INFO: usage score: -0.6672709
INFO: need score: -0.6644607
INFO: input score: -0.66088146
INFO: type score: -0.65575445
INFO: term score: -0.65543723
INFO: helpful score: -0.65306437
INFO: standard score: -0.65233696
INFO: description score: -0.6471171
INFO: argument score: -0.6434945
INFO: expression score: -0.6367238
INFO: sense score: -0.6330772
INFO: source score: -0.6294477
INFO: mechanism score: -0.62867415
INFO: invoke score: -0.6275898
INFO: arguments score: -0.6212753
INFO: distinguishing score: -0.6174523
INFO: order score: -0.61716115
INFO: alternative score: -0.615902
INFO: similar score: -0.61059546
INFO: information score: -0.608228
INFO: result score: -0.60625505
INFO: positional score: -0.5997811
INFO: question score: -0.59225535
INFO: different score: -0.5890305
INFO: confusing score: -0.5849045
INFO: formal score: -0.58354014
INFO: key score: -0.5820028
INFO: response score: -0.57933897
INFO: mutable score: -0.5744948
INFO: data score: -0.57332087
INFO: immutable score: -0.57250917
INFO: notation score: -0.56792414
INFO: structure score: -0.5671527
INFO: macro score: -0.56681
INFO: code score: -0.56587553
INFO: placeholder score: -0.5616307
INFO: statement score: -0.55905575
INFO: thought score: -0.5578343
INFO: common score: -0.5529928
INFO: view score: -0.55209196
INFO: meaning score: -0.5518979
INFO: address score: -0.5509574
INFO: parenthesis score: -0.5489862
INFO: instantiation score: -0.5475567
INFO: kind score: -0.54690516
INFO: default score: -0.54088557
INFO: easy score: -0.5407803
INFO: output score: -0.5313822
INFO: point score: -0.52955556
INFO: index score: -0.52742726
INFO: perspective score: -0.52723384
INFO: connection score: -0.5231919
INFO: distinction score: -0.5216643
INFO: human score: -0.5191164
INFO: datum score: -0.51908267
INFO: signature score: -0.5084658
INFO: special score: -0.5084631
INFO: natural score: -0.49900663
INFO: message score: -0.49849027
INFO: keyword score: -0.49131307
INFO: person score: -0.48503086
INFO: copy score: -0.48470646
INFO: integer score: -0.47880006
INFO: datatype score: -0.47865176
INFO: much score: -0.47641507
INFO: mnemonic score: -0.46016622
INFO: call score: -0.45533982
INFO: interchangeable score: -0.45440042
INFO: answer score: -0.4530887
INFO: documentation score: -0.44790727
INFO: comma score: -0.4467207
INFO: dilemma score: -0.44427758
INFO: compile score: -0.44403177
INFO: invocation score: -0.44322878
INFO: conceptual score: -0.4411231
INFO: metaphor score: -0.4390021
INFO: blank score: -0.43311065
INFO: bit score: -0.43253607
INFO: body score: -0.42494053
INFO: separate score: -0.4232138
INFO: write score: -0.42225304
INFO: wrong score: -0.42034453
INFO: practice score: -0.41988724
INFO: able score: -0.41921344
INFO: look score: -0.4160939
INFO: let score: -0.4116216
INFO: runtime score: -0.39851925
INFO: thing score: -0.39444494
INFO: machine score: -0.39442298
INFO: oracle score: -0.39226285
INFO: computer score: -0.38566455
INFO: number score: -0.38521773
INFO: convention score: -0.38483927
INFO: info score: -0.3827808
INFO: replace score: -0.3818214
INFO: mind score: -0.3806274
INFO: optional score: -0.3787294
INFO: identifier score: -0.37841734
INFO: f score: -0.37526116
INFO: caller score: -0.36100543
INFO: visible score: -0.35870573
INFO: thesis score: -0.35794967
INFO: remember score: -0.35583073
INFO: constructor score: -0.3535525
INFO: declare score: -0.35212338
INFO: issue score: -0.35109022
INFO: language score: -0.3493784
INFO: dot score: -0.34919974
INFO: well score: -0.34838328
INFO: various score: -0.34638324
INFO: brain score: -0.3456366
INFO: x score: -0.34357738
INFO: programming score: -0.3401961
INFO: time score: -0.33985412
INFO: string score: -0.33920103
INFO: plane score: -0.33657673
INFO: name score: -0.33406943
INFO: programmer score: -0.32980752
INFO: b score: -0.32551205
INFO: arg score: -0.31993425
INFO: myname score: -0.31966367
INFO: declaration score: -0.3175826
INFO: foo score: -0.31592897
INFO: c score: -0.31468672
INFO: fill score: -0.3146089
INFO: text score: -0.31376848
INFO: inside score: -0.3133251
INFO: func score: -0.301632
INFO: role score: -0.30002588
INFO: install score: -0.2987879
INFO: plug score: -0.29619846
INFO: thematic score: -0.29466447
INFO: synonyms score: -0.29394993
INFO: previous score: -0.28837827
INFO: format score: -0.27912477
INFO: position score: -0.27691287
INFO: mathematics score: -0.27579823
INFO: program score: -0.2643959
INFO: opposite score: -0.25802156
INFO: = score: -0.25427115
INFO: pass score: -0.24573332
INFO: main score: -0.2433898
INFO: list score: -0.237061
INFO: stop score: -0.23589025
INFO: toolkit score: -0.2317464
INFO: prototype score: -0.23059045
INFO: java score: -0.2226918
INFO: big score: -0.22132307
INFO: int score: -0.21963711
INFO: socket score: -0.21545178
INFO: sqrt score: -0.213294
INFO: c++ score: -0.20078379
INFO: nice score: -0.19941045
INFO: min score: -0.19588196
INFO: part score: -0.1938169
INFO: lingo score: -0.19297181
INFO: course score: -0.17978531
INFO: tutorial score: -0.17916444
INFO: site score: -0.17276424
INFO: faq score: -0.16918705
INFO: concrete score: -0.16515969
INFO: run score: -0.1631506
INFO: egg score: -0.15963751
INFO: place score: -0.14957988
INFO: money score: -0.14432138
INFO: book score: -0.14300238
INFO: store score: -0.14194795
INFO: wall score: -0.12532575
INFO: people score: -0.11769065
INFO: exam score: -0.11418887
INFO: wikipedia score: -0.103580564
INFO: head score: -0.10004671
INFO: bar score: -0.09673298
INFO: happy score: -0.09671319
INFO: second score: -0.07198114
INFO: day score: -0.071927
INFO: unleaded score: -0.06189624
INFO: monkey score: -0.060583133
INFO: author score: -0.047149703
INFO: community score: -0.033553664
INFO: petrol score: -0.033276435
INFO: next score: -0.027235294
INFO: unicorn score: -0.014011042
INFO: pee score: -0.0071013197
INFO: car score: -0.0034655186
INFO: airplane score: -0.00151903
INFO: printname score: -0.0
INFO: console.log(name score: -0.0
INFO: printname("peter score: -0.0
INFO: mcsd score: -0.0
INFO: cerfification score: -0.0
INFO: basics.both score: -0.0
INFO: f(x score: -0.0
INFO: f(3 score: -0.0
INFO: alabahari score: -0.0
INFO: p. score: -0.0
INFO: savitch score: -0.0
INFO: http://en.wikipedia.org/wiki/parameter_(computer_science)#parameters_and_argument score: -0.0
INFO: kwargs score: -0.0
INFO: somevar score: -0.0
INFO: isinstance score: -0.0
INFO: c. score: -0.0
INFO: fun(arg score: -0.0
INFO: print(arg score: -0.0
INFO: n’t score: -0.0
INFO: italian score: 0.011128264
INFO: def score: 0.016775006
INFO: sausage score: 0.02297461
INFO: professor score: 0.03188509
INFO: breakfast score: 0.051687382
INFO: peter score: 0.0517782
INFO: airline score: 0.06089875
INFO: walter score: 0.06335123
INFO: joseph score: 0.07407981
INFO: seat score: 0.08525626
INFO: russian score: 0.08840631
INFO: passenger score: 0.09639476
INFO: university score: 0.1301
INFO: ============================================================
