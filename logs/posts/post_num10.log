INFO: ============================================================
INFO: Starts Training Model
INFO: ============================================================
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<327 unique tokens: ["'", '+', '2.x', '3.x', '=']...> from 10 documents (total 987 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<327 unique tokens: ["\'", \'+\', \'2.x\', \'3.x\', \'=\']...> from 10 documents (total 987 corpus positions)', 'datetime': '2023-03-22T01:20:57.301325', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.018 per-word bound, 129.6 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"variable" + 0.046*"global" + 0.041*"local" + 0.034*"function" + 0.032*"scope" + 0.024*"c" + 0.021*"name" + 0.020*"assignment" + 0.019*"num" + 0.018*"="
INFO: topic #1 (1.000): 0.050*"variable" + 0.038*"scope" + 0.032*"function" + 0.030*"local" + 0.030*"name" + 0.024*"global" + 0.022*"line" + 0.022*"code" + 0.020*"assignment" + 0.020*"num"
INFO: topic #2 (1.000): 0.063*"variable" + 0.054*"function" + 0.032*"global" + 0.031*"local" + 0.027*"scope" + 0.023*"value" + 0.016*"access" + 0.016*"line" + 0.016*"assignment" + 0.014*"name"
INFO: topic diff=2.773388, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.066 per-word bound, 1071.8 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.085*"variable" + 0.062*"global" + 0.052*"local" + 0.042*"function" + 0.032*"scope" + 0.022*"assignment" + 0.020*"name" + 0.018*"value" + 0.017*"error" + 0.016*"c"
INFO: topic #1 (1.000): 0.045*"variable" + 0.032*"function" + 0.031*"scope" + 0.028*"local" + 0.026*"global" + 0.025*"name" + 0.022*"code" + 0.019*"line" + 0.018*"assignment" + 0.017*"="
INFO: topic #2 (1.000): 0.090*"variable" + 0.079*"function" + 0.072*"global" + 0.041*"local" + 0.036*"value" + 0.031*"var1" + 0.031*"f" + 0.025*"scope" + 0.020*"inside" + 0.012*"assignment"
INFO: topic diff=2.346089, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 57.73947975813855
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.6824005720428952
DEBUG: bound: at document #0
INFO: -5.795 per-word bound, 55.5 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.071*"variable" + 0.046*"global" + 0.043*"local" + 0.036*"function" + 0.034*"scope" + 0.022*"name" + 0.021*"assignment" + 0.021*"c" + 0.018*"line" + 0.018*"num"
INFO: topic #1 (1.000): 0.039*"variable" + 0.028*"function" + 0.026*"scope" + 0.023*"local" + 0.023*"global" + 0.021*"name" + 0.019*"code" + 0.016*"line" + 0.015*"value" + 0.015*"assignment"
INFO: topic #2 (1.000): 0.084*"variable" + 0.080*"function" + 0.067*"global" + 0.039*"value" + 0.035*"local" + 0.024*"var1" + 0.024*"f" + 0.021*"scope" + 0.020*"inside" + 0.016*"other"
INFO: topic diff=0.956630, rho=0.500000
DEBUG: bound: at document #0
INFO: -6.571 per-word bound, 95.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"variable" + 0.046*"local" + 0.045*"global" + 0.036*"function" + 0.034*"scope" + 0.023*"name" + 0.023*"assignment" + 0.018*"c" + 0.017*"line" + 0.017*"error"
INFO: topic #1 (1.000): 0.031*"variable" + 0.023*"function" + 0.020*"scope" + 0.019*"global" + 0.019*"local" + 0.016*"name" + 0.016*"code" + 0.014*"line" + 0.013*"value" + 0.012*"="
INFO: topic #2 (1.000): 0.094*"variable" + 0.089*"global" + 0.076*"function" + 0.043*"f" + 0.043*"var1" + 0.043*"local" + 0.037*"value" + 0.021*"inside" + 0.021*"scope" + 0.013*"work"
INFO: topic diff=1.018942, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 49.75893032723759
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -0.6230021269491387
DEBUG: bound: at document #0
INFO: -5.612 per-word bound, 48.9 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"variable" + 0.041*"local" + 0.041*"global" + 0.034*"scope" + 0.033*"function" + 0.023*"name" + 0.021*"assignment" + 0.021*"c" + 0.019*"line" + 0.018*"num"
INFO: topic #1 (1.000): 0.024*"variable" + 0.018*"function" + 0.016*"scope" + 0.015*"global" + 0.015*"local" + 0.012*"name" + 0.012*"code" + 0.011*"value" + 0.010*"line" + 0.009*"assignment"
INFO: topic #2 (1.000): 0.097*"variable" + 0.088*"global" + 0.087*"function" + 0.041*"value" + 0.040*"local" + 0.034*"var1" + 0.034*"f" + 0.024*"inside" + 0.019*"scope" + 0.013*"other"
INFO: topic diff=0.548602, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.067 per-word bound, 67.0 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"variable" + 0.043*"local" + 0.039*"global" + 0.034*"scope" + 0.033*"function" + 0.024*"name" + 0.023*"assignment" + 0.019*"c" + 0.018*"line" + 0.017*"="
INFO: topic #1 (1.000): 0.018*"variable" + 0.014*"function" + 0.012*"global" + 0.011*"scope" + 0.011*"local" + 0.009*"code" + 0.009*"name" + 0.009*"value" + 0.009*"line" + 0.007*"="
INFO: topic #2 (1.000): 0.102*"variable" + 0.096*"global" + 0.080*"function" + 0.047*"local" + 0.043*"var1" + 0.043*"f" + 0.038*"value" + 0.023*"inside" + 0.020*"scope" + 0.015*"work"
INFO: topic diff=0.545941, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 47.93526448710263
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -0.7311274068470827
DEBUG: bound: at document #0
INFO: -5.560 per-word bound, 47.2 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.064*"variable" + 0.040*"local" + 0.039*"global" + 0.035*"scope" + 0.031*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.019*"line" + 0.018*"num"
INFO: topic #1 (1.000): 0.013*"variable" + 0.010*"function" + 0.009*"global" + 0.009*"scope" + 0.008*"local" + 0.007*"code" + 0.007*"name" + 0.007*"value" + 0.007*"line" + 0.006*"="
INFO: topic #2 (1.000): 0.107*"variable" + 0.096*"global" + 0.091*"function" + 0.045*"local" + 0.041*"value" + 0.035*"var1" + 0.035*"f" + 0.027*"inside" + 0.019*"scope" + 0.015*"work"
INFO: topic diff=0.351889, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.964 per-word bound, 62.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.064*"variable" + 0.041*"local" + 0.037*"global" + 0.034*"scope" + 0.031*"function" + 0.025*"name" + 0.023*"assignment" + 0.019*"c" + 0.019*"line" + 0.018*"="
INFO: topic #1 (1.000): 0.010*"variable" + 0.008*"function" + 0.007*"global" + 0.007*"scope" + 0.006*"local" + 0.006*"code" + 0.006*"name" + 0.006*"value" + 0.005*"line" + 0.005*"="
INFO: topic #2 (1.000): 0.107*"variable" + 0.099*"global" + 0.083*"function" + 0.050*"local" + 0.041*"var1" + 0.041*"f" + 0.038*"value" + 0.024*"inside" + 0.020*"scope" + 0.016*"work"
INFO: topic diff=0.345905, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 47.31817799987499
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -0.7311274068470827
DEBUG: bound: at document #0
INFO: -5.539 per-word bound, 46.5 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.063*"variable" + 0.040*"local" + 0.037*"global" + 0.035*"scope" + 0.030*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.007*"variable" + 0.006*"function" + 0.005*"global" + 0.005*"scope" + 0.005*"local" + 0.005*"code" + 0.005*"name" + 0.005*"value" + 0.005*"line" + 0.004*"="
INFO: topic #2 (1.000): 0.113*"variable" + 0.099*"global" + 0.094*"function" + 0.049*"local" + 0.041*"value" + 0.034*"var1" + 0.034*"f" + 0.028*"inside" + 0.019*"scope" + 0.016*"work"
INFO: topic diff=0.257643, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.925 per-word bound, 60.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.062*"variable" + 0.040*"local" + 0.036*"global" + 0.034*"scope" + 0.030*"function" + 0.025*"name" + 0.024*"assignment" + 0.019*"c" + 0.019*"line" + 0.018*"="
INFO: topic #1 (1.000): 0.006*"variable" + 0.005*"function" + 0.005*"global" + 0.005*"scope" + 0.004*"local" + 0.004*"code" + 0.004*"name" + 0.004*"value" + 0.004*"line" + 0.004*"="
INFO: topic #2 (1.000): 0.110*"variable" + 0.099*"global" + 0.085*"function" + 0.052*"local" + 0.040*"var1" + 0.040*"f" + 0.038*"value" + 0.025*"inside" + 0.021*"scope" + 0.016*"work"
INFO: topic diff=0.248728, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 47.06094035379759
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -0.7311274068470827
DEBUG: bound: at document #0
INFO: -5.529 per-word bound, 46.2 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.062*"variable" + 0.039*"local" + 0.037*"global" + 0.035*"scope" + 0.030*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.005*"variable" + 0.004*"function" + 0.004*"global" + 0.004*"scope" + 0.004*"local" + 0.004*"code" + 0.004*"value" + 0.004*"name" + 0.004*"line" + 0.004*"="
INFO: topic #2 (1.000): 0.115*"variable" + 0.099*"global" + 0.095*"function" + 0.051*"local" + 0.041*"value" + 0.034*"f" + 0.034*"var1" + 0.028*"inside" + 0.020*"scope" + 0.017*"work"
INFO: topic diff=0.207377, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.902 per-word bound, 59.8 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.061*"variable" + 0.040*"local" + 0.036*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.023*"assignment" + 0.020*"c" + 0.019*"line" + 0.018*"="
INFO: topic #1 (1.000): 0.004*"variable" + 0.004*"function" + 0.004*"global" + 0.004*"scope" + 0.004*"local" + 0.004*"code" + 0.004*"value" + 0.004*"name" + 0.003*"line" + 0.003*"="
INFO: topic #2 (1.000): 0.112*"variable" + 0.099*"global" + 0.086*"function" + 0.053*"local" + 0.040*"var1" + 0.040*"f" + 0.038*"value" + 0.025*"inside" + 0.021*"scope" + 0.016*"work"
INFO: topic diff=0.198287, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 46.93036664147941
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -0.7383928087212436
DEBUG: bound: at document #0
INFO: -5.522 per-word bound, 46.0 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.061*"variable" + 0.039*"local" + 0.037*"global" + 0.035*"scope" + 0.029*"function" + 0.025*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.004*"variable" + 0.004*"function" + 0.004*"global" + 0.003*"scope" + 0.003*"local" + 0.003*"code" + 0.003*"value" + 0.003*"name" + 0.003*"line" + 0.003*"="
INFO: topic #2 (1.000): 0.117*"variable" + 0.100*"global" + 0.095*"function" + 0.052*"local" + 0.041*"value" + 0.034*"f" + 0.034*"var1" + 0.028*"inside" + 0.020*"scope" + 0.017*"work"
INFO: topic diff=0.177640, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.887 per-word bound, 59.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.061*"variable" + 0.039*"local" + 0.036*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.023*"assignment" + 0.020*"c" + 0.019*"line" + 0.018*"="
INFO: topic #1 (1.000): 0.004*"variable" + 0.003*"function" + 0.003*"global" + 0.003*"scope" + 0.003*"local" + 0.003*"code" + 0.003*"value" + 0.003*"name" + 0.003*"line" + 0.003*"="
INFO: topic #2 (1.000): 0.113*"variable" + 0.099*"global" + 0.086*"function" + 0.054*"local" + 0.039*"f" + 0.039*"var1" + 0.038*"value" + 0.025*"inside" + 0.021*"scope" + 0.017*"work"
INFO: topic diff=0.170629, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 46.85456212612151
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -0.7383928087212436
DEBUG: bound: at document #0
INFO: -5.518 per-word bound, 45.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.061*"variable" + 0.039*"local" + 0.037*"global" + 0.034*"scope" + 0.029*"function" + 0.025*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.003*"variable" + 0.003*"function" + 0.003*"global" + 0.003*"scope" + 0.003*"local" + 0.003*"code" + 0.003*"value" + 0.003*"name" + 0.003*"line" + 0.003*"="
INFO: topic #2 (1.000): 0.118*"variable" + 0.099*"global" + 0.095*"function" + 0.053*"local" + 0.040*"value" + 0.033*"f" + 0.033*"var1" + 0.028*"inside" + 0.021*"scope" + 0.017*"work"
INFO: topic diff=0.158788, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.877 per-word bound, 58.8 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"variable" + 0.039*"local" + 0.035*"global" + 0.034*"scope" + 0.028*"function" + 0.026*"name" + 0.023*"assignment" + 0.020*"c" + 0.019*"line" + 0.018*"="
INFO: topic #1 (1.000): 0.003*"variable" + 0.003*"function" + 0.003*"global" + 0.003*"scope" + 0.003*"local" + 0.003*"code" + 0.003*"value" + 0.003*"name" + 0.003*"line" + 0.003*"="
INFO: topic #2 (1.000): 0.114*"variable" + 0.099*"global" + 0.086*"function" + 0.054*"local" + 0.038*"f" + 0.038*"var1" + 0.038*"value" + 0.025*"inside" + 0.022*"scope" + 0.017*"work"
INFO: topic diff=0.153729, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 46.80644254862246
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -0.7383928087212436
DEBUG: bound: at document #0
INFO: -5.514 per-word bound, 45.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.061*"variable" + 0.039*"local" + 0.036*"global" + 0.034*"scope" + 0.029*"function" + 0.025*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.003*"variable" + 0.003*"function" + 0.003*"global" + 0.003*"scope" + 0.003*"local" + 0.003*"code" + 0.003*"value" + 0.003*"name" + 0.003*"line" + 0.003*"="
INFO: topic #2 (1.000): 0.118*"variable" + 0.099*"global" + 0.095*"function" + 0.054*"local" + 0.040*"value" + 0.033*"var1" + 0.033*"f" + 0.028*"inside" + 0.021*"scope" + 0.017*"work"
INFO: topic diff=0.145789, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.869 per-word bound, 58.5 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"variable" + 0.039*"local" + 0.035*"global" + 0.034*"scope" + 0.028*"function" + 0.026*"name" + 0.023*"assignment" + 0.020*"c" + 0.019*"line" + 0.018*"="
INFO: topic #1 (1.000): 0.003*"variable" + 0.003*"function" + 0.003*"global" + 0.003*"scope" + 0.003*"local" + 0.003*"code" + 0.003*"value" + 0.003*"name" + 0.003*"line" + 0.003*"="
INFO: topic #2 (1.000): 0.114*"variable" + 0.099*"global" + 0.087*"function" + 0.055*"local" + 0.038*"var1" + 0.038*"f" + 0.038*"value" + 0.025*"inside" + 0.022*"scope" + 0.017*"work"
INFO: topic diff=0.142102, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 46.77350279569799
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -0.7383928087212436
DEBUG: bound: at document #0
INFO: -5.512 per-word bound, 45.6 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"variable" + 0.038*"local" + 0.036*"global" + 0.034*"scope" + 0.029*"function" + 0.025*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.003*"variable" + 0.003*"function" + 0.003*"global" + 0.003*"scope" + 0.003*"local" + 0.003*"code" + 0.003*"value" + 0.003*"name" + 0.003*"line" + 0.003*"="
INFO: topic #2 (1.000): 0.119*"variable" + 0.099*"global" + 0.095*"function" + 0.054*"local" + 0.040*"value" + 0.033*"var1" + 0.033*"f" + 0.028*"inside" + 0.021*"scope" + 0.017*"work"
INFO: topic diff=0.136008, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.863 per-word bound, 58.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"variable" + 0.039*"local" + 0.035*"global" + 0.034*"scope" + 0.028*"function" + 0.026*"name" + 0.023*"assignment" + 0.020*"c" + 0.020*"line" + 0.018*"="
INFO: topic #1 (1.000): 0.003*"variable" + 0.003*"function" + 0.003*"global" + 0.003*"scope" + 0.003*"local" + 0.003*"code" + 0.003*"value" + 0.003*"name" + 0.003*"line" + 0.003*"="
INFO: topic #2 (1.000): 0.114*"variable" + 0.099*"global" + 0.087*"function" + 0.055*"local" + 0.038*"var1" + 0.038*"f" + 0.038*"value" + 0.025*"inside" + 0.022*"scope" + 0.017*"work"
INFO: topic diff=0.133246, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 46.75032765288948
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -0.7383928087212436
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5> in 0.20s', 'datetime': '2023-03-22T01:20:57.553458', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: <<Training Time>>: 0.257188081741333
INFO: topic #0 (1.000): 0.060*"variable" + 0.039*"local" + 0.035*"global" + 0.034*"scope" + 0.028*"function" + 0.026*"name" + 0.023*"assignment" + 0.020*"c" + 0.020*"line" + 0.018*"="
INFO: topic #1 (1.000): 0.003*"variable" + 0.003*"function" + 0.003*"global" + 0.003*"scope" + 0.003*"local" + 0.003*"code" + 0.003*"value" + 0.003*"name" + 0.003*"line" + 0.003*"="
INFO: topic #2 (1.000): 0.114*"variable" + 0.099*"global" + 0.087*"function" + 0.055*"local" + 0.038*"var1" + 0.038*"f" + 0.038*"value" + 0.025*"inside" + 0.022*"scope" + 0.017*"work"
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/post_num/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-22T01:20:57.554239', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/post_num/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model.state
DEBUG: {'uri': 'model/post_num/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/post_num/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-22T01:20:57.561085', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/post_num/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/post_num/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model
INFO: ============================================================
INFO: Starts Training Model
INFO: ============================================================
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<327 unique tokens: ["'", '+', '2.x', '3.x', '=']...> from 10 documents (total 987 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<327 unique tokens: ["\'", \'+\', \'2.x\', \'3.x\', \'=\']...> from 10 documents (total 987 corpus positions)', 'datetime': '2023-03-22T01:20:57.568162', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.035 per-word bound, 131.1 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"variable" + 0.052*"global" + 0.042*"local" + 0.035*"function" + 0.025*"scope" + 0.021*"assignment" + 0.021*"name" + 0.020*"value" + 0.019*"c" + 0.017*"error"
INFO: topic #1 (1.000): 0.066*"variable" + 0.037*"function" + 0.037*"local" + 0.037*"scope" + 0.035*"global" + 0.024*"name" + 0.022*"c" + 0.021*"num" + 0.020*"assignment" + 0.020*"line"
INFO: topic #2 (1.000): 0.045*"global" + 0.044*"variable" + 0.034*"local" + 0.028*"scope" + 0.026*"function" + 0.018*"value" + 0.017*"c" + 0.017*"error" + 0.016*"assignment" + 0.016*"line"
INFO: topic diff=2.586943, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.246 per-word bound, 1214.0 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.102*"variable" + 0.088*"global" + 0.059*"function" + 0.054*"local" + 0.029*"value" + 0.028*"scope" + 0.018*"assignment" + 0.017*"inside" + 0.017*"name" + 0.016*"error"
INFO: topic #1 (1.000): 0.074*"variable" + 0.045*"function" + 0.044*"local" + 0.037*"global" + 0.035*"scope" + 0.023*"name" + 0.022*"assignment" + 0.017*"c" + 0.016*"line" + 0.016*"num"
INFO: topic #2 (1.000): 0.062*"global" + 0.043*"variable" + 0.034*"function" + 0.033*"local" + 0.030*"value" + 0.023*"scope" + 0.013*"code" + 0.013*"line" + 0.013*"f" + 0.013*"var1"
INFO: topic diff=2.385458, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 59.3569482290635
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.7526903034779203
DEBUG: bound: at document #0
INFO: -5.799 per-word bound, 55.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.113*"variable" + 0.085*"global" + 0.077*"function" + 0.054*"local" + 0.033*"value" + 0.028*"scope" + 0.021*"inside" + 0.020*"access" + 0.017*"assignment" + 0.015*"error"
INFO: topic #1 (1.000): 0.062*"variable" + 0.039*"local" + 0.037*"global" + 0.034*"scope" + 0.032*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"num" + 0.020*"line"
INFO: topic #2 (1.000): 0.050*"global" + 0.035*"variable" + 0.029*"value" + 0.028*"function" + 0.026*"local" + 0.018*"scope" + 0.011*"code" + 0.011*"appropriate" + 0.010*"loop" + 0.010*"line"
INFO: topic diff=1.103506, rho=0.500000
DEBUG: bound: at document #0
INFO: -6.816 per-word bound, 112.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.112*"variable" + 0.092*"global" + 0.074*"function" + 0.055*"local" + 0.031*"f" + 0.031*"var1" + 0.029*"scope" + 0.026*"value" + 0.021*"inside" + 0.016*"work"
INFO: topic #1 (1.000): 0.063*"variable" + 0.041*"local" + 0.035*"global" + 0.033*"scope" + 0.033*"function" + 0.024*"name" + 0.022*"assignment" + 0.020*"c" + 0.018*"=" + 0.018*"line"
INFO: topic #2 (1.000): 0.051*"value" + 0.045*"global" + 0.025*"condition" + 0.022*"function" + 0.021*"variable" + 0.018*"local" + 0.017*"comment" + 0.017*"instance" + 0.017*"bit" + 0.017*"execute"
INFO: topic diff=1.151386, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 48.64438322140973
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -3.8504062945014357
DEBUG: bound: at document #0
INFO: -5.605 per-word bound, 48.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.089*"global" + 0.088*"function" + 0.055*"local" + 0.029*"scope" + 0.029*"value" + 0.023*"inside" + 0.022*"var1" + 0.022*"f" + 0.021*"access"
INFO: topic #1 (1.000): 0.060*"variable" + 0.038*"local" + 0.036*"global" + 0.034*"scope" + 0.029*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.048*"value" + 0.034*"global" + 0.019*"appropriate" + 0.018*"condition" + 0.018*"function" + 0.016*"variable" + 0.014*"local" + 0.013*"instance" + 0.013*"execute" + 0.013*"bit"
INFO: topic diff=0.634543, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.016 per-word bound, 64.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.115*"variable" + 0.095*"global" + 0.080*"function" + 0.055*"local" + 0.036*"var1" + 0.036*"f" + 0.029*"scope" + 0.024*"value" + 0.022*"inside" + 0.017*"work"
INFO: topic #1 (1.000): 0.061*"variable" + 0.040*"local" + 0.035*"global" + 0.032*"scope" + 0.030*"function" + 0.024*"name" + 0.022*"assignment" + 0.020*"c" + 0.019*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.071*"value" + 0.039*"condition" + 0.030*"global" + 0.023*"execute" + 0.023*"define" + 0.023*"instance" + 0.023*"long" + 0.023*"bit" + 0.023*"comment" + 0.022*"force"
INFO: topic diff=0.650345, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 46.69915948945246
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -3.1842166666558787
DEBUG: bound: at document #0
INFO: -5.554 per-word bound, 47.0 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.122*"variable" + 0.092*"global" + 0.092*"function" + 0.056*"local" + 0.029*"scope" + 0.027*"f" + 0.027*"var1" + 0.026*"value" + 0.024*"inside" + 0.021*"access"
INFO: topic #1 (1.000): 0.059*"variable" + 0.038*"local" + 0.036*"global" + 0.034*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.066*"value" + 0.028*"condition" + 0.024*"appropriate" + 0.022*"global" + 0.017*"define" + 0.017*"execute" + 0.017*"long" + 0.017*"comment" + 0.017*"bit" + 0.017*"instance"
INFO: topic diff=0.331230, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.882 per-word bound, 59.0 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.116*"variable" + 0.097*"global" + 0.083*"function" + 0.056*"local" + 0.037*"var1" + 0.037*"f" + 0.029*"scope" + 0.023*"inside" + 0.022*"value" + 0.017*"work"
INFO: topic #1 (1.000): 0.060*"variable" + 0.040*"local" + 0.035*"global" + 0.032*"scope" + 0.029*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.085*"value" + 0.045*"condition" + 0.024*"bit" + 0.024*"long" + 0.024*"define" + 0.024*"execute" + 0.024*"comment" + 0.024*"instance" + 0.024*"force" + 0.024*"coffee_machine"
INFO: topic diff=0.408015, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 46.1391483090734
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -3.2793759204539357
DEBUG: bound: at document #0
INFO: -5.534 per-word bound, 46.3 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.122*"variable" + 0.094*"global" + 0.093*"function" + 0.056*"local" + 0.029*"scope" + 0.028*"f" + 0.028*"var1" + 0.024*"inside" + 0.024*"value" + 0.021*"access"
INFO: topic #1 (1.000): 0.059*"variable" + 0.038*"local" + 0.036*"global" + 0.033*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.079*"value" + 0.033*"condition" + 0.026*"appropriate" + 0.018*"long" + 0.018*"define" + 0.018*"execute" + 0.018*"comment" + 0.018*"instance" + 0.018*"bit" + 0.018*"force"
INFO: topic diff=0.218115, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.837 per-word bound, 57.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.117*"variable" + 0.098*"global" + 0.084*"function" + 0.056*"local" + 0.037*"var1" + 0.037*"f" + 0.029*"scope" + 0.023*"inside" + 0.021*"value" + 0.017*"work"
INFO: topic #1 (1.000): 0.060*"variable" + 0.040*"local" + 0.035*"global" + 0.032*"scope" + 0.029*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.094*"value" + 0.047*"condition" + 0.025*"bit" + 0.025*"long" + 0.025*"define" + 0.025*"execute" + 0.025*"comment" + 0.025*"instance" + 0.025*"force" + 0.025*"coffee_machine"
INFO: topic diff=0.290295, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 45.92623110355607
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -3.2793759204539357
DEBUG: bound: at document #0
INFO: -5.524 per-word bound, 46.0 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.122*"variable" + 0.095*"global" + 0.093*"function" + 0.056*"local" + 0.029*"scope" + 0.029*"f" + 0.029*"var1" + 0.025*"inside" + 0.023*"value" + 0.021*"access"
INFO: topic #1 (1.000): 0.059*"variable" + 0.038*"local" + 0.036*"global" + 0.033*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.087*"value" + 0.035*"condition" + 0.027*"appropriate" + 0.019*"long" + 0.019*"define" + 0.019*"execute" + 0.019*"comment" + 0.019*"instance" + 0.019*"bit" + 0.019*"force"
INFO: topic diff=0.191257, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.816 per-word bound, 56.3 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.117*"variable" + 0.099*"global" + 0.085*"function" + 0.056*"local" + 0.037*"var1" + 0.037*"f" + 0.029*"scope" + 0.023*"inside" + 0.021*"value" + 0.017*"work"
INFO: topic #1 (1.000): 0.060*"variable" + 0.039*"local" + 0.035*"global" + 0.032*"scope" + 0.029*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.099*"value" + 0.048*"condition" + 0.025*"instance" + 0.025*"comment" + 0.025*"execute" + 0.025*"bit" + 0.025*"define" + 0.025*"long" + 0.025*"start" + 0.025*"coffee_machine"
INFO: topic diff=0.231318, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 45.824304470089714
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -3.2793759204539357
DEBUG: bound: at document #0
INFO: -5.517 per-word bound, 45.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.122*"variable" + 0.096*"global" + 0.093*"function" + 0.056*"local" + 0.029*"scope" + 0.029*"f" + 0.029*"var1" + 0.025*"inside" + 0.023*"value" + 0.021*"access"
INFO: topic #1 (1.000): 0.059*"variable" + 0.038*"local" + 0.036*"global" + 0.033*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.092*"value" + 0.036*"condition" + 0.027*"appropriate" + 0.019*"long" + 0.019*"comment" + 0.019*"bit" + 0.019*"execute" + 0.019*"instance" + 0.019*"define" + 0.019*"force"
INFO: topic diff=0.181180, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.804 per-word bound, 55.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.117*"variable" + 0.099*"global" + 0.085*"function" + 0.056*"local" + 0.037*"f" + 0.037*"var1" + 0.029*"scope" + 0.024*"inside" + 0.020*"value" + 0.017*"work"
INFO: topic #1 (1.000): 0.059*"variable" + 0.039*"local" + 0.035*"global" + 0.032*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.103*"value" + 0.048*"condition" + 0.025*"define" + 0.025*"execute" + 0.025*"instance" + 0.025*"long" + 0.025*"comment" + 0.025*"bit" + 0.025*"start" + 0.025*"force"
INFO: topic diff=0.199426, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 45.76505743508996
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -3.2793759204539357
DEBUG: bound: at document #0
INFO: -5.512 per-word bound, 45.6 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.122*"variable" + 0.096*"global" + 0.093*"function" + 0.056*"local" + 0.029*"f" + 0.029*"var1" + 0.029*"scope" + 0.025*"inside" + 0.022*"value" + 0.020*"access"
INFO: topic #1 (1.000): 0.059*"variable" + 0.038*"local" + 0.036*"global" + 0.033*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.095*"value" + 0.036*"condition" + 0.026*"appropriate" + 0.019*"define" + 0.019*"execute" + 0.019*"instance" + 0.019*"bit" + 0.019*"long" + 0.019*"comment" + 0.019*"force"
INFO: topic diff=0.173069, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.795 per-word bound, 55.5 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.117*"variable" + 0.099*"global" + 0.086*"function" + 0.056*"local" + 0.036*"f" + 0.036*"var1" + 0.029*"scope" + 0.024*"inside" + 0.020*"value" + 0.017*"work"
INFO: topic #1 (1.000): 0.059*"variable" + 0.039*"local" + 0.035*"global" + 0.032*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.105*"value" + 0.048*"condition" + 0.025*"define" + 0.025*"execute" + 0.025*"instance" + 0.025*"long" + 0.025*"comment" + 0.025*"bit" + 0.025*"start" + 0.025*"force"
INFO: topic diff=0.179992, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 45.726400347025546
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -3.2793759204539357
DEBUG: bound: at document #0
INFO: -5.508 per-word bound, 45.5 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.122*"variable" + 0.096*"global" + 0.093*"function" + 0.056*"local" + 0.030*"f" + 0.030*"var1" + 0.029*"scope" + 0.025*"inside" + 0.022*"value" + 0.020*"access"
INFO: topic #1 (1.000): 0.059*"variable" + 0.038*"local" + 0.036*"global" + 0.033*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.098*"value" + 0.037*"condition" + 0.026*"appropriate" + 0.020*"define" + 0.020*"comment" + 0.020*"bit" + 0.020*"long" + 0.020*"execute" + 0.020*"instance" + 0.019*"force"
INFO: topic diff=0.165148, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.788 per-word bound, 55.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.118*"variable" + 0.099*"global" + 0.086*"function" + 0.056*"local" + 0.036*"f" + 0.036*"var1" + 0.029*"scope" + 0.024*"inside" + 0.020*"value" + 0.017*"work"
INFO: topic #1 (1.000): 0.059*"variable" + 0.039*"local" + 0.035*"global" + 0.032*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.106*"value" + 0.047*"condition" + 0.025*"instance" + 0.025*"long" + 0.025*"comment" + 0.025*"bit" + 0.025*"execute" + 0.025*"define" + 0.025*"force" + 0.025*"start"
INFO: topic diff=0.166625, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 45.698983045416206
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -3.2793759204539357
DEBUG: bound: at document #0
INFO: -5.505 per-word bound, 45.4 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.122*"variable" + 0.097*"global" + 0.093*"function" + 0.056*"local" + 0.030*"f" + 0.030*"var1" + 0.029*"scope" + 0.025*"inside" + 0.022*"value" + 0.020*"access"
INFO: topic #1 (1.000): 0.059*"variable" + 0.038*"local" + 0.036*"global" + 0.033*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.099*"value" + 0.037*"condition" + 0.026*"appropriate" + 0.020*"instance" + 0.020*"comment" + 0.020*"bit" + 0.020*"execute" + 0.020*"define" + 0.020*"long" + 0.020*"force"
INFO: topic diff=0.157424, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.782 per-word bound, 55.0 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.118*"variable" + 0.099*"global" + 0.086*"function" + 0.056*"local" + 0.036*"var1" + 0.036*"f" + 0.029*"scope" + 0.024*"inside" + 0.020*"value" + 0.017*"work"
INFO: topic #1 (1.000): 0.059*"variable" + 0.039*"local" + 0.035*"global" + 0.032*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.107*"value" + 0.047*"condition" + 0.024*"bit" + 0.024*"long" + 0.024*"define" + 0.024*"comment" + 0.024*"execute" + 0.024*"instance" + 0.024*"coffee_machine" + 0.024*"force"
INFO: topic diff=0.156621, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 45.67777928330822
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -3.2793759204539357
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5> in 0.19s', 'datetime': '2023-03-22T01:20:57.757978', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: <<Training Time>>: 0.19303274154663086
INFO: topic #0 (1.000): 0.118*"variable" + 0.099*"global" + 0.086*"function" + 0.056*"local" + 0.036*"var1" + 0.036*"f" + 0.029*"scope" + 0.024*"inside" + 0.020*"value" + 0.017*"work"
INFO: topic #1 (1.000): 0.059*"variable" + 0.039*"local" + 0.035*"global" + 0.032*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.107*"value" + 0.047*"condition" + 0.024*"bit" + 0.024*"long" + 0.024*"define" + 0.024*"comment" + 0.024*"execute" + 0.024*"instance" + 0.024*"coffee_machine" + 0.024*"force"
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/post_num/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-22T01:20:57.758546', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/post_num/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model.state
DEBUG: {'uri': 'model/post_num/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/post_num/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-22T01:20:57.763681', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/post_num/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/post_num/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model
INFO: ============================================================
INFO: Starts Training Model
INFO: ============================================================
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<327 unique tokens: ["'", '+', '2.x', '3.x', '=']...> from 10 documents (total 987 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<327 unique tokens: ["\'", \'+\', \'2.x\', \'3.x\', \'=\']...> from 10 documents (total 987 corpus positions)', 'datetime': '2023-03-22T01:20:57.770355', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.044 per-word bound, 132.0 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.071*"variable" + 0.041*"function" + 0.039*"global" + 0.037*"local" + 0.025*"scope" + 0.021*"name" + 0.020*"=" + 0.020*"c" + 0.019*"value" + 0.017*"assignment"
INFO: topic #1 (1.000): 0.081*"variable" + 0.043*"global" + 0.036*"scope" + 0.035*"local" + 0.034*"function" + 0.020*"assignment" + 0.018*"name" + 0.017*"num" + 0.016*"=" + 0.016*"c"
INFO: topic #2 (1.000): 0.052*"variable" + 0.040*"local" + 0.040*"global" + 0.037*"scope" + 0.033*"function" + 0.025*"name" + 0.024*"c" + 0.022*"line" + 0.022*"num" + 0.021*"assignment"
INFO: topic diff=2.363534, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.538 per-word bound, 1486.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.078*"variable" + 0.058*"global" + 0.056*"function" + 0.043*"local" + 0.032*"value" + 0.022*"scope" + 0.018*"name" + 0.016*"assignment" + 0.015*"=" + 0.015*"error"
INFO: topic #1 (1.000): 0.111*"variable" + 0.076*"global" + 0.053*"function" + 0.050*"local" + 0.037*"scope" + 0.019*"assignment" + 0.016*"value" + 0.016*"code" + 0.016*"name" + 0.014*"inside"
INFO: topic #2 (1.000): 0.055*"variable" + 0.046*"local" + 0.043*"global" + 0.039*"function" + 0.032*"scope" + 0.023*"name" + 0.023*"assignment" + 0.019*"value" + 0.019*"line" + 0.018*"c"
INFO: topic diff=2.179810, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 66.7376496521463
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.6186151564667189
DEBUG: bound: at document #0
INFO: -5.965 per-word bound, 62.5 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.079*"variable" + 0.053*"function" + 0.046*"global" + 0.040*"value" + 0.034*"local" + 0.024*"program" + 0.021*"scope" + 0.018*"loop" + 0.017*"access" + 0.014*"class"
INFO: topic #1 (1.000): 0.119*"variable" + 0.077*"global" + 0.066*"function" + 0.050*"local" + 0.036*"scope" + 0.018*"assignment" + 0.017*"value" + 0.017*"inside" + 0.015*"work" + 0.013*"error"
INFO: topic #2 (1.000): 0.057*"variable" + 0.040*"local" + 0.040*"global" + 0.034*"scope" + 0.031*"function" + 0.025*"name" + 0.023*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"num"
INFO: topic diff=1.311055, rho=0.500000
DEBUG: bound: at document #0
INFO: -7.039 per-word bound, 131.5 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.061*"variable" + 0.056*"value" + 0.050*"function" + 0.046*"global" + 0.029*"local" + 0.018*"program" + 0.016*"loop" + 0.016*"scope" + 0.014*"code" + 0.012*"access"
INFO: topic #1 (1.000): 0.115*"variable" + 0.087*"global" + 0.067*"function" + 0.054*"local" + 0.033*"var1" + 0.033*"f" + 0.032*"scope" + 0.019*"inside" + 0.017*"value" + 0.016*"work"
INFO: topic #2 (1.000): 0.057*"variable" + 0.042*"local" + 0.038*"global" + 0.032*"scope" + 0.031*"function" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic diff=1.227377, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 49.26503109872189
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.4884098665733303
DEBUG: bound: at document #0
INFO: -5.595 per-word bound, 48.3 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.062*"variable" + 0.058*"value" + 0.039*"function" + 0.037*"program" + 0.031*"global" + 0.029*"loop" + 0.024*"access" + 0.020*"local" + 0.019*"class" + 0.019*"definition"
INFO: topic #1 (1.000): 0.124*"variable" + 0.088*"global" + 0.082*"function" + 0.055*"local" + 0.032*"scope" + 0.025*"f" + 0.025*"var1" + 0.022*"inside" + 0.017*"value" + 0.017*"work"
INFO: topic #2 (1.000): 0.057*"variable" + 0.040*"local" + 0.039*"global" + 0.034*"scope" + 0.030*"function" + 0.026*"name" + 0.023*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"num"
INFO: topic diff=0.835131, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.152 per-word bound, 71.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"value" + 0.046*"variable" + 0.034*"function" + 0.030*"global" + 0.026*"program" + 0.025*"loop" + 0.017*"access" + 0.016*"local" + 0.016*"code" + 0.015*"condition"
INFO: topic #1 (1.000): 0.117*"variable" + 0.094*"global" + 0.076*"function" + 0.056*"local" + 0.037*"var1" + 0.037*"f" + 0.031*"scope" + 0.022*"inside" + 0.017*"work" + 0.017*"value"
INFO: topic #2 (1.000): 0.057*"variable" + 0.041*"local" + 0.037*"global" + 0.032*"scope" + 0.030*"function" + 0.025*"name" + 0.023*"assignment" + 0.022*"c" + 0.020*"line" + 0.019*"="
INFO: topic diff=0.679378, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 46.395237025796696
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -1.9068506292785825
DEBUG: bound: at document #0
INFO: -5.515 per-word bound, 45.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"value" + 0.049*"variable" + 0.043*"program" + 0.036*"loop" + 0.026*"access" + 0.023*"function" + 0.022*"class" + 0.022*"definition" + 0.020*"test" + 0.019*"global"
INFO: topic #1 (1.000): 0.126*"variable" + 0.093*"global" + 0.090*"function" + 0.057*"local" + 0.031*"scope" + 0.028*"var1" + 0.028*"f" + 0.025*"inside" + 0.018*"value" + 0.017*"work"
INFO: topic #2 (1.000): 0.058*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.023*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"num"
INFO: topic diff=0.483519, rho=0.408248
DEBUG: bound: at document #0
INFO: -6.003 per-word bound, 64.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.081*"value" + 0.037*"variable" + 0.031*"program" + 0.031*"loop" + 0.020*"condition" + 0.020*"function" + 0.019*"access" + 0.017*"code" + 0.017*"global" + 0.016*"class"
INFO: topic #1 (1.000): 0.118*"variable" + 0.097*"global" + 0.081*"function" + 0.057*"local" + 0.038*"var1" + 0.038*"f" + 0.030*"scope" + 0.023*"inside" + 0.017*"work" + 0.017*"value"
INFO: topic #2 (1.000): 0.058*"variable" + 0.041*"local" + 0.037*"global" + 0.033*"scope" + 0.030*"function" + 0.025*"name" + 0.023*"assignment" + 0.022*"c" + 0.020*"line" + 0.020*"="
INFO: topic diff=0.402132, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 45.41993298289685
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -1.8634193650961433
DEBUG: bound: at document #0
INFO: -5.482 per-word bound, 44.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.072*"value" + 0.047*"program" + 0.042*"variable" + 0.039*"loop" + 0.025*"access" + 0.024*"class" + 0.024*"definition" + 0.022*"test" + 0.017*"code" + 0.013*"function"
INFO: topic #1 (1.000): 0.126*"variable" + 0.096*"global" + 0.093*"function" + 0.058*"local" + 0.031*"scope" + 0.029*"var1" + 0.029*"f" + 0.025*"inside" + 0.018*"value" + 0.017*"work"
INFO: topic #2 (1.000): 0.058*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.023*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"num"
INFO: topic diff=0.325495, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.946 per-word bound, 61.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.084*"value" + 0.034*"program" + 0.034*"loop" + 0.033*"variable" + 0.023*"condition" + 0.018*"access" + 0.018*"code" + 0.018*"class" + 0.018*"definition" + 0.016*"test"
INFO: topic #1 (1.000): 0.119*"variable" + 0.099*"global" + 0.084*"function" + 0.057*"local" + 0.038*"f" + 0.038*"var1" + 0.030*"scope" + 0.024*"inside" + 0.018*"value" + 0.017*"work"
INFO: topic #2 (1.000): 0.058*"variable" + 0.041*"local" + 0.037*"global" + 0.033*"scope" + 0.030*"function" + 0.025*"name" + 0.023*"assignment" + 0.022*"c" + 0.020*"line" + 0.020*"="
INFO: topic diff=0.291377, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 44.960741509312165
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -2.0551435451014926
DEBUG: bound: at document #0
INFO: -5.464 per-word bound, 44.1 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.074*"value" + 0.048*"program" + 0.041*"loop" + 0.039*"variable" + 0.025*"class" + 0.025*"definition" + 0.023*"test" + 0.022*"access" + 0.018*"code" + 0.014*"condition"
INFO: topic #1 (1.000): 0.126*"variable" + 0.097*"global" + 0.095*"function" + 0.058*"local" + 0.030*"scope" + 0.030*"f" + 0.030*"var1" + 0.025*"inside" + 0.019*"value" + 0.017*"work"
INFO: topic #2 (1.000): 0.058*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.023*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"num"
INFO: topic diff=0.268506, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.915 per-word bound, 60.3 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.085*"value" + 0.036*"loop" + 0.036*"program" + 0.030*"variable" + 0.026*"condition" + 0.019*"code" + 0.018*"class" + 0.018*"definition" + 0.017*"test" + 0.016*"access"
INFO: topic #1 (1.000): 0.119*"variable" + 0.100*"global" + 0.085*"function" + 0.057*"local" + 0.037*"f" + 0.037*"var1" + 0.030*"scope" + 0.024*"inside" + 0.018*"value" + 0.017*"work"
INFO: topic #2 (1.000): 0.058*"variable" + 0.041*"local" + 0.037*"global" + 0.033*"scope" + 0.030*"function" + 0.025*"name" + 0.023*"assignment" + 0.022*"c" + 0.021*"line" + 0.020*"="
INFO: topic diff=0.244713, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 44.721019625146305
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -2.056402056485162
DEBUG: bound: at document #0
INFO: -5.453 per-word bound, 43.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.075*"value" + 0.049*"program" + 0.042*"loop" + 0.036*"variable" + 0.025*"class" + 0.025*"definition" + 0.024*"test" + 0.019*"access" + 0.018*"code" + 0.016*"condition"
INFO: topic #1 (1.000): 0.126*"variable" + 0.098*"global" + 0.095*"function" + 0.057*"local" + 0.030*"scope" + 0.030*"var1" + 0.030*"f" + 0.025*"inside" + 0.019*"value" + 0.017*"work"
INFO: topic #2 (1.000): 0.058*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.023*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"num"
INFO: topic diff=0.233689, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.896 per-word bound, 59.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.085*"value" + 0.037*"loop" + 0.037*"program" + 0.029*"variable" + 0.027*"condition" + 0.019*"class" + 0.019*"definition" + 0.019*"code" + 0.018*"test" + 0.015*"bit"
INFO: topic #1 (1.000): 0.119*"variable" + 0.100*"global" + 0.086*"function" + 0.057*"local" + 0.037*"var1" + 0.037*"f" + 0.030*"scope" + 0.024*"inside" + 0.018*"value" + 0.017*"work"
INFO: topic #2 (1.000): 0.058*"variable" + 0.041*"local" + 0.037*"global" + 0.033*"scope" + 0.030*"function" + 0.025*"name" + 0.023*"assignment" + 0.022*"c" + 0.021*"line" + 0.020*"="
INFO: topic diff=0.216508, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 44.57968925583676
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -2.6273940591331617
DEBUG: bound: at document #0
INFO: -5.445 per-word bound, 43.6 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.075*"value" + 0.049*"program" + 0.043*"loop" + 0.035*"variable" + 0.025*"class" + 0.025*"definition" + 0.024*"test" + 0.018*"code" + 0.017*"condition" + 0.017*"access"
INFO: topic #1 (1.000): 0.125*"variable" + 0.098*"global" + 0.095*"function" + 0.057*"local" + 0.030*"scope" + 0.030*"f" + 0.030*"var1" + 0.025*"inside" + 0.020*"value" + 0.017*"work"
INFO: topic #2 (1.000): 0.058*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.023*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"num"
INFO: topic diff=0.208770, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.884 per-word bound, 59.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.085*"value" + 0.038*"loop" + 0.038*"program" + 0.028*"variable" + 0.028*"condition" + 0.019*"class" + 0.019*"definition" + 0.019*"code" + 0.019*"test" + 0.015*"bit"
INFO: topic #1 (1.000): 0.119*"variable" + 0.100*"global" + 0.086*"function" + 0.057*"local" + 0.037*"var1" + 0.037*"f" + 0.030*"scope" + 0.024*"inside" + 0.019*"value" + 0.017*"work"
INFO: topic #2 (1.000): 0.059*"variable" + 0.041*"local" + 0.037*"global" + 0.033*"scope" + 0.030*"function" + 0.025*"name" + 0.023*"assignment" + 0.022*"c" + 0.021*"line" + 0.020*"="
INFO: topic diff=0.196893, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 44.48493780054121
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -2.6273940591331617
DEBUG: bound: at document #0
INFO: -5.439 per-word bound, 43.4 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.075*"value" + 0.050*"program" + 0.044*"loop" + 0.034*"variable" + 0.025*"class" + 0.025*"definition" + 0.024*"test" + 0.019*"code" + 0.018*"condition" + 0.015*"access"
INFO: topic #1 (1.000): 0.125*"variable" + 0.098*"global" + 0.095*"function" + 0.057*"local" + 0.030*"scope" + 0.030*"f" + 0.030*"var1" + 0.025*"inside" + 0.020*"value" + 0.017*"work"
INFO: topic #2 (1.000): 0.058*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.023*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"num"
INFO: topic diff=0.191157, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.875 per-word bound, 58.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.084*"value" + 0.039*"loop" + 0.038*"program" + 0.028*"condition" + 0.028*"variable" + 0.020*"class" + 0.020*"definition" + 0.019*"code" + 0.019*"test" + 0.015*"bit"
INFO: topic #1 (1.000): 0.119*"variable" + 0.100*"global" + 0.087*"function" + 0.057*"local" + 0.037*"var1" + 0.037*"f" + 0.030*"scope" + 0.024*"inside" + 0.019*"value" + 0.017*"work"
INFO: topic #2 (1.000): 0.059*"variable" + 0.041*"local" + 0.037*"global" + 0.033*"scope" + 0.030*"function" + 0.025*"name" + 0.023*"assignment" + 0.022*"c" + 0.021*"line" + 0.020*"="
INFO: topic diff=0.182033, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 44.42353682757957
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -2.618114333440604
DEBUG: bound: at document #0
INFO: -5.435 per-word bound, 43.2 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.075*"value" + 0.050*"program" + 0.044*"loop" + 0.033*"variable" + 0.025*"class" + 0.025*"definition" + 0.024*"test" + 0.019*"code" + 0.019*"condition" + 0.014*"access"
INFO: topic #1 (1.000): 0.125*"variable" + 0.098*"global" + 0.094*"function" + 0.057*"local" + 0.031*"scope" + 0.030*"f" + 0.030*"var1" + 0.025*"inside" + 0.020*"value" + 0.017*"work"
INFO: topic #2 (1.000): 0.058*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.023*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"num"
INFO: topic diff=0.178342, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.869 per-word bound, 58.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.084*"value" + 0.039*"loop" + 0.039*"program" + 0.028*"condition" + 0.027*"variable" + 0.020*"class" + 0.020*"definition" + 0.019*"code" + 0.019*"test" + 0.015*"bit"
INFO: topic #1 (1.000): 0.120*"variable" + 0.100*"global" + 0.087*"function" + 0.056*"local" + 0.036*"var1" + 0.036*"f" + 0.030*"scope" + 0.024*"inside" + 0.019*"value" + 0.017*"work"
INFO: topic #2 (1.000): 0.059*"variable" + 0.041*"local" + 0.037*"global" + 0.033*"scope" + 0.030*"function" + 0.025*"name" + 0.023*"assignment" + 0.022*"c" + 0.021*"line" + 0.020*"="
INFO: topic diff=0.170401, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 44.3860347002454
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -2.618114333440604
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5> in 0.21s', 'datetime': '2023-03-22T01:20:57.977796', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: <<Training Time>>: 0.21059083938598633
INFO: topic #0 (1.000): 0.084*"value" + 0.039*"loop" + 0.039*"program" + 0.028*"condition" + 0.027*"variable" + 0.020*"class" + 0.020*"definition" + 0.019*"code" + 0.019*"test" + 0.015*"bit"
INFO: topic #1 (1.000): 0.120*"variable" + 0.100*"global" + 0.087*"function" + 0.056*"local" + 0.036*"var1" + 0.036*"f" + 0.030*"scope" + 0.024*"inside" + 0.019*"value" + 0.017*"work"
INFO: topic #2 (1.000): 0.059*"variable" + 0.041*"local" + 0.037*"global" + 0.033*"scope" + 0.030*"function" + 0.025*"name" + 0.023*"assignment" + 0.022*"c" + 0.021*"line" + 0.020*"="
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/post_num/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-22T01:20:57.978352', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/post_num/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model.state
DEBUG: {'uri': 'model/post_num/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/post_num/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-22T01:20:57.980938', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/post_num/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/post_num/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model
INFO: ============================================================
INFO: Starts Training Model
INFO: ============================================================
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<327 unique tokens: ["'", '+', '2.x', '3.x', '=']...> from 10 documents (total 987 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<327 unique tokens: ["\'", \'+\', \'2.x\', \'3.x\', \'=\']...> from 10 documents (total 987 corpus positions)', 'datetime': '2023-03-22T01:20:57.986422', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.019 per-word bound, 129.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.077*"variable" + 0.048*"global" + 0.039*"function" + 0.034*"local" + 0.030*"scope" + 0.024*"c" + 0.022*"num" + 0.020*"name" + 0.018*"assignment" + 0.017*"line"
INFO: topic #1 (1.000): 0.062*"variable" + 0.043*"local" + 0.037*"scope" + 0.037*"global" + 0.031*"function" + 0.024*"name" + 0.021*"assignment" + 0.021*"line" + 0.019*"c" + 0.017*"="
INFO: topic #2 (1.000): 0.042*"variable" + 0.040*"function" + 0.034*"local" + 0.032*"global" + 0.030*"scope" + 0.022*"name" + 0.022*"=" + 0.020*"c" + 0.019*"assignment" + 0.017*"line"
INFO: topic diff=2.386483, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.522 per-word bound, 1470.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.105*"variable" + 0.079*"global" + 0.058*"function" + 0.047*"local" + 0.032*"scope" + 0.020*"value" + 0.018*"name" + 0.018*"assignment" + 0.015*"error" + 0.014*"code"
INFO: topic #1 (1.000): 0.068*"variable" + 0.051*"local" + 0.042*"global" + 0.038*"function" + 0.033*"scope" + 0.025*"value" + 0.023*"assignment" + 0.021*"name" + 0.017*"line" + 0.015*"error"
INFO: topic #2 (1.000): 0.049*"function" + 0.044*"global" + 0.042*"variable" + 0.036*"local" + 0.025*"scope" + 0.020*"value" + 0.017*"name" + 0.016*"=" + 0.015*"assignment" + 0.014*"line"
INFO: topic diff=2.228238, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 70.79411954324861
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.5742686261026133
DEBUG: bound: at document #0
INFO: -6.036 per-word bound, 65.6 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.112*"variable" + 0.079*"global" + 0.072*"function" + 0.048*"local" + 0.031*"scope" + 0.022*"value" + 0.017*"assignment" + 0.016*"inside" + 0.015*"error" + 0.014*"access"
INFO: topic #1 (1.000): 0.060*"variable" + 0.040*"local" + 0.037*"global" + 0.034*"scope" + 0.030*"function" + 0.024*"name" + 0.021*"c" + 0.021*"assignment" + 0.020*"line" + 0.019*"num"
INFO: topic #2 (1.000): 0.042*"function" + 0.037*"global" + 0.036*"variable" + 0.029*"local" + 0.021*"scope" + 0.019*"value" + 0.014*"name" + 0.013*"=" + 0.013*"assignment" + 0.012*"line"
INFO: topic diff=1.137299, rho=0.500000
DEBUG: bound: at document #0
INFO: -7.212 per-word bound, 148.3 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.112*"variable" + 0.089*"global" + 0.071*"function" + 0.052*"local" + 0.030*"scope" + 0.027*"f" + 0.027*"var1" + 0.022*"value" + 0.019*"inside" + 0.015*"assignment"
INFO: topic #1 (1.000): 0.059*"variable" + 0.041*"local" + 0.035*"global" + 0.032*"scope" + 0.030*"function" + 0.023*"name" + 0.022*"assignment" + 0.019*"c" + 0.018*"line" + 0.018*"="
INFO: topic #2 (1.000): 0.037*"value" + 0.036*"global" + 0.035*"function" + 0.023*"variable" + 0.022*"local" + 0.015*"condition" + 0.015*"define" + 0.015*"execute" + 0.015*"instance" + 0.015*"bit"
INFO: topic diff=1.227552, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 50.766860159905164
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -3.8898141846283654
DEBUG: bound: at document #0
INFO: -5.653 per-word bound, 50.3 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.119*"variable" + 0.087*"global" + 0.085*"function" + 0.053*"local" + 0.030*"scope" + 0.025*"value" + 0.021*"inside" + 0.020*"var1" + 0.020*"f" + 0.019*"access"
INFO: topic #1 (1.000): 0.059*"variable" + 0.038*"local" + 0.036*"global" + 0.034*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.033*"value" + 0.029*"global" + 0.029*"function" + 0.018*"variable" + 0.017*"local" + 0.012*"condition" + 0.012*"define" + 0.012*"execute" + 0.012*"instance" + 0.012*"bit"
INFO: topic diff=0.754106, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.099 per-word bound, 68.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.115*"variable" + 0.093*"global" + 0.078*"function" + 0.055*"local" + 0.034*"var1" + 0.034*"f" + 0.030*"scope" + 0.023*"value" + 0.022*"inside" + 0.016*"work"
INFO: topic #1 (1.000): 0.059*"variable" + 0.040*"local" + 0.035*"global" + 0.032*"scope" + 0.029*"function" + 0.024*"name" + 0.022*"assignment" + 0.020*"c" + 0.019*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.056*"value" + 0.027*"condition" + 0.025*"global" + 0.022*"long" + 0.022*"comment" + 0.022*"instance" + 0.022*"execute" + 0.022*"define" + 0.022*"bit" + 0.022*"start"
INFO: topic diff=0.754942, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 47.339737237772205
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -3.1842166666558787
DEBUG: bound: at document #0
INFO: -5.568 per-word bound, 47.4 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.121*"variable" + 0.091*"global" + 0.090*"function" + 0.055*"local" + 0.029*"scope" + 0.026*"value" + 0.025*"f" + 0.025*"var1" + 0.023*"inside" + 0.020*"access"
INFO: topic #1 (1.000): 0.059*"variable" + 0.038*"local" + 0.036*"global" + 0.033*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.049*"value" + 0.020*"condition" + 0.020*"global" + 0.017*"function" + 0.017*"instance" + 0.017*"define" + 0.017*"bit" + 0.017*"execute" + 0.017*"long" + 0.017*"comment"
INFO: topic diff=0.421201, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.915 per-word bound, 60.3 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.116*"variable" + 0.096*"global" + 0.082*"function" + 0.055*"local" + 0.036*"f" + 0.036*"var1" + 0.029*"scope" + 0.023*"value" + 0.023*"inside" + 0.017*"work"
INFO: topic #1 (1.000): 0.059*"variable" + 0.039*"local" + 0.035*"global" + 0.032*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"assignment" + 0.020*"c" + 0.019*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.072*"value" + 0.036*"condition" + 0.025*"instance" + 0.025*"execute" + 0.025*"define" + 0.025*"comment" + 0.025*"long" + 0.025*"bit" + 0.025*"start" + 0.025*"coffee_machine"
INFO: topic diff=0.482380, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 46.3780324171886
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -3.282857428818719
DEBUG: bound: at document #0
INFO: -5.539 per-word bound, 46.5 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.121*"variable" + 0.093*"global" + 0.092*"function" + 0.055*"local" + 0.029*"scope" + 0.027*"var1" + 0.027*"f" + 0.026*"value" + 0.024*"inside" + 0.021*"access"
INFO: topic #1 (1.000): 0.059*"variable" + 0.038*"local" + 0.036*"global" + 0.033*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.063*"value" + 0.027*"condition" + 0.019*"instance" + 0.019*"execute" + 0.019*"define" + 0.019*"comment" + 0.019*"long" + 0.019*"bit" + 0.019*"start" + 0.019*"coffee_machine"
INFO: topic diff=0.248073, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.851 per-word bound, 57.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.116*"variable" + 0.097*"global" + 0.083*"function" + 0.055*"local" + 0.036*"var1" + 0.036*"f" + 0.029*"scope" + 0.023*"inside" + 0.023*"value" + 0.017*"work"
INFO: topic #1 (1.000): 0.059*"variable" + 0.039*"local" + 0.035*"global" + 0.032*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.082*"value" + 0.043*"condition" + 0.026*"instance" + 0.026*"execute" + 0.026*"define" + 0.026*"comment" + 0.026*"long" + 0.026*"bit" + 0.026*"start" + 0.026*"coffee_machine"
INFO: topic diff=0.332549, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 46.03027310356234
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -3.2793759204539357
DEBUG: bound: at document #0
INFO: -5.526 per-word bound, 46.1 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.121*"variable" + 0.094*"global" + 0.092*"function" + 0.056*"local" + 0.029*"scope" + 0.028*"var1" + 0.028*"f" + 0.025*"value" + 0.024*"inside" + 0.021*"access"
INFO: topic #1 (1.000): 0.059*"variable" + 0.038*"local" + 0.036*"global" + 0.033*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.073*"value" + 0.032*"condition" + 0.020*"long" + 0.020*"bit" + 0.020*"comment" + 0.020*"define" + 0.020*"instance" + 0.020*"execute" + 0.020*"start" + 0.020*"force"
INFO: topic diff=0.196916, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.822 per-word bound, 56.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.116*"variable" + 0.098*"global" + 0.084*"function" + 0.056*"local" + 0.036*"f" + 0.036*"var1" + 0.029*"scope" + 0.023*"inside" + 0.022*"value" + 0.017*"work"
INFO: topic #1 (1.000): 0.059*"variable" + 0.039*"local" + 0.035*"global" + 0.032*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.089*"value" + 0.046*"condition" + 0.026*"long" + 0.026*"bit" + 0.026*"comment" + 0.026*"define" + 0.026*"instance" + 0.026*"execute" + 0.026*"start" + 0.026*"force"
INFO: topic diff=0.256093, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 45.874443940564156
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -3.2793759204539357
DEBUG: bound: at document #0
INFO: -5.518 per-word bound, 45.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.121*"variable" + 0.095*"global" + 0.093*"function" + 0.056*"local" + 0.029*"scope" + 0.029*"var1" + 0.029*"f" + 0.025*"value" + 0.024*"inside" + 0.021*"access"
INFO: topic #1 (1.000): 0.059*"variable" + 0.038*"local" + 0.036*"global" + 0.033*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.080*"value" + 0.035*"condition" + 0.020*"bit" + 0.020*"long" + 0.020*"instance" + 0.020*"execute" + 0.020*"define" + 0.020*"comment" + 0.020*"coffee_machine" + 0.020*"force"
INFO: topic diff=0.182767, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.805 per-word bound, 55.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.117*"variable" + 0.099*"global" + 0.085*"function" + 0.056*"local" + 0.036*"var1" + 0.036*"f" + 0.029*"scope" + 0.023*"inside" + 0.022*"value" + 0.017*"work"
INFO: topic #1 (1.000): 0.059*"variable" + 0.039*"local" + 0.035*"global" + 0.032*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.094*"value" + 0.048*"condition" + 0.026*"comment" + 0.026*"bit" + 0.026*"long" + 0.026*"define" + 0.026*"execute" + 0.026*"instance" + 0.026*"start" + 0.026*"coffee_machine"
INFO: topic diff=0.214355, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 45.794787427271906
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -3.2793759204539357
DEBUG: bound: at document #0
INFO: -5.513 per-word bound, 45.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.121*"variable" + 0.095*"global" + 0.093*"function" + 0.056*"local" + 0.029*"f" + 0.029*"var1" + 0.029*"scope" + 0.024*"inside" + 0.024*"value" + 0.020*"access"
INFO: topic #1 (1.000): 0.059*"variable" + 0.038*"local" + 0.036*"global" + 0.033*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.085*"value" + 0.037*"condition" + 0.020*"comment" + 0.020*"bit" + 0.020*"long" + 0.020*"define" + 0.020*"execute" + 0.020*"instance" + 0.020*"force" + 0.020*"coffee_machine"
INFO: topic diff=0.174565, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.795 per-word bound, 55.5 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.117*"variable" + 0.099*"global" + 0.085*"function" + 0.056*"local" + 0.036*"var1" + 0.036*"f" + 0.029*"scope" + 0.023*"inside" + 0.022*"value" + 0.017*"work"
INFO: topic #1 (1.000): 0.059*"variable" + 0.039*"local" + 0.035*"global" + 0.032*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.097*"value" + 0.048*"condition" + 0.026*"comment" + 0.026*"bit" + 0.026*"long" + 0.026*"define" + 0.026*"execute" + 0.026*"instance" + 0.026*"force" + 0.026*"coffee_machine"
INFO: topic diff=0.189089, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 45.74978422917423
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -3.2793759204539357
DEBUG: bound: at document #0
INFO: -5.509 per-word bound, 45.5 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.121*"variable" + 0.096*"global" + 0.093*"function" + 0.056*"local" + 0.029*"f" + 0.029*"var1" + 0.029*"scope" + 0.024*"inside" + 0.024*"value" + 0.020*"access"
INFO: topic #1 (1.000): 0.059*"variable" + 0.038*"local" + 0.036*"global" + 0.033*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.088*"value" + 0.038*"condition" + 0.020*"bit" + 0.020*"instance" + 0.020*"execute" + 0.020*"long" + 0.020*"define" + 0.020*"comment" + 0.020*"force" + 0.020*"start"
INFO: topic diff=0.166853, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.788 per-word bound, 55.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.117*"variable" + 0.099*"global" + 0.085*"function" + 0.056*"local" + 0.036*"f" + 0.036*"var1" + 0.029*"scope" + 0.023*"inside" + 0.021*"value" + 0.017*"work"
INFO: topic #1 (1.000): 0.059*"variable" + 0.039*"local" + 0.035*"global" + 0.032*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.099*"value" + 0.048*"condition" + 0.025*"comment" + 0.025*"bit" + 0.025*"long" + 0.025*"define" + 0.025*"execute" + 0.025*"instance" + 0.025*"force" + 0.025*"coffee_machine"
INFO: topic diff=0.172398, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 45.720741041620045
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -3.2793759204539357
DEBUG: bound: at document #0
INFO: -5.506 per-word bound, 45.4 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.121*"variable" + 0.096*"global" + 0.092*"function" + 0.056*"local" + 0.030*"f" + 0.030*"var1" + 0.029*"scope" + 0.024*"inside" + 0.024*"value" + 0.020*"access"
INFO: topic #1 (1.000): 0.059*"variable" + 0.038*"local" + 0.036*"global" + 0.033*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.090*"value" + 0.039*"condition" + 0.020*"bit" + 0.020*"comment" + 0.020*"define" + 0.020*"instance" + 0.020*"long" + 0.020*"execute" + 0.020*"coffee_machine" + 0.020*"start"
INFO: topic diff=0.159329, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.782 per-word bound, 55.0 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.117*"variable" + 0.099*"global" + 0.086*"function" + 0.056*"local" + 0.036*"f" + 0.036*"var1" + 0.029*"scope" + 0.024*"inside" + 0.021*"value" + 0.017*"work"
INFO: topic #1 (1.000): 0.059*"variable" + 0.039*"local" + 0.035*"global" + 0.032*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.100*"value" + 0.048*"condition" + 0.025*"comment" + 0.025*"bit" + 0.025*"define" + 0.025*"execute" + 0.025*"long" + 0.025*"instance" + 0.025*"coffee_machine" + 0.025*"force"
INFO: topic diff=0.160546, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 45.699460583389325
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -3.2793759204539357
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5> in 0.20s', 'datetime': '2023-03-22T01:20:58.192259', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: <<Training Time>>: 0.20804691314697266
INFO: topic #0 (1.000): 0.117*"variable" + 0.099*"global" + 0.086*"function" + 0.056*"local" + 0.036*"f" + 0.036*"var1" + 0.029*"scope" + 0.024*"inside" + 0.021*"value" + 0.017*"work"
INFO: topic #1 (1.000): 0.059*"variable" + 0.039*"local" + 0.035*"global" + 0.032*"scope" + 0.028*"function" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"="
INFO: topic #2 (1.000): 0.100*"value" + 0.048*"condition" + 0.025*"comment" + 0.025*"bit" + 0.025*"define" + 0.025*"execute" + 0.025*"long" + 0.025*"instance" + 0.025*"coffee_machine" + 0.025*"force"
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/post_num/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-22T01:20:58.192852', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/post_num/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model.state
DEBUG: {'uri': 'model/post_num/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/post_num/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-22T01:20:58.195425', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/post_num/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/post_num/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model
INFO: ============================================================
INFO: Starts Training Model
INFO: ============================================================
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<327 unique tokens: ["'", '+', '2.x', '3.x', '=']...> from 10 documents (total 987 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<327 unique tokens: ["\'", \'+\', \'2.x\', \'3.x\', \'=\']...> from 10 documents (total 987 corpus positions)', 'datetime': '2023-03-22T01:20:58.200996', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.042 per-word bound, 131.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.095*"variable" + 0.050*"function" + 0.049*"global" + 0.032*"local" + 0.025*"scope" + 0.018*"num" + 0.018*"name" + 0.017*"value" + 0.017*"code" + 0.016*"line"
INFO: topic #1 (1.000): 0.052*"variable" + 0.042*"local" + 0.038*"scope" + 0.038*"global" + 0.030*"function" + 0.025*"c" + 0.025*"name" + 0.024*"assignment" + 0.021*"line" + 0.020*"="
INFO: topic #2 (1.000): 0.048*"variable" + 0.029*"global" + 0.028*"function" + 0.027*"local" + 0.024*"scope" + 0.021*"value" + 0.018*"program" + 0.017*"name" + 0.015*"loop" + 0.014*"num"
INFO: topic diff=2.845277, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.123 per-word bound, 1115.5 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.121*"variable" + 0.087*"global" + 0.073*"function" + 0.049*"local" + 0.028*"scope" + 0.023*"value" + 0.019*"inside" + 0.016*"code" + 0.016*"name" + 0.015*"error"
INFO: topic #1 (1.000): 0.055*"variable" + 0.048*"local" + 0.039*"global" + 0.036*"scope" + 0.033*"function" + 0.026*"assignment" + 0.023*"name" + 0.020*"c" + 0.019*"=" + 0.018*"line"
INFO: topic #2 (1.000): 0.045*"variable" + 0.039*"global" + 0.035*"value" + 0.030*"function" + 0.029*"local" + 0.025*"var1" + 0.025*"f" + 0.020*"scope" + 0.011*"name" + 0.009*"assignment"
INFO: topic diff=2.390891, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 57.948316372282655
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.6939525663753449
DEBUG: bound: at document #0
INFO: -5.738 per-word bound, 53.4 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.121*"variable" + 0.077*"function" + 0.075*"global" + 0.044*"local" + 0.030*"value" + 0.028*"scope" + 0.019*"inside" + 0.018*"program" + 0.017*"access" + 0.014*"code"
INFO: topic #1 (1.000): 0.057*"variable" + 0.041*"local" + 0.039*"global" + 0.035*"scope" + 0.030*"function" + 0.025*"name" + 0.023*"c" + 0.023*"assignment" + 0.021*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.035*"variable" + 0.034*"value" + 0.030*"global" + 0.024*"function" + 0.022*"local" + 0.018*"f" + 0.018*"var1" + 0.015*"scope" + 0.015*"other" + 0.013*"loop"
INFO: topic diff=1.087360, rho=0.500000
DEBUG: bound: at document #0
INFO: -6.926 per-word bound, 121.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.124*"variable" + 0.090*"global" + 0.080*"function" + 0.055*"local" + 0.030*"scope" + 0.025*"value" + 0.022*"inside" + 0.017*"f" + 0.017*"var1" + 0.016*"work"
INFO: topic #1 (1.000): 0.055*"variable" + 0.041*"local" + 0.037*"global" + 0.033*"scope" + 0.029*"function" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.020*"=" + 0.020*"line"
INFO: topic #2 (1.000): 0.049*"f" + 0.049*"var1" + 0.044*"value" + 0.028*"global" + 0.025*"variable" + 0.022*"condition" + 0.018*"local" + 0.017*"function" + 0.013*"instance" + 0.013*"execute"
INFO: topic diff=1.133234, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 49.299429110283256
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -3.409047326022929
DEBUG: bound: at document #0
INFO: -5.565 per-word bound, 47.3 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.123*"variable" + 0.081*"function" + 0.078*"global" + 0.049*"local" + 0.031*"value" + 0.029*"scope" + 0.021*"inside" + 0.019*"program" + 0.018*"access" + 0.015*"loop"
INFO: topic #1 (1.000): 0.057*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.024*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"num"
INFO: topic #2 (1.000): 0.042*"value" + 0.038*"var1" + 0.038*"f" + 0.023*"global" + 0.020*"variable" + 0.020*"other" + 0.017*"condition" + 0.014*"function" + 0.014*"local" + 0.011*"bit"
INFO: topic diff=0.612068, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.308 per-word bound, 79.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.122*"variable" + 0.089*"global" + 0.080*"function" + 0.056*"local" + 0.030*"scope" + 0.024*"value" + 0.022*"var1" + 0.022*"f" + 0.022*"inside" + 0.015*"work"
INFO: topic #1 (1.000): 0.055*"variable" + 0.040*"local" + 0.037*"global" + 0.033*"scope" + 0.028*"function" + 0.025*"name" + 0.023*"assignment" + 0.022*"c" + 0.021*"line" + 0.021*"="
INFO: topic #2 (1.000): 0.056*"value" + 0.046*"f" + 0.046*"var1" + 0.031*"condition" + 0.021*"global" + 0.017*"bit" + 0.017*"comment" + 0.017*"define" + 0.017*"execute" + 0.017*"long"
INFO: topic diff=0.592670, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 47.195574822374304
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -3.9502417654764366
DEBUG: bound: at document #0
INFO: -5.519 per-word bound, 45.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.122*"variable" + 0.081*"function" + 0.078*"global" + 0.050*"local" + 0.029*"scope" + 0.029*"value" + 0.021*"inside" + 0.019*"program" + 0.018*"access" + 0.016*"loop"
INFO: topic #1 (1.000): 0.057*"variable" + 0.039*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.024*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"num"
INFO: topic #2 (1.000): 0.053*"value" + 0.035*"f" + 0.035*"var1" + 0.024*"condition" + 0.024*"other" + 0.017*"global" + 0.014*"bit" + 0.014*"comment" + 0.014*"define" + 0.014*"execute"
INFO: topic diff=0.387256, rho=0.408248
DEBUG: bound: at document #0
INFO: -6.116 per-word bound, 69.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.118*"variable" + 0.086*"global" + 0.078*"function" + 0.055*"local" + 0.029*"scope" + 0.028*"f" + 0.028*"var1" + 0.024*"value" + 0.021*"inside" + 0.015*"work"
INFO: topic #1 (1.000): 0.055*"variable" + 0.039*"local" + 0.037*"global" + 0.033*"scope" + 0.028*"function" + 0.025*"name" + 0.022*"assignment" + 0.022*"c" + 0.021*"line" + 0.021*"="
INFO: topic #2 (1.000): 0.072*"value" + 0.041*"condition" + 0.023*"f" + 0.023*"var1" + 0.022*"bit" + 0.022*"comment" + 0.022*"define" + 0.022*"execute" + 0.022*"long" + 0.022*"instance"
INFO: topic diff=0.390698, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 46.04338817270358
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -3.306700953447372
DEBUG: bound: at document #0
INFO: -5.496 per-word bound, 45.1 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.119*"variable" + 0.080*"function" + 0.077*"global" + 0.050*"local" + 0.029*"scope" + 0.028*"value" + 0.021*"inside" + 0.020*"f" + 0.020*"var1" + 0.018*"program"
INFO: topic #1 (1.000): 0.057*"variable" + 0.039*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.024*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"num"
INFO: topic #2 (1.000): 0.066*"value" + 0.031*"condition" + 0.023*"other" + 0.018*"f" + 0.018*"var1" + 0.017*"bit" + 0.017*"comment" + 0.017*"define" + 0.017*"execute" + 0.017*"long"
INFO: topic diff=0.271103, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.983 per-word bound, 63.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.116*"variable" + 0.085*"global" + 0.077*"function" + 0.055*"local" + 0.030*"var1" + 0.030*"f" + 0.029*"scope" + 0.023*"value" + 0.021*"inside" + 0.014*"work"
INFO: topic #1 (1.000): 0.055*"variable" + 0.039*"local" + 0.037*"global" + 0.033*"scope" + 0.028*"function" + 0.026*"name" + 0.022*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"="
INFO: topic #2 (1.000): 0.083*"value" + 0.046*"condition" + 0.024*"define" + 0.024*"long" + 0.024*"execute" + 0.024*"bit" + 0.024*"comment" + 0.024*"instance" + 0.024*"force" + 0.024*"coffee_machine"
INFO: topic diff=0.299924, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 45.560100671088534
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -3.272588581699312
DEBUG: bound: at document #0
INFO: -5.483 per-word bound, 44.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.118*"variable" + 0.079*"function" + 0.077*"global" + 0.050*"local" + 0.029*"scope" + 0.027*"value" + 0.022*"f" + 0.022*"var1" + 0.020*"inside" + 0.017*"program"
INFO: topic #1 (1.000): 0.057*"variable" + 0.039*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.024*"c" + 0.022*"assignment" + 0.022*"line" + 0.021*"num"
INFO: topic #2 (1.000): 0.075*"value" + 0.035*"condition" + 0.020*"other" + 0.019*"define" + 0.019*"long" + 0.019*"execute" + 0.019*"bit" + 0.019*"comment" + 0.019*"instance" + 0.018*"coffee_machine"
INFO: topic diff=0.227047, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.931 per-word bound, 61.0 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.116*"variable" + 0.084*"global" + 0.077*"function" + 0.054*"local" + 0.030*"var1" + 0.030*"f" + 0.029*"scope" + 0.023*"value" + 0.021*"inside" + 0.014*"work"
INFO: topic #1 (1.000): 0.055*"variable" + 0.039*"local" + 0.038*"global" + 0.033*"scope" + 0.028*"function" + 0.026*"name" + 0.023*"c" + 0.022*"assignment" + 0.021*"line" + 0.021*"="
INFO: topic #2 (1.000): 0.090*"value" + 0.048*"condition" + 0.025*"define" + 0.025*"long" + 0.025*"execute" + 0.025*"bit" + 0.025*"comment" + 0.025*"instance" + 0.025*"force" + 0.025*"coffee_machine"
INFO: topic diff=0.245929, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 45.35166674665517
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -3.272588581699312
DEBUG: bound: at document #0
INFO: -5.475 per-word bound, 44.5 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.117*"variable" + 0.078*"function" + 0.077*"global" + 0.050*"local" + 0.029*"scope" + 0.027*"value" + 0.023*"var1" + 0.023*"f" + 0.020*"inside" + 0.017*"program"
INFO: topic #1 (1.000): 0.057*"variable" + 0.039*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.024*"c" + 0.022*"assignment" + 0.022*"line" + 0.021*"num"
INFO: topic #2 (1.000): 0.081*"value" + 0.037*"condition" + 0.019*"define" + 0.019*"long" + 0.019*"execute" + 0.019*"bit" + 0.019*"comment" + 0.019*"instance" + 0.019*"force" + 0.019*"coffee_machine"
INFO: topic diff=0.199688, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.906 per-word bound, 60.0 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.115*"variable" + 0.084*"global" + 0.077*"function" + 0.054*"local" + 0.030*"var1" + 0.030*"f" + 0.029*"scope" + 0.023*"value" + 0.020*"inside" + 0.014*"work"
INFO: topic #1 (1.000): 0.055*"variable" + 0.039*"local" + 0.038*"global" + 0.033*"scope" + 0.028*"function" + 0.026*"name" + 0.023*"c" + 0.022*"assignment" + 0.022*"line" + 0.021*"="
INFO: topic #2 (1.000): 0.094*"value" + 0.048*"condition" + 0.025*"define" + 0.025*"long" + 0.025*"execute" + 0.025*"bit" + 0.025*"comment" + 0.025*"instance" + 0.025*"force" + 0.025*"coffee_machine"
INFO: topic diff=0.210185, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 45.252247023317366
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -3.272588581699312
DEBUG: bound: at document #0
INFO: -5.469 per-word bound, 44.3 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.117*"variable" + 0.078*"function" + 0.077*"global" + 0.050*"local" + 0.029*"scope" + 0.026*"value" + 0.023*"var1" + 0.023*"f" + 0.020*"inside" + 0.017*"program"
INFO: topic #1 (1.000): 0.057*"variable" + 0.039*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.024*"c" + 0.022*"assignment" + 0.022*"line" + 0.021*"num"
INFO: topic #2 (1.000): 0.084*"value" + 0.038*"condition" + 0.020*"define" + 0.020*"long" + 0.020*"execute" + 0.020*"bit" + 0.020*"comment" + 0.020*"instance" + 0.020*"force" + 0.020*"coffee_machine"
INFO: topic diff=0.180295, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.891 per-word bound, 59.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.115*"variable" + 0.084*"global" + 0.076*"function" + 0.054*"local" + 0.030*"var1" + 0.030*"f" + 0.029*"scope" + 0.023*"value" + 0.020*"inside" + 0.014*"work"
INFO: topic #1 (1.000): 0.055*"variable" + 0.039*"local" + 0.038*"global" + 0.033*"scope" + 0.028*"function" + 0.026*"name" + 0.023*"c" + 0.022*"assignment" + 0.022*"line" + 0.021*"="
INFO: topic #2 (1.000): 0.096*"value" + 0.049*"condition" + 0.025*"define" + 0.025*"long" + 0.025*"execute" + 0.025*"bit" + 0.025*"comment" + 0.025*"instance" + 0.025*"force" + 0.025*"coffee_machine"
INFO: topic diff=0.186652, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 45.19640969017419
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -3.272588581699312
DEBUG: bound: at document #0
INFO: -5.465 per-word bound, 44.2 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.116*"variable" + 0.078*"function" + 0.077*"global" + 0.050*"local" + 0.029*"scope" + 0.026*"value" + 0.024*"var1" + 0.024*"f" + 0.020*"inside" + 0.017*"program"
INFO: topic #1 (1.000): 0.057*"variable" + 0.039*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.024*"c" + 0.022*"assignment" + 0.022*"line" + 0.021*"num"
INFO: topic #2 (1.000): 0.086*"value" + 0.038*"condition" + 0.020*"define" + 0.020*"long" + 0.020*"execute" + 0.020*"bit" + 0.020*"comment" + 0.020*"instance" + 0.020*"force" + 0.020*"coffee_machine"
INFO: topic diff=0.166163, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.881 per-word bound, 58.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.115*"variable" + 0.083*"global" + 0.076*"function" + 0.054*"local" + 0.030*"var1" + 0.030*"f" + 0.029*"scope" + 0.023*"value" + 0.020*"inside" + 0.014*"work"
INFO: topic #1 (1.000): 0.056*"variable" + 0.039*"local" + 0.038*"global" + 0.033*"scope" + 0.028*"function" + 0.026*"name" + 0.023*"c" + 0.022*"assignment" + 0.022*"line" + 0.021*"="
INFO: topic #2 (1.000): 0.097*"value" + 0.048*"condition" + 0.025*"long" + 0.025*"define" + 0.025*"instance" + 0.025*"comment" + 0.025*"execute" + 0.025*"bit" + 0.025*"coffee_machine" + 0.025*"force"
INFO: topic diff=0.170724, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 45.1585188019209
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -3.272588581699312
DEBUG: bound: at document #0
INFO: -5.462 per-word bound, 44.1 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.116*"variable" + 0.078*"function" + 0.077*"global" + 0.050*"local" + 0.029*"scope" + 0.026*"value" + 0.024*"var1" + 0.024*"f" + 0.020*"inside" + 0.016*"program"
INFO: topic #1 (1.000): 0.057*"variable" + 0.039*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.024*"c" + 0.022*"assignment" + 0.022*"line" + 0.021*"num"
INFO: topic #2 (1.000): 0.087*"value" + 0.039*"condition" + 0.020*"long" + 0.020*"define" + 0.020*"instance" + 0.020*"comment" + 0.020*"execute" + 0.020*"bit" + 0.020*"coffee_machine" + 0.020*"force"
INFO: topic diff=0.157658, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.874 per-word bound, 58.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.115*"variable" + 0.083*"global" + 0.076*"function" + 0.054*"local" + 0.030*"var1" + 0.030*"f" + 0.029*"scope" + 0.023*"value" + 0.020*"inside" + 0.014*"work"
INFO: topic #1 (1.000): 0.056*"variable" + 0.039*"local" + 0.038*"global" + 0.033*"scope" + 0.028*"function" + 0.026*"name" + 0.023*"c" + 0.022*"assignment" + 0.022*"line" + 0.021*"="
INFO: topic #2 (1.000): 0.098*"value" + 0.048*"condition" + 0.025*"comment" + 0.025*"execute" + 0.025*"define" + 0.025*"instance" + 0.025*"long" + 0.025*"bit" + 0.025*"force" + 0.025*"start"
INFO: topic diff=0.159274, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 45.129788157113744
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -3.272588581699312
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5> in 0.18s', 'datetime': '2023-03-22T01:20:58.385745', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: <<Training Time>>: 0.18737006187438965
INFO: topic #0 (1.000): 0.115*"variable" + 0.083*"global" + 0.076*"function" + 0.054*"local" + 0.030*"var1" + 0.030*"f" + 0.029*"scope" + 0.023*"value" + 0.020*"inside" + 0.014*"work"
INFO: topic #1 (1.000): 0.056*"variable" + 0.039*"local" + 0.038*"global" + 0.033*"scope" + 0.028*"function" + 0.026*"name" + 0.023*"c" + 0.022*"assignment" + 0.022*"line" + 0.021*"="
INFO: topic #2 (1.000): 0.098*"value" + 0.048*"condition" + 0.025*"comment" + 0.025*"execute" + 0.025*"define" + 0.025*"instance" + 0.025*"long" + 0.025*"bit" + 0.025*"force" + 0.025*"start"
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/post_num/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-22T01:20:58.386335', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/post_num/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model.state
DEBUG: {'uri': 'model/post_num/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/post_num/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-22T01:20:58.391605', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/post_num/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/post_num/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model
INFO: ============================================================
INFO: Starts Training Model
INFO: ============================================================
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<327 unique tokens: ["'", '+', '2.x', '3.x', '=']...> from 10 documents (total 987 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<327 unique tokens: ["\'", \'+\', \'2.x\', \'3.x\', \'=\']...> from 10 documents (total 987 corpus positions)', 'datetime': '2023-03-22T01:20:58.396575', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.033 per-word bound, 131.0 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.072*"variable" + 0.053*"function" + 0.038*"global" + 0.031*"value" + 0.028*"scope" + 0.028*"program" + 0.027*"local" + 0.018*"loop" + 0.018*"access" + 0.013*"definition"
INFO: topic #1 (1.000): 0.064*"variable" + 0.038*"function" + 0.034*"local" + 0.028*"global" + 0.027*"value" + 0.021*"scope" + 0.017*"code" + 0.016*"num" + 0.015*"name" + 0.015*"="
INFO: topic #2 (1.000): 0.064*"variable" + 0.042*"global" + 0.040*"local" + 0.035*"scope" + 0.033*"function" + 0.024*"name" + 0.024*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic diff=3.270231, rho=1.000000
DEBUG: bound: at document #0
INFO: -9.843 per-word bound, 918.3 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.102*"variable" + 0.084*"global" + 0.079*"function" + 0.039*"value" + 0.038*"local" + 0.029*"f" + 0.029*"var1" + 0.026*"scope" + 0.020*"inside" + 0.013*"print"
INFO: topic #1 (1.000): 0.055*"variable" + 0.040*"value" + 0.040*"function" + 0.036*"global" + 0.031*"local" + 0.017*"code" + 0.015*"scope" + 0.012*"=" + 0.012*"line" + 0.011*"name"
INFO: topic #2 (1.000): 0.077*"variable" + 0.054*"global" + 0.051*"local" + 0.040*"function" + 0.035*"scope" + 0.024*"name" + 0.024*"assignment" + 0.018*"line" + 0.018*"error" + 0.017*"c"
INFO: topic diff=2.460314, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 53.46700988357161
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.7396166316022881
DEBUG: bound: at document #0
INFO: -5.670 per-word bound, 50.9 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.111*"variable" + 0.084*"function" + 0.071*"global" + 0.042*"value" + 0.034*"local" + 0.025*"scope" + 0.023*"program" + 0.021*"inside" + 0.017*"loop" + 0.015*"var1"
INFO: topic #1 (1.000): 0.044*"variable" + 0.040*"value" + 0.029*"function" + 0.025*"global" + 0.021*"local" + 0.017*"program" + 0.017*"loop" + 0.016*"code" + 0.016*"access" + 0.014*"appropriate"
INFO: topic #2 (1.000): 0.065*"variable" + 0.044*"global" + 0.043*"local" + 0.035*"scope" + 0.033*"function" + 0.025*"name" + 0.022*"assignment" + 0.022*"c" + 0.020*"line" + 0.019*"num"
INFO: topic diff=1.058404, rho=0.500000
DEBUG: bound: at document #0
INFO: -6.652 per-word bound, 100.5 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.113*"variable" + 0.091*"global" + 0.082*"function" + 0.044*"local" + 0.039*"var1" + 0.039*"f" + 0.032*"value" + 0.025*"scope" + 0.023*"inside" + 0.014*"work"
INFO: topic #1 (1.000): 0.060*"value" + 0.028*"variable" + 0.020*"function" + 0.018*"code" + 0.018*"global" + 0.017*"long" + 0.017*"execute" + 0.017*"bit" + 0.017*"comment" + 0.017*"instance"
INFO: topic #2 (1.000): 0.064*"variable" + 0.046*"local" + 0.043*"global" + 0.034*"scope" + 0.032*"function" + 0.026*"name" + 0.025*"assignment" + 0.020*"line" + 0.019*"c" + 0.018*"error"
INFO: topic diff=0.866532, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 48.16066911569349
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -3.610630570838462
DEBUG: bound: at document #0
INFO: -5.558 per-word bound, 47.1 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.118*"variable" + 0.084*"function" + 0.078*"global" + 0.040*"local" + 0.035*"value" + 0.025*"scope" + 0.024*"f" + 0.024*"var1" + 0.022*"inside" + 0.021*"program"
INFO: topic #1 (1.000): 0.056*"value" + 0.023*"appropriate" + 0.021*"variable" + 0.017*"access" + 0.017*"loop" + 0.015*"function" + 0.015*"code" + 0.013*"global" + 0.012*"program" + 0.012*"define"
INFO: topic #2 (1.000): 0.060*"variable" + 0.042*"local" + 0.040*"global" + 0.035*"scope" + 0.030*"function" + 0.026*"name" + 0.023*"assignment" + 0.022*"c" + 0.021*"line" + 0.020*"num"
INFO: topic diff=0.530501, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.162 per-word bound, 71.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.118*"variable" + 0.092*"global" + 0.083*"function" + 0.048*"local" + 0.038*"var1" + 0.038*"f" + 0.029*"value" + 0.025*"scope" + 0.023*"inside" + 0.015*"work"
INFO: topic #1 (1.000): 0.077*"value" + 0.025*"condition" + 0.024*"comment" + 0.024*"define" + 0.024*"bit" + 0.024*"instance" + 0.024*"execute" + 0.024*"long" + 0.016*"code" + 0.013*"appropriate"
INFO: topic #2 (1.000): 0.060*"variable" + 0.044*"local" + 0.039*"global" + 0.034*"scope" + 0.030*"function" + 0.027*"name" + 0.025*"assignment" + 0.021*"line" + 0.020*"c" + 0.018*"="
INFO: topic diff=0.462672, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 46.62840967277897
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -2.1687685383020843
DEBUG: bound: at document #0
INFO: -5.506 per-word bound, 45.4 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.084*"function" + 0.080*"global" + 0.043*"local" + 0.033*"value" + 0.025*"f" + 0.025*"var1" + 0.025*"scope" + 0.022*"inside" + 0.020*"program"
INFO: topic #1 (1.000): 0.068*"value" + 0.027*"appropriate" + 0.018*"condition" + 0.017*"execute" + 0.017*"instance" + 0.017*"define" + 0.017*"bit" + 0.017*"comment" + 0.017*"long" + 0.014*"access"
INFO: topic #2 (1.000): 0.059*"variable" + 0.041*"local" + 0.039*"global" + 0.034*"scope" + 0.029*"function" + 0.026*"name" + 0.023*"assignment" + 0.023*"c" + 0.021*"line" + 0.020*"num"
INFO: topic diff=0.315857, rho=0.408248
DEBUG: bound: at document #0
INFO: -6.067 per-word bound, 67.0 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.119*"variable" + 0.092*"global" + 0.083*"function" + 0.050*"local" + 0.037*"f" + 0.037*"var1" + 0.028*"value" + 0.025*"scope" + 0.024*"inside" + 0.015*"work"
INFO: topic #1 (1.000): 0.086*"value" + 0.030*"condition" + 0.027*"define" + 0.027*"long" + 0.027*"bit" + 0.027*"comment" + 0.027*"instance" + 0.027*"execute" + 0.016*"appropriate" + 0.012*"code"
INFO: topic #2 (1.000): 0.058*"variable" + 0.042*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.028*"name" + 0.025*"assignment" + 0.022*"line" + 0.020*"c" + 0.019*"="
INFO: topic diff=0.316410, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 46.039747890362584
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -2.1584996911826777
DEBUG: bound: at document #0
INFO: -5.482 per-word bound, 44.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.084*"function" + 0.081*"global" + 0.045*"local" + 0.032*"value" + 0.026*"var1" + 0.026*"f" + 0.025*"scope" + 0.023*"inside" + 0.020*"program"
INFO: topic #1 (1.000): 0.075*"value" + 0.029*"appropriate" + 0.021*"condition" + 0.019*"bit" + 0.019*"long" + 0.019*"execute" + 0.019*"instance" + 0.019*"define" + 0.019*"comment" + 0.010*"access"
INFO: topic #2 (1.000): 0.058*"variable" + 0.040*"local" + 0.039*"global" + 0.034*"scope" + 0.029*"function" + 0.027*"name" + 0.023*"assignment" + 0.023*"c" + 0.022*"line" + 0.020*"num"
INFO: topic diff=0.241818, rho=0.377964
DEBUG: bound: at document #0
INFO: -6.031 per-word bound, 65.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.092*"global" + 0.083*"function" + 0.051*"local" + 0.037*"var1" + 0.037*"f" + 0.028*"value" + 0.025*"scope" + 0.023*"inside" + 0.015*"work"
INFO: topic #1 (1.000): 0.090*"value" + 0.033*"condition" + 0.028*"execute" + 0.028*"comment" + 0.028*"bit" + 0.028*"define" + 0.028*"long" + 0.028*"instance" + 0.017*"appropriate" + 0.009*"code"
INFO: topic #2 (1.000): 0.057*"variable" + 0.041*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.028*"name" + 0.024*"assignment" + 0.022*"line" + 0.021*"c" + 0.019*"="
INFO: topic diff=0.244021, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 45.785951042912195
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -2.1584996911826777
DEBUG: bound: at document #0
INFO: -5.468 per-word bound, 44.3 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.084*"function" + 0.081*"global" + 0.046*"local" + 0.031*"value" + 0.026*"var1" + 0.026*"f" + 0.026*"scope" + 0.023*"inside" + 0.019*"program"
INFO: topic #1 (1.000): 0.079*"value" + 0.029*"appropriate" + 0.024*"condition" + 0.020*"execute" + 0.020*"comment" + 0.020*"bit" + 0.020*"define" + 0.020*"long" + 0.020*"instance" + 0.007*"code"
INFO: topic #2 (1.000): 0.058*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.027*"name" + 0.023*"assignment" + 0.023*"c" + 0.022*"line" + 0.020*"num"
INFO: topic diff=0.204002, rho=0.353553
DEBUG: bound: at document #0
INFO: -6.013 per-word bound, 64.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.091*"global" + 0.083*"function" + 0.051*"local" + 0.036*"f" + 0.036*"var1" + 0.028*"value" + 0.025*"scope" + 0.023*"inside" + 0.015*"work"
INFO: topic #1 (1.000): 0.092*"value" + 0.035*"condition" + 0.028*"execute" + 0.028*"define" + 0.028*"long" + 0.028*"bit" + 0.028*"comment" + 0.028*"instance" + 0.018*"appropriate" + 0.006*"code"
INFO: topic #2 (1.000): 0.057*"variable" + 0.041*"local" + 0.038*"global" + 0.034*"scope" + 0.028*"function" + 0.028*"name" + 0.024*"assignment" + 0.022*"line" + 0.021*"c" + 0.019*"="
INFO: topic diff=0.205521, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 45.65373736862721
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -2.1584996911826777
DEBUG: bound: at document #0
INFO: -5.460 per-word bound, 44.0 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.121*"variable" + 0.084*"function" + 0.082*"global" + 0.047*"local" + 0.031*"value" + 0.026*"f" + 0.026*"var1" + 0.026*"scope" + 0.023*"inside" + 0.019*"program"
INFO: topic #1 (1.000): 0.081*"value" + 0.029*"appropriate" + 0.026*"condition" + 0.021*"bit" + 0.021*"define" + 0.021*"execute" + 0.021*"long" + 0.021*"instance" + 0.021*"comment" + 0.005*"code"
INFO: topic #2 (1.000): 0.058*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.027*"name" + 0.023*"assignment" + 0.023*"c" + 0.022*"line" + 0.020*"num"
INFO: topic diff=0.180784, rho=0.333333
DEBUG: bound: at document #0
INFO: -6.001 per-word bound, 64.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.091*"global" + 0.083*"function" + 0.051*"local" + 0.036*"f" + 0.036*"var1" + 0.028*"value" + 0.025*"scope" + 0.023*"inside" + 0.015*"work"
INFO: topic #1 (1.000): 0.093*"value" + 0.037*"condition" + 0.028*"execute" + 0.028*"instance" + 0.028*"define" + 0.028*"long" + 0.028*"comment" + 0.028*"bit" + 0.019*"appropriate" + 0.004*"code"
INFO: topic #2 (1.000): 0.057*"variable" + 0.041*"local" + 0.038*"global" + 0.034*"scope" + 0.028*"function" + 0.028*"name" + 0.024*"assignment" + 0.022*"line" + 0.021*"c" + 0.019*"="
INFO: topic diff=0.181650, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 45.574798492731595
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -2.1584996911826777
DEBUG: bound: at document #0
INFO: -5.453 per-word bound, 43.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.084*"function" + 0.082*"global" + 0.048*"local" + 0.031*"value" + 0.026*"f" + 0.026*"var1" + 0.026*"scope" + 0.023*"inside" + 0.019*"program"
INFO: topic #1 (1.000): 0.082*"value" + 0.029*"appropriate" + 0.028*"condition" + 0.021*"long" + 0.021*"instance" + 0.021*"define" + 0.021*"comment" + 0.021*"bit" + 0.021*"execute" + 0.004*"code"
INFO: topic #2 (1.000): 0.057*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.027*"name" + 0.023*"assignment" + 0.023*"c" + 0.022*"line" + 0.020*"num"
INFO: topic diff=0.165564, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.993 per-word bound, 63.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.090*"global" + 0.083*"function" + 0.051*"local" + 0.035*"f" + 0.035*"var1" + 0.028*"value" + 0.025*"scope" + 0.023*"inside" + 0.015*"work"
INFO: topic #1 (1.000): 0.093*"value" + 0.039*"condition" + 0.028*"long" + 0.028*"instance" + 0.028*"define" + 0.028*"bit" + 0.028*"execute" + 0.028*"comment" + 0.019*"appropriate" + 0.003*"code"
INFO: topic #2 (1.000): 0.057*"variable" + 0.041*"local" + 0.038*"global" + 0.034*"scope" + 0.028*"function" + 0.028*"name" + 0.024*"assignment" + 0.022*"line" + 0.021*"c" + 0.019*"="
INFO: topic diff=0.165363, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 45.52326924817509
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -2.1584996911826777
DEBUG: bound: at document #0
INFO: -5.448 per-word bound, 43.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.084*"function" + 0.082*"global" + 0.048*"local" + 0.031*"value" + 0.027*"f" + 0.027*"var1" + 0.026*"scope" + 0.023*"inside" + 0.019*"program"
INFO: topic #1 (1.000): 0.083*"value" + 0.030*"condition" + 0.029*"appropriate" + 0.021*"define" + 0.021*"long" + 0.021*"comment" + 0.021*"execute" + 0.021*"instance" + 0.021*"bit" + 0.003*"code"
INFO: topic #2 (1.000): 0.057*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.027*"name" + 0.023*"assignment" + 0.023*"c" + 0.022*"line" + 0.020*"num"
INFO: topic diff=0.154528, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.987 per-word bound, 63.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.090*"global" + 0.083*"function" + 0.051*"local" + 0.035*"f" + 0.035*"var1" + 0.028*"value" + 0.026*"scope" + 0.023*"inside" + 0.015*"work"
INFO: topic #1 (1.000): 0.094*"value" + 0.041*"condition" + 0.028*"instance" + 0.028*"bit" + 0.028*"comment" + 0.028*"define" + 0.028*"long" + 0.028*"execute" + 0.019*"appropriate" + 0.003*"code"
INFO: topic #2 (1.000): 0.057*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.028*"function" + 0.028*"name" + 0.024*"assignment" + 0.022*"line" + 0.021*"c" + 0.019*"="
INFO: topic diff=0.153371, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 45.48638452434322
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -2.1584996911826777
DEBUG: bound: at document #0
INFO: -5.445 per-word bound, 43.6 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.084*"function" + 0.082*"global" + 0.048*"local" + 0.030*"value" + 0.027*"f" + 0.027*"var1" + 0.026*"scope" + 0.023*"inside" + 0.018*"program"
INFO: topic #1 (1.000): 0.083*"value" + 0.032*"condition" + 0.029*"appropriate" + 0.022*"execute" + 0.022*"comment" + 0.022*"define" + 0.022*"long" + 0.022*"bit" + 0.022*"instance" + 0.003*"code"
INFO: topic #2 (1.000): 0.057*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.029*"function" + 0.027*"name" + 0.023*"assignment" + 0.023*"c" + 0.022*"line" + 0.020*"num"
INFO: topic diff=0.145816, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.981 per-word bound, 63.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.090*"global" + 0.083*"function" + 0.051*"local" + 0.035*"f" + 0.035*"var1" + 0.028*"value" + 0.026*"scope" + 0.023*"inside" + 0.015*"work"
INFO: topic #1 (1.000): 0.093*"value" + 0.043*"condition" + 0.027*"comment" + 0.027*"define" + 0.027*"long" + 0.027*"execute" + 0.027*"bit" + 0.027*"instance" + 0.020*"appropriate" + 0.002*"code"
INFO: topic #2 (1.000): 0.057*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.028*"function" + 0.028*"name" + 0.024*"assignment" + 0.022*"line" + 0.021*"c" + 0.019*"="
INFO: topic diff=0.144091, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 45.4578572096856
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -2.1584996911826777
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5> in 0.18s', 'datetime': '2023-03-22T01:20:58.578191', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: <<Training Time>>: 0.18362689018249512
INFO: topic #0 (1.000): 0.120*"variable" + 0.090*"global" + 0.083*"function" + 0.051*"local" + 0.035*"f" + 0.035*"var1" + 0.028*"value" + 0.026*"scope" + 0.023*"inside" + 0.015*"work"
INFO: topic #1 (1.000): 0.093*"value" + 0.043*"condition" + 0.027*"comment" + 0.027*"define" + 0.027*"long" + 0.027*"execute" + 0.027*"bit" + 0.027*"instance" + 0.020*"appropriate" + 0.002*"code"
INFO: topic #2 (1.000): 0.057*"variable" + 0.040*"local" + 0.038*"global" + 0.034*"scope" + 0.028*"function" + 0.028*"name" + 0.024*"assignment" + 0.022*"line" + 0.021*"c" + 0.019*"="
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/post_num/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-22T01:20:58.578775', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/post_num/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model.state
DEBUG: {'uri': 'model/post_num/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/post_num/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-22T01:20:58.581372', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/post_num/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/post_num/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model
INFO: ============================================================
INFO: Starts Training Model
INFO: ============================================================
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<327 unique tokens: ["'", '+', '2.x', '3.x', '=']...> from 10 documents (total 987 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<327 unique tokens: ["\'", \'+\', \'2.x\', \'3.x\', \'=\']...> from 10 documents (total 987 corpus positions)', 'datetime': '2023-03-22T01:20:58.587388', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.021 per-word bound, 129.9 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.064*"variable" + 0.043*"global" + 0.042*"local" + 0.035*"scope" + 0.035*"function" + 0.023*"name" + 0.021*"assignment" + 0.020*"c" + 0.020*"line" + 0.019*"="
INFO: topic #1 (1.000): 0.073*"variable" + 0.041*"function" + 0.028*"global" + 0.024*"program" + 0.023*"local" + 0.022*"value" + 0.021*"scope" + 0.019*"access" + 0.017*"loop" + 0.016*"class"
INFO: topic #2 (1.000): 0.064*"variable" + 0.036*"function" + 0.034*"global" + 0.029*"scope" + 0.029*"c" + 0.029*"local" + 0.025*"name" + 0.020*"num" + 0.019*"assignment" + 0.018*"line"
INFO: topic diff=2.943022, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.058 per-word bound, 1066.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.080*"variable" + 0.062*"global" + 0.055*"local" + 0.046*"function" + 0.035*"scope" + 0.022*"assignment" + 0.022*"name" + 0.021*"value" + 0.018*"error" + 0.017*"line"
INFO: topic #1 (1.000): 0.098*"variable" + 0.062*"function" + 0.055*"global" + 0.035*"value" + 0.032*"var1" + 0.032*"f" + 0.028*"local" + 0.018*"scope" + 0.015*"inside" + 0.013*"code"
INFO: topic #2 (1.000): 0.061*"variable" + 0.045*"global" + 0.041*"function" + 0.029*"local" + 0.024*"scope" + 0.021*"name" + 0.020*"c" + 0.017*"assignment" + 0.016*"line" + 0.014*"num"
INFO: topic diff=2.382502, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 57.356482427579344
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.6550095486738567
DEBUG: bound: at document #0
INFO: -5.764 per-word bound, 54.3 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"variable" + 0.048*"global" + 0.045*"local" + 0.039*"function" + 0.035*"scope" + 0.023*"name" + 0.022*"assignment" + 0.020*"c" + 0.019*"line" + 0.018*"num"
INFO: topic #1 (1.000): 0.084*"variable" + 0.043*"function" + 0.043*"value" + 0.036*"global" + 0.035*"program" + 0.025*"loop" + 0.018*"var1" + 0.018*"f" + 0.017*"definition" + 0.017*"local"
INFO: topic #2 (1.000): 0.053*"variable" + 0.039*"global" + 0.037*"function" + 0.024*"local" + 0.020*"scope" + 0.017*"name" + 0.017*"c" + 0.014*"assignment" + 0.013*"line" + 0.012*"num"
INFO: topic diff=1.076701, rho=0.500000
DEBUG: bound: at document #0
INFO: -6.801 per-word bound, 111.5 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"variable" + 0.053*"global" + 0.052*"local" + 0.043*"function" + 0.035*"scope" + 0.024*"name" + 0.024*"assignment" + 0.019*"line" + 0.018*"error" + 0.017*"c"
INFO: topic #1 (1.000): 0.094*"variable" + 0.062*"global" + 0.056*"function" + 0.048*"var1" + 0.048*"f" + 0.044*"value" + 0.022*"local" + 0.015*"scope" + 0.015*"inside" + 0.013*"print"
INFO: topic #2 (1.000): 0.041*"variable" + 0.038*"global" + 0.034*"function" + 0.020*"local" + 0.016*"scope" + 0.013*"name" + 0.012*"c" + 0.012*"line" + 0.011*"assignment" + 0.009*"num"
INFO: topic diff=0.992056, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 49.33521723603941
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -0.6933922364087205
DEBUG: bound: at document #0
INFO: -5.579 per-word bound, 47.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"variable" + 0.046*"global" + 0.045*"local" + 0.039*"function" + 0.035*"scope" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.018*"num"
INFO: topic #1 (1.000): 0.086*"variable" + 0.047*"value" + 0.047*"global" + 0.044*"function" + 0.032*"f" + 0.032*"var1" + 0.030*"program" + 0.024*"loop" + 0.016*"scope" + 0.015*"local"
INFO: topic #2 (1.000): 0.033*"variable" + 0.030*"global" + 0.028*"function" + 0.015*"local" + 0.012*"scope" + 0.010*"name" + 0.010*"c" + 0.009*"line" + 0.009*"assignment" + 0.007*"value"
INFO: topic diff=0.604388, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.252 per-word bound, 76.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.071*"variable" + 0.052*"local" + 0.049*"global" + 0.042*"function" + 0.035*"scope" + 0.024*"name" + 0.024*"assignment" + 0.019*"line" + 0.018*"error" + 0.018*"c"
INFO: topic #1 (1.000): 0.093*"variable" + 0.071*"global" + 0.056*"function" + 0.048*"var1" + 0.048*"f" + 0.046*"value" + 0.020*"local" + 0.017*"inside" + 0.015*"scope" + 0.014*"print"
INFO: topic #2 (1.000): 0.025*"global" + 0.024*"variable" + 0.022*"function" + 0.011*"local" + 0.009*"scope" + 0.008*"name" + 0.007*"line" + 0.007*"c" + 0.007*"assignment" + 0.006*"value"
INFO: topic diff=0.520368, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 47.45982156390412
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -0.6213245759247649
DEBUG: bound: at document #0
INFO: -5.521 per-word bound, 45.9 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"variable" + 0.046*"local" + 0.045*"global" + 0.039*"function" + 0.035*"scope" + 0.024*"name" + 0.023*"assignment" + 0.021*"c" + 0.020*"line" + 0.018*"num"
INFO: topic #1 (1.000): 0.088*"variable" + 0.056*"global" + 0.049*"value" + 0.047*"function" + 0.034*"f" + 0.034*"var1" + 0.028*"program" + 0.024*"loop" + 0.016*"scope" + 0.015*"local"
INFO: topic #2 (1.000): 0.019*"global" + 0.018*"variable" + 0.017*"function" + 0.009*"local" + 0.007*"scope" + 0.006*"name" + 0.006*"line" + 0.006*"c" + 0.005*"assignment" + 0.005*"value"
INFO: topic diff=0.377430, rho=0.408248
DEBUG: bound: at document #0
INFO: -6.143 per-word bound, 70.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.070*"variable" + 0.051*"local" + 0.046*"global" + 0.041*"function" + 0.035*"scope" + 0.025*"name" + 0.024*"assignment" + 0.020*"line" + 0.018*"error" + 0.018*"c"
INFO: topic #1 (1.000): 0.094*"variable" + 0.077*"global" + 0.057*"function" + 0.048*"value" + 0.047*"var1" + 0.047*"f" + 0.020*"local" + 0.018*"inside" + 0.016*"scope" + 0.014*"print"
INFO: topic #2 (1.000): 0.014*"global" + 0.013*"function" + 0.013*"variable" + 0.007*"local" + 0.006*"scope" + 0.005*"name" + 0.005*"line" + 0.005*"c" + 0.005*"assignment" + 0.004*"value"
INFO: topic diff=0.327944, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 46.81309821155189
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -0.6521311172829848
DEBUG: bound: at document #0
INFO: -5.498 per-word bound, 45.2 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"variable" + 0.046*"local" + 0.044*"global" + 0.038*"function" + 0.035*"scope" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.020*"line" + 0.018*"num"
INFO: topic #1 (1.000): 0.090*"variable" + 0.064*"global" + 0.050*"value" + 0.050*"function" + 0.035*"var1" + 0.035*"f" + 0.027*"program" + 0.023*"loop" + 0.016*"scope" + 0.016*"inside"
INFO: topic #2 (1.000): 0.011*"global" + 0.010*"function" + 0.010*"variable" + 0.005*"local" + 0.005*"scope" + 0.004*"name" + 0.004*"line" + 0.004*"c" + 0.004*"assignment" + 0.004*"value"
INFO: topic diff=0.270042, rho=0.377964
DEBUG: bound: at document #0
INFO: -6.093 per-word bound, 68.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"variable" + 0.051*"local" + 0.044*"global" + 0.040*"function" + 0.035*"scope" + 0.025*"name" + 0.025*"assignment" + 0.020*"line" + 0.018*"c" + 0.018*"error"
INFO: topic #1 (1.000): 0.095*"variable" + 0.082*"global" + 0.059*"function" + 0.048*"value" + 0.046*"var1" + 0.046*"f" + 0.020*"local" + 0.019*"inside" + 0.016*"scope" + 0.014*"loop"
INFO: topic #2 (1.000): 0.008*"global" + 0.008*"function" + 0.007*"variable" + 0.005*"local" + 0.004*"scope" + 0.004*"name" + 0.004*"line" + 0.004*"c" + 0.004*"assignment" + 0.004*"value"
INFO: topic diff=0.241035, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 46.51990665292143
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -1.0170983593923857
DEBUG: bound: at document #0
INFO: -5.486 per-word bound, 44.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"variable" + 0.046*"local" + 0.043*"global" + 0.038*"function" + 0.035*"scope" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.020*"line" + 0.018*"num"
INFO: topic #1 (1.000): 0.092*"variable" + 0.070*"global" + 0.053*"function" + 0.051*"value" + 0.035*"f" + 0.035*"var1" + 0.026*"program" + 0.022*"loop" + 0.017*"inside" + 0.016*"scope"
INFO: topic #2 (1.000): 0.006*"global" + 0.006*"function" + 0.006*"variable" + 0.004*"local" + 0.004*"scope" + 0.004*"name" + 0.004*"line" + 0.004*"c" + 0.003*"assignment" + 0.003*"value"
INFO: topic diff=0.213796, rho=0.353553
DEBUG: bound: at document #0
INFO: -6.063 per-word bound, 66.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"variable" + 0.050*"local" + 0.043*"global" + 0.039*"function" + 0.035*"scope" + 0.025*"name" + 0.025*"assignment" + 0.020*"line" + 0.019*"c" + 0.018*"error"
INFO: topic #1 (1.000): 0.096*"variable" + 0.085*"global" + 0.061*"function" + 0.049*"value" + 0.045*"f" + 0.045*"var1" + 0.021*"local" + 0.020*"inside" + 0.017*"scope" + 0.014*"program"
INFO: topic #2 (1.000): 0.005*"global" + 0.005*"function" + 0.005*"variable" + 0.004*"local" + 0.003*"scope" + 0.003*"name" + 0.003*"line" + 0.003*"c" + 0.003*"assignment" + 0.003*"value"
INFO: topic diff=0.198796, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 46.36710750731841
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -1.8125218385033641
DEBUG: bound: at document #0
INFO: -5.478 per-word bound, 44.6 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.066*"variable" + 0.046*"local" + 0.042*"global" + 0.037*"function" + 0.035*"scope" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.094*"variable" + 0.074*"global" + 0.056*"function" + 0.051*"value" + 0.035*"f" + 0.035*"var1" + 0.025*"program" + 0.022*"loop" + 0.019*"inside" + 0.017*"local"
INFO: topic #2 (1.000): 0.005*"global" + 0.004*"function" + 0.004*"variable" + 0.003*"local" + 0.003*"scope" + 0.003*"name" + 0.003*"line" + 0.003*"c" + 0.003*"assignment" + 0.003*"value"
INFO: topic diff=0.180645, rho=0.333333
DEBUG: bound: at document #0
INFO: -6.044 per-word bound, 66.0 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"variable" + 0.050*"local" + 0.042*"global" + 0.038*"function" + 0.035*"scope" + 0.025*"name" + 0.025*"assignment" + 0.020*"line" + 0.019*"c" + 0.018*"error"
INFO: topic #1 (1.000): 0.097*"variable" + 0.087*"global" + 0.063*"function" + 0.049*"value" + 0.044*"var1" + 0.044*"f" + 0.022*"local" + 0.020*"inside" + 0.017*"scope" + 0.015*"program"
INFO: topic #2 (1.000): 0.004*"global" + 0.004*"function" + 0.004*"variable" + 0.003*"local" + 0.003*"scope" + 0.003*"name" + 0.003*"line" + 0.003*"c" + 0.003*"assignment" + 0.003*"value"
INFO: topic diff=0.173417, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 46.27858896591636
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -1.8125218385033641
DEBUG: bound: at document #0
INFO: -5.473 per-word bound, 44.4 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.066*"variable" + 0.046*"local" + 0.042*"global" + 0.037*"function" + 0.035*"scope" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.096*"variable" + 0.076*"global" + 0.059*"function" + 0.051*"value" + 0.035*"f" + 0.035*"var1" + 0.025*"program" + 0.021*"loop" + 0.020*"inside" + 0.018*"local"
INFO: topic #2 (1.000): 0.004*"global" + 0.004*"function" + 0.004*"variable" + 0.003*"local" + 0.003*"scope" + 0.003*"name" + 0.003*"line" + 0.003*"c" + 0.003*"assignment" + 0.003*"value"
INFO: topic diff=0.159218, rho=0.316228
DEBUG: bound: at document #0
INFO: -6.031 per-word bound, 65.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"variable" + 0.049*"local" + 0.041*"global" + 0.038*"function" + 0.035*"scope" + 0.025*"name" + 0.025*"assignment" + 0.020*"line" + 0.019*"c" + 0.019*"error"
INFO: topic #1 (1.000): 0.098*"variable" + 0.089*"global" + 0.064*"function" + 0.049*"value" + 0.044*"var1" + 0.044*"f" + 0.023*"local" + 0.021*"inside" + 0.017*"scope" + 0.015*"program"
INFO: topic #2 (1.000): 0.004*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"local" + 0.003*"scope" + 0.003*"name" + 0.003*"line" + 0.003*"c" + 0.003*"assignment" + 0.003*"value"
INFO: topic diff=0.155980, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 46.22093110919001
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -1.8125218385033641
DEBUG: bound: at document #0
INFO: -5.468 per-word bound, 44.3 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.065*"variable" + 0.046*"local" + 0.041*"global" + 0.036*"function" + 0.035*"scope" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.097*"variable" + 0.078*"global" + 0.061*"function" + 0.051*"value" + 0.034*"f" + 0.034*"var1" + 0.024*"program" + 0.021*"inside" + 0.021*"loop" + 0.019*"local"
INFO: topic #2 (1.000): 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"local" + 0.003*"scope" + 0.003*"name" + 0.003*"line" + 0.003*"c" + 0.003*"assignment" + 0.003*"value"
INFO: topic diff=0.145125, rho=0.301511
DEBUG: bound: at document #0
INFO: -6.021 per-word bound, 64.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"variable" + 0.049*"local" + 0.041*"global" + 0.037*"function" + 0.035*"scope" + 0.025*"name" + 0.025*"assignment" + 0.020*"line" + 0.019*"c" + 0.019*"error"
INFO: topic #1 (1.000): 0.099*"variable" + 0.089*"global" + 0.066*"function" + 0.049*"value" + 0.043*"f" + 0.043*"var1" + 0.024*"local" + 0.022*"inside" + 0.018*"scope" + 0.015*"program"
INFO: topic #2 (1.000): 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"local" + 0.003*"scope" + 0.003*"name" + 0.003*"line" + 0.003*"c" + 0.003*"assignment" + 0.003*"value"
INFO: topic diff=0.143195, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 46.18004506825213
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -1.8125218385033641
DEBUG: bound: at document #0
INFO: -5.465 per-word bound, 44.2 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.065*"variable" + 0.046*"local" + 0.041*"global" + 0.036*"function" + 0.035*"scope" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.099*"variable" + 0.080*"global" + 0.063*"function" + 0.051*"value" + 0.034*"f" + 0.034*"var1" + 0.024*"program" + 0.021*"inside" + 0.021*"local" + 0.020*"loop"
INFO: topic #2 (1.000): 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"local" + 0.003*"scope" + 0.003*"name" + 0.003*"line" + 0.003*"c" + 0.003*"assignment" + 0.003*"value"
INFO: topic diff=0.134779, rho=0.288675
DEBUG: bound: at document #0
INFO: -6.013 per-word bound, 64.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.066*"variable" + 0.049*"local" + 0.040*"global" + 0.037*"function" + 0.035*"scope" + 0.025*"name" + 0.025*"assignment" + 0.020*"line" + 0.019*"c" + 0.019*"error"
INFO: topic #1 (1.000): 0.100*"variable" + 0.090*"global" + 0.067*"function" + 0.049*"value" + 0.042*"f" + 0.042*"var1" + 0.025*"local" + 0.022*"inside" + 0.018*"scope" + 0.015*"program"
INFO: topic #2 (1.000): 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"local" + 0.003*"scope" + 0.003*"name" + 0.003*"line" + 0.003*"c" + 0.003*"assignment" + 0.003*"value"
INFO: topic diff=0.133393, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 46.149900374286354
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.8125218385033641
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5> in 0.19s', 'datetime': '2023-03-22T01:20:58.775922', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: <<Training Time>>: 0.19103312492370605
INFO: topic #0 (1.000): 0.066*"variable" + 0.049*"local" + 0.040*"global" + 0.037*"function" + 0.035*"scope" + 0.025*"name" + 0.025*"assignment" + 0.020*"line" + 0.019*"c" + 0.019*"error"
INFO: topic #1 (1.000): 0.100*"variable" + 0.090*"global" + 0.067*"function" + 0.049*"value" + 0.042*"f" + 0.042*"var1" + 0.025*"local" + 0.022*"inside" + 0.018*"scope" + 0.015*"program"
INFO: topic #2 (1.000): 0.003*"global" + 0.003*"function" + 0.003*"variable" + 0.003*"local" + 0.003*"scope" + 0.003*"name" + 0.003*"line" + 0.003*"c" + 0.003*"assignment" + 0.003*"value"
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/post_num/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-22T01:20:58.776472', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/post_num/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model.state
DEBUG: {'uri': 'model/post_num/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/post_num/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-22T01:20:58.781227', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/post_num/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/post_num/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model
INFO: ============================================================
INFO: Starts Training Model
INFO: ============================================================
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<327 unique tokens: ["'", '+', '2.x', '3.x', '=']...> from 10 documents (total 987 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<327 unique tokens: ["\'", \'+\', \'2.x\', \'3.x\', \'=\']...> from 10 documents (total 987 corpus positions)', 'datetime': '2023-03-22T01:20:58.786665', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.021 per-word bound, 129.9 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.050*"variable" + 0.049*"local" + 0.041*"global" + 0.026*"scope" + 0.021*"function" + 0.020*"name" + 0.018*"error" + 0.018*"num" + 0.016*"line" + 0.015*"c"
INFO: topic #1 (1.000): 0.056*"variable" + 0.043*"local" + 0.035*"global" + 0.028*"function" + 0.025*"scope" + 0.021*"name" + 0.019*"value" + 0.019*"assignment" + 0.019*"c" + 0.018*"="
INFO: topic #2 (1.000): 0.072*"variable" + 0.043*"global" + 0.042*"function" + 0.039*"scope" + 0.033*"local" + 0.023*"name" + 0.023*"c" + 0.021*"line" + 0.021*"assignment" + 0.020*"num"
INFO: topic diff=2.517526, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.353 per-word bound, 1307.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.071*"global" + 0.067*"variable" + 0.060*"local" + 0.030*"function" + 0.023*"scope" + 0.022*"f" + 0.022*"var1" + 0.018*"value" + 0.016*"error" + 0.014*"name"
INFO: topic #1 (1.000): 0.055*"variable" + 0.043*"local" + 0.040*"global" + 0.032*"value" + 0.032*"function" + 0.021*"scope" + 0.017*"name" + 0.017*"assignment" + 0.017*"=" + 0.015*"code"
INFO: topic #2 (1.000): 0.096*"variable" + 0.063*"global" + 0.062*"function" + 0.044*"local" + 0.038*"scope" + 0.023*"assignment" + 0.021*"name" + 0.018*"value" + 0.017*"line" + 0.015*"code"
INFO: topic diff=2.321432, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 62.84681670656658
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.6498737326528617
DEBUG: bound: at document #0
INFO: -5.871 per-word bound, 58.5 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.062*"global" + 0.058*"variable" + 0.050*"local" + 0.027*"function" + 0.020*"scope" + 0.018*"var1" + 0.018*"f" + 0.017*"value" + 0.014*"other" + 0.013*"error"
INFO: topic #1 (1.000): 0.055*"variable" + 0.038*"value" + 0.031*"program" + 0.029*"local" + 0.028*"global" + 0.024*"loop" + 0.022*"function" + 0.020*"scope" + 0.018*"class" + 0.016*"code"
INFO: topic #2 (1.000): 0.073*"variable" + 0.048*"global" + 0.044*"function" + 0.042*"local" + 0.036*"scope" + 0.023*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.018*"num"
INFO: topic diff=1.201297, rho=0.500000
DEBUG: bound: at document #0
INFO: -6.992 per-word bound, 127.3 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.090*"global" + 0.079*"variable" + 0.052*"local" + 0.051*"var1" + 0.051*"f" + 0.041*"function" + 0.019*"scope" + 0.018*"value" + 0.013*"load" + 0.013*"caller"
INFO: topic #1 (1.000): 0.057*"value" + 0.043*"variable" + 0.023*"global" + 0.022*"program" + 0.022*"local" + 0.020*"loop" + 0.020*"function" + 0.019*"code" + 0.015*"=" + 0.015*"scope"
INFO: topic #2 (1.000): 0.080*"variable" + 0.051*"function" + 0.050*"global" + 0.045*"local" + 0.035*"scope" + 0.024*"assignment" + 0.023*"name" + 0.018*"line" + 0.017*"c" + 0.016*"error"
INFO: topic diff=1.205822, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 49.06403363549063
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.5032972998525118
DEBUG: bound: at document #0
INFO: -5.586 per-word bound, 48.0 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.084*"global" + 0.074*"variable" + 0.045*"local" + 0.043*"var1" + 0.043*"f" + 0.040*"function" + 0.017*"value" + 0.017*"scope" + 0.016*"other" + 0.012*"load"
INFO: topic #1 (1.000): 0.056*"value" + 0.047*"variable" + 0.045*"program" + 0.035*"loop" + 0.023*"class" + 0.023*"definition" + 0.019*"code" + 0.016*"scope" + 0.014*"global" + 0.013*"local"
INFO: topic #2 (1.000): 0.071*"variable" + 0.045*"global" + 0.043*"local" + 0.042*"function" + 0.035*"scope" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic diff=0.713741, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.163 per-word bound, 71.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.102*"global" + 0.091*"variable" + 0.056*"function" + 0.054*"f" + 0.054*"var1" + 0.049*"local" + 0.019*"scope" + 0.019*"value" + 0.014*"work" + 0.014*"caller"
INFO: topic #1 (1.000): 0.071*"value" + 0.034*"variable" + 0.030*"program" + 0.029*"loop" + 0.022*"code" + 0.018*"condition" + 0.016*"class" + 0.016*"definition" + 0.014*"note" + 0.014*"="
INFO: topic #2 (1.000): 0.075*"variable" + 0.046*"local" + 0.046*"function" + 0.044*"global" + 0.035*"scope" + 0.024*"assignment" + 0.024*"name" + 0.019*"line" + 0.018*"c" + 0.017*"error"
INFO: topic diff=0.668338, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 46.448223879992135
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -2.084811315348871
DEBUG: bound: at document #0
INFO: -5.519 per-word bound, 45.9 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.098*"global" + 0.088*"variable" + 0.057*"function" + 0.046*"f" + 0.046*"var1" + 0.044*"local" + 0.018*"value" + 0.018*"scope" + 0.016*"other" + 0.013*"work"
INFO: topic #1 (1.000): 0.064*"value" + 0.049*"program" + 0.042*"variable" + 0.040*"loop" + 0.025*"class" + 0.025*"definition" + 0.021*"code" + 0.014*"scope" + 0.013*"test" + 0.013*"point"
INFO: topic #2 (1.000): 0.069*"variable" + 0.043*"global" + 0.043*"local" + 0.040*"function" + 0.035*"scope" + 0.024*"name" + 0.023*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic diff=0.458912, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.987 per-word bound, 63.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.107*"global" + 0.098*"variable" + 0.066*"function" + 0.052*"f" + 0.052*"var1" + 0.048*"local" + 0.020*"scope" + 0.020*"value" + 0.016*"work" + 0.013*"caller"
INFO: topic #1 (1.000): 0.076*"value" + 0.034*"program" + 0.033*"loop" + 0.031*"variable" + 0.024*"code" + 0.024*"condition" + 0.018*"class" + 0.017*"definition" + 0.015*"note" + 0.015*"solution"
INFO: topic #2 (1.000): 0.071*"variable" + 0.046*"local" + 0.042*"function" + 0.042*"global" + 0.035*"scope" + 0.025*"name" + 0.025*"assignment" + 0.019*"line" + 0.019*"c" + 0.017*"error"
INFO: topic diff=0.412658, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 45.64175835284032
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -2.0641208856492974
DEBUG: bound: at document #0
INFO: -5.495 per-word bound, 45.1 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.105*"global" + 0.099*"variable" + 0.070*"function" + 0.045*"local" + 0.044*"var1" + 0.044*"f" + 0.020*"value" + 0.019*"scope" + 0.016*"work" + 0.015*"other"
INFO: topic #1 (1.000): 0.068*"value" + 0.051*"program" + 0.043*"loop" + 0.038*"variable" + 0.026*"class" + 0.026*"definition" + 0.021*"code" + 0.014*"test" + 0.014*"condition" + 0.014*"version"
INFO: topic #2 (1.000): 0.067*"variable" + 0.043*"local" + 0.042*"global" + 0.038*"function" + 0.035*"scope" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic diff=0.336340, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.914 per-word bound, 60.3 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.109*"global" + 0.103*"variable" + 0.072*"function" + 0.049*"var1" + 0.049*"f" + 0.048*"local" + 0.021*"scope" + 0.021*"value" + 0.018*"work" + 0.016*"inside"
INFO: topic #1 (1.000): 0.077*"value" + 0.036*"program" + 0.036*"loop" + 0.029*"variable" + 0.027*"condition" + 0.024*"code" + 0.018*"class" + 0.018*"definition" + 0.015*"note" + 0.015*"solution"
INFO: topic #2 (1.000): 0.069*"variable" + 0.045*"local" + 0.040*"global" + 0.040*"function" + 0.035*"scope" + 0.025*"name" + 0.025*"assignment" + 0.020*"c" + 0.019*"line" + 0.017*"error"
INFO: topic diff=0.289969, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 45.31229638053109
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -1.97613889617889
DEBUG: bound: at document #0
INFO: -5.482 per-word bound, 44.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.108*"global" + 0.107*"variable" + 0.080*"function" + 0.046*"local" + 0.042*"f" + 0.042*"var1" + 0.022*"value" + 0.020*"scope" + 0.018*"work" + 0.017*"inside"
INFO: topic #1 (1.000): 0.069*"value" + 0.051*"program" + 0.044*"loop" + 0.036*"variable" + 0.026*"class" + 0.026*"definition" + 0.022*"code" + 0.016*"condition" + 0.014*"test" + 0.014*"version"
INFO: topic #2 (1.000): 0.066*"variable" + 0.043*"local" + 0.040*"global" + 0.037*"function" + 0.035*"scope" + 0.025*"name" + 0.023*"assignment" + 0.022*"c" + 0.020*"line" + 0.019*"num"
INFO: topic diff=0.269065, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.881 per-word bound, 58.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.110*"global" + 0.108*"variable" + 0.077*"function" + 0.049*"local" + 0.047*"f" + 0.047*"var1" + 0.023*"scope" + 0.022*"value" + 0.019*"inside" + 0.018*"work"
INFO: topic #1 (1.000): 0.077*"value" + 0.037*"loop" + 0.037*"program" + 0.028*"condition" + 0.028*"variable" + 0.024*"code" + 0.019*"class" + 0.019*"definition" + 0.015*"note" + 0.015*"solution"
INFO: topic #2 (1.000): 0.067*"variable" + 0.045*"local" + 0.039*"global" + 0.038*"function" + 0.035*"scope" + 0.026*"name" + 0.025*"assignment" + 0.020*"c" + 0.020*"line" + 0.018*"num"
INFO: topic diff=0.241448, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 45.14211446327656
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -2.0796408108244413
DEBUG: bound: at document #0
INFO: -5.474 per-word bound, 44.4 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.113*"variable" + 0.109*"global" + 0.086*"function" + 0.048*"local" + 0.040*"f" + 0.040*"var1" + 0.023*"value" + 0.022*"scope" + 0.021*"inside" + 0.019*"work"
INFO: topic #1 (1.000): 0.069*"value" + 0.051*"program" + 0.044*"loop" + 0.035*"variable" + 0.026*"class" + 0.026*"definition" + 0.022*"code" + 0.017*"condition" + 0.014*"test" + 0.014*"version"
INFO: topic #2 (1.000): 0.065*"variable" + 0.043*"local" + 0.040*"global" + 0.035*"function" + 0.035*"scope" + 0.025*"name" + 0.024*"assignment" + 0.022*"c" + 0.020*"line" + 0.019*"num"
INFO: topic diff=0.232266, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.863 per-word bound, 58.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.111*"variable" + 0.110*"global" + 0.081*"function" + 0.050*"local" + 0.046*"f" + 0.046*"var1" + 0.024*"scope" + 0.022*"value" + 0.021*"inside" + 0.019*"work"
INFO: topic #1 (1.000): 0.077*"value" + 0.038*"loop" + 0.037*"program" + 0.028*"condition" + 0.027*"variable" + 0.024*"code" + 0.019*"class" + 0.019*"definition" + 0.015*"note" + 0.015*"solution"
INFO: topic #2 (1.000): 0.066*"variable" + 0.045*"local" + 0.039*"global" + 0.036*"function" + 0.035*"scope" + 0.026*"name" + 0.026*"assignment" + 0.020*"c" + 0.020*"line" + 0.018*"num"
INFO: topic diff=0.215399, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 45.046750547054174
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -2.0796408108244413
DEBUG: bound: at document #0
INFO: -5.468 per-word bound, 44.3 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.116*"variable" + 0.110*"global" + 0.089*"function" + 0.049*"local" + 0.039*"var1" + 0.039*"f" + 0.024*"inside" + 0.024*"value" + 0.023*"scope" + 0.019*"work"
INFO: topic #1 (1.000): 0.069*"value" + 0.051*"program" + 0.044*"loop" + 0.034*"variable" + 0.026*"class" + 0.026*"definition" + 0.022*"code" + 0.018*"condition" + 0.014*"test" + 0.014*"version"
INFO: topic #2 (1.000): 0.064*"variable" + 0.043*"local" + 0.039*"global" + 0.035*"scope" + 0.034*"function" + 0.025*"name" + 0.024*"assignment" + 0.022*"c" + 0.020*"line" + 0.019*"num"
INFO: topic diff=0.208735, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.851 per-word bound, 57.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.113*"variable" + 0.110*"global" + 0.083*"function" + 0.050*"local" + 0.045*"var1" + 0.045*"f" + 0.024*"scope" + 0.023*"value" + 0.023*"inside" + 0.019*"work"
INFO: topic #1 (1.000): 0.076*"value" + 0.038*"loop" + 0.038*"program" + 0.028*"condition" + 0.027*"variable" + 0.024*"code" + 0.020*"class" + 0.020*"definition" + 0.015*"note" + 0.015*"solution"
INFO: topic #2 (1.000): 0.065*"variable" + 0.044*"local" + 0.038*"global" + 0.035*"function" + 0.035*"scope" + 0.026*"name" + 0.026*"assignment" + 0.020*"c" + 0.020*"line" + 0.018*"num"
INFO: topic diff=0.197794, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 44.990055790804966
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -2.0796408108244413
DEBUG: bound: at document #0
INFO: -5.463 per-word bound, 44.1 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.118*"variable" + 0.110*"global" + 0.092*"function" + 0.049*"local" + 0.039*"var1" + 0.039*"f" + 0.025*"inside" + 0.024*"value" + 0.024*"scope" + 0.019*"work"
INFO: topic #1 (1.000): 0.069*"value" + 0.050*"program" + 0.044*"loop" + 0.034*"variable" + 0.026*"class" + 0.026*"definition" + 0.022*"code" + 0.019*"condition" + 0.014*"test" + 0.013*"version"
INFO: topic #2 (1.000): 0.063*"variable" + 0.042*"local" + 0.039*"global" + 0.035*"scope" + 0.034*"function" + 0.026*"name" + 0.024*"assignment" + 0.022*"c" + 0.020*"line" + 0.019*"num"
INFO: topic diff=0.192607, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.843 per-word bound, 57.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.115*"variable" + 0.110*"global" + 0.085*"function" + 0.051*"local" + 0.044*"var1" + 0.044*"f" + 0.025*"scope" + 0.024*"inside" + 0.023*"value" + 0.019*"work"
INFO: topic #1 (1.000): 0.076*"value" + 0.039*"loop" + 0.038*"program" + 0.028*"condition" + 0.027*"variable" + 0.024*"code" + 0.020*"class" + 0.020*"definition" + 0.015*"note" + 0.015*"solution"
INFO: topic #2 (1.000): 0.064*"variable" + 0.044*"local" + 0.038*"global" + 0.034*"scope" + 0.034*"function" + 0.027*"name" + 0.026*"assignment" + 0.021*"c" + 0.020*"line" + 0.018*"num"
INFO: topic diff=0.184559, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 44.9513450180039
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -2.0736669155217236
DEBUG: bound: at document #0
INFO: -5.460 per-word bound, 44.0 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"variable" + 0.109*"global" + 0.093*"function" + 0.050*"local" + 0.038*"f" + 0.038*"var1" + 0.026*"inside" + 0.024*"value" + 0.024*"scope" + 0.019*"work"
INFO: topic #1 (1.000): 0.069*"value" + 0.050*"program" + 0.044*"loop" + 0.033*"variable" + 0.026*"class" + 0.026*"definition" + 0.022*"code" + 0.019*"condition" + 0.014*"test" + 0.013*"version"
INFO: topic #2 (1.000): 0.063*"variable" + 0.042*"local" + 0.039*"global" + 0.035*"scope" + 0.033*"function" + 0.026*"name" + 0.024*"assignment" + 0.022*"c" + 0.020*"line" + 0.019*"num"
INFO: topic diff=0.180623, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.836 per-word bound, 57.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.116*"variable" + 0.110*"global" + 0.086*"function" + 0.051*"local" + 0.044*"var1" + 0.044*"f" + 0.025*"scope" + 0.025*"inside" + 0.023*"value" + 0.019*"work"
INFO: topic #1 (1.000): 0.075*"value" + 0.039*"program" + 0.039*"loop" + 0.028*"condition" + 0.027*"variable" + 0.024*"code" + 0.020*"class" + 0.020*"definition" + 0.015*"note" + 0.015*"solution"
INFO: topic #2 (1.000): 0.064*"variable" + 0.044*"local" + 0.038*"global" + 0.034*"scope" + 0.034*"function" + 0.027*"name" + 0.026*"assignment" + 0.021*"c" + 0.020*"line" + 0.018*"num"
INFO: topic diff=0.174615, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 44.92029846802649
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -2.0633980684023165
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5> in 0.19s', 'datetime': '2023-03-22T01:20:58.976050', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: <<Training Time>>: 0.19160914421081543
INFO: topic #0 (1.000): 0.116*"variable" + 0.110*"global" + 0.086*"function" + 0.051*"local" + 0.044*"var1" + 0.044*"f" + 0.025*"scope" + 0.025*"inside" + 0.023*"value" + 0.019*"work"
INFO: topic #1 (1.000): 0.075*"value" + 0.039*"program" + 0.039*"loop" + 0.028*"condition" + 0.027*"variable" + 0.024*"code" + 0.020*"class" + 0.020*"definition" + 0.015*"note" + 0.015*"solution"
INFO: topic #2 (1.000): 0.064*"variable" + 0.044*"local" + 0.038*"global" + 0.034*"scope" + 0.034*"function" + 0.027*"name" + 0.026*"assignment" + 0.021*"c" + 0.020*"line" + 0.018*"num"
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/post_num/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-22T01:20:58.976613', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/post_num/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model.state
DEBUG: {'uri': 'model/post_num/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/post_num/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-22T01:20:58.979360', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/post_num/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/post_num/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model
INFO: ============================================================
INFO: Starts Training Model
INFO: ============================================================
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<327 unique tokens: ["'", '+', '2.x', '3.x', '=']...> from 10 documents (total 987 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<327 unique tokens: ["\'", \'+\', \'2.x\', \'3.x\', \'=\']...> from 10 documents (total 987 corpus positions)', 'datetime': '2023-03-22T01:20:58.984538', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.030 per-word bound, 130.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.049*"variable" + 0.043*"local" + 0.035*"global" + 0.029*"function" + 0.026*"scope" + 0.024*"assignment" + 0.023*"name" + 0.022*"num" + 0.020*"value" + 0.017*"="
INFO: topic #1 (1.000): 0.073*"variable" + 0.045*"global" + 0.039*"scope" + 0.036*"function" + 0.036*"local" + 0.024*"name" + 0.022*"c" + 0.018*"=" + 0.018*"line" + 0.017*"assignment"
INFO: topic #2 (1.000): 0.067*"variable" + 0.041*"function" + 0.038*"global" + 0.036*"local" + 0.029*"scope" + 0.025*"c" + 0.023*"line" + 0.020*"assignment" + 0.019*"num" + 0.017*"name"
INFO: topic diff=2.342424, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.577 per-word bound, 1527.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.048*"variable" + 0.044*"local" + 0.042*"global" + 0.035*"value" + 0.033*"function" + 0.022*"scope" + 0.021*"assignment" + 0.019*"name" + 0.018*"code" + 0.016*"="
INFO: topic #1 (1.000): 0.091*"variable" + 0.063*"global" + 0.050*"function" + 0.048*"local" + 0.038*"scope" + 0.022*"name" + 0.019*"assignment" + 0.017*"error" + 0.016*"value" + 0.014*"c"
INFO: topic #2 (1.000): 0.091*"variable" + 0.066*"global" + 0.059*"function" + 0.047*"local" + 0.029*"scope" + 0.021*"value" + 0.019*"assignment" + 0.018*"line" + 0.015*"name" + 0.014*"code"
INFO: topic diff=2.204268, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 69.25693653366739
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.6523661195912287
DEBUG: bound: at document #0
INFO: -6.010 per-word bound, 64.5 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.050*"variable" + 0.041*"value" + 0.031*"program" + 0.029*"local" + 0.028*"global" + 0.024*"loop" + 0.023*"function" + 0.020*"scope" + 0.018*"code" + 0.017*"class"
INFO: topic #1 (1.000): 0.070*"variable" + 0.047*"global" + 0.042*"local" + 0.039*"function" + 0.036*"scope" + 0.024*"name" + 0.021*"c" + 0.021*"assignment" + 0.019*"line" + 0.018*"num"
INFO: topic #2 (1.000): 0.090*"variable" + 0.063*"global" + 0.063*"function" + 0.044*"local" + 0.026*"scope" + 0.021*"value" + 0.017*"assignment" + 0.015*"line" + 0.013*"work" + 0.013*"error"
INFO: topic diff=1.304013, rho=0.500000
DEBUG: bound: at document #0
INFO: -7.119 per-word bound, 139.0 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.058*"value" + 0.037*"variable" + 0.023*"global" + 0.022*"local" + 0.022*"program" + 0.021*"code" + 0.020*"loop" + 0.018*"function" + 0.015*"scope" + 0.014*"="
INFO: topic #1 (1.000): 0.072*"variable" + 0.045*"local" + 0.044*"global" + 0.041*"function" + 0.034*"scope" + 0.023*"name" + 0.022*"assignment" + 0.019*"c" + 0.017*"line" + 0.016*"error"
INFO: topic #2 (1.000): 0.100*"variable" + 0.089*"global" + 0.067*"function" + 0.050*"local" + 0.035*"var1" + 0.035*"f" + 0.028*"scope" + 0.021*"value" + 0.016*"work" + 0.014*"inside"
INFO: topic diff=1.278393, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 48.69111716542349
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.4185291221055853
DEBUG: bound: at document #0
INFO: -5.601 per-word bound, 48.5 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.056*"value" + 0.044*"program" + 0.043*"variable" + 0.035*"loop" + 0.023*"class" + 0.023*"definition" + 0.020*"code" + 0.016*"scope" + 0.013*"global" + 0.013*"object"
INFO: topic #1 (1.000): 0.065*"variable" + 0.042*"local" + 0.042*"global" + 0.036*"function" + 0.035*"scope" + 0.024*"name" + 0.022*"c" + 0.022*"assignment" + 0.020*"line" + 0.019*"num"
INFO: topic #2 (1.000): 0.106*"variable" + 0.090*"global" + 0.078*"function" + 0.048*"local" + 0.028*"f" + 0.028*"var1" + 0.026*"scope" + 0.022*"value" + 0.017*"work" + 0.017*"inside"
INFO: topic diff=0.821011, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.028 per-word bound, 65.3 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.070*"value" + 0.031*"variable" + 0.030*"program" + 0.028*"loop" + 0.023*"code" + 0.018*"condition" + 0.016*"class" + 0.016*"definition" + 0.014*"bit" + 0.014*"long"
INFO: topic #1 (1.000): 0.067*"variable" + 0.044*"local" + 0.040*"global" + 0.037*"function" + 0.033*"scope" + 0.024*"name" + 0.023*"assignment" + 0.020*"c" + 0.018*"line" + 0.018*"num"
INFO: topic #2 (1.000): 0.105*"variable" + 0.098*"global" + 0.073*"function" + 0.051*"local" + 0.040*"f" + 0.040*"var1" + 0.028*"scope" + 0.021*"value" + 0.018*"inside" + 0.017*"work"
INFO: topic diff=0.710674, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 45.84056269603568
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -3.248591526267463
DEBUG: bound: at document #0
INFO: -5.524 per-word bound, 46.0 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.064*"value" + 0.049*"program" + 0.040*"loop" + 0.039*"variable" + 0.025*"class" + 0.025*"definition" + 0.021*"code" + 0.014*"test" + 0.013*"object" + 0.013*"point"
INFO: topic #1 (1.000): 0.063*"variable" + 0.042*"local" + 0.040*"global" + 0.034*"scope" + 0.034*"function" + 0.025*"name" + 0.022*"c" + 0.022*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.113*"variable" + 0.099*"global" + 0.085*"function" + 0.050*"local" + 0.032*"f" + 0.032*"var1" + 0.027*"scope" + 0.023*"value" + 0.021*"inside" + 0.018*"work"
INFO: topic diff=0.456951, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.872 per-word bound, 58.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.074*"value" + 0.034*"program" + 0.033*"loop" + 0.028*"variable" + 0.024*"code" + 0.022*"condition" + 0.018*"class" + 0.018*"definition" + 0.015*"instance" + 0.015*"comment"
INFO: topic #1 (1.000): 0.065*"variable" + 0.044*"local" + 0.038*"global" + 0.035*"function" + 0.033*"scope" + 0.024*"name" + 0.023*"assignment" + 0.021*"c" + 0.019*"line" + 0.018*"num"
INFO: topic #2 (1.000): 0.109*"variable" + 0.101*"global" + 0.077*"function" + 0.052*"local" + 0.040*"f" + 0.040*"var1" + 0.028*"scope" + 0.022*"value" + 0.020*"inside" + 0.018*"work"
INFO: topic diff=0.415044, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 45.120880587008756
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -3.230032074882347
DEBUG: bound: at document #0
INFO: -5.498 per-word bound, 45.2 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.066*"value" + 0.050*"program" + 0.042*"loop" + 0.036*"variable" + 0.026*"class" + 0.026*"definition" + 0.021*"code" + 0.014*"test" + 0.013*"version" + 0.013*"mind"
INFO: topic #1 (1.000): 0.063*"variable" + 0.042*"local" + 0.039*"global" + 0.034*"scope" + 0.033*"function" + 0.025*"name" + 0.023*"assignment" + 0.022*"c" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.116*"variable" + 0.102*"global" + 0.088*"function" + 0.051*"local" + 0.033*"var1" + 0.033*"f" + 0.027*"scope" + 0.023*"inside" + 0.023*"value" + 0.018*"work"
INFO: topic diff=0.305538, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.826 per-word bound, 56.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.076*"value" + 0.036*"program" + 0.035*"loop" + 0.027*"variable" + 0.024*"condition" + 0.024*"code" + 0.018*"class" + 0.018*"definition" + 0.015*"long" + 0.015*"execute"
INFO: topic #1 (1.000): 0.064*"variable" + 0.044*"local" + 0.038*"global" + 0.034*"function" + 0.033*"scope" + 0.024*"name" + 0.024*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"num"
INFO: topic #2 (1.000): 0.111*"variable" + 0.102*"global" + 0.079*"function" + 0.052*"local" + 0.040*"f" + 0.040*"var1" + 0.028*"scope" + 0.022*"value" + 0.022*"inside" + 0.018*"work"
INFO: topic diff=0.283027, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 44.882271832149335
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -3.2248976513226437
DEBUG: bound: at document #0
INFO: -5.486 per-word bound, 44.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"value" + 0.051*"program" + 0.043*"loop" + 0.034*"variable" + 0.026*"class" + 0.026*"definition" + 0.021*"code" + 0.015*"condition" + 0.014*"test" + 0.014*"version"
INFO: topic #1 (1.000): 0.062*"variable" + 0.042*"local" + 0.039*"global" + 0.034*"scope" + 0.033*"function" + 0.025*"name" + 0.023*"assignment" + 0.023*"c" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.118*"variable" + 0.103*"global" + 0.090*"function" + 0.051*"local" + 0.034*"var1" + 0.034*"f" + 0.027*"scope" + 0.025*"inside" + 0.023*"value" + 0.018*"work"
INFO: topic diff=0.248841, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.805 per-word bound, 55.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.076*"value" + 0.037*"program" + 0.036*"loop" + 0.026*"variable" + 0.026*"condition" + 0.024*"code" + 0.019*"class" + 0.019*"definition" + 0.015*"long" + 0.015*"execute"
INFO: topic #1 (1.000): 0.063*"variable" + 0.043*"local" + 0.038*"global" + 0.034*"function" + 0.033*"scope" + 0.024*"name" + 0.024*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"num"
INFO: topic #2 (1.000): 0.112*"variable" + 0.103*"global" + 0.081*"function" + 0.052*"local" + 0.040*"f" + 0.040*"var1" + 0.028*"scope" + 0.022*"inside" + 0.022*"value" + 0.018*"work"
INFO: topic diff=0.234459, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 44.77382088962273
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -3.2214161429578603
DEBUG: bound: at document #0
INFO: -5.478 per-word bound, 44.6 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"value" + 0.051*"program" + 0.043*"loop" + 0.033*"variable" + 0.026*"class" + 0.026*"definition" + 0.022*"code" + 0.016*"condition" + 0.014*"test" + 0.013*"version"
INFO: topic #1 (1.000): 0.062*"variable" + 0.042*"local" + 0.039*"global" + 0.034*"scope" + 0.032*"function" + 0.025*"name" + 0.023*"assignment" + 0.023*"c" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.119*"variable" + 0.103*"global" + 0.091*"function" + 0.052*"local" + 0.034*"var1" + 0.034*"f" + 0.028*"scope" + 0.025*"inside" + 0.023*"value" + 0.018*"work"
INFO: topic diff=0.222219, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.793 per-word bound, 55.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.076*"value" + 0.037*"program" + 0.037*"loop" + 0.027*"condition" + 0.026*"variable" + 0.024*"code" + 0.019*"class" + 0.019*"definition" + 0.015*"long" + 0.015*"define"
INFO: topic #1 (1.000): 0.063*"variable" + 0.043*"local" + 0.038*"global" + 0.034*"scope" + 0.033*"function" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"num"
INFO: topic #2 (1.000): 0.113*"variable" + 0.103*"global" + 0.082*"function" + 0.053*"local" + 0.040*"f" + 0.040*"var1" + 0.028*"scope" + 0.023*"inside" + 0.022*"value" + 0.018*"work"
INFO: topic diff=0.210080, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 44.707980930900696
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -3.209644030327367
DEBUG: bound: at document #0
INFO: -5.472 per-word bound, 44.4 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"value" + 0.050*"program" + 0.044*"loop" + 0.032*"variable" + 0.026*"class" + 0.026*"definition" + 0.022*"code" + 0.017*"condition" + 0.014*"test" + 0.013*"version"
INFO: topic #1 (1.000): 0.062*"variable" + 0.042*"local" + 0.039*"global" + 0.034*"scope" + 0.032*"function" + 0.025*"name" + 0.023*"assignment" + 0.023*"c" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.120*"variable" + 0.103*"global" + 0.091*"function" + 0.052*"local" + 0.034*"f" + 0.034*"var1" + 0.028*"scope" + 0.026*"inside" + 0.023*"value" + 0.018*"work"
INFO: topic diff=0.204451, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.783 per-word bound, 55.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.076*"value" + 0.038*"program" + 0.038*"loop" + 0.028*"condition" + 0.026*"variable" + 0.023*"code" + 0.020*"class" + 0.019*"definition" + 0.015*"define" + 0.015*"execute"
INFO: topic #1 (1.000): 0.063*"variable" + 0.043*"local" + 0.038*"global" + 0.034*"scope" + 0.033*"function" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"num"
INFO: topic #2 (1.000): 0.114*"variable" + 0.103*"global" + 0.082*"function" + 0.053*"local" + 0.039*"f" + 0.039*"var1" + 0.028*"scope" + 0.024*"inside" + 0.022*"value" + 0.018*"work"
INFO: topic diff=0.195106, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 44.661679363152174
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -3.209644030327367
DEBUG: bound: at document #0
INFO: -5.468 per-word bound, 44.3 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"value" + 0.050*"program" + 0.044*"loop" + 0.032*"variable" + 0.026*"class" + 0.026*"definition" + 0.022*"code" + 0.018*"condition" + 0.014*"test" + 0.013*"version"
INFO: topic #1 (1.000): 0.062*"variable" + 0.042*"local" + 0.039*"global" + 0.034*"scope" + 0.032*"function" + 0.025*"name" + 0.023*"assignment" + 0.023*"c" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.120*"variable" + 0.103*"global" + 0.091*"function" + 0.052*"local" + 0.034*"var1" + 0.034*"f" + 0.028*"scope" + 0.026*"inside" + 0.023*"value" + 0.018*"work"
INFO: topic diff=0.191253, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.776 per-word bound, 54.8 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.076*"value" + 0.038*"program" + 0.038*"loop" + 0.028*"condition" + 0.026*"variable" + 0.023*"code" + 0.020*"class" + 0.020*"definition" + 0.015*"note" + 0.015*"long"
INFO: topic #1 (1.000): 0.062*"variable" + 0.043*"local" + 0.038*"global" + 0.034*"scope" + 0.033*"function" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"num"
INFO: topic #2 (1.000): 0.114*"variable" + 0.103*"global" + 0.083*"function" + 0.053*"local" + 0.039*"f" + 0.039*"var1" + 0.028*"scope" + 0.024*"inside" + 0.022*"value" + 0.018*"work"
INFO: topic diff=0.183515, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 44.628216213906086
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -2.6416554729245267
DEBUG: bound: at document #0
INFO: -5.465 per-word bound, 44.2 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"value" + 0.050*"program" + 0.044*"loop" + 0.032*"variable" + 0.025*"class" + 0.025*"definition" + 0.022*"code" + 0.019*"condition" + 0.014*"test" + 0.013*"version"
INFO: topic #1 (1.000): 0.062*"variable" + 0.042*"local" + 0.039*"global" + 0.034*"scope" + 0.032*"function" + 0.025*"name" + 0.023*"assignment" + 0.022*"c" + 0.020*"line" + 0.020*"num"
INFO: topic #2 (1.000): 0.120*"variable" + 0.103*"global" + 0.091*"function" + 0.052*"local" + 0.034*"var1" + 0.034*"f" + 0.028*"scope" + 0.026*"inside" + 0.023*"value" + 0.018*"work"
INFO: topic diff=0.180285, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.770 per-word bound, 54.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.075*"value" + 0.039*"program" + 0.038*"loop" + 0.028*"condition" + 0.026*"variable" + 0.023*"code" + 0.020*"class" + 0.020*"definition" + 0.015*"note" + 0.015*"solution"
INFO: topic #1 (1.000): 0.062*"variable" + 0.043*"local" + 0.038*"global" + 0.034*"scope" + 0.033*"function" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"num"
INFO: topic #2 (1.000): 0.114*"variable" + 0.103*"global" + 0.083*"function" + 0.053*"local" + 0.039*"var1" + 0.039*"f" + 0.028*"scope" + 0.024*"inside" + 0.022*"value" + 0.018*"work"
INFO: topic diff=0.173749, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 44.60403700051321
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -2.0633980684023165
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5> in 0.20s', 'datetime': '2023-03-22T01:20:59.187963', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: <<Training Time>>: 0.20589208602905273
INFO: topic #0 (1.000): 0.075*"value" + 0.039*"program" + 0.038*"loop" + 0.028*"condition" + 0.026*"variable" + 0.023*"code" + 0.020*"class" + 0.020*"definition" + 0.015*"note" + 0.015*"solution"
INFO: topic #1 (1.000): 0.062*"variable" + 0.043*"local" + 0.038*"global" + 0.034*"scope" + 0.033*"function" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.019*"line" + 0.019*"num"
INFO: topic #2 (1.000): 0.114*"variable" + 0.103*"global" + 0.083*"function" + 0.053*"local" + 0.039*"var1" + 0.039*"f" + 0.028*"scope" + 0.024*"inside" + 0.022*"value" + 0.018*"work"
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/post_num/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-22T01:20:59.188639', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/post_num/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model.state
DEBUG: {'uri': 'model/post_num/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/post_num/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-22T01:20:59.194654', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/post_num/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/post_num/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model
INFO: ============================================================
INFO: Starts Training Model
INFO: ============================================================
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<327 unique tokens: ["'", '+', '2.x', '3.x', '=']...> from 10 documents (total 987 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<327 unique tokens: ["\'", \'+\', \'2.x\', \'3.x\', \'=\']...> from 10 documents (total 987 corpus positions)', 'datetime': '2023-03-22T01:20:59.200057', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.016 per-word bound, 129.4 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.062*"variable" + 0.043*"global" + 0.041*"local" + 0.036*"function" + 0.035*"scope" + 0.024*"name" + 0.024*"c" + 0.021*"assignment" + 0.020*"line" + 0.020*"num"
INFO: topic #1 (1.000): 0.060*"variable" + 0.032*"function" + 0.028*"global" + 0.026*"scope" + 0.024*"program" + 0.022*"value" + 0.022*"local" + 0.017*"loop" + 0.014*"definition" + 0.013*"assignment"
INFO: topic #2 (1.000): 0.092*"variable" + 0.037*"value" + 0.036*"function" + 0.030*"program" + 0.027*"local" + 0.024*"scope" + 0.024*"global" + 0.019*"loop" + 0.017*"access" + 0.017*"class"
INFO: topic diff=3.618527, rho=1.000000
DEBUG: bound: at document #0
INFO: -9.722 per-word bound, 844.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"variable" + 0.062*"global" + 0.052*"local" + 0.047*"function" + 0.034*"scope" + 0.024*"name" + 0.023*"assignment" + 0.018*"line" + 0.018*"error" + 0.017*"c"
INFO: topic #1 (1.000): 0.049*"variable" + 0.043*"global" + 0.039*"function" + 0.030*"value" + 0.020*"local" + 0.018*"scope" + 0.012*"loop" + 0.012*"program" + 0.011*"line" + 0.011*"code"
INFO: topic #2 (1.000): 0.120*"variable" + 0.058*"function" + 0.051*"global" + 0.048*"value" + 0.036*"local" + 0.029*"f" + 0.029*"var1" + 0.026*"inside" + 0.023*"scope" + 0.015*"print"
INFO: topic diff=2.477605, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 52.45288559794778
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -1.5009047964511852
DEBUG: bound: at document #0
INFO: -5.630 per-word bound, 49.5 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.065*"variable" + 0.048*"global" + 0.044*"local" + 0.038*"function" + 0.035*"scope" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.038*"variable" + 0.033*"global" + 0.031*"function" + 0.026*"value" + 0.018*"loop" + 0.015*"local" + 0.014*"scope" + 0.013*"appropriate" + 0.013*"program" + 0.009*"definition"
INFO: topic #2 (1.000): 0.113*"variable" + 0.053*"function" + 0.052*"value" + 0.039*"global" + 0.030*"program" + 0.025*"local" + 0.023*"inside" + 0.021*"loop" + 0.021*"scope" + 0.016*"var1"
INFO: topic diff=0.930121, rho=0.500000
DEBUG: bound: at document #0
INFO: -6.696 per-word bound, 103.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.065*"variable" + 0.052*"global" + 0.050*"local" + 0.040*"function" + 0.034*"scope" + 0.025*"name" + 0.025*"assignment" + 0.020*"line" + 0.019*"error" + 0.018*"c"
INFO: topic #1 (1.000): 0.041*"global" + 0.029*"value" + 0.029*"function" + 0.023*"variable" + 0.018*"start" + 0.018*"coffee_machine" + 0.018*"force" + 0.012*"condition" + 0.012*"local" + 0.011*"loop"
INFO: topic #2 (1.000): 0.116*"variable" + 0.063*"function" + 0.062*"global" + 0.043*"var1" + 0.043*"f" + 0.043*"value" + 0.033*"local" + 0.025*"inside" + 0.021*"scope" + 0.014*"print"
INFO: topic diff=0.848428, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 48.204582880461274
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -2.4184455792946356
DEBUG: bound: at document #0
INFO: -5.547 per-word bound, 46.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.063*"variable" + 0.045*"global" + 0.044*"local" + 0.036*"function" + 0.035*"scope" + 0.025*"name" + 0.023*"assignment" + 0.022*"c" + 0.020*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.031*"global" + 0.025*"value" + 0.025*"appropriate" + 0.022*"function" + 0.017*"variable" + 0.013*"start" + 0.013*"force" + 0.013*"coffee_machine" + 0.012*"loop" + 0.009*"condition"
INFO: topic #2 (1.000): 0.114*"variable" + 0.062*"function" + 0.053*"global" + 0.047*"value" + 0.027*"var1" + 0.027*"f" + 0.027*"local" + 0.026*"program" + 0.024*"inside" + 0.021*"scope"
INFO: topic diff=0.461356, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.211 per-word bound, 74.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.062*"variable" + 0.048*"local" + 0.047*"global" + 0.037*"function" + 0.035*"scope" + 0.026*"name" + 0.025*"assignment" + 0.021*"line" + 0.019*"error" + 0.019*"c"
INFO: topic #1 (1.000): 0.034*"value" + 0.033*"global" + 0.025*"coffee_machine" + 0.025*"force" + 0.025*"start" + 0.019*"bit" + 0.019*"comment" + 0.019*"define" + 0.019*"execute" + 0.019*"instance"
INFO: topic #2 (1.000): 0.118*"variable" + 0.072*"global" + 0.069*"function" + 0.043*"f" + 0.043*"var1" + 0.040*"value" + 0.035*"local" + 0.025*"inside" + 0.021*"scope" + 0.014*"work"
INFO: topic diff=0.448280, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 46.913974852343934
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -4.400014959613872
DEBUG: bound: at document #0
INFO: -5.510 per-word bound, 45.6 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.061*"variable" + 0.044*"local" + 0.043*"global" + 0.035*"scope" + 0.034*"function" + 0.025*"name" + 0.023*"assignment" + 0.022*"c" + 0.021*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.029*"value" + 0.029*"appropriate" + 0.025*"global" + 0.018*"force" + 0.018*"start" + 0.018*"coffee_machine" + 0.014*"function" + 0.013*"comment" + 0.013*"bit" + 0.013*"execute"
INFO: topic #2 (1.000): 0.117*"variable" + 0.070*"function" + 0.063*"global" + 0.044*"value" + 0.030*"local" + 0.029*"var1" + 0.029*"f" + 0.025*"inside" + 0.024*"program" + 0.021*"scope"
INFO: topic diff=0.298734, rho=0.408248
DEBUG: bound: at document #0
INFO: -6.089 per-word bound, 68.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.061*"variable" + 0.047*"local" + 0.044*"global" + 0.035*"scope" + 0.034*"function" + 0.026*"name" + 0.026*"assignment" + 0.021*"line" + 0.019*"error" + 0.019*"c"
INFO: topic #1 (1.000): 0.047*"value" + 0.027*"force" + 0.027*"start" + 0.027*"coffee_machine" + 0.024*"comment" + 0.024*"execute" + 0.024*"instance" + 0.024*"long" + 0.024*"bit" + 0.024*"define"
INFO: topic #2 (1.000): 0.120*"variable" + 0.080*"global" + 0.075*"function" + 0.042*"var1" + 0.042*"f" + 0.038*"local" + 0.036*"value" + 0.026*"inside" + 0.022*"scope" + 0.015*"work"
INFO: topic diff=0.329797, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 46.326027742969686
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -3.9154135433785204
DEBUG: bound: at document #0
INFO: -5.492 per-word bound, 45.0 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"variable" + 0.043*"local" + 0.042*"global" + 0.035*"scope" + 0.033*"function" + 0.026*"name" + 0.024*"assignment" + 0.022*"c" + 0.021*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.041*"value" + 0.029*"appropriate" + 0.019*"force" + 0.019*"coffee_machine" + 0.019*"start" + 0.018*"define" + 0.018*"bit" + 0.018*"long" + 0.018*"execute" + 0.018*"instance"
INFO: topic #2 (1.000): 0.120*"variable" + 0.076*"function" + 0.071*"global" + 0.040*"value" + 0.033*"local" + 0.030*"f" + 0.030*"var1" + 0.025*"inside" + 0.023*"program" + 0.022*"scope"
INFO: topic diff=0.240231, rho=0.377964
DEBUG: bound: at document #0
INFO: -6.028 per-word bound, 65.3 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"variable" + 0.046*"local" + 0.042*"global" + 0.035*"scope" + 0.033*"function" + 0.027*"name" + 0.026*"assignment" + 0.021*"line" + 0.020*"c" + 0.020*"error"
INFO: topic #1 (1.000): 0.062*"value" + 0.027*"start" + 0.027*"force" + 0.027*"coffee_machine" + 0.026*"comment" + 0.026*"define" + 0.026*"bit" + 0.026*"instance" + 0.026*"long" + 0.026*"execute"
INFO: topic #2 (1.000): 0.121*"variable" + 0.086*"global" + 0.079*"function" + 0.041*"f" + 0.041*"var1" + 0.040*"local" + 0.033*"value" + 0.026*"inside" + 0.022*"scope" + 0.016*"work"
INFO: topic diff=0.259467, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 46.044034121297024
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -3.905144696259114
DEBUG: bound: at document #0
INFO: -5.481 per-word bound, 44.7 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"variable" + 0.043*"local" + 0.041*"global" + 0.035*"scope" + 0.032*"function" + 0.026*"name" + 0.024*"assignment" + 0.022*"c" + 0.021*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.055*"value" + 0.029*"appropriate" + 0.020*"start" + 0.020*"force" + 0.020*"coffee_machine" + 0.019*"comment" + 0.019*"define" + 0.019*"bit" + 0.019*"long" + 0.019*"execute"
INFO: topic #2 (1.000): 0.121*"variable" + 0.079*"function" + 0.077*"global" + 0.037*"value" + 0.036*"local" + 0.030*"f" + 0.030*"var1" + 0.025*"inside" + 0.022*"program" + 0.022*"scope"
INFO: topic diff=0.208253, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.999 per-word bound, 64.0 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"variable" + 0.045*"local" + 0.040*"global" + 0.034*"scope" + 0.032*"function" + 0.027*"name" + 0.026*"assignment" + 0.021*"line" + 0.020*"c" + 0.020*"error"
INFO: topic #1 (1.000): 0.074*"value" + 0.027*"condition" + 0.027*"start" + 0.027*"force" + 0.027*"coffee_machine" + 0.026*"bit" + 0.026*"comment" + 0.026*"define" + 0.026*"execute" + 0.026*"long"
INFO: topic #2 (1.000): 0.122*"variable" + 0.089*"global" + 0.081*"function" + 0.042*"local" + 0.040*"var1" + 0.040*"f" + 0.031*"value" + 0.026*"inside" + 0.023*"scope" + 0.016*"work"
INFO: topic diff=0.218963, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 45.88937815425447
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -3.970063609365394
DEBUG: bound: at document #0
INFO: -5.473 per-word bound, 44.4 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"variable" + 0.042*"local" + 0.040*"global" + 0.035*"scope" + 0.031*"function" + 0.026*"name" + 0.024*"assignment" + 0.022*"c" + 0.021*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.066*"value" + 0.028*"appropriate" + 0.021*"condition" + 0.020*"start" + 0.020*"force" + 0.020*"coffee_machine" + 0.020*"bit" + 0.020*"comment" + 0.020*"execute" + 0.020*"define"
INFO: topic #2 (1.000): 0.122*"variable" + 0.082*"function" + 0.080*"global" + 0.038*"local" + 0.035*"value" + 0.030*"f" + 0.030*"var1" + 0.025*"inside" + 0.022*"scope" + 0.022*"program"
INFO: topic diff=0.187647, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.983 per-word bound, 63.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"variable" + 0.044*"local" + 0.040*"global" + 0.034*"scope" + 0.031*"function" + 0.027*"name" + 0.026*"assignment" + 0.021*"line" + 0.020*"c" + 0.020*"error"
INFO: topic #1 (1.000): 0.082*"value" + 0.029*"condition" + 0.026*"start" + 0.026*"force" + 0.026*"coffee_machine" + 0.026*"bit" + 0.026*"instance" + 0.026*"long" + 0.026*"comment" + 0.026*"define"
INFO: topic #2 (1.000): 0.123*"variable" + 0.091*"global" + 0.083*"function" + 0.044*"local" + 0.040*"var1" + 0.040*"f" + 0.030*"value" + 0.026*"inside" + 0.023*"scope" + 0.016*"work"
INFO: topic diff=0.192983, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 45.789031640056784
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -3.970063609365394
DEBUG: bound: at document #0
INFO: -5.466 per-word bound, 44.2 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"variable" + 0.042*"local" + 0.040*"global" + 0.035*"scope" + 0.031*"function" + 0.026*"name" + 0.024*"assignment" + 0.022*"c" + 0.021*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.074*"value" + 0.028*"appropriate" + 0.022*"condition" + 0.020*"start" + 0.020*"force" + 0.020*"coffee_machine" + 0.020*"comment" + 0.020*"bit" + 0.020*"instance" + 0.020*"define"
INFO: topic #2 (1.000): 0.122*"variable" + 0.083*"function" + 0.082*"global" + 0.040*"local" + 0.033*"value" + 0.030*"var1" + 0.030*"f" + 0.025*"inside" + 0.023*"scope" + 0.021*"program"
INFO: topic diff=0.172621, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.972 per-word bound, 62.8 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"variable" + 0.043*"local" + 0.039*"global" + 0.034*"scope" + 0.030*"function" + 0.027*"name" + 0.026*"assignment" + 0.022*"line" + 0.020*"c" + 0.020*"error"
INFO: topic #1 (1.000): 0.088*"value" + 0.030*"condition" + 0.026*"start" + 0.026*"force" + 0.026*"coffee_machine" + 0.026*"long" + 0.026*"define" + 0.026*"bit" + 0.026*"instance" + 0.026*"execute"
INFO: topic #2 (1.000): 0.123*"variable" + 0.092*"global" + 0.084*"function" + 0.045*"local" + 0.039*"f" + 0.039*"var1" + 0.029*"value" + 0.025*"inside" + 0.023*"scope" + 0.016*"work"
INFO: topic diff=0.175148, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 45.72075011313996
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -3.970063609365394
DEBUG: bound: at document #0
INFO: -5.461 per-word bound, 44.1 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"variable" + 0.042*"local" + 0.039*"global" + 0.035*"scope" + 0.030*"function" + 0.026*"name" + 0.024*"assignment" + 0.022*"c" + 0.021*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.079*"value" + 0.027*"appropriate" + 0.024*"condition" + 0.020*"coffee_machine" + 0.020*"force" + 0.020*"start" + 0.020*"comment" + 0.020*"long" + 0.020*"execute" + 0.020*"define"
INFO: topic #2 (1.000): 0.123*"variable" + 0.084*"function" + 0.083*"global" + 0.041*"local" + 0.032*"value" + 0.030*"var1" + 0.030*"f" + 0.025*"inside" + 0.023*"scope" + 0.021*"program"
INFO: topic diff=0.161387, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.964 per-word bound, 62.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.058*"variable" + 0.043*"local" + 0.039*"global" + 0.034*"scope" + 0.030*"function" + 0.027*"name" + 0.026*"assignment" + 0.022*"line" + 0.020*"c" + 0.020*"error"
INFO: topic #1 (1.000): 0.092*"value" + 0.032*"condition" + 0.026*"coffee_machine" + 0.026*"start" + 0.026*"force" + 0.026*"bit" + 0.026*"comment" + 0.026*"long" + 0.026*"instance" + 0.026*"define"
INFO: topic #2 (1.000): 0.123*"variable" + 0.092*"global" + 0.084*"function" + 0.046*"local" + 0.038*"f" + 0.038*"var1" + 0.028*"value" + 0.025*"inside" + 0.023*"scope" + 0.016*"work"
INFO: topic diff=0.162017, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 45.675873157281515
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -3.970063609365394
DEBUG: bound: at document #0
INFO: -5.458 per-word bound, 43.9 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"variable" + 0.042*"local" + 0.039*"global" + 0.035*"scope" + 0.030*"function" + 0.026*"name" + 0.025*"assignment" + 0.022*"c" + 0.021*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.083*"value" + 0.027*"appropriate" + 0.025*"condition" + 0.020*"coffee_machine" + 0.020*"start" + 0.020*"force" + 0.020*"instance" + 0.020*"long" + 0.020*"execute" + 0.020*"define"
INFO: topic #2 (1.000): 0.123*"variable" + 0.085*"function" + 0.084*"global" + 0.042*"local" + 0.031*"value" + 0.030*"var1" + 0.030*"f" + 0.025*"inside" + 0.023*"scope" + 0.021*"program"
INFO: topic diff=0.152393, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.958 per-word bound, 62.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.058*"variable" + 0.043*"local" + 0.039*"global" + 0.034*"scope" + 0.030*"function" + 0.027*"name" + 0.026*"assignment" + 0.022*"line" + 0.021*"c" + 0.020*"error"
INFO: topic #1 (1.000): 0.094*"value" + 0.033*"condition" + 0.025*"start" + 0.025*"coffee_machine" + 0.025*"force" + 0.025*"define" + 0.025*"instance" + 0.025*"bit" + 0.025*"long" + 0.025*"execute"
INFO: topic #2 (1.000): 0.123*"variable" + 0.093*"global" + 0.085*"function" + 0.047*"local" + 0.038*"var1" + 0.038*"f" + 0.028*"value" + 0.025*"inside" + 0.024*"scope" + 0.016*"work"
INFO: topic diff=0.151741, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 45.6456919050488
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -3.970063609365394
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5> in 0.19s', 'datetime': '2023-03-22T01:20:59.398014', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: <<Training Time>>: 0.20016694068908691
INFO: topic #0 (1.000): 0.058*"variable" + 0.043*"local" + 0.039*"global" + 0.034*"scope" + 0.030*"function" + 0.027*"name" + 0.026*"assignment" + 0.022*"line" + 0.021*"c" + 0.020*"error"
INFO: topic #1 (1.000): 0.094*"value" + 0.033*"condition" + 0.025*"start" + 0.025*"coffee_machine" + 0.025*"force" + 0.025*"define" + 0.025*"instance" + 0.025*"bit" + 0.025*"long" + 0.025*"execute"
INFO: topic #2 (1.000): 0.123*"variable" + 0.093*"global" + 0.085*"function" + 0.047*"local" + 0.038*"var1" + 0.038*"f" + 0.028*"value" + 0.025*"inside" + 0.024*"scope" + 0.016*"work"
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/post_num/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-22T01:20:59.398594', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/post_num/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model.state
DEBUG: {'uri': 'model/post_num/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/post_num/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['dispatcher', 'id2word', 'state'], 'datetime': '2023-03-22T01:20:59.403607', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/post_num/model.expElogbeta.npy
INFO: not storing attribute dispatcher
INFO: not storing attribute id2word
INFO: not storing attribute state
DEBUG: {'uri': 'model/post_num/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/post_num/model
