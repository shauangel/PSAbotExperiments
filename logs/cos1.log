INFO: --------------------
INFO: Why am I getting an UnboundLocalError when the variable has a value?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<327 unique tokens: ["'", '+', '2.x', '3.x', '=']...> from 10 documents (total 987 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<327 unique tokens: ["\'", \'+\', \'2.x\', \'3.x\', \'=\']...> from 10 documents (total 987 corpus positions)', 'datetime': '2023-04-18T14:15:54.276287', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.042 per-word bound, 131.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.070*"variable" + 0.045*"global" + 0.038*"local" + 0.036*"function" + 0.035*"scope" + 0.024*"name" + 0.023*"c" + 0.022*"assignment" + 0.019*"line" + 0.019*"="
INFO: topic #1 (1.000): 0.047*"variable" + 0.041*"function" + 0.040*"local" + 0.026*"scope" + 0.021*"global" + 0.020*"value" + 0.016*"line" + 0.016*"assignment" + 0.015*"name" + 0.015*"num"
INFO: topic #2 (1.000): 0.050*"variable" + 0.035*"local" + 0.031*"scope" + 0.029*"function" + 0.029*"global" + 0.023*"num" + 0.022*"value" + 0.018*"name" + 0.016*"program" + 0.016*"loop"
INFO: topic diff=2.743793, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.141 per-word bound, 1129.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.091*"variable" + 0.067*"global" + 0.049*"function" + 0.049*"local" + 0.034*"scope" + 0.023*"assignment" + 0.022*"name" + 0.017*"value" + 0.017*"error" + 0.016*"line"
INFO: topic #1 (1.000): 0.063*"variable" + 0.059*"function" + 0.048*"local" + 0.037*"global" + 0.029*"value" + 0.024*"scope" + 0.022*"var1" + 0.022*"f" + 0.012*"assignment" + 0.012*"line"
INFO: topic #2 (1.000): 0.048*"variable" + 0.040*"global" + 0.036*"value" + 0.035*"function" + 0.033*"local" + 0.024*"scope" + 0.014*"num" + 0.013*"name" + 0.013*"loop" + 0.013*"line"
INFO: topic diff=2.489657, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 57.68113776994719
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.6887521524403669
DEBUG: bound: at document #0
INFO: -5.729 per-word bound, 53.0 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"variable" + 0.050*"global" + 0.043*"local" + 0.041*"function" + 0.035*"scope" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.019*"line" + 0.018*"num"
INFO: topic #1 (1.000): 0.055*"variable" + 0.052*"function" + 0.038*"local" + 0.032*"global" + 0.029*"value" + 0.019*"scope" + 0.018*"other" + 0.017*"f" + 0.017*"var1" + 0.011*"access"
INFO: topic #2 (1.000): 0.051*"variable" + 0.041*"program" + 0.041*"value" + 0.032*"loop" + 0.023*"global" + 0.021*"scope" + 0.021*"definition" + 0.021*"class" + 0.020*"function" + 0.018*"local"
INFO: topic diff=1.210235, rho=0.500000
DEBUG: bound: at document #0
INFO: -6.944 per-word bound, 123.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.080*"variable" + 0.057*"global" + 0.047*"local" + 0.044*"function" + 0.034*"scope" + 0.023*"name" + 0.023*"assignment" + 0.018*"line" + 0.017*"error" + 0.017*"c"
INFO: topic #1 (1.000): 0.074*"variable" + 0.062*"function" + 0.061*"global" + 0.051*"var1" + 0.051*"f" + 0.042*"local" + 0.031*"value" + 0.018*"scope" + 0.013*"return" + 0.013*"caller"
INFO: topic #2 (1.000): 0.050*"value" + 0.041*"variable" + 0.030*"program" + 0.028*"loop" + 0.021*"global" + 0.018*"function" + 0.016*"scope" + 0.015*"definition" + 0.015*"code" + 0.015*"class"
INFO: topic diff=1.121341, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 48.41205547021327
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.5362938430038238
DEBUG: bound: at document #0
INFO: -5.548 per-word bound, 46.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.071*"variable" + 0.048*"global" + 0.043*"local" + 0.040*"function" + 0.035*"scope" + 0.024*"name" + 0.022*"assignment" + 0.021*"c" + 0.019*"line" + 0.018*"num"
INFO: topic #1 (1.000): 0.069*"variable" + 0.061*"function" + 0.057*"global" + 0.043*"f" + 0.043*"var1" + 0.037*"local" + 0.030*"value" + 0.017*"other" + 0.016*"scope" + 0.012*"inside"
INFO: topic #2 (1.000): 0.053*"program" + 0.050*"value" + 0.047*"variable" + 0.042*"loop" + 0.027*"definition" + 0.027*"class" + 0.017*"code" + 0.017*"scope" + 0.014*"point" + 0.014*"version"
INFO: topic diff=0.664066, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.201 per-word bound, 73.6 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.074*"variable" + 0.048*"global" + 0.047*"local" + 0.041*"function" + 0.035*"scope" + 0.024*"name" + 0.024*"assignment" + 0.019*"line" + 0.018*"c" + 0.018*"error"
INFO: topic #1 (1.000): 0.084*"global" + 0.084*"variable" + 0.067*"function" + 0.052*"f" + 0.052*"var1" + 0.042*"local" + 0.033*"value" + 0.017*"scope" + 0.016*"inside" + 0.013*"return"
INFO: topic #2 (1.000): 0.050*"value" + 0.041*"program" + 0.039*"variable" + 0.039*"loop" + 0.021*"definition" + 0.021*"class" + 0.015*"code" + 0.014*"scope" + 0.012*"point" + 0.012*"print"
INFO: topic diff=0.526101, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 46.57195827921118
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -0.6261518874904263
DEBUG: bound: at document #0
INFO: -5.496 per-word bound, 45.1 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"variable" + 0.045*"global" + 0.043*"local" + 0.038*"function" + 0.035*"scope" + 0.024*"name" + 0.023*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.083*"variable" + 0.082*"global" + 0.070*"function" + 0.044*"f" + 0.044*"var1" + 0.038*"local" + 0.033*"value" + 0.017*"inside" + 0.015*"scope" + 0.015*"other"
INFO: topic #2 (1.000): 0.058*"program" + 0.050*"value" + 0.048*"loop" + 0.046*"variable" + 0.030*"class" + 0.030*"definition" + 0.017*"code" + 0.016*"point" + 0.016*"test" + 0.015*"version"
INFO: topic diff=0.436879, rho=0.408248
DEBUG: bound: at document #0
INFO: -6.059 per-word bound, 66.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.071*"variable" + 0.046*"local" + 0.043*"global" + 0.039*"function" + 0.035*"scope" + 0.025*"name" + 0.024*"assignment" + 0.019*"line" + 0.019*"c" + 0.018*"error"
INFO: topic #1 (1.000): 0.096*"global" + 0.092*"variable" + 0.071*"function" + 0.050*"f" + 0.050*"var1" + 0.042*"local" + 0.036*"value" + 0.019*"inside" + 0.017*"scope" + 0.014*"work"
INFO: topic #2 (1.000): 0.046*"value" + 0.046*"program" + 0.044*"loop" + 0.038*"variable" + 0.024*"class" + 0.024*"definition" + 0.015*"code" + 0.013*"point" + 0.013*"scope" + 0.013*"test"
INFO: topic diff=0.362200, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 45.92875060374389
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -0.5699065373261315
DEBUG: bound: at document #0
INFO: -5.473 per-word bound, 44.4 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"variable" + 0.043*"local" + 0.042*"global" + 0.036*"function" + 0.035*"scope" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.096*"global" + 0.094*"variable" + 0.078*"function" + 0.042*"f" + 0.042*"var1" + 0.040*"local" + 0.037*"value" + 0.021*"inside" + 0.016*"scope" + 0.014*"other"
INFO: topic #2 (1.000): 0.060*"program" + 0.050*"loop" + 0.048*"value" + 0.045*"variable" + 0.031*"class" + 0.031*"definition" + 0.017*"code" + 0.016*"test" + 0.016*"point" + 0.016*"version"
INFO: topic diff=0.341875, rho=0.377964
DEBUG: bound: at document #0
INFO: -6.005 per-word bound, 64.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"variable" + 0.045*"local" + 0.041*"global" + 0.037*"function" + 0.035*"scope" + 0.026*"name" + 0.025*"assignment" + 0.020*"line" + 0.019*"c" + 0.018*"error"
INFO: topic #1 (1.000): 0.102*"global" + 0.098*"variable" + 0.075*"function" + 0.048*"f" + 0.048*"var1" + 0.044*"local" + 0.037*"value" + 0.021*"inside" + 0.017*"scope" + 0.016*"work"
INFO: topic #2 (1.000): 0.048*"program" + 0.046*"loop" + 0.043*"value" + 0.038*"variable" + 0.025*"class" + 0.025*"definition" + 0.015*"code" + 0.014*"point" + 0.013*"test" + 0.013*"version"
INFO: topic diff=0.301836, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 45.63963580314409
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -0.5695204928731599
DEBUG: bound: at document #0
INFO: -5.461 per-word bound, 44.0 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.065*"variable" + 0.043*"local" + 0.040*"global" + 0.035*"scope" + 0.035*"function" + 0.025*"name" + 0.023*"assignment" + 0.021*"c" + 0.020*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.102*"variable" + 0.102*"global" + 0.084*"function" + 0.042*"local" + 0.040*"var1" + 0.040*"f" + 0.038*"value" + 0.024*"inside" + 0.017*"scope" + 0.016*"work"
INFO: topic #2 (1.000): 0.060*"program" + 0.051*"loop" + 0.046*"value" + 0.044*"variable" + 0.031*"class" + 0.031*"definition" + 0.017*"test" + 0.016*"code" + 0.016*"point" + 0.016*"version"
INFO: topic diff=0.288910, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.979 per-word bound, 63.1 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.066*"variable" + 0.045*"local" + 0.039*"global" + 0.035*"function" + 0.035*"scope" + 0.026*"name" + 0.025*"assignment" + 0.020*"line" + 0.020*"c" + 0.019*"error"
INFO: topic #1 (1.000): 0.104*"global" + 0.103*"variable" + 0.079*"function" + 0.046*"f" + 0.046*"var1" + 0.045*"local" + 0.038*"value" + 0.023*"inside" + 0.018*"scope" + 0.017*"work"
INFO: topic #2 (1.000): 0.049*"program" + 0.047*"loop" + 0.042*"value" + 0.038*"variable" + 0.026*"class" + 0.025*"definition" + 0.015*"code" + 0.014*"point" + 0.014*"test" + 0.014*"version"
INFO: topic diff=0.266215, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 45.488823462386996
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -0.5695204928731599
DEBUG: bound: at document #0
INFO: -5.453 per-word bound, 43.8 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.064*"variable" + 0.043*"local" + 0.040*"global" + 0.035*"scope" + 0.034*"function" + 0.025*"name" + 0.024*"assignment" + 0.022*"c" + 0.020*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.108*"variable" + 0.104*"global" + 0.088*"function" + 0.044*"local" + 0.039*"value" + 0.039*"var1" + 0.039*"f" + 0.026*"inside" + 0.018*"scope" + 0.017*"work"
INFO: topic #2 (1.000): 0.061*"program" + 0.051*"loop" + 0.045*"value" + 0.044*"variable" + 0.031*"class" + 0.031*"definition" + 0.017*"test" + 0.016*"point" + 0.016*"code" + 0.016*"version"
INFO: topic diff=0.256581, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.963 per-word bound, 62.4 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.065*"variable" + 0.044*"local" + 0.038*"global" + 0.035*"scope" + 0.034*"function" + 0.026*"name" + 0.026*"assignment" + 0.020*"line" + 0.020*"c" + 0.019*"error"
INFO: topic #1 (1.000): 0.106*"variable" + 0.105*"global" + 0.081*"function" + 0.046*"local" + 0.044*"var1" + 0.044*"f" + 0.038*"value" + 0.024*"inside" + 0.019*"scope" + 0.018*"work"
INFO: topic #2 (1.000): 0.050*"program" + 0.048*"loop" + 0.041*"value" + 0.038*"variable" + 0.026*"class" + 0.026*"definition" + 0.015*"code" + 0.014*"test" + 0.014*"point" + 0.014*"version"
INFO: topic diff=0.242026, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 45.398391365161494
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -0.5908716305638783
DEBUG: bound: at document #0
INFO: -5.448 per-word bound, 43.6 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.063*"variable" + 0.042*"local" + 0.039*"global" + 0.035*"scope" + 0.033*"function" + 0.026*"name" + 0.024*"assignment" + 0.022*"c" + 0.021*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.111*"variable" + 0.105*"global" + 0.090*"function" + 0.046*"local" + 0.039*"value" + 0.038*"var1" + 0.038*"f" + 0.027*"inside" + 0.019*"scope" + 0.018*"work"
INFO: topic #2 (1.000): 0.061*"program" + 0.051*"loop" + 0.044*"value" + 0.044*"variable" + 0.031*"class" + 0.031*"definition" + 0.017*"test" + 0.016*"point" + 0.016*"version" + 0.016*"mind"
INFO: topic diff=0.234589, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.952 per-word bound, 61.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.064*"variable" + 0.044*"local" + 0.038*"global" + 0.035*"scope" + 0.033*"function" + 0.026*"name" + 0.026*"assignment" + 0.021*"line" + 0.020*"c" + 0.019*"error"
INFO: topic #1 (1.000): 0.108*"variable" + 0.105*"global" + 0.083*"function" + 0.047*"local" + 0.043*"var1" + 0.043*"f" + 0.039*"value" + 0.025*"inside" + 0.020*"scope" + 0.018*"work"
INFO: topic #2 (1.000): 0.051*"program" + 0.048*"loop" + 0.040*"value" + 0.038*"variable" + 0.026*"class" + 0.026*"definition" + 0.015*"code" + 0.014*"test" + 0.014*"point" + 0.014*"version"
INFO: topic diff=0.224829, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 45.338029143325656
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -0.5908716305638783
DEBUG: bound: at document #0
INFO: -5.444 per-word bound, 43.5 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.063*"variable" + 0.042*"local" + 0.039*"global" + 0.035*"scope" + 0.033*"function" + 0.026*"name" + 0.024*"assignment" + 0.022*"c" + 0.021*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.113*"variable" + 0.105*"global" + 0.092*"function" + 0.047*"local" + 0.040*"value" + 0.038*"var1" + 0.038*"f" + 0.027*"inside" + 0.019*"scope" + 0.018*"work"
INFO: topic #2 (1.000): 0.061*"program" + 0.052*"loop" + 0.043*"value" + 0.043*"variable" + 0.031*"class" + 0.031*"definition" + 0.017*"test" + 0.016*"point" + 0.016*"version" + 0.016*"mind"
INFO: topic diff=0.218367, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.943 per-word bound, 61.5 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.063*"variable" + 0.044*"local" + 0.038*"global" + 0.035*"scope" + 0.033*"function" + 0.026*"name" + 0.026*"assignment" + 0.021*"line" + 0.020*"c" + 0.019*"error"
INFO: topic #1 (1.000): 0.110*"variable" + 0.105*"global" + 0.084*"function" + 0.048*"local" + 0.043*"var1" + 0.043*"f" + 0.039*"value" + 0.025*"inside" + 0.021*"scope" + 0.018*"work"
INFO: topic #2 (1.000): 0.051*"program" + 0.049*"loop" + 0.040*"value" + 0.038*"variable" + 0.027*"class" + 0.026*"definition" + 0.015*"code" + 0.015*"test" + 0.014*"point" + 0.014*"version"
INFO: topic diff=0.211558, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 45.29540580496723
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -0.5908716305638783
DEBUG: bound: at document #0
INFO: -5.440 per-word bound, 43.4 perplexity estimate based on a held-out corpus of 5 documents with 772 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.062*"variable" + 0.042*"local" + 0.039*"global" + 0.035*"scope" + 0.032*"function" + 0.026*"name" + 0.024*"assignment" + 0.022*"c" + 0.021*"line" + 0.019*"num"
INFO: topic #1 (1.000): 0.115*"variable" + 0.105*"global" + 0.093*"function" + 0.047*"local" + 0.040*"value" + 0.037*"f" + 0.037*"var1" + 0.028*"inside" + 0.020*"scope" + 0.018*"work"
INFO: topic #2 (1.000): 0.060*"program" + 0.052*"loop" + 0.043*"variable" + 0.043*"value" + 0.031*"class" + 0.031*"definition" + 0.017*"test" + 0.016*"point" + 0.016*"version" + 0.016*"mind"
INFO: topic diff=0.205451, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.936 per-word bound, 61.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.063*"variable" + 0.043*"local" + 0.038*"global" + 0.035*"scope" + 0.032*"function" + 0.027*"name" + 0.026*"assignment" + 0.021*"line" + 0.020*"c" + 0.019*"error"
INFO: topic #1 (1.000): 0.111*"variable" + 0.105*"global" + 0.085*"function" + 0.048*"local" + 0.042*"f" + 0.042*"var1" + 0.039*"value" + 0.026*"inside" + 0.021*"scope" + 0.018*"work"
INFO: topic #2 (1.000): 0.052*"program" + 0.049*"loop" + 0.040*"value" + 0.038*"variable" + 0.027*"class" + 0.027*"definition" + 0.015*"test" + 0.015*"code" + 0.014*"point" + 0.014*"version"
INFO: topic diff=0.200567, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 45.262578832749234
DEBUG: Setting topics to those of the model: LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -0.5887406522494206
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=327, num_topics=3, decay=0.5, chunksize=5> in 0.18s', 'datetime': '2023-04-18T14:15:54.488944', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/cos_threshold/1/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-18T14:15:54.489228', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/cos_threshold/1/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/1/model.state
DEBUG: {'uri': 'model/cos_threshold/1/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/cos_threshold/1/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['state', 'id2word', 'dispatcher'], 'datetime': '2023-04-18T14:15:54.492593', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/cos_threshold/1/model.expElogbeta.npy
INFO: not storing attribute state
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
DEBUG: {'uri': 'model/cos_threshold/1/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/1/model
INFO: topic #0 (1.000): 0.063*"variable" + 0.043*"local" + 0.038*"global" + 0.035*"scope" + 0.032*"function" + 0.027*"name" + 0.026*"assignment" + 0.021*"line" + 0.020*"c" + 0.019*"error"
INFO: topic #1 (1.000): 0.111*"variable" + 0.105*"global" + 0.085*"function" + 0.048*"local" + 0.042*"f" + 0.042*"var1" + 0.039*"value" + 0.026*"inside" + 0.021*"scope" + 0.018*"work"
INFO: topic #2 (1.000): 0.052*"program" + 0.049*"loop" + 0.040*"value" + 0.038*"variable" + 0.027*"class" + 0.027*"definition" + 0.015*"test" + 0.015*"code" + 0.014*"point" + 0.014*"version"
INFO: Question Similarity: [0.09997576475143433, 0.2740594744682312, 0.33948254585266113, 0.1766795516014099, 0.14734762907028198, 0.04911869764328003, 0.1273798942565918, 0.3242040276527405, 0.06313157081604004, 0.2122756838798523]
INFO: 71164410: -0.25320815759634685
INFO: 74412646: -0.3582356553372373
INFO: 74412647: -0.36883030798456956
INFO: 74297685: -0.3734497446171339
INFO: 74412557: -0.3740043473341898
INFO: 53956671: -0.4450125174785256
INFO: 53956563: -0.44853690129518403
INFO: 75285878: -0.595082257273578
INFO: 10852006: -0.6831592605277906
INFO: 10852003: -0.6904088881576219
INFO: 26579841: -0.6927923480603579
INFO: 21836774: -0.6983169029458466
INFO: 10851939: -0.7069212536729195
INFO: 74454524: -0.7718762503518389
INFO: Recommended Keywords
INFO: define score: -0.7839429
INFO: example score: -0.76684225
INFO: function score: -0.75242656
INFO: direct score: -0.74914473
INFO: definition score: -0.7424206
INFO: assign score: -0.72287405
INFO: appropriate score: -0.72014904
INFO: change score: -0.68913984
INFO: assume score: -0.68336564
INFO: instance score: -0.6826322
INFO: case score: -0.6759248
INFO: problem score: -0.67500705
INFO: calculated score: -0.6641418
INFO: solution score: -0.65834624
INFO: simple score: -0.6496975
INFO: scope score: -0.6395535
INFO: value score: -0.62514836
INFO: method score: -0.62467575
INFO: addition score: -0.6234574
INFO: reference score: -0.6224695
INFO: complete score: -0.6224196
INFO: link score: -0.6190433
INFO: testing score: -0.6135368
INFO: error score: -0.61173064
INFO: variable score: -0.6092792
INFO: condition score: -0.60792553
INFO: parameter score: -0.60556567
INFO: key score: -0.5977361
INFO: different score: -0.59590566
INFO: clear score: -0.58764195
INFO: object score: -0.5873398
INFO: utility score: -0.5859993
INFO: unit score: -0.57346207
INFO: offset score: -0.56810516
INFO: mechanism score: -0.56734926
INFO: completeness score: -0.5669988
INFO: code score: -0.56412476
INFO: loop score: -0.55820495
INFO: result score: -0.5576516
INFO: implementation score: -0.5503395
INFO: solve score: -0.5463153
INFO: way score: -0.53113365
INFO: class score: -0.53013813
INFO: variables score: -0.52950037
INFO: conditional score: -0.5258478
INFO: point score: -0.5243467
INFO: test score: -0.5200803
INFO: information score: -0.51793647
INFO: augmented score: -0.5040617
INFO: other score: -0.5018476
INFO: tweak score: -0.4999542
INFO: block score: -0.4992541
INFO: assignment score: -0.49335372
INFO: accessing score: -0.48965856
INFO: default score: -0.48539105
INFO: behavior score: -0.4833
INFO: f score: -0.48326212
INFO: program score: -0.48056743
INFO: new score: -0.48044923
INFO: practice score: -0.47839567
INFO: misleading score: -0.47183567
INFO: locally score: -0.47100753
INFO: update score: -0.46986523
INFO: load score: -0.46543068
INFO: module score: -0.46386153
INFO: statement score: -0.4628613
INFO: global score: -0.4609297
INFO: compile score: -0.46056002
INFO: question score: -0.45926785
INFO: time score: -0.4539345
INFO: local score: -0.45196334
INFO: access score: -0.44854617
INFO: note score: -0.44626993
INFO: version score: -0.44618398
INFO: c score: -0.44463006
INFO: right score: -0.44415975
INFO: original score: -0.44062084
INFO: mutable score: -0.44046313
INFO: var1 score: -0.4380294
INFO: documentation score: -0.4347361
INFO: idea score: -0.43077788
INFO: lookup score: -0.42154163
INFO: execute score: -0.42074662
INFO: little score: -0.41888306
INFO: traditional score: -0.4187089
INFO: name score: -0.4185656
INFO: detail score: -0.4148676
INFO: interesting score: -0.4143412
INFO: post score: -0.4136435
INFO: initialization score: -0.41192502
INFO: b score: -0.41145656
INFO: message score: -0.4109452
INFO: line score: -0.41019228
INFO: long score: -0.4083249
INFO: outside score: -0.4063667
INFO: keyword score: -0.39743483
INFO: bit score: -0.39683667
INFO: table score: -0.39197794
INFO: aware score: -0.3859999
INFO: semantic score: -0.38377792
INFO: parse score: -0.38362065
INFO: work score: -0.3829904
INFO: lie score: -0.38087228
INFO: notice score: -0.3807149
INFO: inside score: -0.3805077
INFO: issue score: -0.3787868
INFO: good score: -0.36928448
INFO: read score: -0.36598343
INFO: scan score: -0.3597414
INFO: copy score: -0.359233
INFO: pointer score: -0.35502562
INFO: nonlocal score: -0.34526134
INFO: look score: -0.34051952
INFO: print score: -0.33691135
INFO: language score: -0.33361545
INFO: pass score: -0.32857284
INFO: first score: -0.3254282
INFO: answer score: -0.32379308
INFO: help score: -0.3196862
INFO: rename score: -0.31652042
INFO: side score: -0.3146208
INFO: compiler score: -0.3120274
INFO: builtin score: -0.308496
INFO: byte score: -0.30622533
INFO: sure score: -0.28885898
INFO: interpreter score: -0.2885265
INFO: force score: -0.2696017
INFO: fine score: -0.2537989
INFO: foo score: -0.2467687
INFO: dictionary score: -0.24545325
INFO: quirk score: -0.242817
INFO: comment score: -0.24113761
INFO: life score: -0.23679543
INFO: = score: -0.23677972
INFO: caller score: -0.23011708
INFO: gotcha score: -0.21814933
INFO: bytecode score: -0.20323429
INFO: mind score: -0.19504143
INFO: mask score: -0.18666118
INFO: uppermost score: -0.17121743
INFO: num score: -0.15314184
INFO: start score: -0.14970587
INFO: return score: -0.14083642
INFO: near score: -0.11869508
INFO: mystery score: -0.04709843
INFO: get_team score: -0.0
INFO: unboundlocalerror score: -0.0
INFO: uncomment score: -0.0
INFO: c+=1 score: -0.0
INFO: bar=0 score: -0.0
INFO: docs.python.org/3.1/faq/programming.html?highlight=nonlocal#why-am-i-getting-an-unboundlocalerror-when-the-variable-has-a-value score: -0.0
INFO: docs.python.org/3.1/faq/programming.html?highlight=nonlocal#how-do-i-write-a-function-with-output-parameters-call-by-reference score: -0.0
INFO: load_global score: -0.0
INFO: ' score: -0.0
INFO: coffee_machine score: -0.0
INFO: boss(live score: -0.0
INFO: 2.7.6 score: -0.0
INFO: team score: 0.11070685
INFO: del score: 0.1398441
INFO: ============================================================
INFO: --------------------
INFO: What are the rules for local and global variables in Python?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<310 unique tokens: ['42', '=', 'access', 'accidental', 'add']...> from 9 documents (total 996 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<310 unique tokens: ['42', '=', 'access', 'accidental', 'add']...> from 9 documents (total 996 corpus positions)", 'datetime': '2023-04-18T14:15:57.033882', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 9 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -6.997 per-word bound, 127.7 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 0, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.116*"variable" + 0.088*"global" + 0.069*"local" + 0.042*"function" + 0.020*"change" + 0.018*"name" + 0.017*"module" + 0.013*"example" + 0.011*"scope" + 0.010*"keyword"
INFO: topic #1 (1.000): 0.128*"global" + 0.105*"variable" + 0.055*"function" + 0.041*"module" + 0.037*"local" + 0.031*"name" + 0.011*"example" + 0.010*"file" + 0.010*"scope" + 0.010*"change"
INFO: topic #2 (1.000): 0.108*"global" + 0.099*"variable" + 0.051*"function" + 0.043*"local" + 0.021*"module" + 0.017*"name" + 0.012*"keyword" + 0.011*"case" + 0.011*"value" + 0.010*"p1o"
INFO: topic diff=3.479215, rho=1.000000
DEBUG: bound: at document #0
INFO: -9.372 per-word bound, 662.5 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 0, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.096*"variable" + 0.075*"global" + 0.056*"local" + 0.040*"function" + 0.016*"name" + 0.015*"value" + 0.013*"module" + 0.012*"change" + 0.012*"example" + 0.011*"case"
INFO: topic #1 (1.000): 0.134*"global" + 0.099*"variable" + 0.067*"function" + 0.045*"module" + 0.034*"local" + 0.032*"name" + 0.019*"value" + 0.016*"assign" + 0.015*"keyword" + 0.013*"attribute"
INFO: topic #2 (1.000): 0.095*"global" + 0.087*"variable" + 0.051*"function" + 0.034*"local" + 0.028*"value" + 0.017*"name" + 0.015*"case" + 0.012*"keyword" + 0.010*"object" + 0.010*"module"
INFO: topic diff=2.815691, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 42.69492809861828
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.6269860856542507
DEBUG: bound: at document #0
INFO: -5.243 per-word bound, 37.9 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 1, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.112*"variable" + 0.072*"global" + 0.069*"local" + 0.032*"function" + 0.026*"change" + 0.019*"value" + 0.017*"bool" + 0.017*"type" + 0.017*"p2o" + 0.016*"p1o"
INFO: topic #1 (1.000): 0.131*"global" + 0.104*"variable" + 0.060*"function" + 0.042*"module" + 0.037*"local" + 0.031*"name" + 0.012*"keyword" + 0.012*"value" + 0.011*"example" + 0.011*"scope"
INFO: topic #2 (1.000): 0.082*"global" + 0.076*"variable" + 0.044*"function" + 0.033*"local" + 0.023*"value" + 0.016*"name" + 0.015*"case" + 0.011*"keyword" + 0.009*"object" + 0.008*"module"
INFO: topic diff=1.263221, rho=0.512989
DEBUG: bound: at document #0
INFO: -6.664 per-word bound, 101.4 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 1, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.093*"variable" + 0.061*"global" + 0.058*"local" + 0.028*"function" + 0.021*"change" + 0.017*"value" + 0.014*"case" + 0.014*"bool" + 0.014*"type" + 0.014*"p2o"
INFO: topic #1 (1.000): 0.131*"global" + 0.097*"variable" + 0.065*"function" + 0.045*"module" + 0.035*"local" + 0.031*"name" + 0.015*"assign" + 0.014*"keyword" + 0.013*"value" + 0.012*"namespace"
INFO: topic #2 (1.000): 0.072*"global" + 0.068*"variable" + 0.041*"function" + 0.039*"value" + 0.026*"local" + 0.018*"bad" + 0.018*"project" + 0.018*"big" + 0.018*"fct1" + 0.018*"programming"
INFO: topic diff=1.080333, rho=0.512989
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 37.80519301019254
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -2.411917630066864
DEBUG: bound: at document #0
INFO: -5.138 per-word bound, 35.2 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 2, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.109*"variable" + 0.069*"local" + 0.060*"global" + 0.030*"change" + 0.022*"function" + 0.020*"bool" + 0.020*"type" + 0.020*"p2o" + 0.020*"value" + 0.020*"p1o"
INFO: topic #1 (1.000): 0.131*"global" + 0.103*"variable" + 0.060*"function" + 0.042*"module" + 0.037*"local" + 0.031*"name" + 0.012*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"class"
INFO: topic #2 (1.000): 0.064*"global" + 0.060*"variable" + 0.037*"function" + 0.035*"value" + 0.025*"local" + 0.015*"bad" + 0.015*"big" + 0.015*"programmer" + 0.015*"programming" + 0.015*"project"
INFO: topic diff=0.691823, rho=0.456435
DEBUG: bound: at document #0
INFO: -6.001 per-word bound, 64.0 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 2, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.092*"variable" + 0.059*"local" + 0.052*"global" + 0.025*"change" + 0.020*"function" + 0.018*"value" + 0.017*"bool" + 0.017*"type" + 0.017*"p2o" + 0.017*"p1o"
INFO: topic #1 (1.000): 0.131*"global" + 0.099*"variable" + 0.065*"function" + 0.044*"module" + 0.036*"local" + 0.031*"name" + 0.015*"keyword" + 0.015*"assign" + 0.012*"scope" + 0.012*"example"
INFO: topic #2 (1.000): 0.061*"global" + 0.060*"variable" + 0.048*"value" + 0.037*"function" + 0.022*"local" + 0.019*"bad" + 0.019*"project" + 0.019*"big" + 0.019*"fct1" + 0.019*"programming"
INFO: topic diff=0.512879, rho=0.456435
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 36.85508745216588
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -2.7964910760051374
DEBUG: bound: at document #0
INFO: -5.099 per-word bound, 34.3 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 3, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.105*"variable" + 0.068*"local" + 0.051*"global" + 0.033*"change" + 0.022*"bool" + 0.022*"type" + 0.022*"p2o" + 0.022*"p1o" + 0.022*"non" + 0.021*"value"
INFO: topic #1 (1.000): 0.131*"global" + 0.104*"variable" + 0.061*"function" + 0.042*"module" + 0.037*"local" + 0.031*"name" + 0.013*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"class"
INFO: topic #2 (1.000): 0.055*"global" + 0.054*"variable" + 0.043*"value" + 0.033*"function" + 0.021*"local" + 0.017*"bad" + 0.017*"project" + 0.017*"big" + 0.017*"fct1" + 0.017*"programming"
INFO: topic diff=0.465372, rho=0.415227
DEBUG: bound: at document #0
INFO: -5.902 per-word bound, 59.8 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 3, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.091*"variable" + 0.059*"local" + 0.045*"global" + 0.027*"change" + 0.018*"bool" + 0.018*"value" + 0.018*"type" + 0.018*"p2o" + 0.018*"p1o" + 0.018*"non"
INFO: topic #1 (1.000): 0.133*"global" + 0.100*"variable" + 0.065*"function" + 0.044*"module" + 0.036*"local" + 0.030*"name" + 0.015*"keyword" + 0.014*"assign" + 0.012*"scope" + 0.012*"example"
INFO: topic #2 (1.000): 0.055*"global" + 0.054*"variable" + 0.052*"value" + 0.033*"function" + 0.020*"bad" + 0.020*"big" + 0.020*"project" + 0.020*"programmer" + 0.020*"programming" + 0.020*"fct1"
INFO: topic diff=0.385777, rho=0.415227
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 36.47234272715447
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -3.1204934125787105
DEBUG: bound: at document #0
INFO: -5.079 per-word bound, 33.8 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 4, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.102*"variable" + 0.066*"local" + 0.045*"global" + 0.034*"change" + 0.023*"bool" + 0.023*"type" + 0.023*"p2o" + 0.023*"p1o" + 0.023*"non" + 0.021*"value"
INFO: topic #1 (1.000): 0.132*"global" + 0.104*"variable" + 0.062*"function" + 0.042*"module" + 0.038*"local" + 0.031*"name" + 0.013*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"class"
INFO: topic #2 (1.000): 0.050*"global" + 0.050*"variable" + 0.047*"value" + 0.030*"function" + 0.019*"local" + 0.017*"bad" + 0.017*"project" + 0.017*"big" + 0.017*"fct1" + 0.017*"programming"
INFO: topic diff=0.373219, rho=0.383482
DEBUG: bound: at document #0
INFO: -5.865 per-word bound, 58.3 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 4, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.089*"variable" + 0.058*"local" + 0.040*"global" + 0.029*"change" + 0.019*"bool" + 0.019*"type" + 0.019*"p2o" + 0.019*"p1o" + 0.019*"non" + 0.019*"value"
INFO: topic #1 (1.000): 0.134*"global" + 0.101*"variable" + 0.066*"function" + 0.044*"module" + 0.037*"local" + 0.030*"name" + 0.015*"keyword" + 0.014*"assign" + 0.012*"scope" + 0.012*"example"
INFO: topic #2 (1.000): 0.055*"value" + 0.051*"variable" + 0.050*"global" + 0.031*"function" + 0.020*"project" + 0.020*"programming" + 0.020*"fct1" + 0.020*"big" + 0.020*"bad" + 0.020*"programmer"
INFO: topic diff=0.341899, rho=0.383482
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 36.27105176139756
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -3.0742836005413814
DEBUG: bound: at document #0
INFO: -5.066 per-word bound, 33.5 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 5, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.100*"variable" + 0.064*"local" + 0.040*"global" + 0.035*"change" + 0.023*"bool" + 0.023*"type" + 0.023*"p2o" + 0.023*"p1o" + 0.023*"non" + 0.022*"value"
INFO: topic #1 (1.000): 0.133*"global" + 0.105*"variable" + 0.062*"function" + 0.042*"module" + 0.038*"local" + 0.031*"name" + 0.013*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"class"
INFO: topic #2 (1.000): 0.050*"value" + 0.046*"variable" + 0.045*"global" + 0.028*"function" + 0.018*"project" + 0.018*"programming" + 0.018*"fct1" + 0.018*"big" + 0.018*"bad" + 0.018*"programmer"
INFO: topic diff=0.326837, rho=0.358057
DEBUG: bound: at document #0
INFO: -5.845 per-word bound, 57.5 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 5, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.087*"variable" + 0.056*"local" + 0.036*"global" + 0.030*"change" + 0.020*"bool" + 0.020*"type" + 0.020*"p2o" + 0.020*"p1o" + 0.020*"non" + 0.019*"value"
INFO: topic #1 (1.000): 0.134*"global" + 0.102*"variable" + 0.066*"function" + 0.043*"module" + 0.037*"local" + 0.030*"name" + 0.015*"keyword" + 0.014*"assign" + 0.012*"scope" + 0.012*"example"
INFO: topic #2 (1.000): 0.057*"value" + 0.047*"variable" + 0.045*"global" + 0.028*"function" + 0.020*"fct1" + 0.020*"programming" + 0.020*"big" + 0.020*"bad" + 0.020*"programmer" + 0.020*"project"
INFO: topic diff=0.308147, rho=0.358057
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 36.14218600492667
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -3.0742836005413814
DEBUG: bound: at document #0
INFO: -5.057 per-word bound, 33.3 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 6, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.098*"variable" + 0.062*"local" + 0.037*"global" + 0.035*"change" + 0.024*"bool" + 0.024*"type" + 0.024*"p2o" + 0.024*"p1o" + 0.024*"non" + 0.022*"value"
INFO: topic #1 (1.000): 0.133*"global" + 0.105*"variable" + 0.063*"function" + 0.042*"module" + 0.038*"local" + 0.031*"name" + 0.013*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"class"
INFO: topic #2 (1.000): 0.052*"value" + 0.044*"variable" + 0.042*"global" + 0.026*"function" + 0.018*"programmer" + 0.018*"programming" + 0.018*"fct1" + 0.018*"big" + 0.018*"project" + 0.018*"bad"
INFO: topic diff=0.296958, rho=0.337100
DEBUG: bound: at document #0
INFO: -5.831 per-word bound, 56.9 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 6, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.086*"variable" + 0.055*"local" + 0.033*"global" + 0.030*"change" + 0.021*"bool" + 0.021*"type" + 0.021*"p2o" + 0.021*"p1o" + 0.020*"non" + 0.020*"value"
INFO: topic #1 (1.000): 0.135*"global" + 0.103*"variable" + 0.066*"function" + 0.043*"module" + 0.038*"local" + 0.030*"name" + 0.015*"keyword" + 0.013*"assign" + 0.012*"scope" + 0.012*"example"
INFO: topic #2 (1.000): 0.057*"value" + 0.045*"variable" + 0.042*"global" + 0.026*"function" + 0.020*"programming" + 0.020*"project" + 0.020*"programmer" + 0.020*"big" + 0.020*"fct1" + 0.020*"bad"
INFO: topic diff=0.282551, rho=0.337100
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 36.05079339912328
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -3.0742836005413814
DEBUG: bound: at document #0
INFO: -5.050 per-word bound, 33.1 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 7, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.096*"variable" + 0.061*"local" + 0.036*"change" + 0.034*"global" + 0.024*"bool" + 0.024*"type" + 0.024*"p2o" + 0.024*"p1o" + 0.024*"non" + 0.022*"value"
INFO: topic #1 (1.000): 0.134*"global" + 0.105*"variable" + 0.063*"function" + 0.042*"module" + 0.039*"local" + 0.031*"name" + 0.013*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"class"
INFO: topic #2 (1.000): 0.053*"value" + 0.042*"variable" + 0.039*"global" + 0.025*"function" + 0.018*"fct1" + 0.018*"big" + 0.018*"bad" + 0.018*"project" + 0.018*"programming" + 0.018*"programmer"
INFO: topic diff=0.275133, rho=0.319438
DEBUG: bound: at document #0
INFO: -5.821 per-word bound, 56.5 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 7, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.086*"variable" + 0.054*"local" + 0.031*"change" + 0.031*"global" + 0.021*"bool" + 0.021*"type" + 0.021*"p2o" + 0.021*"p1o" + 0.021*"non" + 0.020*"value"
INFO: topic #1 (1.000): 0.135*"global" + 0.103*"variable" + 0.066*"function" + 0.043*"module" + 0.038*"local" + 0.030*"name" + 0.015*"keyword" + 0.013*"assign" + 0.012*"scope" + 0.011*"example"
INFO: topic #2 (1.000): 0.058*"value" + 0.043*"variable" + 0.039*"global" + 0.025*"function" + 0.020*"programming" + 0.020*"programmer" + 0.020*"big" + 0.020*"project" + 0.020*"bad" + 0.020*"fct1"
INFO: topic diff=0.264135, rho=0.319438
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 35.983101545772705
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -3.0640147534219744
DEBUG: bound: at document #0
INFO: -5.044 per-word bound, 33.0 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 8, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.095*"variable" + 0.060*"local" + 0.036*"change" + 0.032*"global" + 0.024*"bool" + 0.024*"type" + 0.024*"p2o" + 0.024*"p1o" + 0.024*"non" + 0.022*"value"
INFO: topic #1 (1.000): 0.134*"global" + 0.106*"variable" + 0.063*"function" + 0.042*"module" + 0.039*"local" + 0.031*"name" + 0.013*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"class"
INFO: topic #2 (1.000): 0.054*"value" + 0.040*"variable" + 0.036*"global" + 0.023*"function" + 0.019*"name" + 0.018*"one" + 0.018*"programmer" + 0.018*"programming" + 0.018*"fct1" + 0.018*"project"
INFO: topic diff=0.257651, rho=0.304290
DEBUG: bound: at document #0
INFO: -5.814 per-word bound, 56.3 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 8, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.085*"variable" + 0.054*"local" + 0.031*"change" + 0.029*"global" + 0.021*"bool" + 0.021*"type" + 0.021*"p2o" + 0.021*"p1o" + 0.021*"non" + 0.020*"value"
INFO: topic #1 (1.000): 0.136*"global" + 0.104*"variable" + 0.067*"function" + 0.043*"module" + 0.038*"local" + 0.030*"name" + 0.015*"keyword" + 0.013*"assign" + 0.012*"scope" + 0.011*"example"
INFO: topic #2 (1.000): 0.058*"value" + 0.041*"variable" + 0.037*"global" + 0.023*"function" + 0.020*"bad" + 0.020*"project" + 0.020*"programming" + 0.020*"programmer" + 0.020*"fct1" + 0.020*"big"
INFO: topic diff=0.248390, rho=0.304290
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 35.9325927919865
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -3.0640147534219744
DEBUG: bound: at document #0
INFO: -5.040 per-word bound, 32.9 perplexity estimate based on a held-out corpus of 5 documents with 769 words
INFO: PROGRESS: pass 9, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.094*"variable" + 0.059*"local" + 0.036*"change" + 0.031*"global" + 0.024*"bool" + 0.024*"type" + 0.024*"p2o" + 0.024*"p1o" + 0.024*"non" + 0.023*"value"
INFO: topic #1 (1.000): 0.134*"global" + 0.106*"variable" + 0.063*"function" + 0.042*"module" + 0.039*"local" + 0.030*"name" + 0.013*"keyword" + 0.011*"example" + 0.011*"scope" + 0.010*"class"
INFO: topic #2 (1.000): 0.054*"value" + 0.038*"variable" + 0.034*"global" + 0.022*"function" + 0.020*"name" + 0.019*"one" + 0.018*"bad" + 0.018*"programming" + 0.018*"fct1" + 0.018*"big"
INFO: topic diff=0.243515, rho=0.291111
DEBUG: bound: at document #0
INFO: -5.808 per-word bound, 56.0 perplexity estimate based on a held-out corpus of 4 documents with 227 words
INFO: PROGRESS: pass 9, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.085*"variable" + 0.053*"local" + 0.032*"change" + 0.028*"global" + 0.022*"bool" + 0.022*"type" + 0.022*"p2o" + 0.022*"p1o" + 0.021*"non" + 0.021*"value"
INFO: topic #1 (1.000): 0.136*"global" + 0.104*"variable" + 0.067*"function" + 0.043*"module" + 0.039*"local" + 0.030*"name" + 0.015*"keyword" + 0.013*"assign" + 0.012*"scope" + 0.011*"example"
INFO: topic #2 (1.000): 0.059*"value" + 0.039*"variable" + 0.034*"global" + 0.022*"function" + 0.020*"programming" + 0.020*"project" + 0.020*"big" + 0.020*"bad" + 0.020*"fct1" + 0.020*"programmer"
INFO: topic diff=0.234628, rho=0.291111
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 35.89475363610696
DEBUG: Setting topics to those of the model: LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -3.0640147534219744
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=310, num_topics=3, decay=0.5, chunksize=5> in 0.20s', 'datetime': '2023-04-18T14:15:57.235807', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/cos_threshold/2/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-18T14:15:57.236039', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/cos_threshold/2/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/2/model.state
DEBUG: {'uri': 'model/cos_threshold/2/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/cos_threshold/2/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['state', 'id2word', 'dispatcher'], 'datetime': '2023-04-18T14:15:57.238842', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/cos_threshold/2/model.expElogbeta.npy
INFO: not storing attribute state
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
DEBUG: {'uri': 'model/cos_threshold/2/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/2/model
INFO: topic #0 (1.000): 0.085*"variable" + 0.053*"local" + 0.032*"change" + 0.028*"global" + 0.022*"bool" + 0.022*"type" + 0.022*"p2o" + 0.022*"p1o" + 0.021*"non" + 0.021*"value"
INFO: topic #1 (1.000): 0.136*"global" + 0.104*"variable" + 0.067*"function" + 0.043*"module" + 0.039*"local" + 0.030*"name" + 0.015*"keyword" + 0.013*"assign" + 0.012*"scope" + 0.011*"example"
INFO: topic #2 (1.000): 0.059*"value" + 0.039*"variable" + 0.034*"global" + 0.022*"function" + 0.020*"programming" + 0.020*"project" + 0.020*"big" + 0.020*"bad" + 0.020*"fct1" + 0.020*"programmer"
INFO: Question Similarity: [0.2037978172302246, 0.1842917799949646, 0.05656999349594116, 0.41414839029312134, 0.1270071268081665, 0.12564557790756226, 0.0890117883682251, 0.0569494366645813, 0.2582508325576782, 0.0730162262916565]
INFO: 62212528: -0.2371757346902596
INFO: 62212545: -0.2763729983907603
INFO: 34559513: -0.3524981005472797
INFO: 423668: -0.35318827327888846
INFO: 423401: -0.3533272568169966
INFO: 24572187: -0.3554822640836491
INFO: 423641: -0.3567152899458182
INFO: 427818: -0.3568977998774523
INFO: 71663780: -0.3571970491622923
INFO: 63629668: -0.3575099637812259
INFO: 61992762: -0.35755559983938273
INFO: 6664227: -0.3595785532708679
INFO: 46058078: -0.3601997392682787
INFO: 71074895: -0.3613996858947419
INFO: 423596: -0.36159534614885946
INFO: 19347254: -0.3639586898244686
INFO: 75200331: -0.3643868997589514
INFO: 45769568: -0.3647661402073732
INFO: 19151605: -0.3655155405436031
INFO: 34664752: -0.37286586755565493
INFO: 33320055: -0.3733978183981158
INFO: 71883300: -0.37369198267215836
INFO: 67339244: -0.37646860570945195
INFO: 27287648: -0.38451811628662963
INFO: 27580376: -0.3912621257587033
INFO: 43285234: -0.4085848792948865
INFO: 28329600: -0.44778955764160433
INFO: 72690281: -0.5286002480118084
INFO: 75020199: -0.9822218769218954
INFO: Recommended Keywords
INFO: example score: -0.823193
INFO: particular score: -0.8148449
INFO: function score: -0.8056702
INFO: instance score: -0.7918747
INFO: assign score: -0.78559494
INFO: non score: -0.76848686
INFO: system score: -0.75596225
INFO: element score: -0.7523744
INFO: type score: -0.7499566
INFO: definition score: -0.74393696
INFO: simple score: -0.7429652
INFO: useful score: -0.7374592
INFO: change score: -0.71946776
INFO: process score: -0.7153267
INFO: add score: -0.7058726
INFO: method score: -0.7033998
INFO: attribute score: -0.7024585
INFO: variable score: -0.6911278
INFO: different score: -0.6889458
INFO: information score: -0.6871704
INFO: code score: -0.68620604
INFO: similar score: -0.6797558
INFO: scope score: -0.67925507
INFO: need score: -0.67790544
INFO: internal score: -0.6766937
INFO: problem score: -0.671713
INFO: effect score: -0.66796386
INFO: object score: -0.6653935
INFO: key score: -0.6604012
INFO: requirement score: -0.65869343
INFO: solution score: -0.6554036
INFO: explicit score: -0.64701843
INFO: usual score: -0.64108205
INFO: reference score: -0.6403799
INFO: addition score: -0.63107973
INFO: case score: -0.62991565
INFO: refer score: -0.6215941
INFO: value score: -0.61004204
INFO: expression score: -0.6058708
INFO: usable score: -0.6024945
INFO: programming score: -0.5994863
INFO: default score: -0.59119904
INFO: configuration score: -0.58886415
INFO: programmer score: -0.5851113
INFO: keyword score: -0.58322704
INFO: available score: -0.57590777
INFO: mutable score: -0.57333237
INFO: result score: -0.57042134
INFO: output score: -0.5667584
INFO: module score: -0.5641865
INFO: parameter score: -0.55963904
INFO: true score: -0.55412644
INFO: natural score: -0.55378157
INFO: array score: -0.5536924
INFO: connection score: -0.5520093
INFO: error score: -0.5435381
INFO: condition score: -0.54090244
INFO: test score: -0.5393159
INFO: see score: -0.5373983
INFO: confusing score: -0.53328025
INFO: choice score: -0.53321135
INFO: global score: -0.5262395
INFO: exception score: -0.52444255
INFO: document score: -0.5225599
INFO: project score: -0.521351
INFO: sample score: -0.5172975
INFO: unclear score: -0.5172473
INFO: share score: -0.5171464
INFO: behavior score: -0.51613367
INFO: reason score: -0.5160359
INFO: heuristic score: -0.5157422
INFO: explanation score: -0.5139354
INFO: notion score: -0.5135637
INFO: operation score: -0.5124753
INFO: namespace score: -0.5056517
INFO: parallel score: -0.5030215
INFO: access score: -0.49785063
INFO: singleton score: -0.49665835
INFO: make score: -0.4950102
INFO: symbol score: -0.48959377
INFO: well score: -0.4892497
INFO: execute score: -0.48469722
INFO: avoid score: -0.48328206
INFO: infinite score: -0.48149994
INFO: info score: -0.48085523
INFO: file score: -0.46969408
INFO: note score: -0.4669762
INFO: big score: -0.464708
INFO: load score: -0.46437228
INFO: contrary score: -0.46263102
INFO: design score: -0.46093357
INFO: datum score: -0.4564122
INFO: coding score: -0.45183784
INFO: accessible score: -0.45137718
INFO: point score: -0.4454747
INFO: way score: -0.4259122
INFO: callable score: -0.42539617
INFO: import score: -0.4234048
INFO: statement score: -0.4204285
INFO: main score: -0.4154167
INFO: one score: -0.4129009
INFO: body score: -0.41071385
INFO: original score: -0.41056022
INFO: rare score: -0.40842885
INFO: loop score: -0.40558207
INFO: platform score: -0.40215614
INFO: table score: -0.40157998
INFO: argument score: -0.3957183
INFO: explore score: -0.3953557
INFO: program score: -0.3948473
INFO: small score: -0.3937505
INFO: new score: -0.39076012
INFO: single score: -0.3886526
INFO: call score: -0.38351402
INFO: hand score: -0.3815392
INFO: list score: -0.38025728
INFO: class score: -0.37386447
INFO: mutual score: -0.37368742
INFO: local score: -0.37283793
INFO: bool score: -0.36541826
INFO: config score: -0.3602609
INFO: assignment score: -0.359921
INFO: state score: -0.358174
INFO: execution score: -0.3509821
INFO: bad score: -0.35004717
INFO: max score: -0.3474532
INFO: name score: -0.34219304
INFO: troublesome score: -0.33933145
INFO: print score: -0.33558142
INFO: inside score: -0.33200666
INFO: dictionary score: -0.32504416
INFO: caller score: -0.32387128
INFO: wish score: -0.3234677
INFO: foo score: -0.3207088
INFO: work score: -0.31956208
INFO: multiprocessing score: -0.31233802
INFO: string score: -0.30863532
INFO: answer score: -0.30845436
INFO: linux score: -0.29978654
INFO: outside score: -0.29796165
INFO: = score: -0.29682767
INFO: advanced score: -0.28687638
INFO: time score: -0.27628285
INFO: situation score: -0.27373356
INFO: unexpected score: -0.2737019
INFO: plan score: -0.27036735
INFO: end score: -0.266686
INFO: declare score: -0.25956044
INFO: util score: -0.25176263
INFO: declaration score: -0.24785617
INFO: care score: -0.24364585
INFO: overshadow score: -0.24096856
INFO: show score: -0.23903736
INFO: want score: -0.23515421
INFO: thing score: -0.22417115
INFO: private score: -0.22318506
INFO: line score: -0.20140542
INFO: points score: -0.19762297
INFO: fall score: -0.18940921
INFO: baz score: -0.18573539
INFO: rest score: -0.18388963
INFO: run score: -0.17868981
INFO: tell score: -0.17462708
INFO: side score: -0.17037085
INFO: window score: -0.15409452
INFO: return score: -0.15082324
INFO: wholesale score: -0.14896397
INFO: first score: -0.14495341
INFO: place score: -0.13429463
INFO: start score: -0.13041428
INFO: apple score: -0.12670954
INFO: try score: -0.122141995
INFO: command score: -0.114607066
INFO: hope score: -0.10119729
INFO: var score: -0.07152835
INFO: bar score: -0.06694232
INFO: decoration score: -0.05132048
INFO: ex score: -0.025999015
INFO: mess score: -0.022508923
INFO: oop score: -0.005789431
INFO: globvar score: -0.0
INFO: global_var score: -0.0
INFO: func1 score: -0.0
INFO: my_global score: -0.0
INFO: called.loop score: -0.0
INFO: func_1 score: -0.0
INFO: func_2 score: -0.0
INFO: update_variables score: -0.0
INFO: macos score: -0.0
INFO: envrionment score: -0.0
INFO: getstocks.py score: -0.0
INFO: runner_test.py score: -0.0
INFO: identifi score: -0.0
INFO: p1o score: -0.0
INFO: p2o score: -0.0
INFO: immutual score: -0.0
INFO: d. score: -0.0
INFO: totalcarbs(local score: -0.0
INFO: totalcarbs(global score: -0.0
INFO: fct1 score: -0.0
INFO: fct2 score: -0.0
INFO: main_function score: -0.0
INFO: f_value score: -0.0
INFO: mailinfo score: -0.0
INFO: mail_body score: -0.0
INFO: function1 score: -0.0
INFO: mac score: 0.0768658
INFO: battleship score: 0.08126613
INFO: zealot score: 0.08776208
INFO: runner score: 0.29621354
INFO: ============================================================
INFO: --------------------
INFO: Why do lambdas defined in a loop with different values all return the same result?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<193 unique tokens: ['answer', 'array', 'call', 'code', 'context']...> from 9 documents (total 531 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<193 unique tokens: ['answer', 'array', 'call', 'code', 'context']...> from 9 documents (total 531 corpus positions)", 'datetime': '2023-04-18T14:15:59.884828', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 9 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.526 per-word bound, 184.3 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 0, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.083*"function" + 0.070*"value" + 0.055*"lambda" + 0.039*"default" + 0.037*"loop" + 0.036*"parameter" + 0.023*"time" + 0.022*"code" + 0.018*"last" + 0.017*"variable"
INFO: topic #1 (1.000): 0.104*"value" + 0.073*"lambda" + 0.071*"function" + 0.036*"default" + 0.035*"parameter" + 0.026*"loop" + 0.024*"closure" + 0.021*"name" + 0.021*"time" + 0.020*"expression"
INFO: topic #2 (1.000): 0.102*"lambda" + 0.045*"value" + 0.045*"final" + 0.042*"code" + 0.040*"loop" + 0.033*"variable" + 0.030*"function" + 0.026*"output" + 0.022*"scope" + 0.022*"context"
INFO: topic diff=5.738671, rho=1.000000
DEBUG: bound: at document #0
INFO: -9.666 per-word bound, 812.4 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 0, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.111*"function" + 0.052*"value" + 0.052*"lambda" + 0.033*"example" + 0.033*"loop" + 0.030*"default" + 0.028*"time" + 0.023*"list" + 0.023*"variable" + 0.020*"way"
INFO: topic #1 (1.000): 0.100*"value" + 0.075*"function" + 0.068*"lambda" + 0.035*"default" + 0.033*"time" + 0.031*"parameter" + 0.029*"variable" + 0.027*"example" + 0.021*"argument" + 0.019*"loop"
INFO: topic #2 (1.000): 0.116*"lambda" + 0.041*"variable" + 0.034*"loop" + 0.031*"function" + 0.030*"output" + 0.028*"value" + 0.028*"list" + 0.026*"time" + 0.024*"scope" + 0.024*"work"
INFO: topic diff=5.031443, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 53.28914714785461
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -1.1440220623803012
DEBUG: bound: at document #0
INFO: -6.154 per-word bound, 71.2 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 1, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.113*"function" + 0.054*"value" + 0.045*"lambda" + 0.039*"default" + 0.029*"example" + 0.028*"loop" + 0.028*"parameter" + 0.023*"way" + 0.019*"list" + 0.019*"time"
INFO: topic #1 (1.000): 0.116*"value" + 0.070*"function" + 0.066*"lambda" + 0.037*"parameter" + 0.037*"default" + 0.033*"time" + 0.025*"closure" + 0.025*"name" + 0.025*"loop" + 0.023*"variable"
INFO: topic #2 (1.000): 0.118*"lambda" + 0.040*"loop" + 0.039*"variable" + 0.033*"output" + 0.033*"code" + 0.029*"final" + 0.028*"value" + 0.025*"function" + 0.025*"scope" + 0.025*"time"
INFO: topic diff=1.278095, rho=0.512989
DEBUG: bound: at document #0
INFO: -5.918 per-word bound, 60.5 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 1, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.132*"function" + 0.046*"value" + 0.035*"lambda" + 0.035*"example" + 0.031*"default" + 0.027*"way" + 0.027*"loop" + 0.021*"argument" + 0.020*"problem" + 0.017*"variable"
INFO: topic #1 (1.000): 0.093*"value" + 0.059*"lambda" + 0.058*"function" + 0.035*"time" + 0.034*"variable" + 0.032*"default" + 0.032*"parameter" + 0.026*"statement" + 0.021*"different" + 0.020*"example"
INFO: topic #2 (1.000): 0.113*"lambda" + 0.035*"list" + 0.034*"loop" + 0.034*"comprehension" + 0.032*"output" + 0.030*"variable" + 0.028*"foo" + 0.025*"scope" + 0.024*"time" + 0.023*"work"
INFO: topic diff=1.562196, rho=0.512989
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 42.57641117193188
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -2.2915365883611933
DEBUG: bound: at document #0
INFO: -5.941 per-word bound, 61.4 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 2, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.127*"function" + 0.052*"value" + 0.042*"default" + 0.034*"lambda" + 0.031*"example" + 0.028*"way" + 0.026*"parameter" + 0.022*"loop" + 0.020*"simple" + 0.018*"problem"
INFO: topic #1 (1.000): 0.109*"value" + 0.062*"lambda" + 0.057*"function" + 0.036*"parameter" + 0.035*"time" + 0.033*"default" + 0.029*"variable" + 0.025*"name" + 0.024*"closure" + 0.023*"loop"
INFO: topic #2 (1.000): 0.116*"lambda" + 0.040*"loop" + 0.033*"output" + 0.032*"variable" + 0.029*"final" + 0.029*"code" + 0.028*"list" + 0.027*"scope" + 0.024*"time" + 0.023*"comprehension"
INFO: topic diff=0.865862, rho=0.456435
DEBUG: bound: at document #0
INFO: -5.344 per-word bound, 40.6 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 2, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.130*"function" + 0.045*"value" + 0.035*"example" + 0.032*"way" + 0.031*"default" + 0.030*"lambda" + 0.025*"loop" + 0.022*"argument" + 0.020*"problem" + 0.020*"definition"
INFO: topic #1 (1.000): 0.092*"value" + 0.059*"lambda" + 0.053*"function" + 0.037*"variable" + 0.036*"time" + 0.032*"parameter" + 0.030*"default" + 0.028*"statement" + 0.022*"different" + 0.019*"name"
INFO: topic #2 (1.000): 0.119*"lambda" + 0.041*"list" + 0.040*"comprehension" + 0.036*"loop" + 0.035*"output" + 0.032*"foo" + 0.027*"variable" + 0.026*"scope" + 0.025*"time" + 0.024*"work"
INFO: topic diff=0.910858, rho=0.456435
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 38.94882059478768
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -2.3195830461396576
DEBUG: bound: at document #0
INFO: -5.797 per-word bound, 55.6 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 3, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.128*"function" + 0.051*"value" + 0.040*"default" + 0.032*"example" + 0.031*"way" + 0.030*"lambda" + 0.023*"parameter" + 0.022*"loop" + 0.019*"simple" + 0.018*"problem"
INFO: topic #1 (1.000): 0.107*"value" + 0.061*"lambda" + 0.053*"function" + 0.036*"parameter" + 0.036*"time" + 0.031*"default" + 0.031*"variable" + 0.025*"name" + 0.024*"closure" + 0.023*"loop"
INFO: topic #2 (1.000): 0.121*"lambda" + 0.040*"loop" + 0.036*"output" + 0.032*"list" + 0.032*"final" + 0.029*"variable" + 0.029*"scope" + 0.028*"code" + 0.027*"comprehension" + 0.025*"time"
INFO: topic diff=0.545549, rho=0.415227
DEBUG: bound: at document #0
INFO: -5.174 per-word bound, 36.1 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 3, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.127*"function" + 0.044*"value" + 0.035*"example" + 0.033*"way" + 0.030*"default" + 0.029*"lambda" + 0.025*"loop" + 0.022*"argument" + 0.021*"definition" + 0.019*"problem"
INFO: topic #1 (1.000): 0.093*"value" + 0.059*"lambda" + 0.051*"function" + 0.037*"variable" + 0.036*"time" + 0.032*"parameter" + 0.030*"default" + 0.028*"statement" + 0.022*"different" + 0.020*"name"
INFO: topic #2 (1.000): 0.124*"lambda" + 0.045*"list" + 0.042*"comprehension" + 0.037*"output" + 0.036*"loop" + 0.035*"foo" + 0.026*"time" + 0.025*"scope" + 0.025*"variable" + 0.022*"work"
INFO: topic diff=0.640383, rho=0.415227
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 37.393192285588555
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -2.309733238660906
DEBUG: bound: at document #0
INFO: -5.725 per-word bound, 52.9 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 4, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.127*"function" + 0.049*"value" + 0.038*"default" + 0.032*"way" + 0.032*"example" + 0.029*"lambda" + 0.022*"loop" + 0.020*"parameter" + 0.019*"simple" + 0.018*"problem"
INFO: topic #1 (1.000): 0.106*"value" + 0.061*"lambda" + 0.053*"function" + 0.037*"parameter" + 0.036*"time" + 0.032*"variable" + 0.031*"default" + 0.025*"name" + 0.024*"closure" + 0.023*"loop"
INFO: topic #2 (1.000): 0.125*"lambda" + 0.040*"loop" + 0.037*"output" + 0.036*"list" + 0.034*"final" + 0.030*"comprehension" + 0.028*"scope" + 0.028*"code" + 0.028*"variable" + 0.026*"last"
INFO: topic diff=0.379245, rho=0.383482
DEBUG: bound: at document #0
INFO: -5.097 per-word bound, 34.2 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 4, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.126*"function" + 0.043*"value" + 0.034*"example" + 0.034*"way" + 0.029*"default" + 0.028*"lambda" + 0.025*"loop" + 0.022*"argument" + 0.022*"definition" + 0.018*"problem"
INFO: topic #1 (1.000): 0.093*"value" + 0.059*"lambda" + 0.051*"function" + 0.037*"variable" + 0.036*"time" + 0.033*"parameter" + 0.030*"default" + 0.028*"statement" + 0.022*"different" + 0.020*"name"
INFO: topic #2 (1.000): 0.127*"lambda" + 0.046*"list" + 0.043*"comprehension" + 0.039*"output" + 0.036*"loop" + 0.036*"foo" + 0.027*"time" + 0.024*"final" + 0.023*"last" + 0.023*"variable"
INFO: topic diff=0.467584, rho=0.383482
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 36.70811845841479
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -1.5120604334241372
DEBUG: bound: at document #0
INFO: -5.689 per-word bound, 51.6 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 5, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.126*"function" + 0.047*"value" + 0.037*"default" + 0.033*"way" + 0.032*"example" + 0.028*"lambda" + 0.023*"loop" + 0.018*"simple" + 0.018*"parameter" + 0.017*"problem"
INFO: topic #1 (1.000): 0.106*"value" + 0.061*"lambda" + 0.053*"function" + 0.037*"parameter" + 0.036*"time" + 0.032*"variable" + 0.031*"default" + 0.025*"name" + 0.024*"closure" + 0.023*"loop"
INFO: topic #2 (1.000): 0.127*"lambda" + 0.040*"loop" + 0.039*"output" + 0.038*"list" + 0.035*"final" + 0.031*"comprehension" + 0.029*"last" + 0.027*"code" + 0.027*"time" + 0.026*"variable"
INFO: topic diff=0.297998, rho=0.358057
DEBUG: bound: at document #0
INFO: -5.059 per-word bound, 33.3 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 5, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.125*"function" + 0.043*"value" + 0.035*"way" + 0.034*"example" + 0.029*"default" + 0.028*"lambda" + 0.026*"loop" + 0.022*"argument" + 0.022*"definition" + 0.021*"work"
INFO: topic #1 (1.000): 0.094*"value" + 0.059*"lambda" + 0.051*"function" + 0.037*"variable" + 0.036*"time" + 0.033*"parameter" + 0.030*"default" + 0.027*"statement" + 0.022*"different" + 0.020*"name"
INFO: topic #2 (1.000): 0.129*"lambda" + 0.048*"list" + 0.044*"comprehension" + 0.040*"output" + 0.036*"foo" + 0.035*"loop" + 0.028*"time" + 0.025*"last" + 0.025*"final" + 0.022*"variable"
INFO: topic diff=0.357788, rho=0.358057
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 36.39060989757456
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -1.5353321829511863
DEBUG: bound: at document #0
INFO: -5.670 per-word bound, 50.9 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 6, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.126*"function" + 0.046*"value" + 0.036*"default" + 0.034*"way" + 0.033*"example" + 0.028*"lambda" + 0.023*"loop" + 0.018*"simple" + 0.017*"problem" + 0.017*"variable"
INFO: topic #1 (1.000): 0.106*"value" + 0.061*"lambda" + 0.053*"function" + 0.038*"parameter" + 0.036*"time" + 0.033*"variable" + 0.031*"default" + 0.024*"name" + 0.023*"closure" + 0.023*"loop"
INFO: topic #2 (1.000): 0.129*"lambda" + 0.039*"list" + 0.039*"output" + 0.039*"loop" + 0.036*"final" + 0.032*"comprehension" + 0.030*"last" + 0.027*"code" + 0.027*"time" + 0.026*"foo"
INFO: topic diff=0.252824, rho=0.337100
DEBUG: bound: at document #0
INFO: -5.037 per-word bound, 32.8 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 6, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.125*"function" + 0.042*"value" + 0.035*"way" + 0.034*"example" + 0.029*"default" + 0.028*"lambda" + 0.026*"loop" + 0.024*"work" + 0.022*"scope" + 0.021*"definition"
INFO: topic #1 (1.000): 0.095*"value" + 0.059*"lambda" + 0.052*"function" + 0.037*"variable" + 0.036*"time" + 0.034*"parameter" + 0.030*"default" + 0.027*"statement" + 0.022*"different" + 0.020*"name"
INFO: topic #2 (1.000): 0.130*"lambda" + 0.048*"list" + 0.044*"comprehension" + 0.040*"output" + 0.036*"foo" + 0.035*"loop" + 0.028*"time" + 0.027*"last" + 0.026*"final" + 0.022*"variable"
INFO: topic diff=0.291143, rho=0.337100
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 36.22221058126668
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -1.541339073441644
DEBUG: bound: at document #0
INFO: -5.658 per-word bound, 50.5 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 7, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.126*"function" + 0.045*"value" + 0.035*"default" + 0.034*"way" + 0.033*"example" + 0.028*"lambda" + 0.024*"loop" + 0.020*"work" + 0.019*"scope" + 0.018*"simple"
INFO: topic #1 (1.000): 0.106*"value" + 0.061*"lambda" + 0.053*"function" + 0.038*"parameter" + 0.035*"time" + 0.033*"variable" + 0.031*"default" + 0.024*"name" + 0.023*"loop" + 0.023*"closure"
INFO: topic #2 (1.000): 0.130*"lambda" + 0.041*"list" + 0.040*"output" + 0.039*"loop" + 0.036*"final" + 0.033*"comprehension" + 0.032*"last" + 0.027*"time" + 0.027*"foo" + 0.027*"code"
INFO: topic diff=0.224376, rho=0.319438
DEBUG: bound: at document #0
INFO: -5.022 per-word bound, 32.5 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 7, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.125*"function" + 0.042*"value" + 0.035*"way" + 0.034*"example" + 0.029*"default" + 0.028*"lambda" + 0.027*"loop" + 0.026*"work" + 0.024*"scope" + 0.021*"definition"
INFO: topic #1 (1.000): 0.096*"value" + 0.060*"lambda" + 0.052*"function" + 0.037*"variable" + 0.036*"time" + 0.034*"parameter" + 0.030*"default" + 0.027*"statement" + 0.021*"different" + 0.020*"name"
INFO: topic #2 (1.000): 0.131*"lambda" + 0.049*"list" + 0.044*"comprehension" + 0.041*"output" + 0.036*"foo" + 0.035*"loop" + 0.028*"time" + 0.028*"last" + 0.027*"final" + 0.022*"bad"
INFO: topic diff=0.250440, rho=0.319438
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 36.11443913999786
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -1.3773541869778683
DEBUG: bound: at document #0
INFO: -5.649 per-word bound, 50.2 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 8, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.126*"function" + 0.045*"value" + 0.035*"way" + 0.034*"default" + 0.033*"example" + 0.028*"lambda" + 0.024*"loop" + 0.023*"work" + 0.020*"scope" + 0.018*"variable"
INFO: topic #1 (1.000): 0.106*"value" + 0.061*"lambda" + 0.053*"function" + 0.039*"parameter" + 0.035*"time" + 0.033*"variable" + 0.031*"default" + 0.024*"name" + 0.023*"loop" + 0.023*"closure"
INFO: topic #2 (1.000): 0.130*"lambda" + 0.042*"list" + 0.040*"output" + 0.038*"loop" + 0.036*"final" + 0.033*"comprehension" + 0.033*"last" + 0.028*"foo" + 0.027*"time" + 0.026*"code"
INFO: topic diff=0.204598, rho=0.304290
DEBUG: bound: at document #0
INFO: -5.012 per-word bound, 32.3 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 8, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.125*"function" + 0.042*"value" + 0.035*"way" + 0.034*"example" + 0.028*"lambda" + 0.028*"default" + 0.028*"work" + 0.027*"loop" + 0.025*"scope" + 0.021*"definition"
INFO: topic #1 (1.000): 0.096*"value" + 0.060*"lambda" + 0.052*"function" + 0.037*"variable" + 0.036*"time" + 0.035*"parameter" + 0.030*"default" + 0.026*"statement" + 0.021*"different" + 0.020*"name"
INFO: topic #2 (1.000): 0.132*"lambda" + 0.049*"list" + 0.044*"comprehension" + 0.041*"output" + 0.036*"foo" + 0.035*"loop" + 0.029*"last" + 0.028*"time" + 0.027*"final" + 0.022*"bad"
INFO: topic diff=0.224573, rho=0.304290
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 36.03096775259061
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -1.372428436580881
DEBUG: bound: at document #0
INFO: -5.641 per-word bound, 49.9 perplexity estimate based on a held-out corpus of 5 documents with 209 words
INFO: PROGRESS: pass 9, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.126*"function" + 0.044*"value" + 0.035*"way" + 0.034*"default" + 0.033*"example" + 0.028*"lambda" + 0.025*"loop" + 0.024*"work" + 0.022*"scope" + 0.018*"variable"
INFO: topic #1 (1.000): 0.106*"value" + 0.061*"lambda" + 0.054*"function" + 0.039*"parameter" + 0.035*"time" + 0.033*"variable" + 0.031*"default" + 0.024*"name" + 0.023*"loop" + 0.022*"closure"
INFO: topic #2 (1.000): 0.131*"lambda" + 0.042*"list" + 0.041*"output" + 0.038*"loop" + 0.036*"final" + 0.034*"last" + 0.034*"comprehension" + 0.028*"foo" + 0.028*"time" + 0.026*"code"
INFO: topic diff=0.194109, rho=0.291111
DEBUG: bound: at document #0
INFO: -5.003 per-word bound, 32.1 perplexity estimate based on a held-out corpus of 4 documents with 322 words
INFO: PROGRESS: pass 9, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.125*"function" + 0.042*"value" + 0.035*"way" + 0.034*"example" + 0.029*"work" + 0.029*"lambda" + 0.028*"default" + 0.027*"loop" + 0.026*"scope" + 0.021*"definition"
INFO: topic #1 (1.000): 0.097*"value" + 0.060*"lambda" + 0.052*"function" + 0.037*"variable" + 0.036*"time" + 0.035*"parameter" + 0.030*"default" + 0.026*"statement" + 0.021*"different" + 0.021*"name"
INFO: topic #2 (1.000): 0.132*"lambda" + 0.049*"list" + 0.044*"comprehension" + 0.041*"output" + 0.036*"foo" + 0.034*"loop" + 0.030*"last" + 0.028*"time" + 0.028*"final" + 0.022*"bad"
INFO: topic diff=0.207118, rho=0.291111
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 35.958334215760566
DEBUG: Setting topics to those of the model: LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.3561526989709831
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=193, num_topics=3, decay=0.5, chunksize=5> in 0.16s', 'datetime': '2023-04-18T14:16:00.048352', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/cos_threshold/3/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-18T14:16:00.048539', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/cos_threshold/3/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/3/model.state
DEBUG: {'uri': 'model/cos_threshold/3/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/cos_threshold/3/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['state', 'id2word', 'dispatcher'], 'datetime': '2023-04-18T14:16:00.050719', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/cos_threshold/3/model.expElogbeta.npy
INFO: not storing attribute state
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
DEBUG: {'uri': 'model/cos_threshold/3/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/3/model
INFO: topic #0 (1.000): 0.125*"function" + 0.042*"value" + 0.035*"way" + 0.034*"example" + 0.029*"work" + 0.029*"lambda" + 0.028*"default" + 0.027*"loop" + 0.026*"scope" + 0.021*"definition"
INFO: topic #1 (1.000): 0.097*"value" + 0.060*"lambda" + 0.052*"function" + 0.037*"variable" + 0.036*"time" + 0.035*"parameter" + 0.030*"default" + 0.026*"statement" + 0.021*"different" + 0.021*"name"
INFO: topic #2 (1.000): 0.132*"lambda" + 0.049*"list" + 0.044*"comprehension" + 0.041*"output" + 0.036*"foo" + 0.034*"loop" + 0.030*"last" + 0.028*"time" + 0.028*"final" + 0.022*"bad"
INFO: Question Similarity: [0.07075375318527222, 0.10912275314331055, 0.3426234722137451, 0.13805431127548218, 0.13586008548736572, 0.22070395946502686, 0.09046471118927002, 0.1506548523902893, 0.11590653657913208, 0.06816387176513672]
INFO: 74746676: -0.24485773075555453
INFO: 66039981: -0.2502412364803071
INFO: 11723328: -0.2524491158308033
INFO: 63123965: -0.2630891307151332
INFO: 66039895: -0.26611375729012554
INFO: 63123379: -0.2661839465561197
INFO: 66039891: -0.2713740582298229
INFO: 74746577: -0.2751588910948946
INFO: 74746462: -0.295097698014539
INFO: 11723478: -0.32194633416800617
INFO: 11723314: -0.3332763293765862
INFO: 72921203: -0.342662662497239
INFO: 72921246: -0.34810803899065595
INFO: 72921168: -0.37931514450970905
INFO: 72921569: -0.39729567271383287
INFO: 72921188: -0.4186603895474898
INFO: 19837683: -0.4510493132539166
INFO: 19837590: -0.46186619795173073
INFO: 46847190: -0.4731551804987939
INFO: 57288183: -0.49200458914162615
INFO: 68717304: -0.928852594313697
INFO: Recommended Keywords
INFO: define score: -0.83812535
INFO: example score: -0.81784713
INFO: function score: -0.8048683
INFO: definition score: -0.7999274
INFO: simple score: -0.7959884
INFO: necessary score: -0.75646996
INFO: variable score: -0.75486165
INFO: time score: -0.74711335
INFO: value score: -0.732589
INFO: problem score: -0.7317684
INFO: parameter score: -0.71602446
INFO: correct score: -0.7153756
INFO: consider score: -0.71527
INFO: approach score: -0.7147317
INFO: solution score: -0.71390647
INFO: functional score: -0.7097358
INFO: object score: -0.7044254
INFO: scope score: -0.70174336
INFO: method score: -0.67479575
INFO: iteration score: -0.6738215
INFO: last score: -0.6720792
INFO: minimal score: -0.67092407
INFO: order score: -0.66191065
INFO: expression score: -0.6602899
INFO: way score: -0.6423831
INFO: full score: -0.6406098
INFO: first score: -0.63652915
INFO: default score: -0.62784845
INFO: different score: -0.6250687
INFO: step score: -0.6222585
INFO: dependency score: -0.60986847
INFO: result score: -0.6011668
INFO: reference score: -0.597389
INFO: final score: -0.5890098
INFO: point score: -0.58283925
INFO: common score: -0.57521677
INFO: change score: -0.57367355
INFO: run score: -0.5730521
INFO: code score: -0.5729582
INFO: mutable score: -0.5674526
INFO: instance score: -0.5642328
INFO: additional score: -0.5567559
INFO: argument score: -0.5528548
INFO: explanation score: -0.54934907
INFO: precision score: -0.54145336
INFO: current score: -0.5373085
INFO: presence score: -0.5352954
INFO: update score: -0.5162845
INFO: assign score: -0.5126939
INFO: call score: -0.5106463
INFO: option score: -0.5106397
INFO: bad score: -0.5102136
INFO: question score: -0.50722355
INFO: new score: -0.50035244
INFO: list score: -0.497103
INFO: well score: -0.48715624
INFO: statement score: -0.4812678
INFO: behavior score: -0.48039702
INFO: due score: -0.47782975
INFO: single score: -0.47736174
INFO: bind score: -0.46944097
INFO: f score: -0.4681064
INFO: output score: -0.4618317
INFO: x score: -0.4597003
INFO: workaround score: -0.45691678
INFO: fix score: -0.45688277
INFO: resolve score: -0.4565897
INFO: answer score: -0.45617536
INFO: general score: -0.4561481
INFO: documentation score: -0.45593977
INFO: high score: -0.45267302
INFO: early score: -0.44603744
INFO: syntax score: -0.44130674
INFO: closure score: -0.4330745
INFO: sufficient score: -0.42717484
INFO: context score: -0.42715335
INFO: bit score: -0.42696062
INFO: practice score: -0.4233059
INFO: line score: -0.41459876
INFO: foo score: -0.40500292
INFO: work score: -0.4039052
INFO: item score: -0.40115213
INFO: convert score: -0.38570046
INFO: previous score: -0.38275293
INFO: body score: -0.37978762
INFO: loop score: -0.3786353
INFO: comprehension score: -0.37488464
INFO: little score: -0.37330544
INFO: believe score: -0.36812237
INFO: = score: -0.36518317
INFO: plenty score: -0.3651812
INFO: short score: -0.36224136
INFO: introspect score: -0.35251972
INFO: double score: -0.35103035
INFO: preserve score: -0.34792906
INFO: generate score: -0.3416441
INFO: partial score: -0.3325113
INFO: issue score: -0.33222026
INFO: x0 score: -0.33089107
INFO: compiler score: -0.3270868
INFO: verbose score: -0.32504246
INFO: topic score: -0.32236367
INFO: efficient score: -0.32118767
INFO: name score: -0.320248
INFO: inner score: -0.31795382
INFO: lambda score: -0.30963475
INFO: help score: -0.3072725
INFO: clean score: -0.30539414
INFO: map score: -0.29985836
INFO: opinion score: -0.28820837
INFO: state score: -0.28761995
INFO: array score: -0.27768642
INFO: lot score: -0.26873416
INFO: callable score: -0.25772998
INFO: rep score: -0.25132483
INFO: printed score: -0.22720517
INFO: cryptic score: -0.22216144
INFO: print score: -0.22146007
INFO: exec score: -0.21809016
INFO: variant score: -0.20026116
INFO: messy score: -0.19800629
INFO: small score: -0.19316973
INFO: store score: -0.17772435
INFO: next score: -0.12974834
INFO: late score: -0.12836522
INFO: complaint score: -0.123726636
INFO: outer score: -0.12258591
INFO: blog score: -0.08049453
INFO: official score: -0.056506157
INFO: job score: -0.04740943
INFO: doesn#t score: -0.0
INFO: x. score: -0.0
INFO: range(2 score: -0.0
INFO: functools.partial score: -0.0
INFO: send_param score: -0.0
INFO: print(val score: -0.0
INFO: l[3 score: -0.0
INFO: pythonic score: -0.0
INFO: lambda+filter score: -0.0
INFO: testobj(1 score: -0.0
INFO: testobj score: -0.0
INFO: finished score: 0.12093332
INFO: ============================================================
INFO: --------------------
INFO: How do I share global variables across modules?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<208 unique tokens: ['answer', 'code', 'function', 'global', 'main']...> from 7 documents (total 476 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<208 unique tokens: ['answer', 'code', 'function', 'global', 'main']...> from 7 documents (total 476 corpus positions)", 'datetime': '2023-04-18T14:16:02.701989', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 7 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -9.614 per-word bound, 783.5 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 0, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.074*"global" + 0.040*"variable" + 0.034*"import" + 0.033*"module" + 0.022*"file" + 0.020*"constant" + 0.019*"level" + 0.016*"entity" + 0.015*"configuration" + 0.014*"code"
INFO: topic #1 (1.000): 0.102*"global" + 0.078*"module" + 0.035*"variable" + 0.025*"import" + 0.020*"code" + 0.020*"namespace" + 0.019*"entity" + 0.018*"visibility" + 0.017*"level" + 0.015*"constant"
INFO: topic #2 (1.000): 0.049*"variable" + 0.045*"global" + 0.032*"import" + 0.024*"module" + 0.020*"namespace" + 0.020*"constant" + 0.019*"file" + 0.019*"level" + 0.018*"entity" + 0.017*"code"
INFO: topic diff=5.702946, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.114 per-word bound, 1108.1 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 0, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.069*"variable" + 0.060*"global" + 0.050*"module" + 0.032*"import" + 0.031*"name" + 0.014*"value" + 0.014*"function" + 0.012*"object" + 0.012*"scope" + 0.011*"example"
INFO: topic #1 (1.000): 0.138*"module" + 0.092*"global" + 0.074*"variable" + 0.064*"function" + 0.026*"import" + 0.022*"assign" + 0.021*"value" + 0.021*"name" + 0.020*"access" + 0.016*"local"
INFO: topic #2 (1.000): 0.111*"variable" + 0.038*"global" + 0.037*"name" + 0.035*"function" + 0.031*"import" + 0.029*"module" + 0.018*"assign" + 0.018*"local" + 0.017*"value" + 0.015*"scope"
INFO: topic diff=6.033157, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 82.70522624102775
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.7519171635842642
DEBUG: bound: at document #0
INFO: -9.252 per-word bound, 609.7 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 1, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.062*"variable" + 0.052*"global" + 0.042*"module" + 0.034*"import" + 0.026*"name" + 0.014*"file" + 0.012*"database" + 0.012*"value" + 0.012*"function" + 0.011*"direction"
INFO: topic #1 (1.000): 0.109*"module" + 0.094*"global" + 0.062*"variable" + 0.042*"function" + 0.027*"import" + 0.018*"access" + 0.017*"assign" + 0.016*"value" + 0.015*"level" + 0.014*"code"
INFO: topic #2 (1.000): 0.105*"variable" + 0.036*"global" + 0.034*"name" + 0.033*"function" + 0.031*"import" + 0.027*"module" + 0.017*"assign" + 0.017*"local" + 0.016*"value" + 0.014*"scope"
INFO: topic diff=1.074080, rho=0.542326
DEBUG: bound: at document #0
INFO: -5.445 per-word bound, 43.6 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 1, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.071*"module" + 0.041*"documentation" + 0.041*"config" + 0.035*"global" + 0.030*"import" + 0.029*"variable" + 0.028*"name" + 0.021*"application" + 0.021*"special" + 0.021*"change"
INFO: topic #1 (1.000): 0.157*"module" + 0.098*"global" + 0.051*"variable" + 0.042*"function" + 0.025*"import" + 0.018*"code" + 0.017*"access" + 0.016*"test" + 0.016*"instance" + 0.015*"assign"
INFO: topic #2 (1.000): 0.097*"variable" + 0.048*"global" + 0.044*"function" + 0.042*"module" + 0.040*"name" + 0.026*"import" + 0.019*"assign" + 0.019*"value" + 0.017*"scope" + 0.016*"local"
INFO: topic diff=1.356433, rho=0.542326
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 55.62639799870047
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.6398595531867717
DEBUG: bound: at document #0
INFO: -7.979 per-word bound, 252.3 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 2, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.056*"module" + 0.032*"config" + 0.032*"documentation" + 0.031*"import" + 0.029*"global" + 0.027*"variable" + 0.022*"name" + 0.017*"direction" + 0.017*"problem" + 0.017*"change"
INFO: topic #1 (1.000): 0.115*"module" + 0.097*"global" + 0.047*"variable" + 0.027*"import" + 0.026*"function" + 0.020*"code" + 0.017*"level" + 0.016*"namespace" + 0.016*"access" + 0.015*"test"
INFO: topic #2 (1.000): 0.095*"variable" + 0.047*"global" + 0.043*"function" + 0.041*"module" + 0.039*"name" + 0.026*"import" + 0.018*"assign" + 0.018*"value" + 0.016*"scope" + 0.016*"local"
INFO: topic diff=0.830007, rho=0.476731
DEBUG: bound: at document #0
INFO: -5.016 per-word bound, 32.4 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 2, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.110*"module" + 0.053*"config" + 0.053*"documentation" + 0.028*"import" + 0.027*"https://docs.python.org/3/faq/programming.html#how-do-i-share-global-variables-across-module" + 0.027*"canonical" + 0.027*"change" + 0.027*"special" + 0.027*"cfg" + 0.027*"application"
INFO: topic #1 (1.000): 0.135*"module" + 0.093*"global" + 0.041*"variable" + 0.027*"code" + 0.026*"import" + 0.023*"function" + 0.021*"state" + 0.020*"people" + 0.019*"instance" + 0.015*"level"
INFO: topic #2 (1.000): 0.093*"variable" + 0.056*"global" + 0.054*"module" + 0.047*"function" + 0.039*"name" + 0.026*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"scope" + 0.016*"local"
INFO: topic diff=0.922349, rho=0.476731
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 47.635692405311666
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -0.6670569671693821
DEBUG: bound: at document #0
INFO: -7.417 per-word bound, 170.9 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 3, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.092*"module" + 0.043*"config" + 0.043*"documentation" + 0.029*"import" + 0.022*"https://docs.python.org/3/faq/programming.html#how-do-i-share-global-variables-across-module" + 0.022*"canonical" + 0.022*"change" + 0.022*"special" + 0.022*"cfg" + 0.022*"application"
INFO: topic #1 (1.000): 0.097*"module" + 0.095*"global" + 0.041*"variable" + 0.027*"import" + 0.024*"code" + 0.018*"level" + 0.018*"namespace" + 0.018*"state" + 0.017*"instance" + 0.016*"entity"
INFO: topic #2 (1.000): 0.093*"variable" + 0.055*"global" + 0.053*"module" + 0.046*"function" + 0.038*"name" + 0.026*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"scope" + 0.016*"local"
INFO: topic diff=0.532379, rho=0.430331
DEBUG: bound: at document #0
INFO: -4.918 per-word bound, 30.2 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 3, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.146*"module" + 0.054*"config" + 0.054*"documentation" + 0.028*"import" + 0.027*"https://docs.python.org/3/faq/programming.html#how-do-i-share-global-variables-across-module" + 0.027*"canonical" + 0.027*"change" + 0.027*"special" + 0.027*"cfg" + 0.027*"application"
INFO: topic #1 (1.000): 0.098*"module" + 0.091*"global" + 0.036*"variable" + 0.031*"code" + 0.026*"import" + 0.025*"people" + 0.023*"state" + 0.019*"instance" + 0.017*"level" + 0.017*"namespace"
INFO: topic #2 (1.000): 0.092*"variable" + 0.058*"global" + 0.057*"module" + 0.047*"function" + 0.038*"name" + 0.026*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"scope" + 0.016*"local"
INFO: topic diff=0.542810, rho=0.430331
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 45.365126007625456
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -0.6495227181759183
DEBUG: bound: at document #0
INFO: -7.234 per-word bound, 150.6 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 4, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.127*"module" + 0.045*"config" + 0.045*"documentation" + 0.028*"import" + 0.023*"https://docs.python.org/3/faq/programming.html#how-do-i-share-global-variables-across-module" + 0.023*"canonical" + 0.023*"change" + 0.023*"special" + 0.023*"cfg" + 0.023*"application"
INFO: topic #1 (1.000): 0.094*"global" + 0.076*"module" + 0.038*"variable" + 0.027*"import" + 0.026*"code" + 0.019*"namespace" + 0.019*"level" + 0.019*"state" + 0.018*"entity" + 0.018*"constant"
INFO: topic #2 (1.000): 0.092*"variable" + 0.058*"global" + 0.057*"module" + 0.047*"function" + 0.037*"name" + 0.026*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"scope" + 0.016*"local"
INFO: topic diff=0.370898, rho=0.395285
DEBUG: bound: at document #0
INFO: -4.887 per-word bound, 29.6 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 4, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.164*"module" + 0.052*"config" + 0.052*"documentation" + 0.027*"import" + 0.027*"single" + 0.027*"way" + 0.027*"available" + 0.027*"share" + 0.027*"canonical" + 0.027*"change"
INFO: topic #1 (1.000): 0.091*"global" + 0.073*"module" + 0.035*"variable" + 0.029*"code" + 0.028*"people" + 0.026*"import" + 0.020*"state" + 0.018*"namespace" + 0.018*"level" + 0.017*"instance"
INFO: topic #2 (1.000): 0.092*"variable" + 0.059*"global" + 0.059*"module" + 0.047*"function" + 0.038*"name" + 0.025*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"scope" + 0.016*"local"
INFO: topic diff=0.341067, rho=0.395285
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 44.62354627954997
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -0.6586167132200721
DEBUG: bound: at document #0
INFO: -7.171 per-word bound, 144.1 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 5, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.148*"module" + 0.044*"config" + 0.044*"documentation" + 0.028*"import" + 0.023*"single" + 0.023*"way" + 0.023*"available" + 0.023*"share" + 0.023*"canonical" + 0.023*"change"
INFO: topic #1 (1.000): 0.094*"global" + 0.062*"module" + 0.037*"variable" + 0.028*"import" + 0.025*"code" + 0.020*"namespace" + 0.020*"level" + 0.019*"entity" + 0.019*"constant" + 0.018*"state"
INFO: topic #2 (1.000): 0.092*"variable" + 0.059*"global" + 0.058*"module" + 0.047*"function" + 0.037*"name" + 0.026*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"local" + 0.016*"scope"
INFO: topic diff=0.310885, rho=0.367607
DEBUG: bound: at document #0
INFO: -4.872 per-word bound, 29.3 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 5, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.172*"module" + 0.051*"config" + 0.051*"documentation" + 0.027*"import" + 0.026*"single" + 0.026*"way" + 0.026*"available" + 0.026*"share" + 0.026*"canonical" + 0.026*"change"
INFO: topic #1 (1.000): 0.091*"global" + 0.058*"module" + 0.034*"variable" + 0.029*"people" + 0.026*"import" + 0.025*"code" + 0.019*"namespace" + 0.019*"level" + 0.018*"entity" + 0.018*"constant"
INFO: topic #2 (1.000): 0.092*"variable" + 0.060*"global" + 0.059*"module" + 0.048*"function" + 0.038*"name" + 0.025*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"local" + 0.016*"scope"
INFO: topic diff=0.283400, rho=0.367607
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 44.31604131854579
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -1.1273865618043053
DEBUG: bound: at document #0
INFO: -7.142 per-word bound, 141.2 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 6, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.160*"module" + 0.044*"config" + 0.044*"documentation" + 0.027*"import" + 0.023*"single" + 0.023*"way" + 0.023*"available" + 0.023*"share" + 0.023*"canonical" + 0.023*"change"
INFO: topic #1 (1.000): 0.094*"global" + 0.051*"module" + 0.036*"variable" + 0.028*"import" + 0.023*"code" + 0.021*"namespace" + 0.021*"level" + 0.020*"entity" + 0.020*"constant" + 0.018*"people"
INFO: topic #2 (1.000): 0.092*"variable" + 0.059*"global" + 0.059*"module" + 0.047*"function" + 0.037*"name" + 0.025*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"local" + 0.016*"scope"
INFO: topic diff=0.275917, rho=0.345033
DEBUG: bound: at document #0
INFO: -4.864 per-word bound, 29.1 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 6, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.177*"module" + 0.050*"config" + 0.050*"documentation" + 0.027*"import" + 0.026*"single" + 0.026*"way" + 0.025*"available" + 0.025*"share" + 0.025*"canonical" + 0.025*"change"
INFO: topic #1 (1.000): 0.090*"global" + 0.049*"module" + 0.034*"variable" + 0.029*"people" + 0.027*"import" + 0.022*"code" + 0.020*"namespace" + 0.019*"level" + 0.018*"entity" + 0.018*"constant"
INFO: topic #2 (1.000): 0.092*"variable" + 0.060*"global" + 0.060*"module" + 0.048*"function" + 0.038*"name" + 0.025*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"local" + 0.016*"scope"
INFO: topic diff=0.257017, rho=0.345033
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 44.145493222597686
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -1.1273865618043053
DEBUG: bound: at document #0
INFO: -7.123 per-word bound, 139.4 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 7, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.168*"module" + 0.043*"config" + 0.043*"documentation" + 0.027*"import" + 0.023*"single" + 0.023*"way" + 0.022*"available" + 0.022*"share" + 0.022*"canonical" + 0.022*"change"
INFO: topic #1 (1.000): 0.093*"global" + 0.044*"module" + 0.036*"variable" + 0.028*"import" + 0.021*"code" + 0.021*"namespace" + 0.021*"level" + 0.021*"entity" + 0.021*"constant" + 0.019*"people"
INFO: topic #2 (1.000): 0.092*"variable" + 0.060*"module" + 0.059*"global" + 0.048*"function" + 0.037*"name" + 0.025*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"local" + 0.016*"access"
INFO: topic diff=0.251166, rho=0.326164
DEBUG: bound: at document #0
INFO: -4.860 per-word bound, 29.0 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 7, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.180*"module" + 0.049*"config" + 0.049*"documentation" + 0.027*"import" + 0.025*"single" + 0.025*"way" + 0.025*"available" + 0.025*"share" + 0.025*"canonical" + 0.025*"change"
INFO: topic #1 (1.000): 0.089*"global" + 0.042*"module" + 0.033*"variable" + 0.029*"people" + 0.027*"import" + 0.021*"code" + 0.020*"namespace" + 0.020*"level" + 0.019*"entity" + 0.019*"constant"
INFO: topic #2 (1.000): 0.092*"variable" + 0.060*"global" + 0.060*"module" + 0.048*"function" + 0.038*"name" + 0.025*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"local" + 0.016*"scope"
INFO: topic diff=0.240313, rho=0.326164
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 44.027730182535805
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -1.1273865618043053
DEBUG: bound: at document #0
INFO: -7.108 per-word bound, 138.0 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 8, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.173*"module" + 0.043*"documentation" + 0.043*"config" + 0.027*"import" + 0.024*"code" + 0.022*"single" + 0.022*"way" + 0.022*"example" + 0.022*"application" + 0.022*"change"
INFO: topic #1 (1.000): 0.093*"global" + 0.039*"module" + 0.035*"variable" + 0.028*"import" + 0.021*"namespace" + 0.021*"level" + 0.021*"entity" + 0.021*"constant" + 0.020*"code" + 0.019*"people"
INFO: topic #2 (1.000): 0.092*"variable" + 0.060*"module" + 0.060*"global" + 0.048*"function" + 0.037*"name" + 0.025*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"local" + 0.016*"access"
INFO: topic diff=0.233220, rho=0.310087
DEBUG: bound: at document #0
INFO: -4.857 per-word bound, 29.0 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 8, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.182*"module" + 0.049*"documentation" + 0.049*"config" + 0.027*"import" + 0.026*"code" + 0.025*"single" + 0.025*"way" + 0.025*"example" + 0.025*"application" + 0.025*"change"
INFO: topic #1 (1.000): 0.089*"global" + 0.037*"module" + 0.033*"variable" + 0.029*"people" + 0.027*"import" + 0.020*"namespace" + 0.020*"level" + 0.019*"code" + 0.019*"entity" + 0.019*"constant"
INFO: topic #2 (1.000): 0.092*"variable" + 0.060*"module" + 0.060*"global" + 0.048*"function" + 0.038*"name" + 0.025*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"local" + 0.016*"scope"
INFO: topic diff=0.225899, rho=0.310087
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 43.93776875982851
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -1.1125880614146693
DEBUG: bound: at document #0
INFO: -7.097 per-word bound, 136.9 perplexity estimate based on a held-out corpus of 5 documents with 135 words
INFO: PROGRESS: pass 9, at document #5/7
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.178*"module" + 0.043*"config" + 0.043*"documentation" + 0.027*"import" + 0.026*"code" + 0.022*"example" + 0.022*"single" + 0.022*"way" + 0.022*"application" + 0.022*"change"
INFO: topic #1 (1.000): 0.092*"global" + 0.035*"module" + 0.035*"variable" + 0.029*"import" + 0.022*"namespace" + 0.021*"level" + 0.021*"entity" + 0.021*"constant" + 0.020*"people" + 0.019*"code"
INFO: topic #2 (1.000): 0.092*"variable" + 0.060*"module" + 0.060*"global" + 0.048*"function" + 0.037*"name" + 0.025*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"local" + 0.016*"access"
INFO: topic diff=0.219560, rho=0.296174
DEBUG: bound: at document #0
INFO: -4.855 per-word bound, 28.9 perplexity estimate based on a held-out corpus of 2 documents with 341 words
INFO: PROGRESS: pass 9, at document #7/7
DEBUG: performing inference on a chunk of 2 documents
DEBUG: 2/2 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 2 documents into a model of 7 documents
INFO: topic #0 (1.000): 0.184*"module" + 0.048*"config" + 0.048*"documentation" + 0.027*"import" + 0.027*"code" + 0.025*"way" + 0.025*"single" + 0.025*"example" + 0.025*"object" + 0.025*"change"
INFO: topic #1 (1.000): 0.088*"global" + 0.034*"module" + 0.033*"variable" + 0.029*"people" + 0.027*"import" + 0.020*"namespace" + 0.020*"level" + 0.019*"entity" + 0.019*"constant" + 0.019*"code"
INFO: topic #2 (1.000): 0.092*"variable" + 0.060*"module" + 0.060*"global" + 0.048*"function" + 0.038*"name" + 0.025*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"local" + 0.016*"scope"
INFO: topic diff=0.213318, rho=0.296174
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 43.867703333326446
DEBUG: Setting topics to those of the model: LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.0630724189876553
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=208, num_topics=3, decay=0.5, chunksize=5> in 0.13s', 'datetime': '2023-04-18T14:16:02.835934', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/cos_threshold/4/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-18T14:16:02.836093', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/cos_threshold/4/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/4/model.state
DEBUG: {'uri': 'model/cos_threshold/4/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/cos_threshold/4/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['state', 'id2word', 'dispatcher'], 'datetime': '2023-04-18T14:16:02.838343', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/cos_threshold/4/model.expElogbeta.npy
INFO: not storing attribute state
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
DEBUG: {'uri': 'model/cos_threshold/4/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/4/model
INFO: topic #0 (1.000): 0.184*"module" + 0.048*"config" + 0.048*"documentation" + 0.027*"import" + 0.027*"code" + 0.025*"way" + 0.025*"single" + 0.025*"example" + 0.025*"object" + 0.025*"change"
INFO: topic #1 (1.000): 0.088*"global" + 0.034*"module" + 0.033*"variable" + 0.029*"people" + 0.027*"import" + 0.020*"namespace" + 0.020*"level" + 0.019*"entity" + 0.019*"constant" + 0.019*"code"
INFO: topic #2 (1.000): 0.092*"variable" + 0.060*"module" + 0.060*"global" + 0.048*"function" + 0.038*"name" + 0.025*"import" + 0.019*"value" + 0.019*"assign" + 0.016*"local" + 0.016*"scope"
INFO: Question Similarity: [0.3989792466163635, 0.30291616916656494, 0.4253098964691162, 0.35540640354156494, 0.32764148712158203, 0.21634775400161743, 0.23531293869018555, 0.39179182052612305, 0.14853441715240479, 0.18363893032073975]
INFO: 1978076: -0.27927282730011815
INFO: 35904211: -0.28114343271308284
INFO: 34168541: -0.2813811547987158
INFO: 1977383: -0.29022642743516847
INFO: 48870337: -0.4383714050956057
INFO: 66869622: -0.4836213397668973
INFO: 64836766: -0.563729096550096
INFO: 71785774: -0.6617931308730348
INFO: 59221129: -0.9202972333602194
INFO: 68153138: -0.9965335773227402
INFO: Recommended Keywords
INFO: function score: -0.7917397
INFO: assign score: -0.75979596
INFO: example score: -0.7584093
INFO: application score: -0.7468051
INFO: necessary score: -0.717141
INFO: code score: -0.7162822
INFO: value score: -0.71084744
INFO: scope score: -0.7052235
INFO: definition score: -0.6633764
INFO: variable score: -0.66229075
INFO: problem score: -0.65987355
INFO: actual score: -0.6589368
INFO: information score: -0.6480884
INFO: static score: -0.6452498
INFO: solution score: -0.6364744
INFO: implementation score: -0.6309396
INFO: constant score: -0.6123478
INFO: explicit score: -0.6079188
INFO: available score: -0.60787904
INFO: object score: -0.60765547
INFO: module score: -0.5932465
INFO: helpful score: -0.5899513
INFO: configuration score: -0.5859753
INFO: special score: -0.5828686
INFO: level score: -0.5809538
INFO: namespace score: -0.5802353
INFO: documentation score: -0.5789222
INFO: order score: -0.5768354
INFO: database score: -0.57280934
INFO: approach score: -0.56909007
INFO: global score: -0.5644248
INFO: entity score: -0.5557452
INFO: way score: -0.5534295
INFO: access score: -0.5502797
INFO: current score: -0.5470504
INFO: test score: -0.5416501
INFO: important score: -0.53788483
INFO: import score: -0.5363034
INFO: immutable score: -0.5354784
INFO: file score: -0.5216667
INFO: config score: -0.5093073
INFO: override score: -0.50842464
INFO: single score: -0.49574983
INFO: keyword score: -0.49480942
INFO: share score: -0.4930515
INFO: execute score: -0.47277227
INFO: artificial score: -0.46809343
INFO: underscores score: -0.46800765
INFO: canonical score: -0.45313844
INFO: workaround score: -0.4390078
INFO: technique score: -0.43297845
INFO: accessible score: -0.42961895
INFO: point score: -0.4289159
INFO: new score: -0.417609
INFO: note score: -0.41676053
INFO: state score: -0.41227728
INFO: visibility score: -0.4121078
INFO: helper score: -0.4107761
INFO: direction score: -0.40309346
INFO: many score: -0.3927648
INFO: main score: -0.39001775
INFO: local score: -0.37688336
INFO: program score: -0.36648852
INFO: subtle score: -0.3511104
INFO: copy score: -0.33455715
INFO: cfg score: -0.32422432
INFO: name score: -0.28402564
INFO: outside score: -0.27502665
INFO: answer score: -0.27327034
INFO: short score: -0.26882577
INFO: mymodule score: -0.25205278
INFO: quirk score: -0.25020272
INFO: none score: -0.22722638
INFO: c score: -0.22372837
INFO: people score: -0.2160792
INFO: int score: -0.21010332
INFO: line score: -0.19336857
INFO: deal score: -0.15961374
INFO: first score: -0.14615482
INFO: stuff score: -0.06593495
INFO: var score: -0.043386873
INFO: alterd score: -0.0
INFO: file2.py score: -0.0
INFO: first_var score: -0.0
INFO: explicity score: -0.0
INFO: steveha score: -0.0
INFO: wisty score: -0.0
INFO: db_name score: -0.0
INFO: module_name.var_name score: -0.0
INFO: accident score: 0.04034358
INFO: ============================================================
INFO: --------------------
INFO: Why are default values shared between objects?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<300 unique tokens: ['=', 'access', 'aliasing', 'answer', 'append']...> from 10 documents (total 883 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<300 unique tokens: ['=', 'access', 'aliasing', 'answer', 'append']...> from 10 documents (total 883 corpus positions)", 'datetime': '2023-04-18T14:16:04.889383', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.005 per-word bound, 128.5 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"default" + 0.054*"value" + 0.043*"class" + 0.043*"instance" + 0.028*"argument" + 0.024*"mutable" + 0.021*"list" + 0.019*"variable" + 0.018*"method" + 0.017*"type"
INFO: topic #1 (1.000): 0.058*"default" + 0.056*"value" + 0.028*"function" + 0.027*"argument" + 0.025*"instance" + 0.024*"class" + 0.018*"mutable" + 0.017*"object" + 0.016*"none" + 0.016*"way"
INFO: topic #2 (1.000): 0.081*"default" + 0.058*"value" + 0.055*"function" + 0.049*"argument" + 0.041*"time" + 0.028*"object" + 0.028*"list" + 0.028*"arg" + 0.024*"mutable" + 0.023*"code"
INFO: topic diff=3.171789, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.285 per-word bound, 1248.1 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.074*"default" + 0.065*"value" + 0.042*"class" + 0.033*"instance" + 0.025*"variable" + 0.020*"list" + 0.019*"argument" + 0.019*"mutable" + 0.018*"new" + 0.017*"method"
INFO: topic #1 (1.000): 0.066*"value" + 0.056*"default" + 0.026*"function" + 0.023*"class" + 0.023*"way" + 0.017*"object" + 0.017*"instance" + 0.014*"mutable" + 0.014*"argument" + 0.014*"none"
INFO: topic #2 (1.000): 0.070*"default" + 0.069*"function" + 0.065*"value" + 0.051*"list" + 0.041*"time" + 0.039*"argument" + 0.035*"none" + 0.030*"object" + 0.016*"mutable" + 0.015*"arg"
INFO: topic diff=2.622314, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 57.36777039165582
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.4752213079258946
DEBUG: bound: at document #0
INFO: -5.611 per-word bound, 48.9 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"default" + 0.053*"value" + 0.047*"class" + 0.043*"instance" + 0.025*"argument" + 0.024*"mutable" + 0.022*"variable" + 0.020*"list" + 0.017*"method" + 0.016*"type"
INFO: topic #1 (1.000): 0.052*"value" + 0.045*"default" + 0.021*"function" + 0.019*"class" + 0.018*"way" + 0.015*"method" + 0.015*"output" + 0.014*"object" + 0.013*"dunder" + 0.013*"instance"
INFO: topic #2 (1.000): 0.083*"default" + 0.071*"function" + 0.069*"value" + 0.048*"argument" + 0.047*"time" + 0.038*"list" + 0.035*"object" + 0.031*"none" + 0.029*"arg" + 0.020*"code"
INFO: topic diff=1.232856, rho=0.500000
DEBUG: bound: at document #0
INFO: -7.289 per-word bound, 156.4 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.070*"default" + 0.055*"value" + 0.048*"class" + 0.040*"instance" + 0.026*"variable" + 0.022*"mutable" + 0.021*"argument" + 0.017*"method" + 0.017*"list" + 0.015*"type"
INFO: topic #1 (1.000): 0.062*"value" + 0.047*"default" + 0.036*"reset" + 0.018*"file" + 0.018*"plot" + 0.018*"approach" + 0.018*"operation" + 0.017*"class" + 0.017*"function" + 0.017*"way"
INFO: topic #2 (1.000): 0.071*"function" + 0.068*"default" + 0.066*"value" + 0.052*"list" + 0.042*"time" + 0.040*"argument" + 0.038*"none" + 0.032*"object" + 0.025*"l" + 0.019*"empty"
INFO: topic diff=1.151267, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 47.1515635510534
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -0.977670206313585
DEBUG: bound: at document #0
INFO: -5.430 per-word bound, 43.1 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"default" + 0.050*"value" + 0.049*"class" + 0.044*"instance" + 0.027*"argument" + 0.025*"mutable" + 0.022*"variable" + 0.019*"list" + 0.017*"method" + 0.016*"code"
INFO: topic #1 (1.000): 0.051*"value" + 0.039*"default" + 0.028*"reset" + 0.020*"output" + 0.018*"method" + 0.016*"dunder" + 0.015*"repr" + 0.015*"plot" + 0.015*"approach" + 0.015*"file"
INFO: topic #2 (1.000): 0.081*"default" + 0.073*"function" + 0.070*"value" + 0.048*"time" + 0.046*"argument" + 0.040*"list" + 0.037*"object" + 0.034*"none" + 0.029*"arg" + 0.018*"code"
INFO: topic diff=0.763718, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.420 per-word bound, 85.6 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.070*"default" + 0.053*"value" + 0.050*"class" + 0.042*"instance" + 0.025*"variable" + 0.024*"mutable" + 0.023*"argument" + 0.016*"method" + 0.016*"list" + 0.016*"code"
INFO: topic #1 (1.000): 0.060*"value" + 0.042*"default" + 0.041*"reset" + 0.021*"plot" + 0.021*"file" + 0.021*"approach" + 0.021*"operation" + 0.015*"output" + 0.015*"method" + 0.013*"class"
INFO: topic #2 (1.000): 0.073*"function" + 0.069*"default" + 0.067*"value" + 0.053*"list" + 0.044*"time" + 0.039*"none" + 0.039*"argument" + 0.034*"object" + 0.028*"l" + 0.021*"empty"
INFO: topic diff=0.609632, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 44.922447568791895
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -0.7740788092339607
DEBUG: bound: at document #0
INFO: -5.362 per-word bound, 41.1 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"default" + 0.050*"value" + 0.050*"class" + 0.045*"instance" + 0.027*"argument" + 0.026*"mutable" + 0.022*"variable" + 0.018*"list" + 0.017*"code" + 0.016*"method"
INFO: topic #1 (1.000): 0.049*"value" + 0.034*"default" + 0.033*"reset" + 0.026*"method" + 0.023*"dunder" + 0.022*"repr" + 0.022*"output" + 0.019*"str" + 0.017*"plot" + 0.017*"approach"
INFO: topic #2 (1.000): 0.080*"default" + 0.074*"function" + 0.071*"value" + 0.048*"time" + 0.044*"argument" + 0.041*"list" + 0.038*"object" + 0.035*"none" + 0.029*"arg" + 0.018*"code"
INFO: topic diff=0.495112, rho=0.408248
DEBUG: bound: at document #0
INFO: -6.288 per-word bound, 78.2 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.071*"default" + 0.053*"value" + 0.051*"class" + 0.043*"instance" + 0.025*"mutable" + 0.025*"variable" + 0.024*"argument" + 0.016*"code" + 0.016*"list" + 0.016*"type"
INFO: topic #1 (1.000): 0.058*"value" + 0.042*"reset" + 0.037*"default" + 0.021*"file" + 0.021*"approach" + 0.021*"plot" + 0.021*"operation" + 0.020*"method" + 0.017*"output" + 0.011*"variable"
INFO: topic #2 (1.000): 0.074*"function" + 0.069*"default" + 0.068*"value" + 0.052*"list" + 0.044*"time" + 0.040*"none" + 0.039*"argument" + 0.035*"object" + 0.028*"l" + 0.021*"empty"
INFO: topic diff=0.397503, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 44.04052435791748
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -0.9908834751992829
DEBUG: bound: at document #0
INFO: -5.327 per-word bound, 40.1 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.070*"default" + 0.050*"class" + 0.050*"value" + 0.045*"instance" + 0.027*"argument" + 0.026*"mutable" + 0.022*"variable" + 0.018*"list" + 0.017*"code" + 0.016*"type"
INFO: topic #1 (1.000): 0.048*"value" + 0.034*"reset" + 0.032*"method" + 0.031*"default" + 0.025*"dunder" + 0.025*"repr" + 0.024*"str" + 0.022*"output" + 0.018*"approach" + 0.018*"file"
INFO: topic #2 (1.000): 0.080*"default" + 0.075*"function" + 0.071*"value" + 0.049*"time" + 0.044*"argument" + 0.042*"list" + 0.038*"object" + 0.036*"none" + 0.029*"arg" + 0.018*"creation"
INFO: topic diff=0.375769, rho=0.377964
DEBUG: bound: at document #0
INFO: -6.234 per-word bound, 75.3 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.072*"default" + 0.053*"value" + 0.052*"class" + 0.043*"instance" + 0.026*"mutable" + 0.025*"variable" + 0.024*"argument" + 0.017*"code" + 0.016*"list" + 0.016*"way"
INFO: topic #1 (1.000): 0.057*"value" + 0.042*"reset" + 0.034*"default" + 0.025*"method" + 0.021*"approach" + 0.021*"plot" + 0.021*"file" + 0.021*"operation" + 0.017*"output" + 0.012*"dunder"
INFO: topic #2 (1.000): 0.074*"function" + 0.070*"default" + 0.068*"value" + 0.052*"list" + 0.045*"time" + 0.040*"none" + 0.039*"argument" + 0.036*"object" + 0.027*"l" + 0.021*"empty"
INFO: topic diff=0.310829, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 43.667453299343194
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -2.1387823523194682
DEBUG: bound: at document #0
INFO: -5.310 per-word bound, 39.7 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.070*"default" + 0.051*"class" + 0.050*"value" + 0.045*"instance" + 0.027*"argument" + 0.026*"mutable" + 0.023*"variable" + 0.018*"list" + 0.017*"code" + 0.016*"type"
INFO: topic #1 (1.000): 0.048*"value" + 0.036*"method" + 0.035*"reset" + 0.029*"default" + 0.025*"dunder" + 0.025*"repr" + 0.025*"str" + 0.022*"output" + 0.018*"approach" + 0.018*"plot"
INFO: topic #2 (1.000): 0.079*"default" + 0.075*"function" + 0.071*"value" + 0.049*"time" + 0.044*"argument" + 0.043*"list" + 0.038*"object" + 0.036*"none" + 0.029*"arg" + 0.018*"creation"
INFO: topic diff=0.312758, rho=0.353553
DEBUG: bound: at document #0
INFO: -6.205 per-word bound, 73.8 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"default" + 0.053*"class" + 0.053*"value" + 0.043*"instance" + 0.026*"mutable" + 0.025*"variable" + 0.024*"argument" + 0.017*"code" + 0.016*"way" + 0.016*"list"
INFO: topic #1 (1.000): 0.056*"value" + 0.042*"reset" + 0.031*"default" + 0.028*"method" + 0.021*"approach" + 0.021*"file" + 0.021*"plot" + 0.021*"operation" + 0.017*"output" + 0.013*"dunder"
INFO: topic #2 (1.000): 0.075*"function" + 0.070*"default" + 0.068*"value" + 0.052*"list" + 0.045*"time" + 0.040*"none" + 0.040*"argument" + 0.036*"object" + 0.027*"l" + 0.022*"arg"
INFO: topic diff=0.272226, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 43.4810306856879
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -2.3623413618515356
DEBUG: bound: at document #0
INFO: -5.299 per-word bound, 39.4 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.071*"default" + 0.051*"class" + 0.050*"value" + 0.045*"instance" + 0.027*"argument" + 0.027*"mutable" + 0.023*"variable" + 0.018*"list" + 0.017*"code" + 0.016*"type"
INFO: topic #1 (1.000): 0.047*"value" + 0.038*"method" + 0.035*"reset" + 0.027*"default" + 0.025*"dunder" + 0.025*"repr" + 0.025*"str" + 0.022*"output" + 0.018*"plot" + 0.018*"approach"
INFO: topic #2 (1.000): 0.079*"default" + 0.075*"function" + 0.071*"value" + 0.049*"time" + 0.044*"argument" + 0.043*"list" + 0.038*"object" + 0.036*"none" + 0.029*"arg" + 0.018*"creation"
INFO: topic diff=0.274110, rho=0.333333
DEBUG: bound: at document #0
INFO: -6.187 per-word bound, 72.9 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"default" + 0.053*"class" + 0.053*"value" + 0.044*"instance" + 0.026*"mutable" + 0.025*"variable" + 0.024*"argument" + 0.017*"code" + 0.016*"way" + 0.016*"list"
INFO: topic #1 (1.000): 0.055*"value" + 0.042*"reset" + 0.029*"method" + 0.029*"default" + 0.021*"approach" + 0.021*"plot" + 0.021*"file" + 0.021*"operation" + 0.018*"output" + 0.014*"dunder"
INFO: topic #2 (1.000): 0.075*"function" + 0.070*"default" + 0.068*"value" + 0.052*"list" + 0.046*"time" + 0.040*"none" + 0.040*"argument" + 0.036*"object" + 0.026*"l" + 0.022*"arg"
INFO: topic diff=0.249335, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 43.363602406745024
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -2.3598489749136005
DEBUG: bound: at document #0
INFO: -5.291 per-word bound, 39.1 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.071*"default" + 0.052*"class" + 0.050*"value" + 0.046*"instance" + 0.027*"argument" + 0.027*"mutable" + 0.023*"variable" + 0.017*"list" + 0.017*"code" + 0.016*"type"
INFO: topic #1 (1.000): 0.047*"value" + 0.039*"method" + 0.035*"reset" + 0.025*"dunder" + 0.025*"repr" + 0.025*"str" + 0.025*"default" + 0.022*"output" + 0.018*"plot" + 0.018*"approach"
INFO: topic #2 (1.000): 0.079*"default" + 0.075*"function" + 0.071*"value" + 0.049*"time" + 0.044*"list" + 0.044*"argument" + 0.038*"object" + 0.036*"none" + 0.029*"arg" + 0.017*"creation"
INFO: topic diff=0.248538, rho=0.316228
DEBUG: bound: at document #0
INFO: -6.174 per-word bound, 72.2 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.074*"default" + 0.053*"class" + 0.053*"value" + 0.044*"instance" + 0.026*"mutable" + 0.025*"variable" + 0.024*"argument" + 0.017*"code" + 0.017*"way" + 0.016*"list"
INFO: topic #1 (1.000): 0.055*"value" + 0.042*"reset" + 0.031*"method" + 0.027*"default" + 0.021*"file" + 0.021*"approach" + 0.021*"plot" + 0.021*"operation" + 0.018*"output" + 0.014*"dunder"
INFO: topic #2 (1.000): 0.075*"function" + 0.071*"default" + 0.068*"value" + 0.051*"list" + 0.046*"time" + 0.040*"argument" + 0.040*"none" + 0.036*"object" + 0.026*"l" + 0.022*"arg"
INFO: topic diff=0.232281, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 43.27428742457734
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -2.356845529668355
DEBUG: bound: at document #0
INFO: -5.285 per-word bound, 39.0 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.071*"default" + 0.052*"class" + 0.050*"value" + 0.046*"instance" + 0.027*"argument" + 0.027*"mutable" + 0.023*"variable" + 0.017*"list" + 0.017*"code" + 0.016*"type"
INFO: topic #1 (1.000): 0.047*"value" + 0.040*"method" + 0.036*"reset" + 0.025*"dunder" + 0.025*"repr" + 0.025*"str" + 0.024*"default" + 0.022*"output" + 0.018*"plot" + 0.018*"approach"
INFO: topic #2 (1.000): 0.078*"default" + 0.075*"function" + 0.071*"value" + 0.049*"time" + 0.044*"list" + 0.044*"argument" + 0.038*"object" + 0.036*"none" + 0.028*"arg" + 0.017*"creation"
INFO: topic diff=0.231067, rho=0.301511
DEBUG: bound: at document #0
INFO: -6.163 per-word bound, 71.6 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.074*"default" + 0.054*"class" + 0.052*"value" + 0.044*"instance" + 0.026*"mutable" + 0.025*"variable" + 0.024*"argument" + 0.017*"code" + 0.017*"way" + 0.016*"list"
INFO: topic #1 (1.000): 0.054*"value" + 0.042*"reset" + 0.032*"method" + 0.025*"default" + 0.021*"file" + 0.021*"approach" + 0.021*"plot" + 0.021*"operation" + 0.018*"output" + 0.016*"decorator"
INFO: topic #2 (1.000): 0.075*"function" + 0.071*"default" + 0.068*"value" + 0.051*"list" + 0.046*"time" + 0.040*"argument" + 0.039*"none" + 0.037*"object" + 0.026*"l" + 0.023*"arg"
INFO: topic diff=0.219022, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 43.19722708909707
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -1.0281159466885301
DEBUG: bound: at document #0
INFO: -5.279 per-word bound, 38.8 perplexity estimate based on a held-out corpus of 5 documents with 660 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.072*"default" + 0.052*"class" + 0.050*"value" + 0.046*"instance" + 0.027*"argument" + 0.027*"mutable" + 0.023*"variable" + 0.017*"list" + 0.017*"code" + 0.016*"type"
INFO: topic #1 (1.000): 0.047*"value" + 0.041*"method" + 0.036*"reset" + 0.025*"dunder" + 0.025*"repr" + 0.025*"str" + 0.022*"default" + 0.022*"output" + 0.018*"approach" + 0.018*"file"
INFO: topic #2 (1.000): 0.078*"default" + 0.075*"function" + 0.071*"value" + 0.049*"time" + 0.044*"list" + 0.044*"argument" + 0.038*"object" + 0.036*"none" + 0.028*"arg" + 0.017*"creation"
INFO: topic diff=0.217539, rho=0.288675
DEBUG: bound: at document #0
INFO: -6.154 per-word bound, 71.2 perplexity estimate based on a held-out corpus of 5 documents with 223 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.074*"default" + 0.054*"class" + 0.052*"value" + 0.044*"instance" + 0.027*"mutable" + 0.025*"variable" + 0.025*"argument" + 0.017*"code" + 0.017*"way" + 0.016*"list"
INFO: topic #1 (1.000): 0.054*"value" + 0.041*"reset" + 0.032*"method" + 0.024*"default" + 0.021*"plot" + 0.021*"file" + 0.021*"approach" + 0.021*"operation" + 0.018*"output" + 0.017*"decorator"
INFO: topic #2 (1.000): 0.075*"function" + 0.071*"default" + 0.068*"value" + 0.051*"list" + 0.046*"time" + 0.040*"argument" + 0.039*"none" + 0.037*"object" + 0.025*"l" + 0.023*"arg"
INFO: topic diff=0.208060, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 43.130316665570625
DEBUG: Setting topics to those of the model: LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.0281159466885301
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=300, num_topics=3, decay=0.5, chunksize=5> in 0.19s', 'datetime': '2023-04-18T14:16:05.077665', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/cos_threshold/5/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-18T14:16:05.077824', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/cos_threshold/5/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/5/model.state
DEBUG: {'uri': 'model/cos_threshold/5/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/cos_threshold/5/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['state', 'id2word', 'dispatcher'], 'datetime': '2023-04-18T14:16:05.081079', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/cos_threshold/5/model.expElogbeta.npy
INFO: not storing attribute state
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
DEBUG: {'uri': 'model/cos_threshold/5/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/5/model
INFO: topic #0 (1.000): 0.074*"default" + 0.054*"class" + 0.052*"value" + 0.044*"instance" + 0.027*"mutable" + 0.025*"variable" + 0.025*"argument" + 0.017*"code" + 0.017*"way" + 0.016*"list"
INFO: topic #1 (1.000): 0.054*"value" + 0.041*"reset" + 0.032*"method" + 0.024*"default" + 0.021*"plot" + 0.021*"file" + 0.021*"approach" + 0.021*"operation" + 0.018*"output" + 0.017*"decorator"
INFO: topic #2 (1.000): 0.075*"function" + 0.071*"default" + 0.068*"value" + 0.051*"list" + 0.046*"time" + 0.040*"argument" + 0.039*"none" + 0.037*"object" + 0.025*"l" + 0.023*"arg"
INFO: Question Similarity: [0.25903064012527466, 0.15963959693908691, 0.27537524700164795, 0.20878994464874268, 0.1713152527809143, 0.1682124137878418, 0.4628903865814209, 0.20760440826416016, 0.22944653034210205, 0.1243329644203186]
INFO: 32939277: -0.2696898676497286
INFO: 61756644: -0.36481766100918106
INFO: 63603063: -0.37095844660712873
INFO: 2681303: -0.40322724725697756
INFO: 67959907: -0.40645927519003744
INFO: 30515149: -0.4080399310155826
INFO: 2681363: -0.411707556442425
INFO: 2681507: -0.41228369605913445
INFO: 62758003: -0.4133624934485372
INFO: 2681286: -0.4153664539414627
INFO: 65867534: -0.4807002698558045
INFO: 65780484: -0.4817519390091933
INFO: 65780209: -0.49254531349834785
INFO: 65780083: -0.4987743581748285
INFO: 65780080: -0.5014914412346028
INFO: 6838275: -0.5071203414396419
INFO: 65780089: -0.5169666149488474
INFO: 56880524: -0.5178346124026636
INFO: 56883874: -0.5200681967566424
INFO: 56879961: -0.5262552505028528
INFO: 54132750: -0.5268497737607518
INFO: 6838271: -0.5429238329645395
INFO: 6838283: -0.5635737873716422
INFO: 6840648: -0.5978138716760865
INFO: 6838280: -0.6041709862249889
INFO: 6838605: -0.618588402352848
INFO: 61424805: -0.8093590569891521
INFO: 61424917: -0.8150086264292471
INFO: 61424772: -0.8257164378767231
INFO: Recommended Keywords
INFO: instance score: -0.8309259
INFO: example score: -0.80371773
INFO: possible score: -0.7602011
INFO: method score: -0.74571717
INFO: difference score: -0.7354992
INFO: attribute score: -0.7334971
INFO: definition score: -0.71891135
INFO: function score: -0.7098987
INFO: problem score: -0.7013947
INFO: default score: -0.7004448
INFO: reset score: -0.6961414
INFO: object score: -0.6920914
INFO: case score: -0.6895582
INFO: equal score: -0.68159443
INFO: mutable score: -0.6773479
INFO: order score: -0.67682797
INFO: value score: -0.67302704
INFO: true score: -0.6701351
INFO: code score: -0.6681951
INFO: real score: -0.66599333
INFO: useful score: -0.6656416
INFO: output score: -0.6638689
INFO: approach score: -0.66269314
INFO: standard score: -0.658981
INFO: solution score: -0.6586935
INFO: need score: -0.6559279
INFO: different score: -0.6527818
INFO: type score: -0.65164024
INFO: result score: -0.64345366
INFO: matter score: -0.6407536
INFO: variable score: -0.63812333
INFO: change score: -0.6354177
INFO: context score: -0.6324326
INFO: immutable score: -0.6307832
INFO: reason score: -0.6293842
INFO: mean score: -0.62861043
INFO: file score: -0.61772895
INFO: reference score: -0.6118255
INFO: point score: -0.6103301
INFO: initial score: -0.60931647
INFO: convenient score: -0.608686
INFO: unmodified score: -0.59402585
INFO: check score: -0.58171386
INFO: fix score: -0.5806624
INFO: other score: -0.5758832
INFO: argument score: -0.5665284
INFO: explanation score: -0.5631414
INFO: note score: -0.5574399
INFO: way score: -0.54682714
INFO: careful score: -0.5455878
INFO: empty score: -0.5385998
INFO: right score: -0.5273072
INFO: behavior score: -0.5263257
INFO: parameter score: -0.525759
INFO: moment score: -0.51678264
INFO: meaning score: -0.51366115
INFO: time score: -0.51003665
INFO: none score: -0.5098452
INFO: install score: -0.50657135
INFO: class score: -0.504422
INFO: subsequent score: -0.4978086
INFO: unwanted score: -0.49582294
INFO: behaviour score: -0.49172807
INFO: idea score: -0.4884271
INFO: tuple score: -0.47337112
INFO: symbolic score: -0.46419024
INFO: pointer score: -0.4624625
INFO: refer score: -0.4617311
INFO: view score: -0.4589603
INFO: constructor score: -0.45583332
INFO: arg score: -0.45358887
INFO: array score: -0.44986758
INFO: prevent score: -0.44788882
INFO: good score: -0.4477503
INFO: integer score: -0.44604573
INFO: call score: -0.445577
INFO: list score: -0.44104055
INFO: info score: -0.43775383
INFO: important score: -0.43658292
INFO: b score: -0.4326665
INFO: documentation score: -0.4316298
INFO: answer score: -0.43132374
INFO: datum score: -0.43114087
INFO: create score: -0.43034032
INFO: little score: -0.42727494
INFO: invocation score: -0.41455695
INFO: feature score: -0.40687057
INFO: f score: -0.40638807
INFO: long score: -0.40553477
INFO: surprising score: -0.40268105
INFO: creation score: -0.39911768
INFO: propagation score: -0.39784026
INFO: c score: -0.39759853
INFO: body score: -0.3957646
INFO: mylist score: -0.3917002
INFO: want score: -0.37971583
INFO: field score: -0.37929177
INFO: operation score: -0.37874588
INFO: original score: -0.3771332
INFO: whole score: -0.37494048
INFO: new score: -0.37373173
INFO: declaration score: -0.37104487
INFO: thing score: -0.3698235
INFO: mention score: -0.3697353
INFO: caller score: -0.36373827
INFO: inside score: -0.36146292
INFO: property score: -0.354651
INFO: plot score: -0.34353375
INFO: outside score: -0.34286997
INFO: work score: -0.34128496
INFO: previous score: -0.3406737
INFO: backport score: -0.33977032
INFO: header score: -0.33944026
INFO: my_list score: -0.339034
INFO: exhibit score: -0.3272371
INFO: bug score: -0.32449722
INFO: first score: -0.32183036
INFO: dict score: -0.3214997
INFO: l score: -0.3090388
INFO: hope score: -0.30484524
INFO: fine score: -0.2905755
INFO: print score: -0.29056984
INFO: worth score: -0.2779399
INFO: taste score: -0.27547964
INFO: bad score: -0.27181193
INFO: try score: -0.268715
INFO: num score: -0.26107427
INFO: show score: -0.26077726
INFO: name score: -0.2545847
INFO: lot score: -0.2526248
INFO: place score: -0.24148269
INFO: line score: -0.22582047
INFO: deadly score: -0.20115694
INFO: str score: -0.19048522
INFO: unwary score: -0.19040278
INFO: strange score: -0.1902752
INFO: snippet score: -0.18435715
INFO: nice score: -0.16724107
INFO: state score: -0.15789126
INFO: goal score: -0.15024783
INFO: bp score: -0.14590178
INFO: ownership score: -0.13149428
INFO: decorator score: -0.09505824
INFO: everytime score: -0.09096452
INFO: def score: -0.08564506
INFO: bunch score: -0.06762314
INFO: member score: -0.06540591
INFO: dozen score: -0.06135943
INFO: repr score: -0.036245078
INFO: manager score: -0.03054617
INFO: dunder score: -0.0
INFO: i=6 score: -0.0
INFO: f(arg score: -0.0
INFO: self.root score: -0.0
INFO: dataclasse score: -0.0
INFO: dataclass score: -0.0
INFO: t]he score: -0.0
INFO: unchangable score: -0.0
INFO: attributeerror score: -0.0
INFO: b. score: -0.0
INFO: a. score: -0.0
INFO: function_name>.__default score: -0.0
INFO: l= score: -0.0
INFO: http://effbot.org/zone/default-values.htm score: -0.0
INFO: self.default_attr score: -0.0
INFO: imho score: -0.0
INFO: pythonic score: -0.0
INFO: ============================================================
INFO: --------------------
INFO: How can I pass optional or keyword parameters from one function to another?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<221 unique tokens: ['argument', 'caller', 'default', 'example', 'function']...> from 10 documents (total 546 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<221 unique tokens: ['argument', 'caller', 'default', 'example', 'function']...> from 10 documents (total 546 corpus positions)", 'datetime': '2023-04-18T14:16:07.660186', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.361 per-word bound, 164.4 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.115*"argument" + 0.064*"parameter" + 0.034*"default" + 0.032*"value" + 0.028*"keyword" + 0.025*"b" + 0.024*"kwargs" + 0.021*"function" + 0.021*"name" + 0.021*"none"
INFO: topic #1 (1.000): 0.075*"argument" + 0.063*"parameter" + 0.042*"optional" + 0.034*"value" + 0.030*"positional" + 0.030*"default" + 0.024*"none" + 0.021*"keyword" + 0.020*"example" + 0.019*"b"
INFO: topic #2 (1.000): 0.088*"argument" + 0.047*"function" + 0.037*"parameter" + 0.032*"name" + 0.028*"code" + 0.026*"default" + 0.024*"value" + 0.021*"keyword" + 0.019*"decorator" + 0.018*"optional"
INFO: topic diff=4.779820, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.387 per-word bound, 1339.1 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.122*"argument" + 0.058*"parameter" + 0.055*"keyword" + 0.042*"default" + 0.036*"args" + 0.032*"positional" + 0.030*"kwargs" + 0.028*"value" + 0.023*"function" + 0.022*"optional"
INFO: topic #1 (1.000): 0.070*"positional" + 0.067*"argument" + 0.065*"optional" + 0.053*"parameter" + 0.043*"keyword" + 0.038*"value" + 0.037*"args" + 0.037*"default" + 0.027*"c" + 0.019*"b"
INFO: topic #2 (1.000): 0.084*"argument" + 0.079*"function" + 0.042*"parameter" + 0.025*"keyword" + 0.022*"optional" + 0.019*"line" + 0.018*"example" + 0.015*"value" + 0.015*"multiple" + 0.015*"dispatch"
INFO: topic diff=3.938836, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 55.396451330005306
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.589893251795203
DEBUG: bound: at document #0
INFO: -6.105 per-word bound, 68.8 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.129*"argument" + 0.045*"keyword" + 0.044*"default" + 0.043*"parameter" + 0.036*"value" + 0.029*"args" + 0.028*"kwargs" + 0.024*"b" + 0.023*"function" + 0.022*"name"
INFO: topic #1 (1.000): 0.076*"parameter" + 0.073*"argument" + 0.049*"optional" + 0.044*"positional" + 0.031*"value" + 0.030*"default" + 0.027*"keyword" + 0.021*"args" + 0.021*"b" + 0.020*"c"
INFO: topic #2 (1.000): 0.084*"argument" + 0.083*"function" + 0.031*"parameter" + 0.030*"code" + 0.029*"decorator" + 0.023*"implementation" + 0.022*"keyword" + 0.019*"example" + 0.018*"name" + 0.016*"optional"
INFO: topic diff=1.365770, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.998 per-word bound, 63.9 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.123*"argument" + 0.054*"keyword" + 0.052*"default" + 0.043*"args" + 0.042*"parameter" + 0.034*"kwargs" + 0.032*"value" + 0.032*"positional" + 0.022*"function" + 0.021*"arbitrary"
INFO: topic #1 (1.000): 0.065*"positional" + 0.064*"argument" + 0.063*"parameter" + 0.059*"optional" + 0.039*"keyword" + 0.035*"default" + 0.035*"value" + 0.034*"args" + 0.029*"c" + 0.024*"kwarg"
INFO: topic #2 (1.000): 0.077*"argument" + 0.067*"function" + 0.036*"parameter" + 0.024*"keyword" + 0.022*"line" + 0.019*"optional" + 0.019*"multiple" + 0.018*"dispatch" + 0.018*"different" + 0.017*"example"
INFO: topic diff=1.162311, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 44.235517299617456
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -0.7321062676112299
DEBUG: bound: at document #0
INFO: -5.681 per-word bound, 51.3 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.129*"argument" + 0.053*"default" + 0.045*"keyword" + 0.043*"value" + 0.032*"args" + 0.032*"parameter" + 0.028*"kwargs" + 0.025*"operations(a" + 0.025*"name" + 0.023*"b"
INFO: topic #1 (1.000): 0.080*"parameter" + 0.071*"argument" + 0.048*"optional" + 0.046*"positional" + 0.029*"default" + 0.028*"value" + 0.028*"keyword" + 0.023*"c" + 0.023*"b" + 0.022*"args"
INFO: topic #2 (1.000): 0.078*"argument" + 0.072*"function" + 0.029*"parameter" + 0.027*"code" + 0.026*"decorator" + 0.022*"keyword" + 0.020*"implementation" + 0.018*"example" + 0.018*"line" + 0.015*"optional"
INFO: topic diff=0.860328, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.604 per-word bound, 48.6 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.123*"argument" + 0.058*"default" + 0.053*"keyword" + 0.045*"args" + 0.038*"value" + 0.033*"kwargs" + 0.031*"positional" + 0.031*"parameter" + 0.024*"arbitrary" + 0.022*"function"
INFO: topic #1 (1.000): 0.069*"parameter" + 0.065*"argument" + 0.064*"positional" + 0.057*"optional" + 0.037*"keyword" + 0.033*"default" + 0.032*"args" + 0.032*"value" + 0.029*"c" + 0.025*"kwarg"
INFO: topic #2 (1.000): 0.075*"argument" + 0.066*"function" + 0.035*"parameter" + 0.024*"keyword" + 0.022*"line" + 0.019*"multiple" + 0.018*"optional" + 0.018*"dispatch" + 0.018*"different" + 0.016*"example"
INFO: topic diff=0.635665, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 41.668735874132715
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -0.7197064421773657
DEBUG: bound: at document #0
INFO: -5.545 per-word bound, 46.7 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.127*"argument" + 0.058*"default" + 0.048*"value" + 0.045*"keyword" + 0.035*"args" + 0.029*"kwargs" + 0.027*"parameter" + 0.026*"operations(a" + 0.023*"b" + 0.023*"function"
INFO: topic #1 (1.000): 0.082*"parameter" + 0.071*"argument" + 0.047*"optional" + 0.047*"positional" + 0.028*"default" + 0.028*"keyword" + 0.026*"value" + 0.024*"c" + 0.023*"b" + 0.022*"args"
INFO: topic #2 (1.000): 0.078*"argument" + 0.069*"function" + 0.029*"parameter" + 0.027*"code" + 0.025*"decorator" + 0.022*"keyword" + 0.019*"implementation" + 0.018*"line" + 0.017*"example" + 0.016*"multiple"
INFO: topic diff=0.538350, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.519 per-word bound, 45.8 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.122*"argument" + 0.061*"default" + 0.052*"keyword" + 0.045*"args" + 0.043*"value" + 0.032*"kwargs" + 0.032*"positional" + 0.026*"parameter" + 0.025*"arbitrary" + 0.022*"function"
INFO: topic #1 (1.000): 0.072*"parameter" + 0.065*"argument" + 0.063*"positional" + 0.056*"optional" + 0.036*"keyword" + 0.032*"default" + 0.031*"args" + 0.030*"value" + 0.029*"c" + 0.025*"kwarg"
INFO: topic #2 (1.000): 0.075*"argument" + 0.066*"function" + 0.035*"parameter" + 0.024*"keyword" + 0.022*"line" + 0.019*"multiple" + 0.018*"optional" + 0.018*"different" + 0.018*"dispatch" + 0.017*"decorator"
INFO: topic diff=0.402637, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 40.72484313883284
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -0.7590452561516144
DEBUG: bound: at document #0
INFO: -5.478 per-word bound, 44.6 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.126*"argument" + 0.060*"default" + 0.051*"value" + 0.045*"keyword" + 0.036*"args" + 0.029*"kwargs" + 0.027*"operations(a" + 0.025*"parameter" + 0.023*"none" + 0.023*"b"
INFO: topic #1 (1.000): 0.082*"parameter" + 0.071*"argument" + 0.048*"positional" + 0.048*"optional" + 0.028*"keyword" + 0.028*"default" + 0.025*"value" + 0.024*"c" + 0.023*"b" + 0.022*"args"
INFO: topic #2 (1.000): 0.078*"argument" + 0.068*"function" + 0.029*"parameter" + 0.026*"code" + 0.024*"decorator" + 0.023*"keyword" + 0.019*"implementation" + 0.018*"line" + 0.018*"name" + 0.017*"example"
INFO: topic diff=0.397866, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.488 per-word bound, 44.9 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.121*"argument" + 0.063*"default" + 0.052*"keyword" + 0.046*"args" + 0.046*"value" + 0.032*"positional" + 0.032*"kwargs" + 0.026*"arbitrary" + 0.024*"parameter" + 0.022*"function"
INFO: topic #1 (1.000): 0.074*"parameter" + 0.066*"argument" + 0.063*"positional" + 0.055*"optional" + 0.036*"keyword" + 0.031*"default" + 0.030*"args" + 0.029*"c" + 0.028*"value" + 0.024*"kwarg"
INFO: topic #2 (1.000): 0.076*"argument" + 0.065*"function" + 0.034*"parameter" + 0.023*"keyword" + 0.022*"line" + 0.019*"multiple" + 0.018*"optional" + 0.018*"dispatch" + 0.018*"different" + 0.017*"decorator"
INFO: topic diff=0.304719, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 40.29260303680641
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -0.7482983459126703
DEBUG: bound: at document #0
INFO: -5.438 per-word bound, 43.4 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.125*"argument" + 0.061*"default" + 0.053*"value" + 0.046*"keyword" + 0.037*"args" + 0.029*"kwargs" + 0.027*"operations(a" + 0.024*"positional" + 0.024*"none" + 0.023*"parameter"
INFO: topic #1 (1.000): 0.083*"parameter" + 0.071*"argument" + 0.049*"positional" + 0.048*"optional" + 0.028*"keyword" + 0.027*"default" + 0.024*"c" + 0.024*"value" + 0.023*"b" + 0.022*"args"
INFO: topic #2 (1.000): 0.078*"argument" + 0.068*"function" + 0.029*"parameter" + 0.025*"code" + 0.024*"decorator" + 0.023*"keyword" + 0.019*"name" + 0.019*"line" + 0.018*"implementation" + 0.017*"example"
INFO: topic diff=0.321323, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.473 per-word bound, 44.4 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.121*"argument" + 0.064*"default" + 0.052*"keyword" + 0.048*"value" + 0.046*"args" + 0.033*"positional" + 0.032*"kwargs" + 0.027*"arbitrary" + 0.023*"parameter" + 0.022*"function"
INFO: topic #1 (1.000): 0.075*"parameter" + 0.066*"argument" + 0.063*"positional" + 0.055*"optional" + 0.035*"keyword" + 0.030*"default" + 0.029*"args" + 0.029*"c" + 0.026*"value" + 0.024*"b"
INFO: topic #2 (1.000): 0.076*"argument" + 0.065*"function" + 0.034*"parameter" + 0.023*"keyword" + 0.022*"line" + 0.019*"multiple" + 0.018*"optional" + 0.018*"different" + 0.018*"dispatch" + 0.017*"decorator"
INFO: topic diff=0.262856, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 40.0962733494622
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -0.6721461000900031
DEBUG: bound: at document #0
INFO: -5.415 per-word bound, 42.7 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.124*"argument" + 0.062*"default" + 0.055*"value" + 0.046*"keyword" + 0.038*"args" + 0.029*"kwargs" + 0.027*"operations(a" + 0.025*"positional" + 0.024*"none" + 0.023*"b"
INFO: topic #1 (1.000): 0.083*"parameter" + 0.071*"argument" + 0.049*"positional" + 0.048*"optional" + 0.028*"keyword" + 0.027*"default" + 0.025*"c" + 0.023*"b" + 0.023*"value" + 0.022*"args"
INFO: topic #2 (1.000): 0.079*"argument" + 0.068*"function" + 0.029*"parameter" + 0.025*"code" + 0.024*"decorator" + 0.023*"keyword" + 0.020*"name" + 0.019*"line" + 0.018*"implementation" + 0.017*"example"
INFO: topic diff=0.275333, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.464 per-word bound, 44.1 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"argument" + 0.064*"default" + 0.052*"keyword" + 0.050*"value" + 0.046*"args" + 0.033*"positional" + 0.031*"kwargs" + 0.027*"arbitrary" + 0.022*"function" + 0.022*"parameter"
INFO: topic #1 (1.000): 0.076*"parameter" + 0.066*"argument" + 0.063*"positional" + 0.054*"optional" + 0.035*"keyword" + 0.029*"default" + 0.029*"args" + 0.029*"c" + 0.025*"value" + 0.024*"b"
INFO: topic #2 (1.000): 0.076*"argument" + 0.066*"function" + 0.034*"parameter" + 0.023*"keyword" + 0.022*"line" + 0.018*"multiple" + 0.018*"optional" + 0.018*"different" + 0.018*"dispatch" + 0.017*"decorator"
INFO: topic diff=0.240761, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 39.99121024766796
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -0.6742770784044607
DEBUG: bound: at document #0
INFO: -5.399 per-word bound, 42.2 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.124*"argument" + 0.063*"default" + 0.056*"value" + 0.046*"keyword" + 0.038*"args" + 0.029*"kwargs" + 0.027*"operations(a" + 0.025*"positional" + 0.024*"none" + 0.023*"b"
INFO: topic #1 (1.000): 0.083*"parameter" + 0.071*"argument" + 0.050*"positional" + 0.048*"optional" + 0.029*"keyword" + 0.026*"default" + 0.025*"c" + 0.023*"b" + 0.022*"args" + 0.022*"value"
INFO: topic #2 (1.000): 0.079*"argument" + 0.068*"function" + 0.029*"parameter" + 0.025*"code" + 0.023*"decorator" + 0.023*"keyword" + 0.020*"name" + 0.019*"line" + 0.018*"implementation" + 0.017*"example"
INFO: topic diff=0.245650, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.457 per-word bound, 43.9 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"argument" + 0.065*"default" + 0.052*"keyword" + 0.051*"value" + 0.046*"args" + 0.034*"positional" + 0.031*"kwargs" + 0.027*"arbitrary" + 0.022*"function" + 0.021*"parameter"
INFO: topic #1 (1.000): 0.076*"parameter" + 0.067*"argument" + 0.063*"positional" + 0.054*"optional" + 0.035*"keyword" + 0.029*"default" + 0.029*"c" + 0.028*"args" + 0.025*"value" + 0.024*"b"
INFO: topic #2 (1.000): 0.076*"argument" + 0.066*"function" + 0.033*"parameter" + 0.023*"keyword" + 0.022*"line" + 0.018*"multiple" + 0.018*"decorator" + 0.018*"optional" + 0.018*"different" + 0.018*"dispatch"
INFO: topic diff=0.224220, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 39.92260057912687
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -0.6726241632095405
DEBUG: bound: at document #0
INFO: -5.388 per-word bound, 41.9 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.124*"argument" + 0.063*"default" + 0.057*"value" + 0.046*"keyword" + 0.038*"args" + 0.029*"kwargs" + 0.026*"operations(a" + 0.026*"positional" + 0.024*"none" + 0.024*"b"
INFO: topic #1 (1.000): 0.084*"parameter" + 0.071*"argument" + 0.051*"positional" + 0.048*"optional" + 0.029*"keyword" + 0.026*"default" + 0.025*"c" + 0.023*"b" + 0.022*"args" + 0.022*"value"
INFO: topic #2 (1.000): 0.078*"argument" + 0.068*"function" + 0.029*"parameter" + 0.025*"code" + 0.023*"decorator" + 0.022*"keyword" + 0.021*"name" + 0.019*"line" + 0.018*"implementation" + 0.017*"example"
INFO: topic diff=0.226118, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.451 per-word bound, 43.7 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"argument" + 0.065*"default" + 0.052*"keyword" + 0.052*"value" + 0.046*"args" + 0.034*"positional" + 0.031*"kwargs" + 0.026*"arbitrary" + 0.022*"function" + 0.021*"parameter"
INFO: topic #1 (1.000): 0.077*"parameter" + 0.067*"argument" + 0.063*"positional" + 0.054*"optional" + 0.035*"keyword" + 0.029*"default" + 0.028*"c" + 0.028*"args" + 0.024*"value" + 0.024*"b"
INFO: topic #2 (1.000): 0.076*"argument" + 0.066*"function" + 0.033*"parameter" + 0.023*"keyword" + 0.022*"line" + 0.018*"multiple" + 0.018*"decorator" + 0.018*"optional" + 0.018*"different" + 0.018*"dispatch"
INFO: topic diff=0.211044, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 39.86914667292095
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -0.6726241632095405
DEBUG: bound: at document #0
INFO: -5.378 per-word bound, 41.6 perplexity estimate based on a held-out corpus of 5 documents with 264 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.124*"argument" + 0.063*"default" + 0.057*"value" + 0.047*"keyword" + 0.039*"args" + 0.029*"kwargs" + 0.026*"operations(a" + 0.026*"positional" + 0.024*"none" + 0.024*"b"
INFO: topic #1 (1.000): 0.084*"parameter" + 0.071*"argument" + 0.051*"positional" + 0.048*"optional" + 0.029*"keyword" + 0.026*"default" + 0.025*"c" + 0.023*"b" + 0.022*"args" + 0.021*"value"
INFO: topic #2 (1.000): 0.078*"argument" + 0.068*"function" + 0.029*"parameter" + 0.024*"code" + 0.023*"decorator" + 0.022*"keyword" + 0.021*"name" + 0.019*"line" + 0.018*"implementation" + 0.017*"example"
INFO: topic diff=0.212028, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.446 per-word bound, 43.6 perplexity estimate based on a held-out corpus of 5 documents with 282 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.120*"argument" + 0.065*"default" + 0.052*"value" + 0.052*"keyword" + 0.046*"args" + 0.034*"positional" + 0.031*"kwargs" + 0.026*"arbitrary" + 0.022*"function" + 0.021*"parameter"
INFO: topic #1 (1.000): 0.077*"parameter" + 0.067*"argument" + 0.063*"positional" + 0.053*"optional" + 0.035*"keyword" + 0.028*"default" + 0.028*"c" + 0.028*"args" + 0.024*"value" + 0.023*"b"
INFO: topic #2 (1.000): 0.076*"argument" + 0.066*"function" + 0.033*"parameter" + 0.023*"keyword" + 0.022*"line" + 0.018*"multiple" + 0.018*"decorator" + 0.018*"optional" + 0.018*"different" + 0.018*"dispatch"
INFO: topic diff=0.201319, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 39.82224742484102
DEBUG: Setting topics to those of the model: LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -0.6726241632095405
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=221, num_topics=3, decay=0.5, chunksize=5> in 0.18s', 'datetime': '2023-04-18T14:16:07.841198', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/cos_threshold/6/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-18T14:16:07.841363', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/cos_threshold/6/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/6/model.state
DEBUG: {'uri': 'model/cos_threshold/6/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/cos_threshold/6/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['state', 'id2word', 'dispatcher'], 'datetime': '2023-04-18T14:16:07.843650', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/cos_threshold/6/model.expElogbeta.npy
INFO: not storing attribute state
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
DEBUG: {'uri': 'model/cos_threshold/6/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/6/model
INFO: topic #0 (1.000): 0.120*"argument" + 0.065*"default" + 0.052*"value" + 0.052*"keyword" + 0.046*"args" + 0.034*"positional" + 0.031*"kwargs" + 0.026*"arbitrary" + 0.022*"function" + 0.021*"parameter"
INFO: topic #1 (1.000): 0.077*"parameter" + 0.067*"argument" + 0.063*"positional" + 0.053*"optional" + 0.035*"keyword" + 0.028*"default" + 0.028*"c" + 0.028*"args" + 0.024*"value" + 0.023*"b"
INFO: topic #2 (1.000): 0.076*"argument" + 0.066*"function" + 0.033*"parameter" + 0.023*"keyword" + 0.022*"line" + 0.018*"multiple" + 0.018*"decorator" + 0.018*"optional" + 0.018*"different" + 0.018*"dispatch"
INFO: Question Similarity: [0.1107819676399231, 0.0679863691329956, 0.13246041536331177, 0.11179757118225098, 0.4317936301231384, 0.175725519657135, 0.07899463176727295, 0.176108717918396, 0.2747569680213928, 0.0950937271118164]
INFO: 68407936: -0.24304093389459838
INFO: 68168421: -0.24564437025518052
INFO: 68168423: -0.24664103993601139
INFO: 69095633: -0.2751941566309294
INFO: 71618773: -0.30931922908601767
INFO: 67028677: -0.34795166150197326
INFO: 67028449: -0.369890489804205
INFO: 67040767: -0.37645665599303274
INFO: 56817421: -0.4316256389091459
INFO: 50397783: -0.6440688525583029
INFO: 67403023: -0.9376873691935151
INFO: 67402968: -1.088046739257216
INFO: Recommended Keywords
INFO: arbitrary score: -0.83020765
INFO: function score: -0.7990907
INFO: value score: -0.74692905
INFO: default score: -0.72000873
INFO: keyword score: -0.7150056
INFO: multiple score: -0.71413594
INFO: parameter score: -0.7100154
INFO: method score: -0.70157534
INFO: variable score: -0.69448185
INFO: different score: -0.6822641
INFO: error score: -0.68174255
INFO: positional score: -0.6795765
INFO: type score: -0.6647896
INFO: tuple score: -0.6534789
INFO: code score: -0.6415599
INFO: reverse score: -0.6410168
INFO: pattern score: -0.640225
INFO: similar score: -0.63122416
INFO: mechanism score: -0.62709373
INFO: example score: -0.6248755
INFO: restriction score: -0.62367076
INFO: order score: -0.61493844
INFO: logic score: -0.61019933
INFO: approach score: -0.59955096
INFO: case score: -0.5949521
INFO: args score: -0.5835537
INFO: possible score: -0.58108896
INFO: non score: -0.57953405
INFO: omitting score: -0.5793553
INFO: ambiguity score: -0.5791064
INFO: specific score: -0.56749994
INFO: foo score: -0.56652683
INFO: argument score: -0.55952656
INFO: matrix score: -0.5594088
INFO: eg score: -0.5571358
INFO: output score: -0.5459116
INFO: b score: -0.5399966
INFO: implementation score: -0.52899426
INFO: module score: -0.5280835
INFO: vector score: -0.51532245
INFO: optional score: -0.50947636
INFO: option score: -0.50887936
INFO: arg score: -0.50402534
INFO: operator score: -0.5019084
INFO: f score: -0.49825597
INFO: way score: -0.49539307
INFO: syntactic score: -0.49098286
INFO: note score: -0.48938692
INFO: prefix score: -0.47632158
INFO: resolve score: -0.46760985
INFO: c score: -0.46285212
INFO: emulate score: -0.44682887
INFO: single score: -0.44450766
INFO: map score: -0.44225258
INFO: access score: -0.43703154
INFO: easy score: -0.4249076
INFO: dispatch score: -0.42274982
INFO: helpful score: -0.41545588
INFO: statement score: -0.4153749
INFO: support score: -0.4148693
INFO: free score: -0.41011822
INFO: v score: -0.40669855
INFO: dict score: -0.40440252
INFO: sense score: -0.40292895
INFO: signature score: -0.40268555
INFO: inspect score: -0.39110637
INFO: answer score: -0.38291305
INFO: reason score: -0.36854872
INFO: collision score: -0.36152872
INFO: caller score: -0.35504794
INFO: line score: -0.35344827
INFO: let score: -0.3433426
INFO: several score: -0.33721906
INFO: write score: -0.32679525
INFO: word score: -0.3265441
INFO: produce score: -0.32388276
INFO: number score: -0.32242873
INFO: grammar score: -0.3139389
INFO: version score: -0.29542407
INFO: position score: -0.29471564
INFO: print score: -0.26436228
INFO: env score: -0.2564607
INFO: engineering score: -0.24657024
INFO: base score: -0.23883586
INFO: list score: -0.23381005
INFO: length score: -0.22696875
INFO: e score: -0.22652994
INFO: mandatory score: -0.215339
INFO: fast score: -0.2142352
INFO: want score: -0.20766322
INFO: name score: -0.19745058
INFO: library score: -0.19303027
INFO: var score: -0.19287442
INFO: pass score: -0.18910225
INFO: none score: -0.1786551
INFO: various score: -0.144292
INFO: conflict score: -0.13018145
INFO: remark score: -0.12323479
INFO: well score: -0.12120503
INFO: union score: -0.11681636
INFO: many score: -0.1006318
INFO: work score: -0.09557941
INFO: recent score: -0.08750525
INFO: decorator score: -0.086185835
INFO: upgrading score: -0.08221846
INFO: first score: -0.06548588
INFO: factory score: -0.055795606
INFO: hacky score: -0.051757336
INFO: kw score: -0.04809702
INFO: cem score: -0.041953057
INFO: dedicate score: -0.031961795
INFO: torch score: -0.020603959
INFO: world score: -0.00669307
INFO: place score: -0.0046280944
INFO: forgot score: -0.004342612
INFO: optional[list score: -0.0
INFO: | score: -0.0
INFO: test(m score: -0.0
INFO: avión score: -0.0
INFO: arg="default_value score: -0.0
INFO: kwargs score: -0.0
INFO: c. score: -0.0
INFO: args->c score: -0.0
INFO: obj.some_function score: -0.0
INFO: g="foo score: -0.0
INFO: getfullargspec score: -0.0
INFO: parameterise score: -0.0
INFO: operations(a score: -0.0
INFO: pranav score: -0.0
INFO: hosangadi score: -0.0
INFO: kwarg score: -0.0
INFO: multipledispatch score: -0.0
INFO: randint score: -0.0
INFO: gen_pyi.py score: -0.0
INFO: function_hint score: -0.0
INFO: useme2declare score: -0.0
INFO: using*args score: -0.0
INFO: e.g score: -0.0
INFO: n’t score: -0.0
INFO: ============================================================
INFO: --------------------
INFO: What is the difference between arguments and parameters?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<397 unique tokens: ['1st', '2nd', '=', 'able', 'absolute']...> from 10 documents (total 1569 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<397 unique tokens: ['1st', '2nd', '=', 'able', 'absolute']...> from 10 documents (total 1569 corpus positions)", 'datetime': '2023-04-18T14:16:10.291881', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.057 per-word bound, 133.2 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.095*"parameter" + 0.089*"function" + 0.084*"argument" + 0.032*"value" + 0.031*"variable" + 0.021*"actual" + 0.021*"method" + 0.020*"type" + 0.019*"call" + 0.015*"formal"
INFO: topic #1 (1.000): 0.092*"parameter" + 0.073*"argument" + 0.071*"function" + 0.046*"value" + 0.026*"variable" + 0.019*"actual" + 0.016*"call" + 0.014*"name" + 0.014*"formal" + 0.014*"method"
INFO: topic #2 (1.000): 0.104*"argument" + 0.096*"parameter" + 0.050*"function" + 0.041*"value" + 0.028*"method" + 0.025*"actual" + 0.022*"variable" + 0.020*"name" + 0.020*"formal" + 0.019*"definition"
INFO: topic diff=2.521024, rho=1.000000
DEBUG: bound: at document #0
INFO: -8.768 per-word bound, 436.1 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.115*"function" + 0.104*"parameter" + 0.093*"argument" + 0.045*"value" + 0.030*"call" + 0.027*"definition" + 0.027*"variable" + 0.023*"b" + 0.019*"actual" + 0.017*"name"
INFO: topic #1 (1.000): 0.092*"parameter" + 0.077*"function" + 0.073*"argument" + 0.050*"value" + 0.021*"variable" + 0.018*"definition" + 0.018*"actual" + 0.017*"call" + 0.014*"name" + 0.012*"formal"
INFO: topic #2 (1.000): 0.110*"argument" + 0.102*"parameter" + 0.056*"function" + 0.052*"value" + 0.037*"definition" + 0.029*"method" + 0.026*"name" + 0.022*"actual" + 0.021*"variable" + 0.018*"formal"
INFO: topic diff=2.163514, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 48.16609442806377
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.5751714987917852
DEBUG: bound: at document #0
INFO: -5.503 per-word bound, 45.3 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.114*"function" + 0.098*"parameter" + 0.087*"argument" + 0.045*"value" + 0.034*"variable" + 0.026*"type" + 0.022*"call" + 0.020*"definition" + 0.018*"actual" + 0.016*"example"
INFO: topic #1 (1.000): 0.067*"parameter" + 0.062*"function" + 0.054*"argument" + 0.039*"value" + 0.034*"program" + 0.024*"variable" + 0.022*"c++" + 0.021*"address" + 0.019*"output" + 0.017*"actual"
INFO: topic #2 (1.000): 0.100*"argument" + 0.100*"parameter" + 0.059*"function" + 0.041*"value" + 0.029*"method" + 0.024*"actual" + 0.022*"variable" + 0.021*"formal" + 0.021*"definition" + 0.020*"name"
INFO: topic diff=1.413586, rho=0.500000
DEBUG: bound: at document #0
INFO: -6.502 per-word bound, 90.6 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.113*"function" + 0.095*"parameter" + 0.088*"argument" + 0.056*"value" + 0.038*"definition" + 0.031*"b" + 0.031*"call" + 0.027*"default" + 0.027*"variable" + 0.022*"name"
INFO: topic #1 (1.000): 0.067*"parameter" + 0.057*"function" + 0.053*"argument" + 0.039*"program" + 0.034*"value" + 0.020*"c++" + 0.018*"actual" + 0.016*"variable" + 0.014*"declaration" + 0.013*"address"
INFO: topic #2 (1.000): 0.102*"parameter" + 0.102*"argument" + 0.057*"function" + 0.039*"value" + 0.032*"method" + 0.025*"actual" + 0.023*"formal" + 0.021*"definition" + 0.021*"variable" + 0.018*"name"
INFO: topic diff=1.262237, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 35.867596550091676
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -0.6903865025883537
DEBUG: bound: at document #0
INFO: -5.194 per-word bound, 36.6 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.113*"function" + 0.094*"parameter" + 0.085*"argument" + 0.052*"value" + 0.032*"variable" + 0.027*"definition" + 0.026*"type" + 0.023*"call" + 0.020*"b" + 0.018*"name"
INFO: topic #1 (1.000): 0.059*"program" + 0.047*"function" + 0.047*"parameter" + 0.038*"argument" + 0.034*"c++" + 0.030*"address" + 0.029*"output" + 0.027*"value" + 0.023*"variable" + 0.020*"separate"
INFO: topic #2 (1.000): 0.101*"parameter" + 0.099*"argument" + 0.060*"function" + 0.038*"value" + 0.030*"method" + 0.024*"actual" + 0.022*"formal" + 0.022*"variable" + 0.018*"definition" + 0.018*"name"
INFO: topic diff=0.891374, rho=0.447214
DEBUG: bound: at document #0
INFO: -5.478 per-word bound, 44.6 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.112*"function" + 0.092*"parameter" + 0.087*"argument" + 0.059*"value" + 0.040*"definition" + 0.033*"b" + 0.032*"default" + 0.031*"call" + 0.027*"variable" + 0.024*"name"
INFO: topic #1 (1.000): 0.057*"program" + 0.048*"parameter" + 0.044*"function" + 0.038*"argument" + 0.028*"c++" + 0.023*"value" + 0.020*"c." + 0.020*"actual" + 0.019*"declaration" + 0.018*"address"
INFO: topic #2 (1.000): 0.104*"parameter" + 0.101*"argument" + 0.059*"function" + 0.037*"value" + 0.033*"method" + 0.025*"actual" + 0.025*"formal" + 0.021*"variable" + 0.018*"definition" + 0.016*"name"
INFO: topic diff=0.642187, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 34.00428006784946
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -0.8635296811560105
DEBUG: bound: at document #0
INFO: -5.129 per-word bound, 35.0 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.113*"function" + 0.092*"parameter" + 0.084*"argument" + 0.054*"value" + 0.032*"variable" + 0.030*"definition" + 0.025*"type" + 0.024*"call" + 0.022*"b" + 0.020*"default"
INFO: topic #1 (1.000): 0.069*"program" + 0.040*"function" + 0.038*"c++" + 0.036*"parameter" + 0.033*"address" + 0.032*"output" + 0.029*"argument" + 0.023*"object" + 0.023*"variable" + 0.022*"int"
INFO: topic #2 (1.000): 0.101*"parameter" + 0.099*"argument" + 0.060*"function" + 0.037*"value" + 0.030*"method" + 0.025*"actual" + 0.023*"formal" + 0.022*"variable" + 0.017*"definition" + 0.017*"name"
INFO: topic diff=0.541794, rho=0.408248
DEBUG: bound: at document #0
INFO: -5.315 per-word bound, 39.8 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.112*"function" + 0.091*"parameter" + 0.086*"argument" + 0.060*"value" + 0.041*"definition" + 0.033*"default" + 0.033*"b" + 0.031*"call" + 0.027*"variable" + 0.024*"name"
INFO: topic #1 (1.000): 0.067*"program" + 0.038*"function" + 0.037*"parameter" + 0.031*"c++" + 0.029*"argument" + 0.024*"c." + 0.021*"declaration" + 0.021*"address" + 0.021*"output" + 0.020*"actual"
INFO: topic #2 (1.000): 0.105*"parameter" + 0.101*"argument" + 0.059*"function" + 0.036*"value" + 0.033*"method" + 0.026*"actual" + 0.025*"formal" + 0.021*"variable" + 0.018*"definition" + 0.016*"term"
INFO: topic diff=0.386889, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 33.49994721543067
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -1.0648373644601463
DEBUG: bound: at document #0
INFO: -5.106 per-word bound, 34.4 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.113*"function" + 0.091*"parameter" + 0.084*"argument" + 0.055*"value" + 0.032*"variable" + 0.031*"definition" + 0.025*"type" + 0.025*"call" + 0.023*"b" + 0.022*"default"
INFO: topic #1 (1.000): 0.075*"program" + 0.040*"c++" + 0.036*"function" + 0.034*"output" + 0.034*"address" + 0.029*"parameter" + 0.024*"object" + 0.024*"int" + 0.023*"argument" + 0.023*"copy"
INFO: topic #2 (1.000): 0.102*"parameter" + 0.099*"argument" + 0.060*"function" + 0.037*"value" + 0.030*"method" + 0.025*"actual" + 0.023*"formal" + 0.022*"variable" + 0.017*"definition" + 0.017*"name"
INFO: topic diff=0.346248, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.265 per-word bound, 38.5 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.112*"function" + 0.090*"parameter" + 0.086*"argument" + 0.061*"value" + 0.041*"definition" + 0.033*"default" + 0.033*"b" + 0.031*"call" + 0.027*"variable" + 0.024*"name"
INFO: topic #1 (1.000): 0.072*"program" + 0.034*"c++" + 0.033*"function" + 0.029*"parameter" + 0.025*"c." + 0.023*"output" + 0.023*"address" + 0.023*"argument" + 0.022*"declaration" + 0.020*"actual"
INFO: topic #2 (1.000): 0.105*"parameter" + 0.101*"argument" + 0.060*"function" + 0.036*"value" + 0.032*"method" + 0.026*"actual" + 0.025*"formal" + 0.021*"variable" + 0.017*"definition" + 0.016*"term"
INFO: topic diff=0.262491, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 33.324469603057615
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -0.9923506643351111
DEBUG: bound: at document #0
INFO: -5.094 per-word bound, 34.2 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.113*"function" + 0.091*"parameter" + 0.084*"argument" + 0.056*"value" + 0.032*"variable" + 0.032*"definition" + 0.025*"call" + 0.025*"type" + 0.024*"b" + 0.023*"default"
INFO: topic #1 (1.000): 0.078*"program" + 0.041*"c++" + 0.034*"output" + 0.034*"address" + 0.033*"function" + 0.025*"object" + 0.024*"int" + 0.024*"parameter" + 0.023*"copy" + 0.023*"separate"
INFO: topic #2 (1.000): 0.102*"parameter" + 0.099*"argument" + 0.060*"function" + 0.037*"value" + 0.030*"method" + 0.025*"actual" + 0.023*"formal" + 0.022*"variable" + 0.017*"definition" + 0.017*"name"
INFO: topic diff=0.246217, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.243 per-word bound, 37.9 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.112*"function" + 0.090*"parameter" + 0.085*"argument" + 0.061*"value" + 0.041*"definition" + 0.033*"default" + 0.033*"b" + 0.031*"call" + 0.028*"variable" + 0.024*"name"
INFO: topic #1 (1.000): 0.075*"program" + 0.035*"c++" + 0.031*"function" + 0.025*"c." + 0.024*"output" + 0.024*"address" + 0.024*"parameter" + 0.023*"declaration" + 0.020*"actual" + 0.019*"argument"
INFO: topic #2 (1.000): 0.105*"parameter" + 0.102*"argument" + 0.060*"function" + 0.036*"value" + 0.032*"method" + 0.026*"actual" + 0.025*"formal" + 0.021*"variable" + 0.017*"definition" + 0.016*"term"
INFO: topic diff=0.212025, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 33.24146939720378
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -0.9368871548963328
DEBUG: bound: at document #0
INFO: -5.087 per-word bound, 34.0 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.113*"function" + 0.091*"parameter" + 0.084*"argument" + 0.056*"value" + 0.032*"definition" + 0.032*"variable" + 0.025*"call" + 0.024*"type" + 0.024*"b" + 0.023*"default"
INFO: topic #1 (1.000): 0.080*"program" + 0.041*"c++" + 0.035*"output" + 0.035*"address" + 0.030*"function" + 0.025*"object" + 0.025*"int" + 0.024*"copy" + 0.023*"separate" + 0.023*"equivalent"
INFO: topic #2 (1.000): 0.103*"parameter" + 0.100*"argument" + 0.061*"function" + 0.037*"value" + 0.030*"method" + 0.025*"actual" + 0.023*"formal" + 0.022*"variable" + 0.017*"definition" + 0.017*"name"
INFO: topic diff=0.199106, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.230 per-word bound, 37.5 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.112*"function" + 0.090*"parameter" + 0.085*"argument" + 0.060*"value" + 0.040*"definition" + 0.033*"default" + 0.032*"b" + 0.031*"call" + 0.028*"variable" + 0.024*"name"
INFO: topic #1 (1.000): 0.077*"program" + 0.036*"c++" + 0.029*"function" + 0.025*"c." + 0.025*"output" + 0.025*"address" + 0.023*"declaration" + 0.020*"parameter" + 0.020*"actual" + 0.018*"object"
INFO: topic #2 (1.000): 0.105*"parameter" + 0.102*"argument" + 0.060*"function" + 0.036*"value" + 0.032*"method" + 0.026*"actual" + 0.025*"formal" + 0.021*"variable" + 0.017*"definition" + 0.016*"term"
INFO: topic diff=0.186228, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 33.19076445632534
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -1.1521916411275357
DEBUG: bound: at document #0
INFO: -5.082 per-word bound, 33.9 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.113*"function" + 0.091*"parameter" + 0.084*"argument" + 0.056*"value" + 0.032*"definition" + 0.032*"variable" + 0.025*"call" + 0.024*"b" + 0.024*"type" + 0.023*"default"
INFO: topic #1 (1.000): 0.081*"program" + 0.042*"c++" + 0.035*"output" + 0.035*"address" + 0.029*"function" + 0.026*"object" + 0.025*"int" + 0.024*"copy" + 0.023*"separate" + 0.023*"equivalent"
INFO: topic #2 (1.000): 0.103*"parameter" + 0.100*"argument" + 0.061*"function" + 0.037*"value" + 0.030*"method" + 0.025*"actual" + 0.023*"formal" + 0.021*"variable" + 0.017*"definition" + 0.017*"name"
INFO: topic diff=0.176810, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.220 per-word bound, 37.3 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.112*"function" + 0.090*"parameter" + 0.085*"argument" + 0.060*"value" + 0.040*"definition" + 0.033*"default" + 0.032*"b" + 0.030*"call" + 0.028*"variable" + 0.024*"name"
INFO: topic #1 (1.000): 0.079*"program" + 0.036*"c++" + 0.027*"function" + 0.026*"output" + 0.026*"address" + 0.026*"c." + 0.023*"declaration" + 0.020*"actual" + 0.019*"object" + 0.018*"int"
INFO: topic #2 (1.000): 0.106*"parameter" + 0.102*"argument" + 0.060*"function" + 0.037*"value" + 0.032*"method" + 0.026*"actual" + 0.025*"formal" + 0.021*"variable" + 0.017*"definition" + 0.016*"term"
INFO: topic diff=0.170233, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 33.15598872565676
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -1.3918767385856627
DEBUG: bound: at document #0
INFO: -5.077 per-word bound, 33.8 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.113*"function" + 0.091*"parameter" + 0.084*"argument" + 0.057*"value" + 0.033*"definition" + 0.032*"variable" + 0.025*"call" + 0.025*"b" + 0.024*"type" + 0.024*"default"
INFO: topic #1 (1.000): 0.082*"program" + 0.042*"c++" + 0.035*"output" + 0.035*"address" + 0.027*"function" + 0.026*"object" + 0.025*"int" + 0.024*"copy" + 0.024*"separate" + 0.024*"equivalent"
INFO: topic #2 (1.000): 0.103*"parameter" + 0.100*"argument" + 0.061*"function" + 0.037*"value" + 0.030*"method" + 0.025*"actual" + 0.023*"formal" + 0.021*"variable" + 0.017*"definition" + 0.017*"name"
INFO: topic diff=0.162993, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.213 per-word bound, 37.1 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.112*"function" + 0.090*"parameter" + 0.086*"argument" + 0.060*"value" + 0.040*"definition" + 0.032*"default" + 0.032*"b" + 0.030*"call" + 0.028*"variable" + 0.024*"name"
INFO: topic #1 (1.000): 0.079*"program" + 0.037*"c++" + 0.026*"output" + 0.026*"address" + 0.026*"function" + 0.025*"c." + 0.023*"declaration" + 0.020*"object" + 0.019*"actual" + 0.019*"int"
INFO: topic #2 (1.000): 0.106*"parameter" + 0.102*"argument" + 0.060*"function" + 0.037*"value" + 0.032*"method" + 0.026*"actual" + 0.025*"formal" + 0.021*"variable" + 0.017*"definition" + 0.016*"term"
INFO: topic diff=0.158995, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 33.130705834004644
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -1.362059318654291
DEBUG: bound: at document #0
INFO: -5.074 per-word bound, 33.7 perplexity estimate based on a held-out corpus of 5 documents with 1198 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.113*"function" + 0.091*"parameter" + 0.085*"argument" + 0.057*"value" + 0.033*"definition" + 0.032*"variable" + 0.026*"call" + 0.025*"b" + 0.024*"default" + 0.024*"type"
INFO: topic #1 (1.000): 0.083*"program" + 0.042*"c++" + 0.035*"output" + 0.035*"address" + 0.026*"object" + 0.026*"function" + 0.025*"int" + 0.024*"copy" + 0.024*"separate" + 0.024*"equivalent"
INFO: topic #2 (1.000): 0.103*"parameter" + 0.100*"argument" + 0.061*"function" + 0.037*"value" + 0.030*"method" + 0.025*"actual" + 0.024*"formal" + 0.021*"variable" + 0.017*"definition" + 0.017*"name"
INFO: topic diff=0.152917, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.207 per-word bound, 36.9 perplexity estimate based on a held-out corpus of 5 documents with 371 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.112*"function" + 0.090*"parameter" + 0.086*"argument" + 0.060*"value" + 0.040*"definition" + 0.032*"default" + 0.032*"b" + 0.030*"call" + 0.028*"variable" + 0.024*"name"
INFO: topic #1 (1.000): 0.080*"program" + 0.037*"c++" + 0.027*"output" + 0.027*"address" + 0.025*"c." + 0.024*"function" + 0.023*"declaration" + 0.020*"object" + 0.019*"actual" + 0.019*"int"
INFO: topic #2 (1.000): 0.106*"parameter" + 0.102*"argument" + 0.061*"function" + 0.037*"value" + 0.032*"method" + 0.026*"actual" + 0.025*"formal" + 0.021*"variable" + 0.017*"definition" + 0.016*"term"
INFO: topic diff=0.150108, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 33.110993124686104
DEBUG: Setting topics to those of the model: LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.3466560479751815
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=397, num_topics=3, decay=0.5, chunksize=5> in 0.26s', 'datetime': '2023-04-18T14:16:10.549105', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/cos_threshold/7/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-18T14:16:10.549308', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/cos_threshold/7/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/7/model.state
DEBUG: {'uri': 'model/cos_threshold/7/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/cos_threshold/7/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['state', 'id2word', 'dispatcher'], 'datetime': '2023-04-18T14:16:10.552574', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/cos_threshold/7/model.expElogbeta.npy
INFO: not storing attribute state
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
DEBUG: {'uri': 'model/cos_threshold/7/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/7/model
INFO: topic #0 (1.000): 0.112*"function" + 0.090*"parameter" + 0.086*"argument" + 0.060*"value" + 0.040*"definition" + 0.032*"default" + 0.032*"b" + 0.030*"call" + 0.028*"variable" + 0.024*"name"
INFO: topic #1 (1.000): 0.080*"program" + 0.037*"c++" + 0.027*"output" + 0.027*"address" + 0.025*"c." + 0.024*"function" + 0.023*"declaration" + 0.020*"object" + 0.019*"actual" + 0.019*"int"
INFO: topic #2 (1.000): 0.106*"parameter" + 0.102*"argument" + 0.061*"function" + 0.037*"value" + 0.032*"method" + 0.026*"actual" + 0.025*"formal" + 0.021*"variable" + 0.017*"definition" + 0.016*"term"
INFO: Question Similarity: [0.03763139247894287, 0.27221667766571045, 0.7087501883506775, 0.17243289947509766, 0.05437415838241577, 0.6915662586688995, 0.12265866994857788, 0.10482025146484375, 0.03931593894958496, 0.07596439123153687]
INFO: 3176321: -0.2332442399279952
INFO: 3176327: -0.23716535395885183
INFO: 51054544: -0.2452983588550472
INFO: 51054593: -0.24659247347099356
INFO: 4905833: -0.254434061110625
INFO: 3176323: -0.2622356414674414
INFO: 69118816: -0.4009452602764186
INFO: 72422146: -0.7394273145690697
INFO: 1788926: -1.279579389780229
INFO: 70921285: -1.5442046298560905
INFO: 69273218: -1.5731086426956424
INFO: 47169062: -1.648318111861458
INFO: 67754922: -1.6687476007263307
INFO: Recommended Keywords
INFO: function score: -0.8396636
INFO: definition score: -0.8329592
INFO: define score: -0.82895494
INFO: difference score: -0.8241662
INFO: method score: -0.8169708
INFO: particular score: -0.8144054
INFO: instance score: -0.8099616
INFO: example score: -0.79913425
INFO: certain score: -0.76997435
INFO: simple score: -0.76978314
INFO: actual score: -0.7628675
INFO: specific score: -0.76028085
INFO: exact score: -0.7448368
INFO: absolute score: -0.74287534
INFO: correct score: -0.72896636
INFO: case score: -0.7280238
INFO: object score: -0.7195025
INFO: address score: -0.7177569
INFO: calculate score: -0.71570843
INFO: equate score: -0.7151673
INFO: value score: -0.71420354
INFO: variable score: -0.71395564
INFO: mean score: -0.7103433
INFO: term score: -0.7042565
INFO: variables score: -0.684666
INFO: expression score: -0.6768713
INFO: determine score: -0.67124677
INFO: usage score: -0.66833764
INFO: formal score: -0.66383624
INFO: standard score: -0.6627095
INFO: parameter score: -0.6623798
INFO: mechanism score: -0.6607688
INFO: type score: -0.65967983
INFO: need score: -0.6539266
INFO: real score: -0.65056956
INFO: input score: -0.6479234
INFO: arguments score: -0.6438404
INFO: sense score: -0.64326704
INFO: helpful score: -0.6421148
INFO: argument score: -0.64134055
INFO: default score: -0.6361788
INFO: reference score: -0.6301174
INFO: result score: -0.61926466
INFO: source score: -0.6173701
INFO: output score: -0.61731267
INFO: invoke score: -0.6150164
INFO: alternative score: -0.60717946
INFO: order score: -0.60515
INFO: structure score: -0.6039539
INFO: macro score: -0.59577006
INFO: information score: -0.5955755
INFO: process score: -0.5953723
INFO: different score: -0.5886097
INFO: notation score: -0.58488685
INFO: mutable score: -0.5845795
INFO: code score: -0.58428717
INFO: immutable score: -0.5836648
INFO: data score: -0.5835182
INFO: positional score: -0.58112806
INFO: response score: -0.5760764
INFO: common score: -0.5721528
INFO: confusing score: -0.57148755
INFO: key score: -0.56882113
INFO: instantiation score: -0.56838816
INFO: index score: -0.5671862
INFO: distinction score: -0.55779165
INFO: thought score: -0.55675364
INFO: equivalent score: -0.5538848
INFO: description score: -0.54419726
INFO: statement score: -0.5420312
INFO: integer score: -0.54091525
INFO: distinguishing score: -0.5406851
INFO: similar score: -0.5396555
INFO: keyword score: -0.5392307
INFO: datatype score: -0.5378076
INFO: view score: -0.5367551
INFO: natural score: -0.5336253
INFO: perspective score: -0.5331852
INFO: question score: -0.5323401
INFO: special score: -0.5186898
INFO: kind score: -0.5165062
INFO: human score: -0.51583284
INFO: datum score: -0.51522934
INFO: connection score: -0.5142891
INFO: parenthesis score: -0.51063555
INFO: easy score: -0.5062226
INFO: meaning score: -0.50480866
INFO: point score: -0.49874222
INFO: copy score: -0.49542466
INFO: b score: -0.4953333
INFO: placeholder score: -0.48905933
INFO: message score: -0.4834512
INFO: signature score: -0.47816896
INFO: program score: -0.47255775
INFO: f score: -0.47113317
INFO: practice score: -0.46624398
INFO: interchangeable score: -0.46320364
INFO: person score: -0.46300122
INFO: documentation score: -0.4624991
INFO: much score: -0.45673954
INFO: mnemonic score: -0.445071
INFO: c++ score: -0.43651512
INFO: invocation score: -0.43595594
INFO: body score: -0.43292138
INFO: compile score: -0.4262575
INFO: dilemma score: -0.42624235
INFO: identifier score: -0.42087966
INFO: int score: -0.42015964
INFO: thesis score: -0.41825777
INFO: arg score: -0.4170852
INFO: metaphor score: -0.4166912
INFO: dot score: -0.41643497
INFO: comma score: -0.4139608
INFO: func score: -0.40818307
INFO: foo score: -0.40630773
INFO: convention score: -0.4045461
INFO: able score: -0.40078163
INFO: number score: -0.39107928
INFO: wrong score: -0.39031345
INFO: runtime score: -0.38810742
INFO: optional score: -0.3826184
INFO: answer score: -0.38068524
INFO: computer score: -0.37897623
INFO: write score: -0.37752503
INFO: bit score: -0.3763827
INFO: caller score: -0.3748964
INFO: blank score: -0.3742828
INFO: string score: -0.3705357
INFO: machine score: -0.36423665
INFO: replace score: -0.362103
INFO: brain score: -0.36029923
INFO: conceptual score: -0.3599073
INFO: oracle score: -0.35939714
INFO: separate score: -0.35413003
INFO: programming score: -0.3513657
INFO: mind score: -0.35127568
INFO: well score: -0.34656778
INFO: let score: -0.34575287
INFO: various score: -0.34475064
INFO: x score: -0.33814532
INFO: mathematics score: -0.3381271
INFO: look score: -0.3373515
INFO: declare score: -0.3337443
INFO: thing score: -0.3337227
INFO: fill score: -0.33340698
INFO: plane score: -0.3329334
INFO: issue score: -0.33155185
INFO: declaration score: -0.32774583
INFO: language score: -0.3276111
INFO: call score: -0.3272753
INFO: thematic score: -0.3272001
INFO: c score: -0.32208318
INFO: constructor score: -0.31899288
INFO: info score: -0.31477877
INFO: time score: -0.3123871
INFO: synonyms score: -0.30828246
INFO: role score: -0.29810825
INFO: text score: -0.2916152
INFO: programmer score: -0.2874323
INFO: previous score: -0.2821332
INFO: visible score: -0.2818383
INFO: plug score: -0.27612492
INFO: remember score: -0.27394223
INFO: myname score: -0.272525
INFO: position score: -0.2691217
INFO: min score: -0.26461998
INFO: install score: -0.26238772
INFO: inside score: -0.25790375
INFO: toolkit score: -0.25046602
INFO: = score: -0.24175082
INFO: name score: -0.23099102
INFO: main score: -0.23077106
INFO: big score: -0.2297223
INFO: prototype score: -0.22690311
INFO: pass score: -0.2216078
INFO: opposite score: -0.218485
INFO: faq score: -0.21494135
INFO: sqrt score: -0.21009003
INFO: format score: -0.2097075
INFO: list score: -0.2077177
INFO: java score: -0.20319262
INFO: stop score: -0.19585057
INFO: concrete score: -0.19042538
INFO: tutorial score: -0.18874915
INFO: socket score: -0.18652461
INFO: part score: -0.18465579
INFO: nice score: -0.17751604
INFO: lingo score: -0.17117232
INFO: egg score: -0.16465957
INFO: site score: -0.16075875
INFO: run score: -0.14995877
INFO: exam score: -0.14721234
INFO: store score: -0.14456275
INFO: bar score: -0.12555139
INFO: place score: -0.12244761
INFO: wall score: -0.117941655
INFO: book score: -0.11303064
INFO: course score: -0.104663655
INFO: second score: -0.09968516
INFO: money score: -0.09613666
INFO: people score: -0.09080088
INFO: def score: -0.08317717
INFO: wikipedia score: -0.08164396
INFO: unleaded score: -0.07516359
INFO: head score: -0.063411765
INFO: day score: -0.059266545
INFO: author score: -0.038650688
INFO: pee score: -0.037614077
INFO: community score: -0.03411907
INFO: happy score: -0.027314588
INFO: monkey score: -0.020405004
INFO: petrol score: -0.016889876
INFO: next score: -0.013324805
INFO: printname score: -0.0
INFO: console.log(name score: -0.0
INFO: printname("peter score: -0.0
INFO: mcsd score: -0.0
INFO: cerfification score: -0.0
INFO: basics.both score: -0.0
INFO: f(x score: -0.0
INFO: f(3 score: -0.0
INFO: alabahari score: -0.0
INFO: p. score: -0.0
INFO: savitch score: -0.0
INFO: http://en.wikipedia.org/wiki/parameter_(computer_science)#parameters_and_argument score: -0.0
INFO: kwargs score: -0.0
INFO: somevar score: -0.0
INFO: isinstance score: -0.0
INFO: c. score: -0.0
INFO: fun(arg score: -0.0
INFO: print(arg score: -0.0
INFO: n’t score: -0.0
INFO: airplane score: 0.002246866
INFO: italian score: 0.012141016
INFO: professor score: 0.01977154
INFO: sausage score: 0.022788309
INFO: unicorn score: 0.04051467
INFO: car score: 0.042730518
INFO: seat score: 0.053741496
INFO: airline score: 0.055290613
INFO: walter score: 0.056037206
INFO: breakfast score: 0.06116376
INFO: joseph score: 0.072418354
INFO: passenger score: 0.08805203
INFO: russian score: 0.10091322
INFO: peter score: 0.1017565
INFO: university score: 0.12738648
INFO: ============================================================
INFO: --------------------
INFO: How do I write a function with output parameters (call by reference)?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<494 unique tokens: ['=', '@andrea', '@blair', '@david', '@mark']...> from 9 documents (total 1884 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<494 unique tokens: ['=', '@andrea', '@blair', '@david', '@mark']...> from 9 documents (total 1884 corpus positions)", 'datetime': '2023-04-18T14:16:13.513093', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 9 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.278 per-word bound, 155.2 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 0, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.047*"reference" + 0.045*"object" + 0.044*"value" + 0.041*"function" + 0.022*"variable" + 0.017*"new" + 0.016*"parameter" + 0.014*"list" + 0.013*"argument" + 0.012*"type"
INFO: topic #1 (1.000): 0.039*"object" + 0.038*"function" + 0.034*"reference" + 0.033*"value" + 0.029*"return" + 0.016*"variable" + 0.016*"code" + 0.013*"way" + 0.012*"parameter" + 0.012*"list"
INFO: topic #2 (1.000): 0.058*"object" + 0.056*"reference" + 0.042*"value" + 0.036*"function" + 0.035*"variable" + 0.017*"parameter" + 0.016*"change" + 0.016*"name" + 0.014*"new" + 0.014*"list"
INFO: topic diff=2.429857, rho=1.000000
DEBUG: bound: at document #0
INFO: -11.471 per-word bound, 2838.2 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 0, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.049*"function" + 0.040*"value" + 0.039*"object" + 0.034*"reference" + 0.027*"variable" + 0.016*"argument" + 0.014*"new" + 0.014*"output" + 0.014*"parameter" + 0.010*"way"
INFO: topic #1 (1.000): 0.054*"function" + 0.044*"return" + 0.033*"value" + 0.032*"object" + 0.022*"output" + 0.022*"reference" + 0.018*"variable" + 0.015*"code" + 0.013*"argument" + 0.013*"way"
INFO: topic #2 (1.000): 0.057*"object" + 0.055*"function" + 0.048*"value" + 0.044*"variable" + 0.044*"reference" + 0.014*"parameter" + 0.014*"new" + 0.014*"change" + 0.013*"name" + 0.013*"argument"
INFO: topic diff=1.813980, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 64.64424650596614
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.4854104840751625
DEBUG: bound: at document #0
INFO: -5.827 per-word bound, 56.8 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 1, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.041*"function" + 0.034*"value" + 0.032*"object" + 0.029*"reference" + 0.022*"variable" + 0.013*"argument" + 0.013*"parameter" + 0.012*"output" + 0.012*"new" + 0.009*"list"
INFO: topic #1 (1.000): 0.043*"function" + 0.042*"return" + 0.036*"value" + 0.031*"reference" + 0.029*"object" + 0.020*"code" + 0.020*"output" + 0.015*"tuple" + 0.014*"mat" + 0.014*"array"
INFO: topic #2 (1.000): 0.058*"object" + 0.052*"reference" + 0.044*"value" + 0.041*"function" + 0.038*"variable" + 0.016*"parameter" + 0.015*"new" + 0.015*"name" + 0.015*"change" + 0.013*"list"
INFO: topic diff=1.244068, rho=0.512989
DEBUG: bound: at document #0
INFO: -8.569 per-word bound, 379.8 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 1, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.046*"function" + 0.044*"variable" + 0.040*"command" + 0.032*"line" + 0.026*"output" + 0.024*"script" + 0.023*"input" + 0.019*"argument" + 0.017*"value" + 0.016*"object"
INFO: topic #1 (1.000): 0.061*"function" + 0.050*"return" + 0.042*"value" + 0.031*"object" + 0.026*"arg" + 0.021*"reference" + 0.020*"output" + 0.018*"code" + 0.015*"first" + 0.014*"pass"
INFO: topic #2 (1.000): 0.057*"object" + 0.049*"function" + 0.047*"value" + 0.046*"reference" + 0.041*"variable" + 0.016*"new" + 0.015*"parameter" + 0.014*"name" + 0.014*"change" + 0.012*"instance"
INFO: topic diff=1.010550, rho=0.512989
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 54.62616601674538
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -2.487126240597616
DEBUG: bound: at document #0
INFO: -5.675 per-word bound, 51.1 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 2, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.037*"function" + 0.035*"variable" + 0.031*"command" + 0.025*"line" + 0.023*"output" + 0.021*"input" + 0.019*"script" + 0.016*"argument" + 0.014*"value" + 0.013*"object"
INFO: topic #1 (1.000): 0.048*"function" + 0.044*"return" + 0.040*"value" + 0.030*"reference" + 0.029*"object" + 0.021*"code" + 0.019*"output" + 0.014*"tuple" + 0.014*"mat" + 0.014*"array"
INFO: topic #2 (1.000): 0.058*"object" + 0.052*"reference" + 0.043*"value" + 0.041*"function" + 0.037*"variable" + 0.016*"parameter" + 0.016*"new" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: topic diff=0.683523, rho=0.456435
DEBUG: bound: at document #0
INFO: -7.273 per-word bound, 154.6 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 2, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.059*"variable" + 0.051*"command" + 0.045*"function" + 0.041*"line" + 0.033*"output" + 0.032*"input" + 0.031*"script" + 0.021*"argument" + 0.019*"way" + 0.011*"well"
INFO: topic #1 (1.000): 0.065*"function" + 0.050*"return" + 0.047*"value" + 0.033*"object" + 0.030*"arg" + 0.021*"reference" + 0.019*"code" + 0.019*"output" + 0.016*"case" + 0.016*"test_obj"
INFO: topic #2 (1.000): 0.058*"object" + 0.048*"reference" + 0.046*"function" + 0.046*"value" + 0.040*"variable" + 0.016*"new" + 0.015*"parameter" + 0.014*"name" + 0.014*"change" + 0.013*"instance"
INFO: topic diff=0.546041, rho=0.456435
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 52.76438405987801
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -1.9855321402053259
DEBUG: bound: at document #0
INFO: -5.633 per-word bound, 49.6 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 3, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.047*"variable" + 0.041*"command" + 0.036*"function" + 0.033*"line" + 0.031*"input" + 0.031*"output" + 0.025*"script" + 0.018*"argument" + 0.016*"way" + 0.010*"parameter"
INFO: topic #1 (1.000): 0.052*"function" + 0.045*"return" + 0.043*"value" + 0.031*"object" + 0.030*"reference" + 0.021*"code" + 0.018*"output" + 0.014*"arg" + 0.014*"pass" + 0.014*"tuple"
INFO: topic #2 (1.000): 0.058*"object" + 0.052*"reference" + 0.043*"value" + 0.040*"function" + 0.037*"variable" + 0.016*"new" + 0.016*"parameter" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: topic diff=0.387917, rho=0.415227
DEBUG: bound: at document #0
INFO: -7.066 per-word bound, 134.0 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 3, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.064*"variable" + 0.054*"command" + 0.045*"function" + 0.043*"line" + 0.036*"output" + 0.036*"input" + 0.033*"script" + 0.022*"argument" + 0.021*"way" + 0.013*"well"
INFO: topic #1 (1.000): 0.068*"function" + 0.050*"return" + 0.050*"value" + 0.034*"object" + 0.031*"arg" + 0.022*"reference" + 0.019*"code" + 0.018*"output" + 0.017*"case" + 0.016*"test_obj"
INFO: topic #2 (1.000): 0.058*"object" + 0.049*"reference" + 0.045*"value" + 0.044*"function" + 0.039*"variable" + 0.016*"new" + 0.015*"parameter" + 0.014*"name" + 0.014*"change" + 0.013*"instance"
INFO: topic diff=0.366481, rho=0.415227
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 52.21147930598364
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -1.9845430187784778
DEBUG: bound: at document #0
INFO: -5.616 per-word bound, 49.0 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 4, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.052*"variable" + 0.043*"command" + 0.037*"function" + 0.035*"input" + 0.035*"line" + 0.035*"output" + 0.026*"script" + 0.018*"argument" + 0.018*"way" + 0.010*"parameter"
INFO: topic #1 (1.000): 0.054*"function" + 0.045*"return" + 0.044*"value" + 0.032*"object" + 0.029*"reference" + 0.021*"code" + 0.018*"output" + 0.016*"arg" + 0.014*"pass" + 0.014*"tuple"
INFO: topic #2 (1.000): 0.058*"object" + 0.052*"reference" + 0.043*"value" + 0.040*"function" + 0.037*"variable" + 0.016*"new" + 0.016*"parameter" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: topic diff=0.288917, rho=0.383482
DEBUG: bound: at document #0
INFO: -7.001 per-word bound, 128.1 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 4, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.066*"variable" + 0.054*"command" + 0.044*"function" + 0.044*"line" + 0.038*"output" + 0.037*"input" + 0.033*"script" + 0.022*"argument" + 0.022*"way" + 0.013*"well"
INFO: topic #1 (1.000): 0.069*"function" + 0.051*"value" + 0.049*"return" + 0.035*"object" + 0.030*"arg" + 0.023*"reference" + 0.019*"code" + 0.018*"output" + 0.017*"case" + 0.016*"pass"
INFO: topic #2 (1.000): 0.058*"object" + 0.049*"reference" + 0.045*"value" + 0.043*"function" + 0.039*"variable" + 0.017*"new" + 0.015*"parameter" + 0.015*"name" + 0.014*"change" + 0.013*"instance"
INFO: topic diff=0.286281, rho=0.383482
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 51.983246605104135
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -1.7296664095809835
DEBUG: bound: at document #0
INFO: -5.607 per-word bound, 48.7 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 5, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.055*"variable" + 0.044*"command" + 0.037*"function" + 0.037*"output" + 0.037*"input" + 0.036*"line" + 0.027*"script" + 0.019*"argument" + 0.019*"way" + 0.011*"well"
INFO: topic #1 (1.000): 0.055*"function" + 0.045*"value" + 0.045*"return" + 0.032*"object" + 0.029*"reference" + 0.020*"code" + 0.018*"output" + 0.017*"arg" + 0.015*"pass" + 0.013*"case"
INFO: topic #2 (1.000): 0.058*"object" + 0.052*"reference" + 0.043*"value" + 0.040*"function" + 0.037*"variable" + 0.016*"new" + 0.016*"parameter" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: topic diff=0.250931, rho=0.358057
DEBUG: bound: at document #0
INFO: -6.971 per-word bound, 125.5 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 5, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.066*"variable" + 0.054*"command" + 0.044*"function" + 0.043*"line" + 0.039*"output" + 0.038*"input" + 0.033*"script" + 0.022*"argument" + 0.022*"way" + 0.014*"well"
INFO: topic #1 (1.000): 0.069*"function" + 0.051*"value" + 0.049*"return" + 0.035*"object" + 0.029*"arg" + 0.023*"reference" + 0.019*"code" + 0.018*"output" + 0.017*"case" + 0.016*"pass"
INFO: topic #2 (1.000): 0.058*"object" + 0.049*"reference" + 0.044*"value" + 0.043*"function" + 0.039*"variable" + 0.017*"new" + 0.015*"parameter" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: topic diff=0.248668, rho=0.358057
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 51.86013896705231
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -1.7287939426502177
DEBUG: bound: at document #0
INFO: -5.600 per-word bound, 48.5 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 6, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.056*"variable" + 0.045*"command" + 0.038*"output" + 0.038*"function" + 0.037*"input" + 0.036*"line" + 0.027*"script" + 0.019*"argument" + 0.019*"way" + 0.012*"well"
INFO: topic #1 (1.000): 0.056*"function" + 0.046*"value" + 0.045*"return" + 0.033*"object" + 0.029*"reference" + 0.020*"code" + 0.018*"output" + 0.017*"arg" + 0.015*"pass" + 0.014*"case"
INFO: topic #2 (1.000): 0.058*"object" + 0.052*"reference" + 0.043*"value" + 0.040*"function" + 0.037*"variable" + 0.016*"new" + 0.016*"parameter" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: topic diff=0.229067, rho=0.337100
DEBUG: bound: at document #0
INFO: -6.954 per-word bound, 124.0 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 6, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.067*"variable" + 0.054*"command" + 0.044*"function" + 0.043*"line" + 0.039*"output" + 0.038*"input" + 0.032*"script" + 0.022*"argument" + 0.022*"way" + 0.014*"well"
INFO: topic #1 (1.000): 0.069*"function" + 0.051*"value" + 0.049*"return" + 0.035*"object" + 0.029*"arg" + 0.023*"reference" + 0.019*"code" + 0.017*"output" + 0.017*"case" + 0.016*"pass"
INFO: topic #2 (1.000): 0.058*"object" + 0.049*"reference" + 0.044*"value" + 0.042*"function" + 0.039*"variable" + 0.017*"new" + 0.015*"parameter" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: topic diff=0.225289, rho=0.337100
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 51.78091382077435
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -1.7287939426502177
DEBUG: bound: at document #0
INFO: -5.596 per-word bound, 48.4 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 7, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.057*"variable" + 0.045*"command" + 0.039*"output" + 0.038*"function" + 0.037*"input" + 0.036*"line" + 0.027*"script" + 0.019*"argument" + 0.019*"way" + 0.012*"well"
INFO: topic #1 (1.000): 0.057*"function" + 0.047*"value" + 0.045*"return" + 0.033*"object" + 0.029*"reference" + 0.020*"code" + 0.018*"output" + 0.017*"arg" + 0.015*"pass" + 0.014*"case"
INFO: topic #2 (1.000): 0.058*"object" + 0.052*"reference" + 0.043*"value" + 0.040*"function" + 0.037*"variable" + 0.016*"new" + 0.016*"parameter" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: topic diff=0.213708, rho=0.319438
DEBUG: bound: at document #0
INFO: -6.941 per-word bound, 122.9 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 7, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.067*"variable" + 0.053*"command" + 0.045*"function" + 0.043*"line" + 0.040*"output" + 0.038*"input" + 0.032*"script" + 0.022*"argument" + 0.022*"way" + 0.015*"well"
INFO: topic #1 (1.000): 0.069*"function" + 0.052*"value" + 0.049*"return" + 0.035*"object" + 0.028*"arg" + 0.024*"reference" + 0.019*"code" + 0.017*"output" + 0.017*"case" + 0.016*"pass"
INFO: topic #2 (1.000): 0.058*"object" + 0.050*"reference" + 0.044*"value" + 0.042*"function" + 0.039*"variable" + 0.017*"new" + 0.015*"parameter" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: topic diff=0.208578, rho=0.319438
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 51.72339055634947
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -1.7287939426502177
DEBUG: bound: at document #0
INFO: -5.592 per-word bound, 48.2 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 8, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.057*"variable" + 0.045*"command" + 0.039*"output" + 0.039*"function" + 0.037*"input" + 0.036*"line" + 0.027*"script" + 0.019*"argument" + 0.019*"way" + 0.013*"well"
INFO: topic #1 (1.000): 0.058*"function" + 0.047*"value" + 0.045*"return" + 0.033*"object" + 0.029*"reference" + 0.020*"code" + 0.018*"output" + 0.017*"arg" + 0.015*"pass" + 0.014*"case"
INFO: topic #2 (1.000): 0.058*"object" + 0.052*"reference" + 0.043*"value" + 0.040*"function" + 0.037*"variable" + 0.016*"new" + 0.016*"parameter" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: topic diff=0.200773, rho=0.304290
DEBUG: bound: at document #0
INFO: -6.931 per-word bound, 122.0 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 8, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.066*"variable" + 0.053*"command" + 0.045*"function" + 0.042*"line" + 0.040*"output" + 0.038*"input" + 0.032*"script" + 0.022*"argument" + 0.022*"way" + 0.016*"well"
INFO: topic #1 (1.000): 0.069*"function" + 0.052*"value" + 0.048*"return" + 0.036*"object" + 0.028*"arg" + 0.024*"reference" + 0.019*"code" + 0.017*"output" + 0.017*"case" + 0.016*"pass"
INFO: topic #2 (1.000): 0.058*"object" + 0.050*"reference" + 0.044*"value" + 0.042*"function" + 0.038*"variable" + 0.017*"new" + 0.015*"parameter" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: topic diff=0.195722, rho=0.304290
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 51.6784034029041
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -1.7287939426502177
DEBUG: bound: at document #0
INFO: -5.589 per-word bound, 48.1 perplexity estimate based on a held-out corpus of 5 documents with 1685 words
INFO: PROGRESS: pass 9, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.058*"variable" + 0.045*"command" + 0.040*"output" + 0.039*"function" + 0.037*"input" + 0.036*"line" + 0.028*"script" + 0.020*"argument" + 0.019*"way" + 0.014*"well"
INFO: topic #1 (1.000): 0.058*"function" + 0.047*"value" + 0.045*"return" + 0.033*"object" + 0.029*"reference" + 0.020*"code" + 0.018*"arg" + 0.017*"output" + 0.015*"pass" + 0.014*"case"
INFO: topic #2 (1.000): 0.058*"object" + 0.052*"reference" + 0.043*"value" + 0.040*"function" + 0.037*"variable" + 0.016*"new" + 0.016*"parameter" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: topic diff=0.190050, rho=0.291111
DEBUG: bound: at document #0
INFO: -6.923 per-word bound, 121.3 perplexity estimate based on a held-out corpus of 4 documents with 199 words
INFO: PROGRESS: pass 9, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.066*"variable" + 0.052*"command" + 0.045*"function" + 0.042*"line" + 0.041*"output" + 0.037*"input" + 0.032*"script" + 0.022*"argument" + 0.022*"way" + 0.017*"well"
INFO: topic #1 (1.000): 0.069*"function" + 0.052*"value" + 0.048*"return" + 0.036*"object" + 0.028*"arg" + 0.024*"reference" + 0.019*"code" + 0.017*"output" + 0.017*"case" + 0.016*"pass"
INFO: topic #2 (1.000): 0.058*"object" + 0.050*"reference" + 0.044*"value" + 0.042*"function" + 0.038*"variable" + 0.017*"new" + 0.015*"parameter" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: topic diff=0.185447, rho=0.291111
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 51.64159971901463
DEBUG: Setting topics to those of the model: LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.7287939426502177
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=494, num_topics=3, decay=0.5, chunksize=5> in 0.23s', 'datetime': '2023-04-18T14:16:13.741077', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/cos_threshold/8/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-18T14:16:13.741233', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/cos_threshold/8/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/8/model.state
DEBUG: {'uri': 'model/cos_threshold/8/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/cos_threshold/8/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['state', 'id2word', 'dispatcher'], 'datetime': '2023-04-18T14:16:13.744839', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/cos_threshold/8/model.expElogbeta.npy
INFO: not storing attribute state
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
DEBUG: {'uri': 'model/cos_threshold/8/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/8/model
INFO: topic #0 (1.000): 0.066*"variable" + 0.052*"command" + 0.045*"function" + 0.042*"line" + 0.041*"output" + 0.037*"input" + 0.032*"script" + 0.022*"argument" + 0.022*"way" + 0.017*"well"
INFO: topic #1 (1.000): 0.069*"function" + 0.052*"value" + 0.048*"return" + 0.036*"object" + 0.028*"arg" + 0.024*"reference" + 0.019*"code" + 0.017*"output" + 0.017*"case" + 0.016*"pass"
INFO: topic #2 (1.000): 0.058*"object" + 0.050*"reference" + 0.044*"value" + 0.042*"function" + 0.038*"variable" + 0.017*"new" + 0.015*"parameter" + 0.015*"name" + 0.014*"change" + 0.013*"list"
INFO: Question Similarity: [0.07703560590744019, 0.14776098728179932, 0.11576366424560547, 0.06378495693206787, 0.06334757804870605, 0.06596022844314575, 0.12983381748199463, 0.16314393281936646, 0.16417986154556274, 0.18532365560531616]
INFO: 69913926: -0.24167753833228933
INFO: 69913928: -0.24772318751693595
INFO: 53929523: -0.28083787711114744
INFO: 53929719: -0.28274663976736075
INFO: 4702272: -0.31598737543522415
INFO: 4702442: -0.32340149864737255
INFO: 4702267: -0.3240672904978769
INFO: 4702280: -0.3253955930174135
INFO: 4702301: -0.3279549923761422
INFO: 74505976: -0.3283100707886534
INFO: 49183847: -0.36969845837250176
INFO: 49184305: -0.37367188985310934
INFO: 47050775: -0.4232231268865014
INFO: Recommended Keywords
INFO: example score: -0.81800705
INFO: instance score: -0.80224127
INFO: possible score: -0.7923169
INFO: change score: -0.7824992
INFO: function score: -0.76839805
INFO: actual score: -0.76790625
INFO: assign score: -0.7673463
INFO: corresponding score: -0.7551926
INFO: element score: -0.75034636
INFO: attribute score: -0.73618203
INFO: input score: -0.73025274
INFO: context score: -0.72863454
INFO: reference score: -0.7258028
INFO: correct score: -0.7245424
INFO: definition score: -0.7227156
INFO: simple score: -0.719615
INFO: effect score: -0.7026603
INFO: object score: -0.6992274
INFO: type score: -0.69828653
INFO: basic score: -0.69729954
INFO: component score: -0.692836
INFO: variable score: -0.68946534
INFO: normal score: -0.6802263
INFO: similar score: -0.6797476
INFO: method score: -0.6781858
INFO: process score: -0.67697996
INFO: different score: -0.67668337
INFO: useful score: -0.67154896
INFO: value score: -0.667025
INFO: arbitrary score: -0.6633082
INFO: model score: -0.6595504
INFO: complicated score: -0.65587896
INFO: concept score: -0.65514123
INFO: real score: -0.6534506
INFO: explicit score: -0.6482105
INFO: true score: -0.6475461
INFO: problem score: -0.63864714
INFO: case score: -0.63404095
INFO: need score: -0.63320315
INFO: solution score: -0.63253176
INFO: fact score: -0.6323531
INFO: key score: -0.6320756
INFO: structure score: -0.6317764
INFO: incorrect score: -0.63033074
INFO: result score: -0.629594
INFO: contexts score: -0.62533665
INFO: inputs score: -0.62275034
INFO: calculation score: -0.6168989
INFO: internal score: -0.6162131
INFO: restriction score: -0.61285347
INFO: error score: -0.6109054
INFO: approach score: -0.6089386
INFO: parameter score: -0.60529685
INFO: item score: -0.6044153
INFO: multiple score: -0.6027039
INFO: scheme score: -0.60118586
INFO: explanation score: -0.5994144
INFO: clear score: -0.5937409
INFO: create score: -0.59281665
INFO: target score: -0.5889092
INFO: mutable score: -0.5835728
INFO: condition score: -0.5820888
INFO: code score: -0.5794719
INFO: requirement score: -0.57890326
INFO: output score: -0.577735
INFO: information score: -0.57308155
INFO: sense score: -0.56409776
INFO: significant score: -0.56320506
INFO: scope score: -0.5617117
INFO: other score: -0.56042606
INFO: point score: -0.55667275
INFO: separate score: -0.5527805
INFO: diagram score: -0.55271626
INFO: additional score: -0.551044
INFO: kind score: -0.5496474
INFO: default score: -0.5484981
INFO: content score: -0.5469282
INFO: tool score: -0.54680157
INFO: reliable score: -0.54670787
INFO: careful score: -0.5445768
INFO: address score: -0.5445652
INFO: immutable score: -0.5368976
INFO: data score: -0.5293901
INFO: operator score: -0.5272598
INFO: well score: -0.5231964
INFO: original score: -0.52317053
INFO: memory score: -0.5199673
INFO: easy score: -0.51905626
INFO: test score: -0.5182979
INFO: handle score: -0.51796764
INFO: update score: -0.51601064
INFO: word score: -0.5102137
INFO: understand score: -0.5074518
INFO: idea score: -0.50723267
INFO: way score: -0.5053987
INFO: prefer score: -0.5050739
INFO: accept score: -0.49701467
INFO: look score: -0.49216583
INFO: general score: -0.48957494
INFO: one score: -0.48881146
INFO: simulate score: -0.48702997
INFO: implement score: -0.48665503
INFO: copy score: -0.485635
INFO: common score: -0.4846036
INFO: lookup score: -0.48353848
INFO: behavior score: -0.48281214
INFO: question score: -0.48223093
INFO: inconvenient score: -0.48175886
INFO: execution score: -0.48087505
INFO: generator score: -0.4797343
INFO: quite score: -0.47792217
INFO: option score: -0.47569972
INFO: self score: -0.47392508
INFO: thread score: -0.47390437
INFO: tuple score: -0.47179538
INFO: body score: -0.47021374
INFO: integer score: -0.47007617
INFO: name score: -0.46645766
INFO: database score: -0.46334073
INFO: statement score: -0.463004
INFO: argument score: -0.46269593
INFO: addition score: -0.46224588
INFO: new score: -0.4617863
INFO: traditional score: -0.4602345
INFO: many score: -0.45523947
INFO: array score: -0.45462435
INFO: boolean score: -0.45341372
INFO: documentation score: -0.44897366
INFO: hand score: -0.44773653
INFO: arg score: -0.4464225
INFO: single score: -0.44492817
INFO: hold score: -0.4433224
INFO: entry score: -0.4408429
INFO: insight score: -0.44043553
INFO: empty score: -0.43919286
INFO: long score: -0.43778715
INFO: screen score: -0.43663585
INFO: execute score: -0.43642166
INFO: functionality score: -0.43363908
INFO: hint score: -0.43305188
INFO: little score: -0.4323442
INFO: able score: -0.43054006
INFO: design score: -0.42774174
INFO: visible score: -0.42589825
INFO: line score: -0.42580214
INFO: call score: -0.4239305
INFO: treat score: -0.42314965
INFO: list score: -0.4210121
INFO: date score: -0.41807535
INFO: topic score: -0.41776928
INFO: field score: -0.41079515
INFO: namespace score: -0.40960866
INFO: time score: -0.40801707
INFO: practice score: -0.40755597
INFO: suggestion score: -0.40345103
INFO: identifier score: -0.40232533
INFO: interesting score: -0.4003943
INFO: n score: -0.39818424
INFO: dummy score: -0.39769357
INFO: pointer score: -0.3959589
INFO: subclass score: -0.39526218
INFO: bind score: -0.39288625
INFO: section score: -0.38860902
INFO: global score: -0.38860705
INFO: inside score: -0.38643274
INFO: reading score: -0.38299266
INFO: issue score: -0.38017237
INFO: workaround score: -0.37975508
INFO: property score: -0.37868264
INFO: good score: -0.37745842
INFO: multi score: -0.37624052
INFO: end score: -0.37096903
INFO: safe score: -0.36830375
INFO: assignment score: -0.36713862
INFO: location score: -0.36638921
INFO: class score: -0.36317816
INFO: state score: -0.35963556
INFO: access score: -0.35591555
INFO: answer score: -0.35558808
INFO: string score: -0.35525143
INFO: script score: -0.3522568
INFO: mention score: -0.34804353
INFO: naive score: -0.3443445
INFO: outside score: -0.34161264
INFO: language score: -0.34072724
INFO: work score: -0.34034875
INFO: right score: -0.339021
INFO: situation score: -0.3363145
INFO: wrapper score: -0.33232552
INFO: return score: -0.3316936
INFO: sure score: -0.33136904
INFO: post score: -0.330138
INFO: arrow score: -0.33001864
INFO: thing score: -0.32416838
INFO: mind score: -0.3238827
INFO: b score: -0.3235402
INFO: dubious score: -0.32333037
INFO: print score: -0.3219365
INFO: c score: -0.32191455
INFO: const score: -0.32084128
INFO: wrap score: -0.32058403
INFO: = score: -0.32030594
INFO: programming score: -0.31706858
INFO: outer score: -0.31311324
INFO: dictionary score: -0.3105806
INFO: local score: -0.30924508
INFO: x score: -0.30726737
INFO: perl score: -0.30178863
INFO: javascript score: -0.30127898
INFO: figure score: -0.29546008
INFO: numpy score: -0.2942178
INFO: window score: -0.29372248
INFO: convincing score: -0.2925133
INFO: num score: -0.2910568
INFO: edit score: -0.28561223
INFO: command score: -0.28371248
INFO: caller score: -0.27991706
INFO: show score: -0.27837417
INFO: collection score: -0.26282927
INFO: dict score: -0.26238552
INFO: side score: -0.26169878
INFO: program score: -0.2606083
INFO: container score: -0.25977945
INFO: pass score: -0.257685
INFO: mutation score: -0.25590864
INFO: java score: -0.2558329
INFO: hack score: -0.2546066
INFO: handy score: -0.2531231
INFO: lot score: -0.25228325
INFO: place score: -0.25045678
INFO: opinion score: -0.25002286
INFO: green score: -0.24926625
INFO: great score: -0.23989607
INFO: calling score: -0.23712945
INFO: int score: -0.22153161
INFO: faq score: -0.20967251
INFO: strange score: -0.2034062
INFO: worth score: -0.19889294
INFO: dll score: -0.19608828
INFO: first score: -0.19416052
INFO: store score: -0.18956366
INFO: hope score: -0.18582413
INFO: snippet score: -0.18494402
INFO: elegant score: -0.18231332
INFO: c++ score: -0.16724576
INFO: yellow score: -0.16086993
INFO: people score: -0.15228193
INFO: str score: -0.15194097
INFO: second score: -0.1480355
INFO: yesterday score: -0.14106986
INFO: funny score: -0.12363679
INFO: api score: -0.115391515
INFO: mat score: -0.11223181
INFO: stuff score: -0.10929342
INFO: publishing score: -0.07629867
INFO: year score: -0.069617
INFO: member score: -0.06447862
INFO: var score: -0.060791686
INFO: ugly score: -0.05212388
INFO: fun score: -0.04714815
INFO: trick score: -0.045524407
INFO: os score: -0.021320764
INFO: dataclasse score: -0.0
INFO: ctype score: -0.0
INFO: pythonic score: -0.0
INFO: fortran score: -0.0
INFO: fredrik score: -0.0
INFO: lundh score: -0.0
INFO: @refproperty score: -0.0
INFO: self._myvar score: -0.0
INFO: setattr score: -0.0
INFO: functools.partial score: -0.0
INFO: settatr score: -0.0
INFO: self.variable score: -0.0
INFO: outer_list score: -0.0
INFO: the_list score: -0.0
INFO: http://docs.python.org/3/faq/programming.html#what-are-the-rules-for-local-and-global-variables-in-python score: -0.0
INFO: change_me score: -0.0
INFO: blair score: -0.0
INFO: conrad score: -0.0
INFO: cournapeau score: -0.0
INFO: my_fun score: -0.0
INFO: out_arr score: -0.0
INFO: tark score: -0.0
INFO: tolonen score: -0.0
INFO: pywin32 score: -0.0
INFO: readbinfile(filename score: -0.0
INFO: wantarray score: -0.0
INFO: pointer(ctype score: -0.0
INFO: unncessary score: -0.0
INFO: a. score: -0.0
INFO: b. score: -0.0
INFO: num1 score: -0.0
INFO: num2 score: -0.0
INFO: test_func2(num score: -0.0
INFO: test_func(test_obj score: -0.0
INFO: test_obj score: -0.0
INFO: testclass score: -0.0
INFO: typemap score: -0.0
INFO: dict.hpp score: -0.0
INFO: dict.i score: -0.0
INFO: folk score: 0.007881895
INFO: title score: 0.016956847
INFO: david score: 0.01979503
INFO: pep score: 0.051478866
INFO: decorator score: 0.09195646
INFO: tutor score: 0.11440808
INFO: masterclass score: 0.12948753
INFO: ============================================================
INFO: --------------------
INFO: How do you make a higher order function in Python?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<226 unique tokens: ['argument', 'callable', 'class', 'convenient', 'debate']...> from 9 documents (total 555 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<226 unique tokens: ['argument', 'callable', 'class', 'convenient', 'debate']...> from 9 documents (total 555 corpus positions)", 'datetime': '2023-04-18T14:16:21.107064', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 9 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.313 per-word bound, 159.0 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 0, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.179*"function" + 0.077*"argument" + 0.037*"high" + 0.036*"decorator" + 0.033*"order" + 0.033*"name" + 0.022*"call" + 0.016*"return" + 0.015*"way" + 0.014*"expression"
INFO: topic #1 (1.000): 0.126*"function" + 0.066*"argument" + 0.029*"order" + 0.022*"high" + 0.020*"decorator" + 0.016*"lambda" + 0.015*"call" + 0.015*"way" + 0.014*"positional" + 0.014*"name"
INFO: topic #2 (1.000): 0.071*"function" + 0.049*"argument" + 0.026*"order" + 0.021*"high" + 0.019*"type" + 0.018*"positional" + 0.017*"call" + 0.014*"change" + 0.014*"lambda" + 0.014*"unnamed"
INFO: topic diff=4.588736, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.592 per-word bound, 1543.9 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 0, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.197*"function" + 0.062*"argument" + 0.052*"example" + 0.035*"return" + 0.032*"high" + 0.030*"class" + 0.028*"order" + 0.028*"reference" + 0.022*"decorator" + 0.018*"way"
INFO: topic #1 (1.000): 0.130*"function" + 0.042*"argument" + 0.038*"class" + 0.027*"return" + 0.021*"order" + 0.020*"value" + 0.017*"high" + 0.017*"time" + 0.014*"case" + 0.013*"way"
INFO: topic #2 (1.000): 0.079*"function" + 0.033*"time" + 0.033*"argument" + 0.030*"first" + 0.025*"new" + 0.022*"html_tag" + 0.022*"return" + 0.018*"result" + 0.018*"second" + 0.017*"order"
INFO: topic diff=4.238042, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 54.906136097419505
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -1.8378717639331066
DEBUG: bound: at document #0
INFO: -5.783 per-word bound, 55.1 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 1, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.185*"function" + 0.071*"argument" + 0.037*"high" + 0.033*"decorator" + 0.032*"order" + 0.028*"name" + 0.025*"example" + 0.024*"return" + 0.022*"call" + 0.017*"class"
INFO: topic #1 (1.000): 0.106*"function" + 0.053*"argument" + 0.024*"order" + 0.019*"change" + 0.019*"class" + 0.019*"func" + 0.017*"value" + 0.017*"default" + 0.017*"simple" + 0.016*"unnamed"
INFO: topic #2 (1.000): 0.069*"function" + 0.032*"argument" + 0.031*"first" + 0.029*"time" + 0.022*"new" + 0.020*"return" + 0.019*"html_tag" + 0.016*"order" + 0.016*"result" + 0.015*"second"
INFO: topic diff=1.315062, rho=0.512989
DEBUG: bound: at document #0
INFO: -6.269 per-word bound, 77.1 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 1, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.195*"function" + 0.068*"argument" + 0.053*"example" + 0.036*"high" + 0.031*"order" + 0.028*"decorator" + 0.028*"return" + 0.028*"reference" + 0.021*"name" + 0.020*"call"
INFO: topic #1 (1.000): 0.101*"function" + 0.071*"class" + 0.035*"argument" + 0.022*"change" + 0.021*"order" + 0.019*"value" + 0.018*"case" + 0.016*"func" + 0.016*"good" + 0.014*"multiple"
INFO: topic #2 (1.000): 0.084*"function" + 0.032*"new" + 0.029*"return" + 0.029*"time" + 0.027*"argument" + 0.027*"html_tag" + 0.024*"first" + 0.022*"second" + 0.016*"result" + 0.016*"value"
INFO: topic diff=1.201841, rho=0.512989
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 43.94725614580713
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.7353181106563211
DEBUG: bound: at document #0
INFO: -5.404 per-word bound, 42.3 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 2, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.186*"function" + 0.073*"argument" + 0.038*"high" + 0.035*"decorator" + 0.033*"order" + 0.029*"name" + 0.027*"example" + 0.024*"call" + 0.022*"return" + 0.017*"way"
INFO: topic #1 (1.000): 0.090*"function" + 0.049*"argument" + 0.035*"class" + 0.024*"change" + 0.023*"order" + 0.021*"func" + 0.019*"default" + 0.019*"simple" + 0.019*"unnamed" + 0.019*"choice"
INFO: topic #2 (1.000): 0.079*"function" + 0.030*"new" + 0.028*"return" + 0.027*"time" + 0.026*"argument" + 0.026*"first" + 0.025*"html_tag" + 0.020*"second" + 0.016*"result" + 0.015*"value"
INFO: topic diff=0.858226, rho=0.456435
DEBUG: bound: at document #0
INFO: -5.817 per-word bound, 56.4 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 2, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.191*"function" + 0.072*"argument" + 0.052*"example" + 0.038*"high" + 0.033*"order" + 0.031*"decorator" + 0.027*"reference" + 0.023*"return" + 0.023*"name" + 0.023*"call"
INFO: topic #1 (1.000): 0.090*"class" + 0.085*"function" + 0.036*"argument" + 0.028*"change" + 0.022*"order" + 0.020*"func" + 0.020*"good" + 0.019*"case" + 0.016*"value" + 0.015*"multiple"
INFO: topic #2 (1.000): 0.092*"function" + 0.033*"return" + 0.032*"new" + 0.027*"time" + 0.027*"html_tag" + 0.025*"argument" + 0.023*"first" + 0.021*"second" + 0.017*"value" + 0.016*"result"
INFO: topic diff=0.570712, rho=0.456435
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 41.05127123300372
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -1.6892249531150518
DEBUG: bound: at document #0
INFO: -5.255 per-word bound, 38.2 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 3, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.186*"function" + 0.074*"argument" + 0.039*"high" + 0.035*"decorator" + 0.034*"order" + 0.030*"name" + 0.029*"example" + 0.025*"call" + 0.020*"return" + 0.018*"way"
INFO: topic #1 (1.000): 0.081*"function" + 0.049*"argument" + 0.047*"class" + 0.027*"change" + 0.023*"order" + 0.023*"func" + 0.020*"default" + 0.020*"simple" + 0.020*"unnamed" + 0.020*"choice"
INFO: topic #2 (1.000): 0.087*"function" + 0.032*"return" + 0.030*"new" + 0.026*"time" + 0.026*"first" + 0.025*"html_tag" + 0.024*"argument" + 0.020*"second" + 0.017*"value" + 0.016*"result"
INFO: topic diff=0.567064, rho=0.415227
DEBUG: bound: at document #0
INFO: -5.722 per-word bound, 52.8 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 3, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.188*"function" + 0.074*"argument" + 0.048*"example" + 0.040*"high" + 0.035*"order" + 0.032*"decorator" + 0.026*"reference" + 0.024*"call" + 0.024*"name" + 0.021*"return"
INFO: topic #1 (1.000): 0.100*"class" + 0.076*"function" + 0.038*"argument" + 0.030*"change" + 0.024*"func" + 0.023*"good" + 0.022*"order" + 0.019*"case" + 0.015*"default" + 0.015*"simple"
INFO: topic #2 (1.000): 0.098*"function" + 0.035*"return" + 0.031*"new" + 0.027*"time" + 0.026*"html_tag" + 0.023*"argument" + 0.023*"first" + 0.021*"second" + 0.018*"value" + 0.016*"result"
INFO: topic diff=0.363706, rho=0.415227
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 39.858428401762524
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -1.9201990142049123
DEBUG: bound: at document #0
INFO: -5.191 per-word bound, 36.5 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 4, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.185*"function" + 0.075*"argument" + 0.040*"high" + 0.036*"decorator" + 0.035*"order" + 0.030*"name" + 0.028*"example" + 0.026*"call" + 0.019*"return" + 0.018*"way"
INFO: topic #1 (1.000): 0.075*"function" + 0.056*"class" + 0.049*"argument" + 0.028*"change" + 0.025*"func" + 0.024*"order" + 0.020*"default" + 0.020*"simple" + 0.020*"unnamed" + 0.020*"choice"
INFO: topic #2 (1.000): 0.094*"function" + 0.035*"return" + 0.030*"new" + 0.026*"time" + 0.025*"first" + 0.025*"html_tag" + 0.023*"argument" + 0.020*"second" + 0.017*"value" + 0.015*"result"
INFO: topic diff=0.422547, rho=0.383482
DEBUG: bound: at document #0
INFO: -5.679 per-word bound, 51.2 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 4, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.185*"function" + 0.075*"argument" + 0.043*"example" + 0.041*"high" + 0.035*"order" + 0.033*"decorator" + 0.026*"reference" + 0.025*"call" + 0.025*"name" + 0.020*"way"
INFO: topic #1 (1.000): 0.106*"class" + 0.070*"function" + 0.039*"argument" + 0.031*"change" + 0.026*"func" + 0.024*"good" + 0.023*"order" + 0.019*"case" + 0.016*"default" + 0.016*"simple"
INFO: topic #2 (1.000): 0.102*"function" + 0.036*"return" + 0.031*"new" + 0.026*"time" + 0.026*"html_tag" + 0.023*"first" + 0.023*"argument" + 0.021*"second" + 0.018*"value" + 0.015*"result"
INFO: topic diff=0.309524, rho=0.383482
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 39.31770700526982
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -2.124814221214368
DEBUG: bound: at document #0
INFO: -5.160 per-word bound, 35.8 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 5, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.184*"function" + 0.076*"argument" + 0.041*"high" + 0.036*"decorator" + 0.035*"order" + 0.030*"name" + 0.027*"example" + 0.026*"call" + 0.019*"return" + 0.018*"way"
INFO: topic #1 (1.000): 0.072*"function" + 0.063*"class" + 0.049*"argument" + 0.028*"change" + 0.026*"func" + 0.024*"order" + 0.020*"default" + 0.020*"simple" + 0.020*"unnamed" + 0.020*"choice"
INFO: topic #2 (1.000): 0.098*"function" + 0.036*"return" + 0.029*"new" + 0.025*"time" + 0.025*"first" + 0.025*"html_tag" + 0.022*"argument" + 0.020*"second" + 0.018*"value" + 0.015*"result"
INFO: topic diff=0.343646, rho=0.358057
DEBUG: bound: at document #0
INFO: -5.654 per-word bound, 50.3 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 5, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.183*"function" + 0.076*"argument" + 0.041*"high" + 0.036*"order" + 0.036*"example" + 0.034*"decorator" + 0.026*"reference" + 0.026*"name" + 0.026*"call" + 0.020*"way"
INFO: topic #1 (1.000): 0.110*"class" + 0.067*"function" + 0.040*"argument" + 0.031*"change" + 0.028*"func" + 0.024*"good" + 0.023*"order" + 0.018*"case" + 0.016*"default" + 0.016*"simple"
INFO: topic #2 (1.000): 0.106*"function" + 0.037*"return" + 0.030*"new" + 0.026*"time" + 0.025*"html_tag" + 0.023*"first" + 0.022*"argument" + 0.020*"second" + 0.018*"value" + 0.016*"example"
INFO: topic diff=0.273810, rho=0.358057
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 38.9942275114843
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -2.129076177843261
DEBUG: bound: at document #0
INFO: -5.142 per-word bound, 35.3 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 6, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.183*"function" + 0.077*"argument" + 0.041*"high" + 0.036*"decorator" + 0.035*"order" + 0.030*"name" + 0.026*"call" + 0.024*"example" + 0.018*"return" + 0.018*"way"
INFO: topic #1 (1.000): 0.070*"function" + 0.069*"class" + 0.049*"argument" + 0.029*"change" + 0.027*"func" + 0.024*"order" + 0.020*"default" + 0.020*"simple" + 0.020*"unnamed" + 0.020*"choice"
INFO: topic #2 (1.000): 0.102*"function" + 0.036*"return" + 0.029*"new" + 0.025*"time" + 0.025*"first" + 0.024*"html_tag" + 0.022*"argument" + 0.020*"second" + 0.018*"value" + 0.016*"example"
INFO: topic diff=0.293743, rho=0.337100
DEBUG: bound: at document #0
INFO: -5.634 per-word bound, 49.7 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 6, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.182*"function" + 0.077*"argument" + 0.042*"high" + 0.036*"order" + 0.035*"decorator" + 0.028*"example" + 0.026*"name" + 0.026*"call" + 0.026*"reference" + 0.019*"way"
INFO: topic #1 (1.000): 0.112*"class" + 0.065*"function" + 0.040*"argument" + 0.031*"change" + 0.029*"func" + 0.024*"good" + 0.023*"order" + 0.018*"case" + 0.017*"callable" + 0.016*"default"
INFO: topic #2 (1.000): 0.108*"function" + 0.037*"return" + 0.030*"new" + 0.025*"time" + 0.025*"html_tag" + 0.023*"example" + 0.022*"first" + 0.022*"argument" + 0.020*"second" + 0.018*"value"
INFO: topic diff=0.250730, rho=0.337100
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 38.77219033946878
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -2.2957951195954664
DEBUG: bound: at document #0
INFO: -5.129 per-word bound, 35.0 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 7, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.183*"function" + 0.077*"argument" + 0.042*"high" + 0.037*"decorator" + 0.035*"order" + 0.030*"name" + 0.027*"call" + 0.020*"example" + 0.018*"return" + 0.018*"way"
INFO: topic #1 (1.000): 0.074*"class" + 0.068*"function" + 0.049*"argument" + 0.029*"change" + 0.028*"func" + 0.024*"order" + 0.020*"default" + 0.020*"simple" + 0.020*"unnamed" + 0.020*"choice"
INFO: topic #2 (1.000): 0.105*"function" + 0.036*"return" + 0.029*"new" + 0.025*"time" + 0.025*"first" + 0.024*"html_tag" + 0.023*"example" + 0.022*"argument" + 0.019*"second" + 0.018*"value"
INFO: topic diff=0.262150, rho=0.319438
DEBUG: bound: at document #0
INFO: -5.620 per-word bound, 49.2 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 7, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.181*"function" + 0.078*"argument" + 0.042*"high" + 0.036*"order" + 0.035*"decorator" + 0.027*"name" + 0.026*"call" + 0.025*"reference" + 0.021*"example" + 0.019*"way"
INFO: topic #1 (1.000): 0.114*"class" + 0.064*"function" + 0.041*"argument" + 0.031*"change" + 0.030*"func" + 0.024*"order" + 0.023*"good" + 0.017*"callable" + 0.017*"case" + 0.017*"default"
INFO: topic #2 (1.000): 0.110*"function" + 0.037*"return" + 0.029*"new" + 0.029*"example" + 0.025*"time" + 0.025*"html_tag" + 0.022*"argument" + 0.022*"first" + 0.020*"second" + 0.018*"value"
INFO: topic diff=0.236046, rho=0.319438
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 38.63304200148461
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -2.3110817357785165
DEBUG: bound: at document #0
INFO: -5.120 per-word bound, 34.8 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 8, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.182*"function" + 0.078*"argument" + 0.042*"high" + 0.037*"decorator" + 0.035*"order" + 0.030*"name" + 0.027*"call" + 0.018*"return" + 0.018*"way" + 0.017*"example"
INFO: topic #1 (1.000): 0.078*"class" + 0.067*"function" + 0.049*"argument" + 0.029*"change" + 0.028*"func" + 0.024*"order" + 0.020*"default" + 0.020*"simple" + 0.020*"unnamed" + 0.020*"choice"
INFO: topic #2 (1.000): 0.107*"function" + 0.036*"return" + 0.028*"new" + 0.028*"example" + 0.025*"time" + 0.024*"first" + 0.024*"html_tag" + 0.022*"argument" + 0.019*"second" + 0.018*"value"
INFO: topic diff=0.240198, rho=0.304290
DEBUG: bound: at document #0
INFO: -5.610 per-word bound, 48.8 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 8, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.181*"function" + 0.078*"argument" + 0.042*"high" + 0.036*"decorator" + 0.036*"order" + 0.027*"name" + 0.027*"call" + 0.025*"reference" + 0.018*"way" + 0.018*"return"
INFO: topic #1 (1.000): 0.116*"class" + 0.063*"function" + 0.041*"argument" + 0.031*"change" + 0.031*"func" + 0.024*"order" + 0.023*"good" + 0.018*"callable" + 0.017*"default" + 0.017*"simple"
INFO: topic #2 (1.000): 0.112*"function" + 0.037*"return" + 0.032*"example" + 0.029*"new" + 0.025*"time" + 0.024*"html_tag" + 0.023*"argument" + 0.022*"first" + 0.020*"second" + 0.018*"value"
INFO: topic diff=0.224389, rho=0.304290
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 38.54629650480863
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -2.6859234211959406
DEBUG: bound: at document #0
INFO: -5.114 per-word bound, 34.6 perplexity estimate based on a held-out corpus of 5 documents with 320 words
INFO: PROGRESS: pass 9, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.182*"function" + 0.078*"argument" + 0.042*"high" + 0.037*"decorator" + 0.035*"order" + 0.031*"name" + 0.027*"call" + 0.018*"return" + 0.017*"way" + 0.016*"reference"
INFO: topic #1 (1.000): 0.082*"class" + 0.066*"function" + 0.048*"argument" + 0.029*"change" + 0.028*"func" + 0.025*"order" + 0.020*"default" + 0.020*"simple" + 0.020*"unnamed" + 0.020*"choice"
INFO: topic #2 (1.000): 0.109*"function" + 0.036*"return" + 0.031*"example" + 0.028*"new" + 0.024*"time" + 0.024*"first" + 0.024*"html_tag" + 0.022*"argument" + 0.019*"second" + 0.018*"value"
INFO: topic diff=0.223954, rho=0.291111
DEBUG: bound: at document #0
INFO: -5.602 per-word bound, 48.6 perplexity estimate based on a held-out corpus of 4 documents with 235 words
INFO: PROGRESS: pass 9, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.180*"function" + 0.079*"argument" + 0.042*"high" + 0.036*"decorator" + 0.035*"order" + 0.028*"name" + 0.027*"call" + 0.025*"reference" + 0.018*"way" + 0.018*"return"
INFO: topic #1 (1.000): 0.117*"class" + 0.063*"function" + 0.041*"argument" + 0.031*"change" + 0.031*"func" + 0.024*"order" + 0.023*"good" + 0.019*"callable" + 0.017*"default" + 0.017*"simple"
INFO: topic #2 (1.000): 0.113*"function" + 0.037*"return" + 0.034*"example" + 0.029*"new" + 0.025*"time" + 0.024*"html_tag" + 0.023*"argument" + 0.022*"first" + 0.019*"second" + 0.018*"value"
INFO: topic diff=0.213945, rho=0.291111
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 38.4856297486445
DEBUG: Setting topics to those of the model: LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -2.6859234211959406
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=226, num_topics=3, decay=0.5, chunksize=5> in 0.15s', 'datetime': '2023-04-18T14:16:21.261506', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/cos_threshold/9/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-18T14:16:21.261657', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/cos_threshold/9/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/9/model.state
DEBUG: {'uri': 'model/cos_threshold/9/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/cos_threshold/9/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['state', 'id2word', 'dispatcher'], 'datetime': '2023-04-18T14:16:21.263904', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/cos_threshold/9/model.expElogbeta.npy
INFO: not storing attribute state
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
DEBUG: {'uri': 'model/cos_threshold/9/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/9/model
INFO: topic #0 (1.000): 0.180*"function" + 0.079*"argument" + 0.042*"high" + 0.036*"decorator" + 0.035*"order" + 0.028*"name" + 0.027*"call" + 0.025*"reference" + 0.018*"way" + 0.018*"return"
INFO: topic #1 (1.000): 0.117*"class" + 0.063*"function" + 0.041*"argument" + 0.031*"change" + 0.031*"func" + 0.024*"order" + 0.023*"good" + 0.019*"callable" + 0.017*"default" + 0.017*"simple"
INFO: topic #2 (1.000): 0.113*"function" + 0.037*"return" + 0.034*"example" + 0.029*"new" + 0.025*"time" + 0.024*"html_tag" + 0.023*"argument" + 0.022*"first" + 0.019*"second" + 0.018*"value"
INFO: Question Similarity: [0.10462534427642822, 0.14560920000076294, 0.2888372540473938, 0.4489741325378418, 0.05246710777282715, 0.3915720582008362, 0.4021875858306885, 0.14681553840637207, 0.5099236369132996, 0.15382105112075806]
INFO: 62328997: -0.17632859977297782
INFO: 62328793: -0.184018692778221
INFO: 50623708: -0.3661839449358357
INFO: 65901747: -0.3815325878787432
INFO: 74854675: -0.38361745164215194
INFO: 74483521: -0.6193884377553197
INFO: 74483522: -0.6838765618592395
INFO: 70170666: -0.7046197486147696
INFO: 70170703: -0.7894282163897596
INFO: 70168888: -0.8687639343099844
INFO: 70168821: -0.971050391728835
INFO: 70168970: -0.9828731240547971
INFO: 61810300: -1.1498586503637838
INFO: 61810298: -1.2298739041476219
INFO: 61810249: -1.2611070203068995
INFO: Recommended Keywords
INFO: time score: -0.83384293
INFO: give score: -0.83315206
INFO: order score: -0.82695633
INFO: way score: -0.82137185
INFO: possible score: -0.80542386
INFO: result score: -0.7716798
INFO: simple score: -0.7619654
INFO: change score: -0.75177836
INFO: choice score: -0.7421254
INFO: example score: -0.7364192
INFO: function score: -0.73549515
INFO: first score: -0.72529805
INFO: case score: -0.7215745
INFO: step score: -0.71327
INFO: pre score: -0.7051409
INFO: call score: -0.6976445
INFO: instance score: -0.6939447
INFO: key score: -0.6928077
INFO: reason score: -0.69208294
INFO: advantage score: -0.6859674
INFO: default score: -0.68133867
INFO: new score: -0.6742241
INFO: difference score: -0.65705764
INFO: invoke score: -0.6550071
INFO: real score: -0.65418214
INFO: second score: -0.6520508
INFO: note score: -0.6438554
INFO: argument score: -0.64249307
INFO: individual score: -0.64198995
INFO: convenient score: -0.6360061
INFO: need score: -0.6223647
INFO: extra score: -0.6207574
INFO: positional score: -0.6180595
INFO: element score: -0.6132487
INFO: return score: -0.60715395
INFO: run score: -0.59044755
INFO: problem score: -0.5835497
INFO: object score: -0.5821809
INFO: statement score: -0.5777693
INFO: multiple score: -0.5766336
INFO: equivalent score: -0.5730877
INFO: link score: -0.55705535
INFO: name score: -0.5519621
INFO: additional score: -0.5325707
INFO: benefit score: -0.531813
INFO: solution score: -0.5278894
INFO: reference score: -0.52750784
INFO: shorthand score: -0.51712775
INFO: redundant score: -0.507982
INFO: execute score: -0.5054623
INFO: refer score: -0.50263214
INFO: last score: -0.4997959
INFO: conditional score: -0.4932275
INFO: attribute score: -0.4922793
INFO: phrase score: -0.48230758
INFO: different score: -0.4808824
INFO: class score: -0.4795527
INFO: operation score: -0.47876954
INFO: value score: -0.47712743
INFO: single score: -0.4747282
INFO: guess score: -0.47382155
INFO: define score: -0.47352448
INFO: type score: -0.46400875
INFO: high score: -0.45718345
INFO: available score: -0.45569202
INFO: debate score: -0.45511496
INFO: signature score: -0.45345074
INFO: pointer score: -0.4427525
INFO: expression score: -0.4404347
INFO: detail score: -0.43986142
INFO: memory score: -0.4382753
INFO: state score: -0.43027797
INFO: body score: -0.4275766
INFO: relevant score: -0.42545357
INFO: mind score: -0.42463982
INFO: block score: -0.42206648
INFO: tuple score: -0.41325045
INFO: resource score: -0.4131488
INFO: func score: -0.41152838
INFO: efficient score: -0.39779755
INFO: core score: -0.397044
INFO: learn score: -0.38049814
INFO: mode score: -0.37373546
INFO: talk score: -0.37122563
INFO: args score: -0.3640684
INFO: functional score: -0.3579419
INFO: version score: -0.35224122
INFO: programming score: -0.34652928
INFO: list score: -0.3212236
INFO: helper score: -0.31961775
INFO: code score: -0.30676517
INFO: lot score: -0.3026101
INFO: variable score: -0.29741395
INFO: string score: -0.28622717
INFO: maximal score: -0.27932876
INFO: sum score: -0.25409502
INFO: lambda score: -0.24844263
INFO: print score: -0.22078012
INFO: callable score: -0.21584134
INFO: syntactic score: -0.21499346
INFO: datum score: -0.2129983
INFO: syntax score: -0.21166477
INFO: parameter score: -0.2098109
INFO: wiil score: -0.16717082
INFO: later score: -0.16600701
INFO: ref score: -0.16185193
INFO: online score: -0.15622053
INFO: unnamed score: -0.1528178
INFO: x score: -0.14788559
INFO: lst score: -0.13835138
INFO: homework score: -0.12710969
INFO: g score: -0.12243813
INFO: research score: -0.121008866
INFO: f score: -0.11150281
INFO: decorator score: -0.1104704
INFO: panda score: -0.052742884
INFO: hof score: -0.035125874
INFO: weird score: -0.033461984
INFO: fnc score: -0.0
INFO: fnc(*args score: -0.0
INFO: https://docs.python.org/3/library/typing.html#callable score: -0.0
INFO: make_function_print_arg score: -0.0
INFO: f(x score: -0.0
INFO: html_tag score: -0.0
INFO: print_h1 score: -0.0
INFO: def score: 0.06310016
INFO: ============================================================
INFO: --------------------
INFO: How do I copy an object in Python?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<147 unique tokens: ['assignment', 'batchelder', 'case', 'copy', 'copy.deepcopy']...> from 10 documents (total 393 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<147 unique tokens: ['assignment', 'batchelder', 'case', 'copy', 'copy.deepcopy']...> from 10 documents (total 393 corpus positions)", 'datetime': '2023-04-18T14:16:23.390262', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.432 per-word bound, 172.7 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.070*"object" + 0.063*"copy" + 0.060*"deepcopy" + 0.037*"new" + 0.028*"list" + 0.027*"name" + 0.020*"lots_of_data" + 0.020*"dictionary" + 0.020*"shallow" + 0.019*"foo"
INFO: topic #1 (1.000): 0.081*"object" + 0.053*"reference" + 0.047*"copy" + 0.042*"instance" + 0.042*"df" + 0.034*"variable" + 0.032*"deepcopy" + 0.026*"name" + 0.023*"dict_b" + 0.021*"dictionary"
INFO: topic #2 (1.000): 0.050*"object" + 0.044*"deepcopy" + 0.039*"copy" + 0.027*"reference" + 0.027*"name" + 0.025*"df" + 0.024*"new" + 0.018*"dictionary" + 0.017*"instance" + 0.016*"list"
INFO: topic diff=4.859515, rho=1.000000
DEBUG: bound: at document #0
INFO: -9.375 per-word bound, 664.0 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.192*"copy" + 0.118*"object" + 0.056*"shallow" + 0.041*"list" + 0.040*"new" + 0.040*"class" + 0.035*"deepcopy" + 0.027*"original" + 0.017*"deep" + 0.013*"method"
INFO: topic #1 (1.000): 0.095*"object" + 0.067*"reference" + 0.061*"copy" + 0.036*"deepcopy" + 0.034*"memory" + 0.031*"instance" + 0.026*"=" + 0.024*"df" + 0.020*"variable" + 0.019*"new"
INFO: topic #2 (1.000): 0.104*"copy" + 0.084*"object" + 0.045*"deep" + 0.037*"method" + 0.025*"change" + 0.025*"deepcopy" + 0.024*"immutable" + 0.022*"shallow" + 0.022*"interior" + 0.018*"mutable"
INFO: topic diff=4.349255, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 40.57338983975117
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -1.6270089735792812
DEBUG: bound: at document #0
INFO: -6.403 per-word bound, 84.6 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.143*"copy" + 0.096*"object" + 0.047*"deepcopy" + 0.044*"shallow" + 0.043*"new" + 0.039*"list" + 0.029*"class" + 0.021*"original" + 0.017*"answer" + 0.017*"dictionary"
INFO: topic #1 (1.000): 0.089*"object" + 0.068*"reference" + 0.050*"instance" + 0.048*"df" + 0.042*"copy" + 0.037*"variable" + 0.030*"deepcopy" + 0.025*"memory" + 0.025*"dict_b" + 0.025*"name"
INFO: topic #2 (1.000): 0.097*"copy" + 0.080*"object" + 0.041*"deep" + 0.033*"method" + 0.025*"deepcopy" + 0.023*"change" + 0.022*"immutable" + 0.021*"shallow" + 0.020*"interior" + 0.016*"mutable"
INFO: topic diff=1.141136, rho=0.500000
DEBUG: bound: at document #0
INFO: -5.097 per-word bound, 34.2 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.166*"copy" + 0.097*"object" + 0.052*"new" + 0.050*"list" + 0.050*"shallow" + 0.045*"class" + 0.039*"deepcopy" + 0.028*"original" + 0.016*"content" + 0.016*"deep"
INFO: topic #1 (1.000): 0.087*"object" + 0.082*"reference" + 0.045*"instance" + 0.042*"memory" + 0.038*"copy" + 0.037*"deepcopy" + 0.036*"df" + 0.029*"=" + 0.028*"variable" + 0.019*"dict_b"
INFO: topic #2 (1.000): 0.130*"copy" + 0.099*"object" + 0.049*"deep" + 0.043*"method" + 0.031*"shallow" + 0.029*"change" + 0.026*"immutable" + 0.024*"interior" + 0.021*"mutable" + 0.019*"deepcopy"
INFO: topic diff=1.094382, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 33.20152127971267
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.833960746288528
DEBUG: bound: at document #0
INFO: -5.880 per-word bound, 58.9 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.128*"copy" + 0.083*"object" + 0.051*"new" + 0.048*"deepcopy" + 0.045*"list" + 0.040*"shallow" + 0.032*"class" + 0.022*"original" + 0.018*"answer" + 0.017*"dictionary"
INFO: topic #1 (1.000): 0.087*"object" + 0.075*"reference" + 0.055*"instance" + 0.052*"df" + 0.039*"variable" + 0.032*"copy" + 0.031*"deepcopy" + 0.029*"memory" + 0.027*"dict_b" + 0.023*"name"
INFO: topic #2 (1.000): 0.126*"copy" + 0.096*"object" + 0.046*"deep" + 0.040*"method" + 0.029*"shallow" + 0.027*"change" + 0.024*"immutable" + 0.023*"interior" + 0.020*"mutable" + 0.020*"deepcopy"
INFO: topic diff=0.779889, rho=0.447214
DEBUG: bound: at document #0
INFO: -4.822 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.142*"copy" + 0.081*"object" + 0.062*"new" + 0.058*"list" + 0.048*"class" + 0.042*"deepcopy" + 0.041*"shallow" + 0.028*"original" + 0.021*"content" + 0.018*"value"
INFO: topic #1 (1.000): 0.086*"object" + 0.085*"reference" + 0.054*"instance" + 0.045*"memory" + 0.040*"df" + 0.039*"deepcopy" + 0.030*"variable" + 0.030*"copy" + 0.029*"=" + 0.021*"dict_b"
INFO: topic #2 (1.000): 0.150*"copy" + 0.108*"object" + 0.047*"deep" + 0.043*"method" + 0.039*"shallow" + 0.028*"change" + 0.025*"immutable" + 0.023*"interior" + 0.021*"mutable" + 0.018*"deepcopy"
INFO: topic diff=0.676244, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 30.98158442611459
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -1.982601385551891
DEBUG: bound: at document #0
INFO: -5.683 per-word bound, 51.4 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.113*"copy" + 0.072*"object" + 0.057*"new" + 0.050*"deepcopy" + 0.050*"list" + 0.035*"class" + 0.034*"shallow" + 0.022*"original" + 0.019*"memo" + 0.019*"answer"
INFO: topic #1 (1.000): 0.087*"object" + 0.077*"reference" + 0.058*"instance" + 0.052*"df" + 0.040*"variable" + 0.033*"deepcopy" + 0.032*"memory" + 0.028*"copy" + 0.027*"dict_b" + 0.022*"="
INFO: topic #2 (1.000): 0.147*"copy" + 0.106*"object" + 0.045*"deep" + 0.041*"method" + 0.037*"shallow" + 0.027*"change" + 0.024*"immutable" + 0.022*"interior" + 0.020*"mutable" + 0.018*"deepcopy"
INFO: topic diff=0.532510, rho=0.408248
DEBUG: bound: at document #0
INFO: -4.735 per-word bound, 26.6 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.123*"copy" + 0.071*"new" + 0.070*"object" + 0.065*"list" + 0.049*"class" + 0.045*"deepcopy" + 0.033*"shallow" + 0.028*"original" + 0.024*"content" + 0.021*"value"
INFO: topic #1 (1.000): 0.086*"object" + 0.086*"reference" + 0.061*"instance" + 0.045*"memory" + 0.041*"df" + 0.039*"deepcopy" + 0.031*"variable" + 0.029*"=" + 0.026*"copy" + 0.021*"dict_b"
INFO: topic #2 (1.000): 0.160*"copy" + 0.112*"object" + 0.046*"deep" + 0.043*"shallow" + 0.042*"method" + 0.027*"change" + 0.024*"immutable" + 0.022*"interior" + 0.021*"mutable" + 0.017*"deepcopy"
INFO: topic diff=0.439793, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 29.95580582997426
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -1.9708899897155028
DEBUG: bound: at document #0
INFO: -5.583 per-word bound, 47.9 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.101*"copy" + 0.065*"object" + 0.063*"new" + 0.055*"list" + 0.052*"deepcopy" + 0.035*"class" + 0.030*"shallow" + 0.022*"original" + 0.021*"name" + 0.020*"memo"
INFO: topic #1 (1.000): 0.088*"object" + 0.078*"reference" + 0.062*"instance" + 0.052*"df" + 0.040*"variable" + 0.034*"deepcopy" + 0.033*"memory" + 0.027*"dict_b" + 0.025*"copy" + 0.022*"="
INFO: topic #2 (1.000): 0.159*"copy" + 0.111*"object" + 0.044*"deep" + 0.042*"shallow" + 0.040*"method" + 0.026*"change" + 0.023*"immutable" + 0.021*"interior" + 0.020*"mutable" + 0.018*"deepcopy"
INFO: topic diff=0.406619, rho=0.377964
DEBUG: bound: at document #0
INFO: -4.692 per-word bound, 25.8 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.110*"copy" + 0.077*"new" + 0.071*"list" + 0.063*"object" + 0.048*"deepcopy" + 0.044*"class" + 0.029*"shallow" + 0.027*"original" + 0.025*"content" + 0.022*"value"
INFO: topic #1 (1.000): 0.087*"object" + 0.085*"reference" + 0.067*"instance" + 0.046*"memory" + 0.042*"df" + 0.040*"deepcopy" + 0.032*"variable" + 0.028*"=" + 0.023*"copy" + 0.022*"dict_b"
INFO: topic #2 (1.000): 0.166*"copy" + 0.114*"object" + 0.046*"shallow" + 0.045*"deep" + 0.041*"method" + 0.026*"change" + 0.024*"immutable" + 0.021*"interior" + 0.021*"mutable" + 0.017*"deepcopy"
INFO: topic diff=0.340140, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 29.385636900861094
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -1.9728122948672444
DEBUG: bound: at document #0
INFO: -5.525 per-word bound, 46.0 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.093*"copy" + 0.067*"new" + 0.060*"object" + 0.058*"list" + 0.053*"deepcopy" + 0.032*"class" + 0.027*"shallow" + 0.022*"name" + 0.022*"original" + 0.021*"memo"
INFO: topic #1 (1.000): 0.088*"object" + 0.078*"reference" + 0.065*"instance" + 0.052*"df" + 0.039*"variable" + 0.034*"deepcopy" + 0.034*"memory" + 0.027*"dict_b" + 0.023*"copy" + 0.022*"="
INFO: topic #2 (1.000): 0.165*"copy" + 0.113*"object" + 0.044*"shallow" + 0.043*"deep" + 0.039*"method" + 0.025*"change" + 0.023*"immutable" + 0.020*"interior" + 0.020*"mutable" + 0.018*"deepcopy"
INFO: topic diff=0.334829, rho=0.353553
DEBUG: bound: at document #0
INFO: -4.666 per-word bound, 25.4 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.100*"copy" + 0.082*"new" + 0.075*"list" + 0.058*"object" + 0.049*"deepcopy" + 0.036*"class" + 0.027*"content" + 0.027*"original" + 0.026*"shallow" + 0.023*"value"
INFO: topic #1 (1.000): 0.087*"object" + 0.084*"reference" + 0.071*"instance" + 0.045*"memory" + 0.042*"df" + 0.040*"deepcopy" + 0.032*"variable" + 0.028*"=" + 0.022*"dict_b" + 0.022*"copy"
INFO: topic #2 (1.000): 0.170*"copy" + 0.114*"object" + 0.047*"shallow" + 0.045*"deep" + 0.040*"method" + 0.025*"change" + 0.024*"immutable" + 0.020*"interior" + 0.020*"mutable" + 0.018*"class"
INFO: topic diff=0.285689, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 29.064122326553658
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -1.9489687702385412
DEBUG: bound: at document #0
INFO: -5.489 per-word bound, 44.9 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.087*"copy" + 0.070*"new" + 0.061*"list" + 0.056*"object" + 0.054*"deepcopy" + 0.028*"class" + 0.025*"shallow" + 0.023*"name" + 0.022*"memo" + 0.022*"original"
INFO: topic #1 (1.000): 0.089*"object" + 0.077*"reference" + 0.067*"instance" + 0.052*"df" + 0.039*"variable" + 0.034*"deepcopy" + 0.034*"memory" + 0.027*"dict_b" + 0.023*"=" + 0.022*"copy"
INFO: topic #2 (1.000): 0.169*"copy" + 0.114*"object" + 0.045*"shallow" + 0.043*"deep" + 0.038*"method" + 0.024*"change" + 0.023*"immutable" + 0.020*"interior" + 0.019*"mutable" + 0.018*"deepcopy"
INFO: topic diff=0.286299, rho=0.333333
DEBUG: bound: at document #0
INFO: -4.650 per-word bound, 25.1 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.094*"copy" + 0.085*"new" + 0.078*"list" + 0.055*"object" + 0.050*"deepcopy" + 0.028*"class" + 0.027*"content" + 0.026*"original" + 0.024*"shallow" + 0.024*"value"
INFO: topic #1 (1.000): 0.088*"object" + 0.083*"reference" + 0.073*"instance" + 0.045*"memory" + 0.043*"df" + 0.040*"deepcopy" + 0.033*"variable" + 0.028*"=" + 0.022*"dict_b" + 0.020*"copy"
INFO: topic #2 (1.000): 0.172*"copy" + 0.115*"object" + 0.047*"shallow" + 0.045*"deep" + 0.039*"method" + 0.025*"change" + 0.024*"immutable" + 0.023*"class" + 0.020*"interior" + 0.020*"mutable"
INFO: topic diff=0.254472, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 28.87416657984017
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -1.960110084288736
DEBUG: bound: at document #0
INFO: -5.466 per-word bound, 44.2 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.082*"copy" + 0.073*"new" + 0.064*"list" + 0.054*"deepcopy" + 0.054*"object" + 0.024*"shallow" + 0.024*"name" + 0.022*"memo" + 0.022*"class" + 0.021*"original"
INFO: topic #1 (1.000): 0.089*"object" + 0.077*"reference" + 0.069*"instance" + 0.052*"df" + 0.039*"variable" + 0.035*"deepcopy" + 0.034*"memory" + 0.027*"dict_b" + 0.023*"=" + 0.021*"copy"
INFO: topic #2 (1.000): 0.172*"copy" + 0.114*"object" + 0.046*"shallow" + 0.044*"deep" + 0.038*"method" + 0.024*"change" + 0.023*"immutable" + 0.022*"class" + 0.019*"interior" + 0.019*"mutable"
INFO: topic diff=0.251710, rho=0.316228
DEBUG: bound: at document #0
INFO: -4.640 per-word bound, 24.9 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.089*"copy" + 0.087*"new" + 0.080*"list" + 0.052*"object" + 0.051*"deepcopy" + 0.028*"content" + 0.026*"original" + 0.025*"value" + 0.023*"shallow" + 0.022*"memo"
INFO: topic #1 (1.000): 0.088*"object" + 0.082*"reference" + 0.074*"instance" + 0.045*"memory" + 0.043*"df" + 0.039*"deepcopy" + 0.033*"variable" + 0.028*"=" + 0.022*"dict_b" + 0.020*"copy"
INFO: topic #2 (1.000): 0.174*"copy" + 0.115*"object" + 0.047*"shallow" + 0.045*"deep" + 0.038*"method" + 0.026*"class" + 0.024*"change" + 0.024*"immutable" + 0.019*"interior" + 0.019*"mutable"
INFO: topic diff=0.231022, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 28.759480239730365
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -2.3576288016177847
DEBUG: bound: at document #0
INFO: -5.450 per-word bound, 43.7 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.079*"copy" + 0.074*"new" + 0.065*"list" + 0.055*"deepcopy" + 0.052*"object" + 0.025*"name" + 0.023*"shallow" + 0.023*"memo" + 0.021*"original" + 0.021*"value"
INFO: topic #1 (1.000): 0.089*"object" + 0.077*"reference" + 0.070*"instance" + 0.052*"df" + 0.039*"variable" + 0.035*"deepcopy" + 0.035*"memory" + 0.026*"dict_b" + 0.023*"=" + 0.020*"copy"
INFO: topic #2 (1.000): 0.173*"copy" + 0.115*"object" + 0.046*"shallow" + 0.044*"deep" + 0.037*"method" + 0.025*"class" + 0.023*"change" + 0.023*"immutable" + 0.019*"interior" + 0.019*"mutable"
INFO: topic diff=0.227581, rho=0.301511
DEBUG: bound: at document #0
INFO: -4.633 per-word bound, 24.8 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.088*"new" + 0.085*"copy" + 0.081*"list" + 0.051*"deepcopy" + 0.051*"object" + 0.028*"content" + 0.025*"original" + 0.025*"value" + 0.023*"shallow" + 0.022*"memo"
INFO: topic #1 (1.000): 0.089*"object" + 0.082*"reference" + 0.074*"instance" + 0.044*"memory" + 0.044*"df" + 0.039*"deepcopy" + 0.033*"variable" + 0.027*"=" + 0.023*"dict_b" + 0.019*"copy"
INFO: topic #2 (1.000): 0.175*"copy" + 0.115*"object" + 0.047*"shallow" + 0.046*"deep" + 0.038*"method" + 0.028*"class" + 0.024*"change" + 0.024*"immutable" + 0.019*"interior" + 0.019*"mutable"
INFO: topic diff=0.213005, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 28.687706337145563
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -2.3514132379645774
DEBUG: bound: at document #0
INFO: -5.439 per-word bound, 43.4 perplexity estimate based on a held-out corpus of 5 documents with 134 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.077*"copy" + 0.075*"new" + 0.067*"list" + 0.055*"deepcopy" + 0.051*"object" + 0.025*"name" + 0.023*"memo" + 0.023*"shallow" + 0.021*"original" + 0.021*"value"
INFO: topic #1 (1.000): 0.090*"object" + 0.076*"reference" + 0.070*"instance" + 0.052*"df" + 0.039*"variable" + 0.035*"deepcopy" + 0.035*"memory" + 0.026*"dict_b" + 0.023*"=" + 0.019*"copy"
INFO: topic #2 (1.000): 0.175*"copy" + 0.115*"object" + 0.046*"shallow" + 0.044*"deep" + 0.037*"method" + 0.027*"class" + 0.023*"change" + 0.023*"immutable" + 0.019*"interior" + 0.019*"mutable"
INFO: topic diff=0.209938, rho=0.288675
DEBUG: bound: at document #0
INFO: -4.628 per-word bound, 24.7 perplexity estimate based on a held-out corpus of 5 documents with 259 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.089*"new" + 0.082*"list" + 0.082*"copy" + 0.052*"deepcopy" + 0.050*"object" + 0.028*"content" + 0.025*"value" + 0.025*"original" + 0.022*"memo" + 0.022*"shallow"
INFO: topic #1 (1.000): 0.089*"object" + 0.081*"reference" + 0.075*"instance" + 0.044*"df" + 0.044*"memory" + 0.039*"deepcopy" + 0.033*"variable" + 0.027*"=" + 0.023*"dict_b" + 0.019*"copy"
INFO: topic #2 (1.000): 0.175*"copy" + 0.115*"object" + 0.047*"shallow" + 0.046*"deep" + 0.038*"method" + 0.030*"class" + 0.024*"change" + 0.024*"immutable" + 0.019*"interior" + 0.019*"mutable"
INFO: topic diff=0.199917, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 28.63832270983964
DEBUG: Setting topics to those of the model: LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -2.326219183285598
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=147, num_topics=3, decay=0.5, chunksize=5> in 0.14s', 'datetime': '2023-04-18T14:16:23.526274', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/cos_threshold/10/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-18T14:16:23.526429', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/cos_threshold/10/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/10/model.state
DEBUG: {'uri': 'model/cos_threshold/10/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/cos_threshold/10/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['state', 'id2word', 'dispatcher'], 'datetime': '2023-04-18T14:16:23.528182', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/cos_threshold/10/model.expElogbeta.npy
INFO: not storing attribute state
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
DEBUG: {'uri': 'model/cos_threshold/10/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/10/model
INFO: topic #0 (1.000): 0.089*"new" + 0.082*"list" + 0.082*"copy" + 0.052*"deepcopy" + 0.050*"object" + 0.028*"content" + 0.025*"value" + 0.025*"original" + 0.022*"memo" + 0.022*"shallow"
INFO: topic #1 (1.000): 0.089*"object" + 0.081*"reference" + 0.075*"instance" + 0.044*"df" + 0.044*"memory" + 0.039*"deepcopy" + 0.033*"variable" + 0.027*"=" + 0.023*"dict_b" + 0.019*"copy"
INFO: topic #2 (1.000): 0.175*"copy" + 0.115*"object" + 0.047*"shallow" + 0.046*"deep" + 0.038*"method" + 0.030*"class" + 0.024*"change" + 0.024*"immutable" + 0.019*"interior" + 0.019*"mutable"
INFO: Question Similarity: [0.1959053874015808, 0.17413294315338135, 0.0930936336517334, 0.1420188546180725, 0.09221601486206055, 0.1343625783920288, 0.044537901878356934, 0.1096653938293457, 0.12416106462478638, 0.30900347232818604]
INFO: 29398459: -0.2346243702637827
INFO: 42143502: -0.2582697823737814
INFO: 56478412: -0.26409756829478787
INFO: 23581063: -0.32646503965785606
INFO: 68746763: -0.3452063923384795
INFO: 73328910: -0.43239597628706034
INFO: 68737463: -0.47806367056665805
INFO: 26014778: -0.700844979328848
INFO: Recommended Keywords
INFO: instance score: -0.80100447
INFO: function score: -0.7579773
INFO: object score: -0.75019586
INFO: reference score: -0.7159595
INFO: original score: -0.7027591
INFO: change score: -0.70128906
INFO: content score: -0.6984601
INFO: copy score: -0.6980991
INFO: method score: -0.6870629
INFO: attribute score: -0.681203
INFO: need score: -0.6696948
INFO: mutable score: -0.661024
INFO: source score: -0.6509884
INFO: variable score: -0.6506665
INFO: exact score: -0.6477724
INFO: different score: -0.6404282
INFO: immutable score: -0.63359255
INFO: memory score: -0.6304126
INFO: difference score: -0.62844276
INFO: item score: -0.6235745
INFO: value score: -0.6151971
INFO: case score: -0.6071838
INFO: element score: -0.6058137
INFO: basic score: -0.59560955
INFO: explanation score: -0.5905499
INFO: new score: -0.57995945
INFO: detail score: -0.57275236
INFO: deep score: -0.57222164
INFO: multiple score: -0.5702001
INFO: information score: -0.56057817
INFO: produce score: -0.54844767
INFO: related score: -0.54522943
INFO: way score: -0.5333749
INFO: avoid score: -0.5233164
INFO: address score: -0.520147
INFO: solution score: -0.51648146
INFO: copying score: -0.503787
INFO: selection score: -0.49973592
INFO: list score: -0.49955896
INFO: individual score: -0.49472624
INFO: doubt score: -0.49136755
INFO: test score: -0.48191565
INFO: whole score: -0.47022802
INFO: slice score: -0.46684894
INFO: interior score: -0.46587214
INFO: many score: -0.46575168
INFO: point score: -0.46567
INFO: classed score: -0.46216992
INFO: implement score: -0.46003276
INFO: pointer score: -0.45957077
INFO: time score: -0.45543748
INFO: class score: -0.4478311
INFO: b score: -0.4443955
INFO: question score: -0.44065103
INFO: independent score: -0.4356737
INFO: answer score: -0.4349004
INFO: memo score: -0.43265247
INFO: override score: -0.4279231
INFO: = score: -0.4274314
INFO: module score: -0.4243287
INFO: general score: -0.42206004
INFO: df score: -0.42024377
INFO: recursive score: -0.4105868
INFO: shallow score: -0.41053283
INFO: assignment score: -0.40776077
INFO: several score: -0.40698358
INFO: nested score: -0.40654066
INFO: documentation score: -0.3999688
INFO: dictionary score: -0.3945773
INFO: container score: -0.39410257
INFO: name score: -0.39156502
INFO: print score: -0.3872707
INFO: customize score: -0.37271485
INFO: work score: -0.3612787
INFO: help score: -0.35769176
INFO: look score: -0.35728312
INFO: eq score: -0.3362795
INFO: string score: -0.33071244
INFO: field score: -0.31438157
INFO: datum score: -0.31419736
INFO: tuple score: -0.31045988
INFO: course score: -0.31021985
INFO: mutate score: -0.30040166
INFO: right score: -0.2764877
INFO: outer score: -0.26723525
INFO: replica score: -0.26429802
INFO: import score: -0.25121382
INFO: nice score: -0.2433398
INFO: hook score: -0.22819598
INFO: place score: -0.22457385
INFO: foo score: -0.2237768
INFO: library score: -0.21913019
INFO: args score: -0.18219808
INFO: story score: -0.1503216
INFO: board score: -0.093044505
INFO: member score: -0.08232218
INFO: dict_b score: -0.0
INFO: deepcopy score: -0.0
INFO: foo(5 score: -0.0
INFO: lots_of_data score: -0.0
INFO: ============================================================
INFO: --------------------
INFO: How can I find the methods or attributes of an object?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<448 unique tokens: ["'", 'a.', 'a.__class__.__getattribute__(a', 'a.m', 'addmethod']...> from 9 documents (total 1382 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<448 unique tokens: ["\'", \'a.\', \'a.__class__.__getattribute__(a\', \'a.m\', \'addmethod\']...> from 9 documents (total 1382 corpus positions)', 'datetime': '2023-04-18T14:16:25.671800', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 9 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.422 per-word bound, 171.5 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 0, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.094*"method" + 0.056*"function" + 0.051*"class" + 0.047*"instance" + 0.040*"object" + 0.018*"attribute" + 0.016*"code" + 0.012*"way" + 0.012*"argument" + 0.012*"list"
INFO: topic #1 (1.000): 0.133*"method" + 0.068*"class" + 0.033*"object" + 0.029*"list" + 0.023*"instance" + 0.021*"attribute" + 0.020*"function" + 0.016*"dir" + 0.012*"return" + 0.012*"code"
INFO: topic #2 (1.000): 0.083*"method" + 0.042*"class" + 0.036*"object" + 0.028*"instance" + 0.024*"attribute" + 0.017*"list" + 0.017*"function" + 0.012*"dir" + 0.011*"name" + 0.010*"return"
INFO: topic diff=3.055727, rho=1.000000
DEBUG: bound: at document #0
INFO: -9.030 per-word bound, 522.9 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 0, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.119*"method" + 0.068*"function" + 0.066*"instance" + 0.060*"class" + 0.058*"object" + 0.028*"attribute" + 0.022*"self" + 0.016*"first" + 0.015*"unbound" + 0.014*"descriptor"
INFO: topic #1 (1.000): 0.134*"method" + 0.072*"class" + 0.036*"object" + 0.025*"attribute" + 0.025*"instance" + 0.022*"list" + 0.021*"function" + 0.011*"dir" + 0.011*"return" + 0.011*"foo"
INFO: topic #2 (1.000): 0.066*"method" + 0.034*"class" + 0.028*"object" + 0.023*"attribute" + 0.023*"instance" + 0.014*"function" + 0.010*"list" + 0.008*"return" + 0.008*"equivalent" + 0.007*"access"
INFO: topic diff=2.285314, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 59.77520995198171
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.8081128087387602
DEBUG: bound: at document #0
INFO: -5.841 per-word bound, 57.3 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 1, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.104*"method" + 0.066*"function" + 0.060*"instance" + 0.055*"class" + 0.048*"object" + 0.021*"attribute" + 0.016*"descriptor" + 0.015*"code" + 0.014*"argument" + 0.013*"first"
INFO: topic #1 (1.000): 0.128*"method" + 0.066*"class" + 0.035*"object" + 0.033*"list" + 0.023*"attribute" + 0.020*"instance" + 0.018*"dir" + 0.018*"function" + 0.014*"return" + 0.014*"name"
INFO: topic #2 (1.000): 0.049*"method" + 0.024*"class" + 0.020*"object" + 0.018*"attribute" + 0.017*"instance" + 0.010*"function" + 0.007*"list" + 0.007*"store" + 0.006*"return" + 0.006*"equivalent"
INFO: topic diff=1.238595, rho=0.512989
DEBUG: bound: at document #0
INFO: -6.913 per-word bound, 120.5 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 1, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.115*"method" + 0.065*"function" + 0.064*"instance" + 0.059*"class" + 0.056*"object" + 0.027*"attribute" + 0.020*"self" + 0.016*"first" + 0.015*"descriptor" + 0.014*"unbound"
INFO: topic #1 (1.000): 0.120*"method" + 0.065*"class" + 0.033*"object" + 0.031*"list" + 0.023*"attribute" + 0.019*"instance" + 0.017*"function" + 0.017*"dir" + 0.013*"return" + 0.012*"name"
INFO: topic #2 (1.000): 0.040*"method" + 0.021*"restriction" + 0.016*"class" + 0.014*"statement" + 0.014*"block" + 0.014*"stack" + 0.014*"look" + 0.014*"peek" + 0.013*"attribute" + 0.011*"creator"
INFO: topic diff=1.094938, rho=0.512989
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 49.280574271834645
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -3.7521958775817583
DEBUG: bound: at document #0
INFO: -5.661 per-word bound, 50.6 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 2, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.104*"method" + 0.065*"function" + 0.063*"instance" + 0.056*"class" + 0.046*"object" + 0.022*"attribute" + 0.017*"descriptor" + 0.015*"argument" + 0.014*"code" + 0.014*"first"
INFO: topic #1 (1.000): 0.123*"method" + 0.063*"class" + 0.037*"object" + 0.034*"list" + 0.023*"attribute" + 0.019*"dir" + 0.019*"function" + 0.018*"instance" + 0.015*"return" + 0.015*"name"
INFO: topic #2 (1.000): 0.031*"method" + 0.015*"restriction" + 0.012*"class" + 0.011*"attribute" + 0.011*"look" + 0.011*"peek" + 0.011*"stack" + 0.011*"statement" + 0.011*"block" + 0.008*"foo.bar"
INFO: topic diff=0.739679, rho=0.456435
DEBUG: bound: at document #0
INFO: -5.989 per-word bound, 63.5 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 2, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.115*"method" + 0.066*"instance" + 0.065*"function" + 0.060*"class" + 0.054*"object" + 0.027*"attribute" + 0.020*"self" + 0.016*"first" + 0.015*"descriptor" + 0.015*"unbound"
INFO: topic #1 (1.000): 0.118*"method" + 0.062*"class" + 0.035*"object" + 0.032*"list" + 0.022*"attribute" + 0.018*"function" + 0.018*"dir" + 0.017*"instance" + 0.015*"return" + 0.014*"name"
INFO: topic #2 (1.000): 0.028*"method" + 0.028*"restriction" + 0.016*"block" + 0.016*"look" + 0.016*"peek" + 0.016*"stack" + 0.016*"statement" + 0.015*"instance.functionname" + 0.015*"history" + 0.015*"foo.bar"
INFO: topic diff=0.591688, rho=0.456435
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 47.054900398125916
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -5.174760513453884
DEBUG: bound: at document #0
INFO: -5.592 per-word bound, 48.2 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 3, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.105*"method" + 0.065*"function" + 0.064*"instance" + 0.057*"class" + 0.045*"object" + 0.022*"attribute" + 0.017*"descriptor" + 0.014*"argument" + 0.014*"first" + 0.014*"code"
INFO: topic #1 (1.000): 0.122*"method" + 0.061*"class" + 0.039*"object" + 0.034*"list" + 0.023*"attribute" + 0.020*"function" + 0.020*"dir" + 0.016*"instance" + 0.016*"return" + 0.015*"name"
INFO: topic #2 (1.000): 0.023*"method" + 0.021*"restriction" + 0.012*"stack" + 0.012*"block" + 0.012*"look" + 0.012*"peek" + 0.012*"statement" + 0.011*"guido" + 0.011*"instance.functionname" + 0.011*"history"
INFO: topic diff=0.492414, rho=0.415227
DEBUG: bound: at document #0
INFO: -5.856 per-word bound, 57.9 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 3, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.116*"method" + 0.067*"instance" + 0.065*"function" + 0.060*"class" + 0.053*"object" + 0.027*"attribute" + 0.020*"self" + 0.016*"first" + 0.016*"descriptor" + 0.015*"unbound"
INFO: topic #1 (1.000): 0.117*"method" + 0.061*"class" + 0.037*"object" + 0.033*"list" + 0.023*"attribute" + 0.019*"function" + 0.018*"dir" + 0.015*"instance" + 0.015*"return" + 0.014*"name"
INFO: topic #2 (1.000): 0.030*"restriction" + 0.021*"method" + 0.016*"stack" + 0.016*"block" + 0.016*"look" + 0.016*"peek" + 0.016*"statement" + 0.016*"guido" + 0.016*"instance.functionname" + 0.016*"history"
INFO: topic diff=0.419555, rho=0.415227
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 46.33140158937258
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -5.1593572427747745
DEBUG: bound: at document #0
INFO: -5.563 per-word bound, 47.3 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 4, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.106*"method" + 0.065*"instance" + 0.064*"function" + 0.058*"class" + 0.045*"object" + 0.022*"attribute" + 0.017*"descriptor" + 0.014*"argument" + 0.014*"first" + 0.014*"self"
INFO: topic #1 (1.000): 0.122*"method" + 0.061*"class" + 0.039*"object" + 0.035*"list" + 0.023*"attribute" + 0.021*"function" + 0.020*"dir" + 0.016*"return" + 0.015*"instance" + 0.015*"name"
INFO: topic #2 (1.000): 0.024*"restriction" + 0.017*"method" + 0.013*"store" + 0.013*"look" + 0.013*"block" + 0.013*"statement" + 0.013*"peek" + 0.013*"stack" + 0.012*"history" + 0.012*"instance.functionname"
INFO: topic diff=0.380204, rho=0.383482
DEBUG: bound: at document #0
INFO: -5.813 per-word bound, 56.2 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 4, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.116*"method" + 0.067*"instance" + 0.065*"function" + 0.060*"class" + 0.052*"object" + 0.027*"attribute" + 0.019*"self" + 0.016*"first" + 0.016*"descriptor" + 0.015*"unbound"
INFO: topic #1 (1.000): 0.117*"method" + 0.060*"class" + 0.038*"object" + 0.034*"list" + 0.023*"attribute" + 0.020*"function" + 0.019*"dir" + 0.015*"return" + 0.015*"instance" + 0.014*"name"
INFO: topic #2 (1.000): 0.031*"restriction" + 0.016*"peek" + 0.016*"stack" + 0.016*"block" + 0.016*"statement" + 0.016*"look" + 0.016*"concept" + 0.016*"instance.functionname" + 0.016*"guido" + 0.016*"history"
INFO: topic diff=0.324263, rho=0.383482
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 46.02047176519147
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -5.034989220454286
DEBUG: bound: at document #0
INFO: -5.546 per-word bound, 46.7 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 5, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.107*"method" + 0.066*"instance" + 0.064*"function" + 0.058*"class" + 0.045*"object" + 0.023*"attribute" + 0.017*"descriptor" + 0.014*"first" + 0.014*"argument" + 0.014*"self"
INFO: topic #1 (1.000): 0.121*"method" + 0.060*"class" + 0.040*"object" + 0.035*"list" + 0.023*"attribute" + 0.021*"function" + 0.020*"dir" + 0.016*"return" + 0.015*"instance" + 0.015*"name"
INFO: topic #2 (1.000): 0.025*"restriction" + 0.014*"store" + 0.013*"look" + 0.013*"peek" + 0.013*"stack" + 0.013*"statement" + 0.013*"block" + 0.013*"creator" + 0.013*"instance.functionname" + 0.013*"full"
INFO: topic diff=0.316086, rho=0.358057
DEBUG: bound: at document #0
INFO: -5.791 per-word bound, 55.4 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 5, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.116*"method" + 0.067*"instance" + 0.065*"function" + 0.060*"class" + 0.051*"object" + 0.026*"attribute" + 0.019*"self" + 0.016*"descriptor" + 0.016*"first" + 0.014*"unbound"
INFO: topic #1 (1.000): 0.117*"method" + 0.060*"class" + 0.038*"object" + 0.034*"list" + 0.023*"attribute" + 0.020*"function" + 0.019*"dir" + 0.015*"return" + 0.014*"instance" + 0.014*"name"
INFO: topic #2 (1.000): 0.031*"restriction" + 0.016*"statement" + 0.016*"peek" + 0.016*"block" + 0.016*"look" + 0.016*"stack" + 0.016*"duck" + 0.016*"design" + 0.016*"filling" + 0.016*"foo.bar"
INFO: topic diff=0.275402, rho=0.358057
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 45.847044644421686
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -5.033336305259366
DEBUG: bound: at document #0
INFO: -5.536 per-word bound, 46.4 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 6, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.107*"method" + 0.066*"instance" + 0.064*"function" + 0.058*"class" + 0.045*"object" + 0.023*"attribute" + 0.017*"descriptor" + 0.015*"first" + 0.014*"argument" + 0.014*"self"
INFO: topic #1 (1.000): 0.121*"method" + 0.060*"class" + 0.040*"object" + 0.035*"list" + 0.023*"attribute" + 0.021*"function" + 0.020*"dir" + 0.016*"return" + 0.015*"name" + 0.015*"instance"
INFO: topic #2 (1.000): 0.025*"restriction" + 0.015*"store" + 0.013*"peek" + 0.013*"statement" + 0.013*"stack" + 0.013*"block" + 0.013*"look" + 0.013*"memory" + 0.013*"x.f" + 0.013*"explanation"
INFO: topic diff=0.276815, rho=0.337100
DEBUG: bound: at document #0
INFO: -5.777 per-word bound, 54.8 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 6, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.116*"method" + 0.067*"instance" + 0.064*"function" + 0.060*"class" + 0.051*"object" + 0.026*"attribute" + 0.019*"self" + 0.016*"descriptor" + 0.016*"first" + 0.014*"unbound"
INFO: topic #1 (1.000): 0.117*"method" + 0.060*"class" + 0.039*"object" + 0.034*"list" + 0.023*"attribute" + 0.021*"function" + 0.019*"dir" + 0.015*"return" + 0.014*"name" + 0.014*"instance"
INFO: topic #2 (1.000): 0.031*"restriction" + 0.016*"peek" + 0.016*"look" + 0.016*"statement" + 0.016*"block" + 0.016*"stack" + 0.016*"memory" + 0.016*"instance.functionname" + 0.016*"history" + 0.016*"full"
INFO: topic diff=0.249064, rho=0.337100
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 45.728596125905156
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -5.027060024812053
DEBUG: bound: at document #0
INFO: -5.527 per-word bound, 46.1 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 7, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.108*"method" + 0.066*"instance" + 0.064*"function" + 0.058*"class" + 0.045*"object" + 0.023*"attribute" + 0.017*"descriptor" + 0.015*"first" + 0.014*"self" + 0.014*"argument"
INFO: topic #1 (1.000): 0.121*"method" + 0.060*"class" + 0.040*"object" + 0.035*"list" + 0.023*"attribute" + 0.021*"function" + 0.020*"dir" + 0.016*"return" + 0.015*"name" + 0.015*"instance"
INFO: topic #2 (1.000): 0.026*"restriction" + 0.015*"store" + 0.014*"look" + 0.014*"stack" + 0.014*"statement" + 0.014*"block" + 0.014*"peek" + 0.013*"memory" + 0.013*"creator" + 0.013*"instance.functionname"
INFO: topic diff=0.250505, rho=0.319438
DEBUG: bound: at document #0
INFO: -5.767 per-word bound, 54.4 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 7, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.116*"method" + 0.067*"instance" + 0.064*"function" + 0.060*"class" + 0.051*"object" + 0.026*"attribute" + 0.019*"self" + 0.016*"descriptor" + 0.016*"first" + 0.014*"unbound"
INFO: topic #1 (1.000): 0.117*"method" + 0.060*"class" + 0.039*"object" + 0.035*"list" + 0.023*"attribute" + 0.021*"function" + 0.019*"dir" + 0.015*"return" + 0.014*"name" + 0.014*"instance"
INFO: topic #2 (1.000): 0.031*"restriction" + 0.016*"stack" + 0.016*"peek" + 0.016*"block" + 0.016*"statement" + 0.016*"look" + 0.016*"duck" + 0.016*"x.f" + 0.016*"class.functionname" + 0.016*"memory"
INFO: topic diff=0.232337, rho=0.319438
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 45.63904625518904
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -5.027060024812053
DEBUG: bound: at document #0
INFO: -5.521 per-word bound, 45.9 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 8, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.108*"method" + 0.066*"instance" + 0.064*"function" + 0.058*"class" + 0.045*"object" + 0.023*"attribute" + 0.017*"descriptor" + 0.015*"first" + 0.014*"self" + 0.014*"argument"
INFO: topic #1 (1.000): 0.121*"method" + 0.060*"class" + 0.040*"object" + 0.035*"list" + 0.023*"attribute" + 0.021*"function" + 0.020*"dir" + 0.016*"return" + 0.015*"name" + 0.014*"instance"
INFO: topic #2 (1.000): 0.026*"restriction" + 0.015*"store" + 0.014*"look" + 0.014*"stack" + 0.014*"statement" + 0.014*"block" + 0.014*"peek" + 0.014*"history" + 0.014*"filling" + 0.014*"guido"
INFO: topic diff=0.232252, rho=0.304290
DEBUG: bound: at document #0
INFO: -5.758 per-word bound, 54.1 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 8, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.116*"method" + 0.067*"instance" + 0.064*"function" + 0.060*"class" + 0.050*"object" + 0.026*"attribute" + 0.018*"self" + 0.016*"descriptor" + 0.016*"first" + 0.014*"unbound"
INFO: topic #1 (1.000): 0.118*"method" + 0.060*"class" + 0.039*"object" + 0.035*"list" + 0.023*"attribute" + 0.021*"function" + 0.019*"dir" + 0.015*"return" + 0.014*"name" + 0.014*"instance"
INFO: topic #2 (1.000): 0.031*"restriction" + 0.016*"peek" + 0.016*"statement" + 0.016*"block" + 0.016*"stack" + 0.016*"look" + 0.016*"concept" + 0.016*"creator" + 0.016*"design" + 0.016*"memory"
INFO: topic diff=0.219974, rho=0.304290
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 45.5680410615528
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -5.027060024812053
DEBUG: bound: at document #0
INFO: -5.516 per-word bound, 45.7 perplexity estimate based on a held-out corpus of 5 documents with 1062 words
INFO: PROGRESS: pass 9, at document #5/9
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.108*"method" + 0.066*"instance" + 0.064*"function" + 0.058*"class" + 0.045*"object" + 0.023*"attribute" + 0.017*"descriptor" + 0.015*"first" + 0.014*"self" + 0.014*"argument"
INFO: topic #1 (1.000): 0.121*"method" + 0.060*"class" + 0.040*"object" + 0.035*"list" + 0.023*"attribute" + 0.021*"function" + 0.020*"dir" + 0.016*"return" + 0.015*"name" + 0.014*"instance"
INFO: topic #2 (1.000): 0.026*"restriction" + 0.015*"store" + 0.014*"stack" + 0.014*"peek" + 0.014*"look" + 0.014*"block" + 0.014*"statement" + 0.014*"x.f" + 0.014*"rossum" + 0.014*"van"
INFO: topic diff=0.218168, rho=0.291111
DEBUG: bound: at document #0
INFO: -5.751 per-word bound, 53.9 perplexity estimate based on a held-out corpus of 4 documents with 320 words
INFO: PROGRESS: pass 9, at document #9/9
DEBUG: performing inference on a chunk of 4 documents
DEBUG: 4/4 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 4 documents into a model of 9 documents
INFO: topic #0 (1.000): 0.115*"method" + 0.067*"instance" + 0.064*"function" + 0.060*"class" + 0.050*"object" + 0.026*"attribute" + 0.018*"self" + 0.016*"descriptor" + 0.016*"first" + 0.014*"unbound"
INFO: topic #1 (1.000): 0.118*"method" + 0.060*"class" + 0.039*"object" + 0.035*"list" + 0.023*"attribute" + 0.021*"function" + 0.019*"dir" + 0.015*"return" + 0.014*"name" + 0.014*"instance"
INFO: topic #2 (1.000): 0.031*"restriction" + 0.016*"block" + 0.016*"look" + 0.016*"peek" + 0.016*"stack" + 0.016*"statement" + 0.016*"memory" + 0.016*"instance.functionname" + 0.016*"history" + 0.016*"duck"
INFO: topic diff=0.209045, rho=0.291111
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 45.510310677007375
DEBUG: Setting topics to those of the model: LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -5.027060024812053
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=448, num_topics=3, decay=0.5, chunksize=5> in 0.24s', 'datetime': '2023-04-18T14:16:25.910192', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/cos_threshold/11/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-18T14:16:25.910348', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/cos_threshold/11/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/11/model.state
DEBUG: {'uri': 'model/cos_threshold/11/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/cos_threshold/11/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['state', 'id2word', 'dispatcher'], 'datetime': '2023-04-18T14:16:25.913984', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/cos_threshold/11/model.expElogbeta.npy
INFO: not storing attribute state
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
DEBUG: {'uri': 'model/cos_threshold/11/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/11/model
INFO: topic #0 (1.000): 0.115*"method" + 0.067*"instance" + 0.064*"function" + 0.060*"class" + 0.050*"object" + 0.026*"attribute" + 0.018*"self" + 0.016*"descriptor" + 0.016*"first" + 0.014*"unbound"
INFO: topic #1 (1.000): 0.118*"method" + 0.060*"class" + 0.039*"object" + 0.035*"list" + 0.023*"attribute" + 0.021*"function" + 0.019*"dir" + 0.015*"return" + 0.014*"name" + 0.014*"instance"
INFO: topic #2 (1.000): 0.031*"restriction" + 0.016*"block" + 0.016*"look" + 0.016*"peek" + 0.016*"stack" + 0.016*"statement" + 0.016*"memory" + 0.016*"instance.functionname" + 0.016*"history" + 0.016*"duck"
INFO: Question Similarity: [0.10374921560287476, 0.08703142404556274, 0.09539961814880371, 0.08364278078079224, 0.12477689981460571, 0.1220749020576477, 0.06367868185043335, 0.05145597457885742, 0.2589115500450134, 0.29363518953323364]
INFO: 73990556: -0.25089039472816904
INFO: 68418526: -0.25687906562102053
INFO: 73990545: -0.25797364900050906
INFO: 68418456: -0.26822596871027327
INFO: 52331202: -0.562336898315587
INFO: 14298870: -0.615571037987051
INFO: 14298889: -0.6396222908894748
INFO: Recommended Keywords
INFO: instance score: -0.8616187
INFO: example score: -0.85878897
INFO: particular score: -0.82910615
INFO: possible score: -0.81228197
INFO: difference score: -0.798649
INFO: simple score: -0.7948421
INFO: object score: -0.7874098
INFO: function score: -0.7797803
INFO: method score: -0.7639562
INFO: attribute score: -0.75882006
INFO: useful score: -0.7552532
INFO: normal score: -0.7472289
INFO: order score: -0.7425681
INFO: correct score: -0.7412514
INFO: process score: -0.73954135
INFO: reference score: -0.7362002
INFO: type score: -0.72874224
INFO: direct score: -0.72831523
INFO: definition score: -0.7236622
INFO: see score: -0.7208205
INFO: usual score: -0.7200499
INFO: specific score: -0.71473205
INFO: fact score: -0.71307856
INFO: distinguish score: -0.71190614
INFO: case score: -0.71168846
INFO: true score: -0.70755213
INFO: equivalent score: -0.70447814
INFO: change score: -0.6998202
INFO: non score: -0.6996108
INFO: representation score: -0.68913895
INFO: restriction score: -0.6804605
INFO: problem score: -0.67898303
INFO: result score: -0.6780158
INFO: descriptor score: -0.6721469
INFO: solution score: -0.6669833
INFO: identical score: -0.6652022
INFO: mechanism score: -0.661431
INFO: external score: -0.65635407
INFO: different score: -0.65546787
INFO: model score: -0.6536942
INFO: source score: -0.6486948
INFO: least score: -0.64814025
INFO: key score: -0.64443713
INFO: valid score: -0.64283746
INFO: incorrect score: -0.63971865
INFO: need score: -0.63463545
INFO: clear score: -0.631688
INFO: convenient score: -0.629488
INFO: self score: -0.62791175
INFO: unbound score: -0.62308145
INFO: reason score: -0.6194148
INFO: generalized score: -0.6168339
INFO: condition score: -0.6165066
INFO: observe score: -0.61038136
INFO: variable score: -0.60894924
INFO: distinct score: -0.6028782
INFO: error score: -0.60102445
INFO: erroneous score: -0.59939444
INFO: whole score: -0.59333086
INFO: confuse score: -0.58922523
INFO: exception score: -0.5887271
INFO: approach score: -0.58717835
INFO: value score: -0.5838623
INFO: remove score: -0.5832256
INFO: important score: -0.58203995
INFO: other score: -0.5815541
INFO: persistent score: -0.57949823
INFO: cycle score: -0.5779085
INFO: completeness score: -0.57322866
INFO: create score: -0.57163626
INFO: easy score: -0.5648146
INFO: argument score: -0.56471175
INFO: descriptive score: -0.564236
INFO: code score: -0.5633999
INFO: behaviour score: -0.56291753
INFO: point score: -0.5587933
INFO: parenthesis score: -0.55754364
INFO: overridden score: -0.55125874
INFO: information score: -0.55046237
INFO: question score: -0.5501063
INFO: scope score: -0.5479709
INFO: execute score: -0.5477174
INFO: attach score: -0.54474205
INFO: reliable score: -0.54392093
INFO: separate score: -0.5434519
INFO: note score: -0.54337287
INFO: item score: -0.53921664
INFO: way score: -0.5385828
INFO: person score: -0.5346503
INFO: current score: -0.5341449
INFO: signature score: -0.5323172
INFO: assure score: -0.5308168
INFO: bind score: -0.5213121
INFO: simulate score: -0.5193083
INFO: well score: -0.51897204
INFO: class score: -0.5175371
INFO: test score: -0.5153847
INFO: data score: -0.51498896
INFO: provide score: -0.5124212
INFO: observation score: -0.50667936
INFO: guide score: -0.50249565
INFO: write score: -0.50207293
INFO: due score: -0.50167555
INFO: detail score: -0.50139874
INFO: static score: -0.4952236
INFO: parameter score: -0.4929794
INFO: name score: -0.49089903
INFO: link score: -0.48859936
INFO: abstract score: -0.48796454
INFO: open score: -0.48560333
INFO: many score: -0.48524
INFO: interesting score: -0.48394996
INFO: call score: -0.48031178
INFO: empty score: -0.4801323
INFO: module score: -0.4798386
INFO: output score: -0.47937477
INFO: statement score: -0.4789763
INFO: level score: -0.47653744
INFO: list score: -0.46840307
INFO: extensions score: -0.4678733
INFO: stack score: -0.46355572
INFO: single score: -0.4604949
INFO: little score: -0.45788056
INFO: sub score: -0.45047155
INFO: user score: -0.4504287
INFO: paragraph score: -0.44851336
INFO: protocol score: -0.44764215
INFO: block score: -0.44584715
INFO: display score: -0.44504628
INFO: believe score: -0.43995044
INFO: encode score: -0.4386297
INFO: good score: -0.43605068
INFO: operation score: -0.43334377
INFO: know score: -0.43106017
INFO: virtual score: -0.42800164
INFO: directive score: -0.42723572
INFO: wrong score: -0.42035627
INFO: base score: -0.41870633
INFO: documentation score: -0.41796827
INFO: look score: -0.41513366
INFO: time score: -0.4137273
INFO: available score: -0.41248995
INFO: notice score: -0.41020975
INFO: sure score: -0.4082299
INFO: none score: -0.406736
INFO: addendum score: -0.40544772
INFO: original score: -0.40371633
INFO: in score: -0.39811817
INFO: pointer score: -0.3945505
INFO: field score: -0.39438125
INFO: comprehension score: -0.39361784
INFO: wrapping score: -0.39076945
INFO: file score: -0.38981846
INFO: c score: -0.3889022
INFO: regular score: -0.38449278
INFO: right score: -0.38276443
INFO: interested score: -0.38100597
INFO: recent score: -0.3779334
INFO: comment score: -0.3764172
INFO: work score: -0.37347168
INFO: post score: -0.3728824
INFO: string score: -0.3722143
INFO: low score: -0.3651921
INFO: overwrite score: -0.36390916
INFO: dictionary score: -0.36358976
INFO: force score: -0.36307114
INFO: design score: -0.35813743
INFO: workaround score: -0.35560215
INFO: first score: -0.3537268
INFO: enum score: -0.3529671
INFO: compiler score: -0.35204056
INFO: return score: -0.35129872
INFO: new score: -0.35069996
INFO: answer score: -0.3506065
INFO: issue score: -0.34582916
INFO: tuple score: -0.3447501
INFO: property score: -0.3436024
INFO: language score: -0.34274608
INFO: runtime score: -0.34114638
INFO: version score: -0.34011602
INFO: patch score: -0.33949175
INFO: callable score: -0.33745262
INFO: needle score: -0.3329454
INFO: page score: -0.33067784
INFO: poor score: -0.32773852
INFO: global score: -0.32664204
INFO: inspect score: -0.3248906
INFO: place score: -0.3233908
INFO: excellent score: -0.32266715
INFO: access score: -0.32252455
INFO: directory score: -0.32003686
INFO: import score: -0.31908387
INFO: reachable score: -0.3178187
INFO: builtin score: -0.31194952
INFO: foo score: -0.30639154
INFO: print score: -0.3054961
INFO: leave score: -0.28846547
INFO: javascript score: -0.2879212
INFO: wrap score: -0.28363848
INFO: tab score: -0.28294128
INFO: intolerant score: -0.28015393
INFO: autocompletion score: -0.2793012
INFO: dict score: -0.27864134
INFO: obj score: -0.2737045
INFO: dot score: -0.27340922
INFO: ubuntu score: -0.26804963
INFO: magic score: -0.26368222
INFO: hack score: -0.26037073
INFO: strange score: -0.2563337
INFO: line score: -0.2517553
INFO: permission score: -0.2505335
INFO: second score: -0.25026897
INFO: binder score: -0.24929664
INFO: edit score: -0.24570113
INFO: howto score: -0.24474615
INFO: f score: -0.24400733
INFO: collection score: -0.24283332
INFO: func score: -0.24141474
INFO: tutorial score: -0.23767556
INFO: style score: -0.23630682
INFO: bash score: -0.23395239
INFO: command score: -0.23216444
INFO: local score: -0.22581097
INFO: introspection score: -0.2212628
INFO: str1 score: -0.2202283
INFO: care score: -0.21868943
INFO: lambda score: -0.21515244
INFO: people score: -0.21092597
INFO: speak score: -0.19317849
INFO: garbage score: -0.18425608
INFO: shell score: -0.18404104
INFO: old score: -0.18105139
INFO: member score: -0.17805822
INFO: nice score: -0.17708424
INFO: wiki score: -0.17513725
INFO: int score: -0.16139355
INFO: str score: -0.1600797
INFO: library score: -0.15011632
INFO: press score: -0.14705415
INFO: trick score: -0.1358053
INFO: doc score: -0.1286495
INFO: store score: -0.12617743
INFO: forgiveness score: -0.124553435
INFO: age score: -0.1199958
INFO: goal score: -0.11975442
INFO: faq score: -0.10859068
INFO: job score: -0.10591013
INFO: top score: -0.105703086
INFO: peek score: -0.09833883
INFO: dir score: -0.09347428
INFO: monkey score: -0.09317146
INFO: bar score: -0.09248549
INFO: liner score: -0.0814675
INFO: repr score: -0.080207065
INFO: community score: -0.065048225
INFO: var score: -0.048021734
INFO: thank score: -0.044429336
INFO: year score: -0.034258317
INFO: vote score: -0.014588567
INFO: track score: -0.01303849
INFO: arturo score: -0.0
INFO: zope score: -0.0
INFO: atwood score: -0.0
INFO: ipython score: -0.0
INFO: a. score: -0.0
INFO: types.functiontype score: -0.0
INFO: guineapig score: -0.0
INFO: types.methodtype score: -0.0
INFO: http://docs.python.org/library/new.html score: -0.0
INFO: patch_me score: -0.0
INFO: modifie score: -0.0
INFO: addmethod score: -0.0
INFO: setattr score: -0.0
INFO: hasattr(module_name score: -0.0
INFO: diveintopython.net score: -0.0
INFO: attributeerror score: -0.0
INFO: dir(objectname score: -0.0
INFO: print_name score: -0.0
INFO: get_object_function score: -0.0
INFO: help(dir score: -0.0
INFO: getattr score: -0.0
INFO: getattribute score: -0.0
INFO: pythonic score: -0.0
INFO: pydoc score: -0.0
INFO: repl score: -0.0
INFO: list(filter(lambda score: -0.0
INFO: callable(getattr(obj score: -0.0
INFO: inspect.ismethod score: -0.0
INFO: cython score: -0.0
INFO: getattrs score: -0.0
INFO: pytest score: -0.0
INFO: print(dir(class score: -0.0
INFO: print(help(classname score: -0.0
INFO: staticmethod score: -0.0
INFO: classmethod score: -0.0
INFO: names¹. score: -0.0
INFO: getmember score: -0.0
INFO: 3.x score: -0.0
INFO: dunder score: -0.0
INFO: functiontype score: -0.0
INFO: class.__dict score: -0.0
INFO: dir(theobject score: -0.0
INFO: codeape score: -0.0
INFO: inspect.getmember score: -0.0
INFO: person.full_name score: -0.0
INFO: person.__dict__['full_name'].__get__(none score: -0.0
INFO: @mgilson score: -0.0
INFO: wombatz score: -0.0
INFO: c.function score: -0.0
INFO: myclass.f score: -0.0
INFO: x.f score: -0.0
INFO: class.functionname score: -0.0
INFO: instance.functionname score: -0.0
INFO: foo.bar score: -0.0
INFO: pratt score: 0.0039035538
INFO: gorilla score: 0.0045059435
INFO: jeff score: 0.009608205
INFO: ahh score: 0.011975255
INFO: decorator score: 0.030545348
INFO: jason score: 0.045127086
INFO: route score: 0.13229834
INFO: ============================================================
INFO: --------------------
INFO: How can my code discover the name of an object?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<599 unique tokens: ['=', '@aivar', '@juan', '@mherzog)-', '@scohe001']...> from 10 documents (total 2018 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<599 unique tokens: ['=', '@aivar', '@juan', '@mherzog)-', '@scohe001']...> from 10 documents (total 2018 corpus positions)", 'datetime': '2023-04-18T14:16:29.430498', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.557 per-word bound, 188.3 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.057*"name" + 0.041*"function" + 0.041*"object" + 0.037*"variable" + 0.025*"code" + 0.018*"value" + 0.017*"list" + 0.013*"global" + 0.011*"class" + 0.011*"frame"
INFO: topic #1 (1.000): 0.086*"name" + 0.057*"variable" + 0.049*"function" + 0.035*"object" + 0.021*"value" + 0.020*"code" + 0.017*"string" + 0.014*"list" + 0.013*"class" + 0.011*"frame"
INFO: topic #2 (1.000): 0.057*"name" + 0.047*"object" + 0.025*"variable" + 0.025*"function" + 0.018*"code" + 0.017*"class" + 0.012*"value" + 0.011*"list" + 0.010*"global" + 0.010*"frame"
INFO: topic diff=3.198073, rho=1.000000
DEBUG: bound: at document #0
INFO: -10.088 per-word bound, 1088.3 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.051*"name" + 0.048*"object" + 0.031*"function" + 0.031*"variable" + 0.024*"code" + 0.022*"instance" + 0.020*"class" + 0.014*"value" + 0.013*"list" + 0.010*"way"
INFO: topic #1 (1.000): 0.086*"name" + 0.054*"object" + 0.053*"variable" + 0.041*"function" + 0.027*"class" + 0.022*"value" + 0.022*"code" + 0.018*"instance" + 0.017*"reference" + 0.014*"way"
INFO: topic #2 (1.000): 0.051*"object" + 0.045*"name" + 0.039*"class" + 0.032*"instance" + 0.018*"code" + 0.017*"variable" + 0.016*"function" + 0.009*"c" + 0.008*"way" + 0.007*"value"
INFO: topic diff=2.198685, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 77.72683095904236
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -0.27465983121831433
DEBUG: bound: at document #0
INFO: -6.016 per-word bound, 64.7 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.052*"object" + 0.046*"name" + 0.028*"code" + 0.027*"function" + 0.019*"variable" + 0.016*"class" + 0.015*"instance" + 0.013*"source" + 0.011*"method" + 0.011*"file"
INFO: topic #1 (1.000): 0.086*"name" + 0.058*"variable" + 0.048*"function" + 0.040*"object" + 0.023*"value" + 0.020*"code" + 0.017*"class" + 0.016*"string" + 0.015*"list" + 0.012*"example"
INFO: topic #2 (1.000): 0.044*"object" + 0.037*"name" + 0.031*"class" + 0.025*"instance" + 0.013*"code" + 0.012*"function" + 0.012*"variable" + 0.012*"c" + 0.008*"global" + 0.007*"method"
INFO: topic diff=1.235844, rho=0.500000
DEBUG: bound: at document #0
INFO: -7.992 per-word bound, 254.6 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.053*"object" + 0.043*"name" + 0.025*"code" + 0.023*"function" + 0.018*"variable" + 0.016*"class" + 0.016*"instance" + 0.011*"way" + 0.011*"line" + 0.011*"source"
INFO: topic #1 (1.000): 0.085*"name" + 0.056*"variable" + 0.048*"object" + 0.043*"function" + 0.023*"value" + 0.020*"code" + 0.019*"class" + 0.016*"reference" + 0.014*"string" + 0.014*"list"
INFO: topic #2 (1.000): 0.063*"class" + 0.061*"instance" + 0.044*"object" + 0.031*"name" + 0.030*"garbage" + 0.014*"code" + 0.013*"design" + 0.013*"quick" + 0.009*"collection" + 0.009*"choice"
INFO: topic diff=1.110288, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 62.205736556975644
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -2.1162439672044275
DEBUG: bound: at document #0
INFO: -5.845 per-word bound, 57.5 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.056*"object" + 0.046*"name" + 0.029*"code" + 0.026*"function" + 0.016*"variable" + 0.015*"class" + 0.014*"source" + 0.012*"method" + 0.012*"way" + 0.012*"file"
INFO: topic #1 (1.000): 0.086*"name" + 0.059*"variable" + 0.048*"function" + 0.039*"object" + 0.024*"value" + 0.019*"code" + 0.016*"string" + 0.016*"list" + 0.015*"class" + 0.012*"example"
INFO: topic #2 (1.000): 0.055*"class" + 0.053*"instance" + 0.040*"object" + 0.027*"name" + 0.024*"garbage" + 0.012*"code" + 0.011*"c" + 0.011*"design" + 0.011*"quick" + 0.008*"collection"
INFO: topic diff=0.770513, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.824 per-word bound, 113.3 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.056*"object" + 0.044*"name" + 0.026*"code" + 0.023*"function" + 0.015*"variable" + 0.014*"class" + 0.012*"source" + 0.012*"way" + 0.012*"line" + 0.011*"instance"
INFO: topic #1 (1.000): 0.086*"name" + 0.057*"variable" + 0.046*"object" + 0.044*"function" + 0.024*"value" + 0.020*"code" + 0.015*"reference" + 0.015*"list" + 0.015*"class" + 0.015*"string"
INFO: topic #2 (1.000): 0.078*"class" + 0.077*"instance" + 0.043*"object" + 0.035*"garbage" + 0.025*"name" + 0.014*"code" + 0.014*"design" + 0.014*"quick" + 0.011*"collection" + 0.010*"choice"
INFO: topic diff=0.540783, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 59.87558325950355
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -2.080873084072698
DEBUG: bound: at document #0
INFO: -5.787 per-word bound, 55.2 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.057*"object" + 0.047*"name" + 0.029*"code" + 0.026*"function" + 0.016*"variable" + 0.015*"source" + 0.012*"class" + 0.012*"way" + 0.012*"method" + 0.012*"file"
INFO: topic #1 (1.000): 0.086*"name" + 0.059*"variable" + 0.048*"function" + 0.038*"object" + 0.024*"value" + 0.019*"code" + 0.016*"list" + 0.016*"string" + 0.013*"class" + 0.012*"example"
INFO: topic #2 (1.000): 0.073*"class" + 0.071*"instance" + 0.040*"object" + 0.029*"garbage" + 0.023*"name" + 0.012*"code" + 0.012*"design" + 0.012*"quick" + 0.012*"c" + 0.010*"track"
INFO: topic diff=0.508856, rho=0.408248
DEBUG: bound: at document #0
INFO: -6.696 per-word bound, 103.7 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.058*"object" + 0.045*"name" + 0.027*"code" + 0.023*"function" + 0.015*"variable" + 0.013*"source" + 0.013*"way" + 0.012*"line" + 0.011*"class" + 0.011*"method"
INFO: topic #1 (1.000): 0.086*"name" + 0.058*"variable" + 0.045*"function" + 0.045*"object" + 0.024*"value" + 0.019*"code" + 0.016*"list" + 0.015*"string" + 0.015*"reference" + 0.013*"class"
INFO: topic #2 (1.000): 0.086*"class" + 0.084*"instance" + 0.042*"object" + 0.036*"garbage" + 0.021*"name" + 0.015*"code" + 0.014*"design" + 0.014*"quick" + 0.011*"collection" + 0.011*"type"
INFO: topic diff=0.383596, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 59.14412817947629
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -1.4524969601494917
DEBUG: bound: at document #0
INFO: -5.764 per-word bound, 54.3 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.058*"object" + 0.047*"name" + 0.029*"code" + 0.026*"function" + 0.015*"variable" + 0.015*"source" + 0.012*"way" + 0.012*"method" + 0.012*"file" + 0.012*"="
INFO: topic #1 (1.000): 0.087*"name" + 0.059*"variable" + 0.049*"function" + 0.038*"object" + 0.024*"value" + 0.019*"code" + 0.016*"list" + 0.016*"string" + 0.012*"class" + 0.012*"example"
INFO: topic #2 (1.000): 0.082*"class" + 0.079*"instance" + 0.039*"object" + 0.030*"garbage" + 0.019*"name" + 0.013*"code" + 0.012*"design" + 0.012*"quick" + 0.012*"c" + 0.012*"track"
INFO: topic diff=0.393316, rho=0.377964
DEBUG: bound: at document #0
INFO: -6.648 per-word bound, 100.3 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"object" + 0.045*"name" + 0.027*"code" + 0.023*"function" + 0.015*"variable" + 0.013*"source" + 0.013*"way" + 0.012*"line" + 0.011*"method" + 0.011*"c"
INFO: topic #1 (1.000): 0.087*"name" + 0.058*"variable" + 0.046*"function" + 0.044*"object" + 0.025*"value" + 0.019*"code" + 0.016*"list" + 0.015*"string" + 0.014*"reference" + 0.013*"way"
INFO: topic #2 (1.000): 0.090*"class" + 0.087*"instance" + 0.042*"object" + 0.036*"garbage" + 0.018*"name" + 0.016*"code" + 0.015*"type" + 0.014*"design" + 0.014*"quick" + 0.012*"collection"
INFO: topic diff=0.328998, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 58.803949111573075
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -1.5142658641035176
DEBUG: bound: at document #0
INFO: -5.750 per-word bound, 53.8 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"object" + 0.047*"name" + 0.029*"code" + 0.026*"function" + 0.015*"variable" + 0.015*"source" + 0.013*"way" + 0.012*"method" + 0.012*"file" + 0.012*"="
INFO: topic #1 (1.000): 0.087*"name" + 0.059*"variable" + 0.049*"function" + 0.038*"object" + 0.025*"value" + 0.019*"code" + 0.017*"list" + 0.016*"string" + 0.012*"example" + 0.012*"class"
INFO: topic #2 (1.000): 0.087*"class" + 0.083*"instance" + 0.039*"object" + 0.031*"garbage" + 0.017*"name" + 0.014*"code" + 0.013*"track" + 0.013*"type" + 0.012*"c" + 0.012*"design"
INFO: topic diff=0.334322, rho=0.353553
DEBUG: bound: at document #0
INFO: -6.623 per-word bound, 98.5 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"object" + 0.046*"name" + 0.027*"code" + 0.024*"function" + 0.015*"variable" + 0.013*"source" + 0.013*"way" + 0.012*"line" + 0.012*"method" + 0.011*"c"
INFO: topic #1 (1.000): 0.087*"name" + 0.058*"variable" + 0.046*"function" + 0.044*"object" + 0.025*"value" + 0.019*"code" + 0.016*"list" + 0.015*"string" + 0.013*"reference" + 0.013*"way"
INFO: topic #2 (1.000): 0.092*"class" + 0.088*"instance" + 0.042*"object" + 0.036*"garbage" + 0.018*"type" + 0.017*"code" + 0.016*"name" + 0.014*"design" + 0.014*"quick" + 0.012*"collection"
INFO: topic diff=0.302518, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 58.611895996338376
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -1.5006911865942707
DEBUG: bound: at document #0
INFO: -5.741 per-word bound, 53.5 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"object" + 0.048*"name" + 0.029*"code" + 0.026*"function" + 0.015*"variable" + 0.015*"source" + 0.013*"way" + 0.012*"method" + 0.012*"file" + 0.012*"="
INFO: topic #1 (1.000): 0.087*"name" + 0.060*"variable" + 0.049*"function" + 0.038*"object" + 0.025*"value" + 0.019*"code" + 0.017*"list" + 0.016*"string" + 0.012*"example" + 0.012*"class"
INFO: topic #2 (1.000): 0.090*"class" + 0.085*"instance" + 0.039*"object" + 0.031*"garbage" + 0.015*"type" + 0.015*"code" + 0.015*"name" + 0.015*"track" + 0.012*"c" + 0.012*"design"
INFO: topic diff=0.299091, rho=0.333333
DEBUG: bound: at document #0
INFO: -6.607 per-word bound, 97.5 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"object" + 0.046*"name" + 0.027*"code" + 0.024*"function" + 0.015*"variable" + 0.014*"source" + 0.013*"way" + 0.012*"line" + 0.012*"method" + 0.011*"c"
INFO: topic #1 (1.000): 0.088*"name" + 0.059*"variable" + 0.046*"function" + 0.043*"object" + 0.025*"value" + 0.019*"code" + 0.016*"list" + 0.015*"string" + 0.013*"way" + 0.013*"reference"
INFO: topic #2 (1.000): 0.094*"class" + 0.089*"instance" + 0.042*"object" + 0.036*"garbage" + 0.019*"type" + 0.018*"code" + 0.015*"name" + 0.014*"reference" + 0.014*"design" + 0.014*"quick"
INFO: topic diff=0.280740, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 58.48871936471978
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -1.4608413143127954
DEBUG: bound: at document #0
INFO: -5.734 per-word bound, 53.2 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.059*"object" + 0.048*"name" + 0.029*"code" + 0.026*"function" + 0.016*"variable" + 0.015*"source" + 0.013*"way" + 0.012*"method" + 0.012*"file" + 0.012*"="
INFO: topic #1 (1.000): 0.087*"name" + 0.060*"variable" + 0.049*"function" + 0.038*"object" + 0.025*"value" + 0.019*"code" + 0.017*"list" + 0.016*"string" + 0.012*"example" + 0.011*"class"
INFO: topic #2 (1.000): 0.091*"class" + 0.086*"instance" + 0.039*"object" + 0.031*"garbage" + 0.017*"type" + 0.016*"code" + 0.016*"track" + 0.014*"reference" + 0.014*"name" + 0.013*"c"
INFO: topic diff=0.274807, rho=0.316228
DEBUG: bound: at document #0
INFO: -6.596 per-word bound, 96.8 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"object" + 0.047*"name" + 0.027*"code" + 0.024*"function" + 0.015*"variable" + 0.014*"source" + 0.013*"way" + 0.012*"line" + 0.012*"method" + 0.012*"c"
INFO: topic #1 (1.000): 0.088*"name" + 0.059*"variable" + 0.046*"function" + 0.043*"object" + 0.025*"value" + 0.019*"code" + 0.016*"list" + 0.015*"string" + 0.013*"way" + 0.012*"example"
INFO: topic #2 (1.000): 0.094*"class" + 0.089*"instance" + 0.041*"object" + 0.035*"garbage" + 0.020*"type" + 0.019*"code" + 0.017*"reference" + 0.014*"design" + 0.014*"quick" + 0.013*"name"
INFO: topic diff=0.262186, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 58.40020245414953
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -1.4271462888901747
DEBUG: bound: at document #0
INFO: -5.729 per-word bound, 53.0 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"object" + 0.048*"name" + 0.029*"code" + 0.026*"function" + 0.016*"variable" + 0.015*"source" + 0.013*"way" + 0.012*"method" + 0.012*"file" + 0.012*"="
INFO: topic #1 (1.000): 0.088*"name" + 0.060*"variable" + 0.049*"function" + 0.038*"object" + 0.025*"value" + 0.019*"code" + 0.017*"list" + 0.016*"string" + 0.012*"example" + 0.011*"class"
INFO: topic #2 (1.000): 0.092*"class" + 0.086*"instance" + 0.039*"object" + 0.031*"garbage" + 0.017*"type" + 0.017*"code" + 0.017*"track" + 0.017*"reference" + 0.013*"c" + 0.012*"name"
INFO: topic diff=0.256562, rho=0.301511
DEBUG: bound: at document #0
INFO: -6.588 per-word bound, 96.2 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"object" + 0.047*"name" + 0.027*"code" + 0.024*"function" + 0.015*"variable" + 0.014*"source" + 0.013*"way" + 0.012*"line" + 0.012*"method" + 0.012*"c"
INFO: topic #1 (1.000): 0.088*"name" + 0.059*"variable" + 0.046*"function" + 0.043*"object" + 0.025*"value" + 0.019*"code" + 0.016*"list" + 0.015*"string" + 0.013*"way" + 0.012*"example"
INFO: topic #2 (1.000): 0.094*"class" + 0.089*"instance" + 0.041*"object" + 0.035*"garbage" + 0.020*"type" + 0.019*"code" + 0.019*"reference" + 0.014*"track" + 0.013*"design" + 0.013*"quick"
INFO: topic diff=0.247166, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 58.33157682604961
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -1.6792642069700117
DEBUG: bound: at document #0
INFO: -5.725 per-word bound, 52.9 perplexity estimate based on a held-out corpus of 5 documents with 1554 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.060*"object" + 0.048*"name" + 0.029*"code" + 0.026*"function" + 0.016*"variable" + 0.015*"source" + 0.013*"way" + 0.012*"method" + 0.012*"file" + 0.012*"="
INFO: topic #1 (1.000): 0.088*"name" + 0.060*"variable" + 0.049*"function" + 0.038*"object" + 0.025*"value" + 0.019*"code" + 0.017*"list" + 0.016*"string" + 0.012*"example" + 0.011*"class"
INFO: topic #2 (1.000): 0.093*"class" + 0.087*"instance" + 0.039*"object" + 0.031*"garbage" + 0.019*"reference" + 0.018*"type" + 0.018*"code" + 0.017*"track" + 0.013*"c" + 0.012*"design"
INFO: topic diff=0.241946, rho=0.288675
DEBUG: bound: at document #0
INFO: -6.582 per-word bound, 95.8 perplexity estimate based on a held-out corpus of 5 documents with 464 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.061*"object" + 0.047*"name" + 0.027*"code" + 0.024*"function" + 0.015*"variable" + 0.014*"source" + 0.013*"way" + 0.012*"c" + 0.012*"method" + 0.012*"line"
INFO: topic #1 (1.000): 0.088*"name" + 0.059*"variable" + 0.047*"function" + 0.043*"object" + 0.025*"value" + 0.019*"code" + 0.016*"list" + 0.015*"string" + 0.013*"way" + 0.013*"example"
INFO: topic #2 (1.000): 0.095*"class" + 0.089*"instance" + 0.041*"object" + 0.035*"garbage" + 0.021*"reference" + 0.020*"type" + 0.020*"code" + 0.014*"track" + 0.013*"design" + 0.013*"quick"
INFO: topic diff=0.234277, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 58.27772664490959
DEBUG: Setting topics to those of the model: LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -1.6886935823464035
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=599, num_topics=3, decay=0.5, chunksize=5> in 0.33s', 'datetime': '2023-04-18T14:16:29.766449', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/cos_threshold/12/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-18T14:16:29.766617', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/cos_threshold/12/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/12/model.state
DEBUG: {'uri': 'model/cos_threshold/12/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/cos_threshold/12/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['state', 'id2word', 'dispatcher'], 'datetime': '2023-04-18T14:16:29.772651', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/cos_threshold/12/model.expElogbeta.npy
INFO: not storing attribute state
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
DEBUG: {'uri': 'model/cos_threshold/12/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/12/model
INFO: topic #0 (1.000): 0.061*"object" + 0.047*"name" + 0.027*"code" + 0.024*"function" + 0.015*"variable" + 0.014*"source" + 0.013*"way" + 0.012*"c" + 0.012*"method" + 0.012*"line"
INFO: topic #1 (1.000): 0.088*"name" + 0.059*"variable" + 0.047*"function" + 0.043*"object" + 0.025*"value" + 0.019*"code" + 0.016*"list" + 0.015*"string" + 0.013*"way" + 0.013*"example"
INFO: topic #2 (1.000): 0.095*"class" + 0.089*"instance" + 0.041*"object" + 0.035*"garbage" + 0.021*"reference" + 0.020*"type" + 0.020*"code" + 0.014*"track" + 0.013*"design" + 0.013*"quick"
INFO: Question Similarity: [0.1509883999824524, 0.04883831739425659, 0.10391420125961304, 0.128229022026062, 0.10648477077484131, 0.09669965505599976, 0.3102548122406006, 0.10299235582351685, 0.09972989559173584, 0.1045263409614563]
INFO: 71791073: -0.21787741130752733
INFO: 8875330: -0.2209400026016669
INFO: 41586688: -0.22120434475266634
INFO: 8875313: -0.22159338418767735
INFO: 8875258: -0.22249810520294563
INFO: 63661634: -0.22283698865700355
INFO: 59914969: -0.22400498443760328
INFO: 33912052: -0.22438235256432898
INFO: 18983535: -0.22479599456117025
INFO: 18983557: -0.22629733242377695
INFO: 18983728: -0.23102308361759646
INFO: 18983795: -0.23471803919889148
INFO: 17196512: -0.23724861291190072
INFO: 19156516: -0.23934524026181814
INFO: 18983610: -0.23957239305147104
INFO: 18983693: -0.24168752334762175
INFO: 17196943: -0.2487672395334479
INFO: 67092322: -0.26867092430741707
INFO: 67092520: -0.281844832691273
INFO: 18425336: -0.30759876581700274
INFO: 18425523: -0.3077412457843351
INFO: 72890920: -0.30791162876465794
INFO: 30922184: -0.3079736898210067
INFO: 73495512: -0.3083465382538515
INFO: 59364138: -0.3084821803374217
INFO: 54033089: -0.30849623603156506
INFO: 59804094: -0.3090620311435039
INFO: 18425275: -0.3090849968947095
INFO: 59079732: -0.3101414757700385
INFO: 54423514: -0.31033856848374713
INFO: 63171710: -0.3105971036007652
INFO: 53684586: -0.3107200834282269
INFO: 69960020: -0.31110995626328264
INFO: 58451182: -0.31121027745613167
INFO: 66833271: -0.3112809578146746
INFO: 60826880: -0.3115841034769302
INFO: 59721785: -0.31178116442632037
INFO: 40536047: -0.31249554626747156
INFO: 18425312: -0.31288981106378705
INFO: 51347986: -0.31318533716099045
INFO: 71962669: -0.3136777188259593
INFO: 65678960: -0.314245435630817
INFO: 67419557: -0.3144758351037486
INFO: 18425285: -0.3151838504829203
INFO: 46471018: -0.31520610915477065
INFO: 57503767: -0.3164323641417489
INFO: 71712672: -0.3164414650227579
INFO: 54999371: -0.31702517366426564
INFO: 69496355: -0.3185472989514759
INFO: 75046191: -0.33175541883431103
INFO: 19201952: -0.33175541883431103
INFO: 38599084: -0.6699754774174248
INFO: 49331805: -0.6982298300087291
INFO: 38599196: -0.7022061522279468
INFO: Recommended Keywords
INFO: example score: -0.87224233
INFO: instance score: -0.86191076
INFO: possible score: -0.7925116
INFO: simple score: -0.7824437
INFO: element score: -0.7803555
INFO: define score: -0.78011537
INFO: function score: -0.7771717
INFO: defining score: -0.7754964
INFO: certain score: -0.76493543
INFO: specific score: -0.763246
INFO: type score: -0.761356
INFO: eg score: -0.7453816
INFO: relation score: -0.73951715
INFO: attribute score: -0.7319618
INFO: object score: -0.7300841
INFO: form score: -0.72542006
INFO: exact score: -0.724105
INFO: useful score: -0.7123655
INFO: reference score: -0.70343965
INFO: denote score: -0.70227045
INFO: arbitrary score: -0.69763637
INFO: equivalent score: -0.6973425
INFO: method score: -0.6924356
INFO: usage score: -0.6914263
INFO: source score: -0.68161696
INFO: mean score: -0.6799534
INFO: variable score: -0.6762821
INFO: true score: -0.6760173
INFO: solution score: -0.67525685
INFO: case score: -0.67460555
INFO: equal score: -0.67054504
INFO: process score: -0.665013
INFO: consider score: -0.6642038
INFO: reverse score: -0.6619022
INFO: key score: -0.6612813
INFO: variation score: -0.66111547
INFO: input score: -0.6555394
INFO: multiple score: -0.6546445
INFO: code score: -0.65453213
INFO: complete score: -0.6543354
INFO: problem score: -0.6499649
INFO: convenient score: -0.6499204
INFO: order score: -0.64985967
INFO: value score: -0.6459628
INFO: determine score: -0.6444491
INFO: least score: -0.64190567
INFO: fact score: -0.6416469
INFO: contain score: -0.63959455
INFO: common score: -0.6321041
INFO: drawback score: -0.6238825
INFO: need score: -0.6236926
INFO: result score: -0.61620533
INFO: purpose score: -0.6136137
INFO: item score: -0.60926694
INFO: error score: -0.60728365
INFO: insert score: -0.606958
INFO: note score: -0.6064126
INFO: other score: -0.6044459
INFO: application score: -0.6042878
INFO: separate score: -0.60173476
INFO: choice score: -0.6005452
INFO: clear score: -0.5964456
INFO: kind score: -0.5931206
INFO: unusual score: -0.5919395
INFO: pointing score: -0.5911747
INFO: create score: -0.59019905
INFO: reason score: -0.589892
INFO: point score: -0.58019924
INFO: well score: -0.5799657
INFO: approach score: -0.57905376
INFO: whole score: -0.5782634
INFO: technique score: -0.57255656
INFO: procedure score: -0.57164395
INFO: easy score: -0.57028884
INFO: requirement score: -0.567343
INFO: subject score: -0.56318456
INFO: information score: -0.5600454
INFO: impossible score: -0.5593676
INFO: number score: -0.55904794
INFO: map score: -0.5586919
INFO: canonical score: -0.5528331
INFO: important score: -0.5526648
INFO: iterate score: -0.55203295
INFO: design score: -0.5518472
INFO: content score: -0.5478838
INFO: current score: -0.54693276
INFO: detail score: -0.5457213
INFO: keyword score: -0.545252
INFO: output score: -0.54130095
INFO: index score: -0.5406187
INFO: effective score: -0.5391755
INFO: prefix score: -0.5383796
INFO: way score: -0.5370067
INFO: difficult score: -0.5362635
INFO: principle score: -0.53590214
INFO: stack score: -0.53541356
INFO: schema score: -0.53326714
INFO: dimension score: -0.53308785
INFO: weak score: -0.5322239
INFO: efficient score: -0.5305385
INFO: base score: -0.5292508
INFO: word score: -0.52877605
INFO: scope score: -0.5270364
INFO: quick score: -0.52567774
INFO: loop score: -0.52561694
INFO: parse score: -0.52328473
INFO: mapping score: -0.52256
INFO: frame score: -0.5221401
INFO: memory score: -0.5213629
INFO: identity score: -0.5122451
INFO: theory score: -0.5045779
INFO: extra score: -0.5044901
INFO: environment score: -0.50344384
INFO: node score: -0.50070196
INFO: consist score: -0.50065064
INFO: generalize score: -0.49884683
INFO: nodes score: -0.48832422
INFO: search score: -0.4876398
INFO: single score: -0.4867626
INFO: string score: -0.48669314
INFO: parent score: -0.48517835
INFO: available score: -0.48482475
INFO: many score: -0.48304018
INFO: level score: -0.48150986
INFO: logic score: -0.4781939
INFO: superset score: -0.4777286
INFO: original score: -0.4762427
INFO: argument score: -0.47389245
INFO: pointer score: -0.47172287
INFO: datum score: -0.47136265
INFO: patch score: -0.47064704
INFO: able score: -0.47022045
INFO: idea score: -0.46966332
INFO: namespace score: -0.46922
INFO: enough score: -0.4674703
INFO: module score: -0.46375912
INFO: general score: -0.46339533
INFO: person score: -0.46227577
INFO: question score: -0.46054754
INFO: hold score: -0.45925042
INFO: large score: -0.4573944
INFO: integer score: -0.45662826
INFO: long score: -0.4560395
INFO: filter score: -0.45160568
INFO: c score: -0.44850308
INFO: self score: -0.44808784
INFO: glance score: -0.4479763
INFO: instant score: -0.4455307
INFO: access score: -0.44529954
INFO: handling score: -0.44474262
INFO: look score: -0.44196284
INFO: write score: -0.43886247
INFO: database score: -0.43638384
INFO: package score: -0.43498704
INFO: implementation score: -0.43307057
INFO: call score: -0.4313359
INFO: list score: -0.42924005
INFO: name score: -0.42907512
INFO: constructor score: -0.42764783
INFO: hack score: -0.42385215
INFO: documentation score: -0.41974524
INFO: builtin score: -0.415751
INFO: main score: -0.4124493
INFO: line score: -0.4106509
INFO: time score: -0.41044256
INFO: garbage score: -0.40991503
INFO: iterator score: -0.40761912
INFO: location score: -0.40756652
INFO: count score: -0.40703785
INFO: ids score: -0.40593478
INFO: wrapper score: -0.40468827
INFO: class score: -0.4017144
INFO: hash score: -0.39984626
INFO: good score: -0.39951503
INFO: file score: -0.39514184
INFO: unicode score: -0.39032272
INFO: version score: -0.3763512
INFO: foo score: -0.37397587
INFO: new score: -0.37320158
INFO: part score: -0.37100336
INFO: property score: -0.3702688
INFO: moment score: -0.3687843
INFO: wish score: -0.36661378
INFO: answer score: -0.36480597
INFO: previous score: -0.36407542
INFO: lambdas score: -0.36190605
INFO: assignment score: -0.36177135
INFO: language score: -0.35808197
INFO: close score: -0.35763055
INFO: bug score: -0.35314688
INFO: none score: -0.3486918
INFO: tree score: -0.34825778
INFO: several score: -0.34739876
INFO: json score: -0.3471539
INFO: thing score: -0.3466532
INFO: pause score: -0.34622425
INFO: lead score: -0.34594527
INFO: init score: -0.3444578
INFO: caller score: -0.343453
INFO: outer score: -0.34226993
INFO: parameter score: -0.34149602
INFO: issue score: -0.3411223
INFO: page score: -0.33993042
INFO: debugging score: -0.3357375
INFO: pass score: -0.33532026
INFO: inspect score: -0.33507448
INFO: comprehensive score: -0.33440495
INFO: g score: -0.33376262
INFO: interpreter score: -0.3335826
INFO: format score: -0.3310165
INFO: dictionary score: -0.33082184
INFO: print score: -0.3298684
INFO: post score: -0.32946208
INFO: global score: -0.32829368
INFO: text score: -0.32458127
INFO: f score: -0.32011992
INFO: my_list score: -0.3200994
INFO: work score: -0.31976864
INFO: program score: -0.31524977
INFO: lifetime score: -0.3139126
INFO: situation score: -0.31153476
INFO: tricky score: -0.31129536
INFO: dict score: -0.3085812
INFO: collection score: -0.30493778
INFO: cleans score: -0.2973283
INFO: alert score: -0.29427406
INFO: want score: -0.29355162
INFO: trustworthy score: -0.2935023
INFO: performance score: -0.2929745
INFO: var1 score: -0.29247952
INFO: local score: -0.29146194
INFO: comment score: -0.28662217
INFO: z score: -0.2795665
INFO: retrieve score: -0.27923048
INFO: track score: -0.27767593
INFO: succ score: -0.27628383
INFO: help score: -0.27182436
INFO: len score: -0.2696357
INFO: lambda score: -0.26839298
INFO: frontend score: -0.26231128
INFO: warning score: -0.25888303
INFO: first score: -0.2553222
INFO: = score: -0.24914362
INFO: whatis score: -0.24846154
INFO: cmd score: -0.24391562
INFO: chance score: -0.24223104
INFO: place score: -0.23939808
INFO: obj score: -0.23295157
INFO: course score: -0.2327973
INFO: str score: -0.22187515
INFO: f2 score: -0.22121632
INFO: exec score: -0.22059217
INFO: script score: -0.21980461
INFO: willing score: -0.21711195
INFO: snippet score: -0.21708968
INFO: magic score: -0.20907238
INFO: worth score: -0.20200615
INFO: return score: -0.19686474
INFO: try score: -0.1968147
INFO: live score: -0.19594362
INFO: store score: -0.1944338
INFO: library score: -0.1763053
INFO: monkey score: -0.16818224
INFO: hope score: -0.16029833
INFO: late score: -0.15250304
INFO: grab score: -0.13811585
INFO: area score: -0.13165805
INFO: orm score: -0.13005127
INFO: fancy score: -0.1298667
INFO: private score: -0.115425445
INFO: command score: -0.107076496
INFO: var score: -0.098666504
INFO: liner score: -0.09721995
INFO: ex score: -0.089670815
INFO: repr score: -0.07191398
INFO: fun score: -0.07170617
INFO: stores score: -0.06872513
INFO: amr score: -0.06768416
INFO: goal score: -0.06426304
INFO: wonderful score: -0.059879564
INFO: astounded score: -0.057973966
INFO: sorcery score: -0.043565944
INFO: wealth score: -0.03212504
INFO: brett score: -0.015608223
INFO: insanity score: -0.010865
INFO: cann score: -0.0005184915
INFO: vol score: -0.00043677166
INFO: dataframe score: -0.0
INFO: kwargs score: -0.0
INFO: slatkin score: -0.0
INFO: dunder score: -0.0
INFO: set_name score: -0.0
INFO: varname score: -0.0
INFO: var_1 score: -0.0
INFO: var_2 score: -0.0
INFO: idilip score: -0.0
INFO: var2 score: -0.0
INFO: myvar score: -0.0
INFO: @mherzog)- score: -0.0
INFO: sharaki score: -0.0
INFO: cann't score: -0.0
INFO: a[1 score: -0.0
INFO: b.val score: -0.0
INFO: python3 score: -0.0
INFO: autodict score: -0.0
INFO: hashmap score: -0.0
INFO: globals().item score: -0.0
INFO: except_word score: -0.0
INFO: each_item score: -0.0
INFO: self.name score: -0.0
INFO: test_function score: -0.0
INFO: dill.source.getname score: -0.0
INFO: getattr score: -0.0
INFO: p3.name score: -0.0
INFO: get_players_at_seat score: -0.0
INFO: atribute score: -0.0
INFO: driax score: -0.0
INFO: assignent score: -0.0
INFO: cpython score: -0.0
INFO: nameof score: -0.0
INFO: https://stackoverflow.com/a/49331683/7386061 score: -0.0
INFO: collector(gc score: -0.0
INFO: weakref score: -0.0
INFO: gc.get_object score: -0.0
INFO: myclass score: -0.0
INFO: some_object score: -0.0
INFO: object1 score: -0.0
INFO: identifier(or score: -0.0
INFO: a.__name score: -0.0
INFO: a().__class__.__name score: -0.0
INFO: round score: 0.008624753
INFO: vel score: 0.014381338
INFO: def score: 0.021654105
INFO: bla score: 0.02262251
INFO: dill score: 0.040465735
INFO: garden score: 0.05700348
INFO: match score: 0.06360087
INFO: player score: 0.069459304
INFO: ============================================================
INFO: --------------------
INFO: Is it possible to write obfuscated one-liners in Python?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<389 unique tokens: ['2.20s', '3.10s', '9.76s', '=', '\\n']...> from 10 documents (total 845 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': "built Dictionary<389 unique tokens: ['2.20s', '3.10s', '9.76s', '=', '\\\\n']...> from 10 documents (total 845 corpus positions)", 'datetime': '2023-04-18T14:16:33.094675', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.539 per-word bound, 186.0 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.046*"line" + 0.022*"print" + 0.020*"function" + 0.015*"list" + 0.014*"variable" + 0.013*"time" + 0.013*"\n" + 0.012*"file" + 0.012*"code" + 0.011*"lambda"
INFO: topic #1 (1.000): 0.043*"line" + 0.024*"function" + 0.023*"print" + 0.019*"file" + 0.018*"\n" + 0.013*"manager" + 0.013*"character" + 0.013*"way" + 0.012*"context" + 0.012*"window"
INFO: topic #2 (1.000): 0.035*"line" + 0.025*"print" + 0.019*"function" + 0.017*"file" + 0.016*"write" + 0.014*"\n" + 0.013*"character" + 0.013*"way" + 0.012*"code" + 0.012*"command"
INFO: topic diff=2.632413, rho=1.000000
DEBUG: bound: at document #0
INFO: -13.244 per-word bound, 9700.2 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.086*"line" + 0.035*"operator" + 0.031*"string" + 0.023*"long" + 0.021*"code" + 0.019*"way" + 0.015*"number" + 0.015*"bracket" + 0.014*"result" + 0.013*"list"
INFO: topic #1 (1.000): 0.050*"line" + 0.019*"string" + 0.019*"function" + 0.015*"print" + 0.015*"\n" + 0.014*"long" + 0.013*"way" + 0.013*"number" + 0.013*"file" + 0.010*"code"
INFO: topic #2 (1.000): 0.039*"line" + 0.019*"print" + 0.015*"function" + 0.014*"command" + 0.013*"\n" + 0.013*"work" + 0.013*"file" + 0.012*"statement" + 0.012*"write" + 0.012*"way"
INFO: topic diff=2.478434, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 132.83072612640052
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -1.6596191418367656
DEBUG: bound: at document #0
INFO: -6.929 per-word bound, 121.8 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.072*"line" + 0.031*"operator" + 0.024*"string" + 0.018*"code" + 0.018*"list" + 0.018*"number" + 0.015*"long" + 0.015*"variable" + 0.014*"function" + 0.014*"bracket"
INFO: topic #1 (1.000): 0.044*"line" + 0.021*"function" + 0.021*"print" + 0.021*"\n" + 0.019*"file" + 0.017*"string" + 0.016*"way" + 0.015*"window" + 0.013*"manager" + 0.013*"newline"
INFO: topic #2 (1.000): 0.040*"line" + 0.026*"print" + 0.019*"function" + 0.016*"write" + 0.016*"file" + 0.014*"\n" + 0.013*"code" + 0.013*"end" + 0.012*"way" + 0.012*"command"
INFO: topic diff=1.397946, rho=0.500000
DEBUG: bound: at document #0
INFO: -8.503 per-word bound, 362.9 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.077*"line" + 0.036*"operator" + 0.033*"string" + 0.027*"long" + 0.020*"continuation" + 0.019*"code" + 0.018*"number" + 0.017*"way" + 0.014*"bracket" + 0.014*"result"
INFO: topic #1 (1.000): 0.043*"line" + 0.020*"\n" + 0.018*"function" + 0.017*"print" + 0.016*"file" + 0.015*"simple" + 0.014*"string" + 0.013*"way" + 0.012*"window" + 0.011*"manager"
INFO: topic #2 (1.000): 0.040*"line" + 0.023*"print" + 0.018*"function" + 0.015*"write" + 0.015*"file" + 0.014*"\n" + 0.014*"command" + 0.012*"code" + 0.012*"end" + 0.011*"way"
INFO: topic diff=1.168882, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 94.52995149406958
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -1.6024926645289146
DEBUG: bound: at document #0
INFO: -6.524 per-word bound, 92.0 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"line" + 0.032*"operator" + 0.027*"string" + 0.020*"number" + 0.019*"long" + 0.017*"code" + 0.016*"list" + 0.014*"continuation" + 0.014*"bracket" + 0.014*"result"
INFO: topic #1 (1.000): 0.036*"line" + 0.021*"\n" + 0.017*"list" + 0.017*"file" + 0.017*"function" + 0.016*"window" + 0.016*"string" + 0.016*"simple" + 0.016*"print" + 0.015*"split"
INFO: topic #2 (1.000): 0.041*"line" + 0.027*"print" + 0.021*"function" + 0.017*"file" + 0.016*"\n" + 0.015*"write" + 0.013*"way" + 0.013*"code" + 0.013*"end" + 0.012*"character"
INFO: topic diff=0.823528, rho=0.447214
DEBUG: bound: at document #0
INFO: -7.288 per-word bound, 156.3 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.074*"line" + 0.036*"operator" + 0.033*"string" + 0.027*"long" + 0.023*"continuation" + 0.019*"number" + 0.018*"code" + 0.016*"way" + 0.015*"binary" + 0.015*"expression"
INFO: topic #1 (1.000): 0.040*"line" + 0.021*"\n" + 0.018*"simple" + 0.013*"function" + 0.013*"list" + 0.013*"separator" + 0.013*"string" + 0.012*"file" + 0.012*"window" + 0.012*"print"
INFO: topic #2 (1.000): 0.041*"line" + 0.026*"print" + 0.020*"function" + 0.017*"file" + 0.015*"\n" + 0.014*"write" + 0.013*"command" + 0.012*"way" + 0.012*"code" + 0.012*"end"
INFO: topic diff=0.709682, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 82.6252181808956
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -1.4561388248175315
DEBUG: bound: at document #0
INFO: -6.321 per-word bound, 79.9 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"line" + 0.033*"operator" + 0.028*"string" + 0.021*"long" + 0.021*"number" + 0.017*"continuation" + 0.017*"code" + 0.015*"list" + 0.014*"result" + 0.014*"bracket"
INFO: topic #1 (1.000): 0.030*"line" + 0.025*"split" + 0.025*"list" + 0.016*"\n" + 0.016*"first" + 0.014*"simple" + 0.013*"word" + 0.013*"unique" + 0.013*"whitespace" + 0.013*"space"
INFO: topic #2 (1.000): 0.042*"line" + 0.027*"print" + 0.021*"function" + 0.018*"file" + 0.017*"\n" + 0.014*"write" + 0.013*"way" + 0.012*"character" + 0.012*"end" + 0.012*"code"
INFO: topic diff=0.543579, rho=0.408248
DEBUG: bound: at document #0
INFO: -6.964 per-word bound, 124.8 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"line" + 0.036*"operator" + 0.033*"string" + 0.028*"long" + 0.023*"continuation" + 0.020*"number" + 0.018*"code" + 0.016*"way" + 0.015*"binary" + 0.015*"expression"
INFO: topic #1 (1.000): 0.035*"line" + 0.018*"list" + 0.018*"simple" + 0.017*"\n" + 0.017*"split" + 0.015*"separator" + 0.015*"least" + 0.015*"problem" + 0.015*"simple_stmt" + 0.015*"pov"
INFO: topic #2 (1.000): 0.041*"line" + 0.026*"print" + 0.020*"function" + 0.018*"file" + 0.017*"\n" + 0.014*"write" + 0.013*"way" + 0.012*"character" + 0.012*"end" + 0.012*"code"
INFO: topic diff=0.506603, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 77.18690627270438
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -3.4799461529686795
DEBUG: bound: at document #0
INFO: -6.217 per-word bound, 74.4 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"line" + 0.033*"operator" + 0.028*"string" + 0.021*"long" + 0.021*"number" + 0.018*"continuation" + 0.017*"code" + 0.015*"list" + 0.014*"result" + 0.014*"bracket"
INFO: topic #1 (1.000): 0.031*"split" + 0.031*"list" + 0.025*"line" + 0.017*"first" + 0.016*"word" + 0.016*"unique" + 0.016*"whitespace" + 0.016*"space" + 0.016*"convert" + 0.016*"argument"
INFO: topic #2 (1.000): 0.042*"line" + 0.027*"print" + 0.021*"function" + 0.019*"file" + 0.017*"\n" + 0.014*"write" + 0.014*"way" + 0.013*"character" + 0.012*"end" + 0.012*"code"
INFO: topic diff=0.368570, rho=0.377964
DEBUG: bound: at document #0
INFO: -6.846 per-word bound, 115.0 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"line" + 0.035*"operator" + 0.033*"string" + 0.027*"long" + 0.023*"continuation" + 0.020*"number" + 0.018*"code" + 0.016*"way" + 0.015*"binary" + 0.015*"expression"
INFO: topic #1 (1.000): 0.030*"line" + 0.021*"list" + 0.021*"split" + 0.017*"quoting" + 0.017*"least" + 0.017*"pov" + 0.017*"simple_stmt" + 0.017*"question" + 0.017*"syntactic" + 0.017*"if_stmt"
INFO: topic #2 (1.000): 0.042*"line" + 0.026*"print" + 0.021*"function" + 0.018*"file" + 0.017*"\n" + 0.013*"write" + 0.013*"way" + 0.012*"character" + 0.012*"end" + 0.012*"code"
INFO: topic diff=0.364325, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 75.3950754706128
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -3.9863216276549323
DEBUG: bound: at document #0
INFO: -6.179 per-word bound, 72.4 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"line" + 0.033*"operator" + 0.029*"string" + 0.022*"long" + 0.021*"number" + 0.018*"continuation" + 0.017*"code" + 0.015*"list" + 0.014*"result" + 0.014*"statement"
INFO: topic #1 (1.000): 0.034*"split" + 0.034*"list" + 0.022*"line" + 0.018*"first" + 0.018*"word" + 0.018*"unique" + 0.018*"whitespace" + 0.018*"space" + 0.018*"convert" + 0.017*"argument"
INFO: topic #2 (1.000): 0.042*"line" + 0.027*"print" + 0.021*"function" + 0.019*"file" + 0.017*"\n" + 0.014*"write" + 0.014*"way" + 0.013*"character" + 0.012*"end" + 0.012*"code"
INFO: topic diff=0.283137, rho=0.353553
DEBUG: bound: at document #0
INFO: -6.798 per-word bound, 111.3 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"line" + 0.035*"operator" + 0.033*"string" + 0.027*"long" + 0.023*"continuation" + 0.020*"number" + 0.018*"code" + 0.015*"way" + 0.015*"binary" + 0.015*"expression"
INFO: topic #1 (1.000): 0.025*"line" + 0.023*"list" + 0.022*"split" + 0.018*"quoting" + 0.018*"question" + 0.018*"https://docs.python.org/2/reference/simple_stmts.html#grammar-token-simple_stmt" + 0.018*"simple_stmt" + 0.018*"funny" + 0.018*"similar" + 0.018*"if_stmt"
INFO: topic #2 (1.000): 0.042*"line" + 0.026*"print" + 0.021*"function" + 0.018*"file" + 0.018*"\n" + 0.013*"write" + 0.013*"way" + 0.012*"character" + 0.012*"end" + 0.012*"code"
INFO: topic diff=0.272773, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 74.7104887602871
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -3.9863216276549323
DEBUG: bound: at document #0
INFO: -6.160 per-word bound, 71.5 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"line" + 0.033*"operator" + 0.029*"string" + 0.022*"long" + 0.021*"number" + 0.018*"continuation" + 0.017*"code" + 0.014*"list" + 0.014*"statement" + 0.014*"result"
INFO: topic #1 (1.000): 0.035*"list" + 0.035*"split" + 0.019*"first" + 0.018*"line" + 0.018*"word" + 0.018*"unique" + 0.018*"whitespace" + 0.018*"space" + 0.018*"convert" + 0.018*"argument"
INFO: topic #2 (1.000): 0.042*"line" + 0.027*"print" + 0.021*"function" + 0.019*"file" + 0.018*"\n" + 0.014*"write" + 0.014*"way" + 0.013*"character" + 0.012*"end" + 0.012*"code"
INFO: topic diff=0.230113, rho=0.333333
DEBUG: bound: at document #0
INFO: -6.775 per-word bound, 109.5 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"line" + 0.035*"operator" + 0.033*"string" + 0.027*"long" + 0.023*"continuation" + 0.020*"number" + 0.018*"code" + 0.015*"binary" + 0.015*"expression" + 0.015*"way"
INFO: topic #1 (1.000): 0.025*"list" + 0.024*"split" + 0.021*"line" + 0.018*"quoting" + 0.018*"question" + 0.018*"https://docs.python.org/2/reference/simple_stmts.html#grammar-token-simple_stmt" + 0.018*"simple_stmt" + 0.018*"funny" + 0.018*"similar" + 0.018*"if_stmt"
INFO: topic #2 (1.000): 0.042*"line" + 0.026*"print" + 0.021*"function" + 0.018*"file" + 0.018*"\n" + 0.013*"write" + 0.013*"way" + 0.012*"character" + 0.012*"end" + 0.012*"code"
INFO: topic diff=0.219766, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 74.42933973099068
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -3.968754383473591
DEBUG: bound: at document #0
INFO: -6.149 per-word bound, 71.0 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.068*"line" + 0.033*"operator" + 0.029*"string" + 0.022*"long" + 0.021*"number" + 0.018*"continuation" + 0.017*"code" + 0.014*"list" + 0.014*"statement" + 0.014*"result"
INFO: topic #1 (1.000): 0.036*"list" + 0.035*"split" + 0.019*"first" + 0.018*"argument" + 0.018*"word" + 0.018*"unique" + 0.018*"whitespace" + 0.018*"space" + 0.018*"convert" + 0.018*"second"
INFO: topic #2 (1.000): 0.042*"line" + 0.027*"print" + 0.022*"function" + 0.019*"file" + 0.018*"\n" + 0.014*"write" + 0.014*"way" + 0.013*"character" + 0.012*"end" + 0.012*"code"
INFO: topic diff=0.195997, rho=0.316228
DEBUG: bound: at document #0
INFO: -6.761 per-word bound, 108.5 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"line" + 0.035*"operator" + 0.033*"string" + 0.027*"long" + 0.023*"continuation" + 0.020*"number" + 0.018*"code" + 0.015*"binary" + 0.015*"expression" + 0.015*"way"
INFO: topic #1 (1.000): 0.026*"list" + 0.024*"split" + 0.019*"simple_stmt" + 0.019*"similar" + 0.019*"least" + 0.019*"syntactic" + 0.019*"https://docs.python.org/2/reference/simple_stmts.html#grammar-token-simple_stmt" + 0.019*"pov" + 0.019*"quoting" + 0.019*"interpret"
INFO: topic #2 (1.000): 0.042*"line" + 0.026*"print" + 0.021*"function" + 0.018*"\n" + 0.018*"file" + 0.013*"way" + 0.013*"write" + 0.013*"character" + 0.012*"end" + 0.012*"code"
INFO: topic diff=0.187640, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 74.28675178332323
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -4.091326807812007
DEBUG: bound: at document #0
INFO: -6.142 per-word bound, 70.6 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"line" + 0.033*"operator" + 0.029*"string" + 0.022*"long" + 0.021*"number" + 0.019*"continuation" + 0.017*"code" + 0.014*"statement" + 0.014*"list" + 0.014*"result"
INFO: topic #1 (1.000): 0.036*"list" + 0.035*"split" + 0.019*"first" + 0.018*"argument" + 0.018*"second" + 0.018*"word" + 0.018*"unique" + 0.018*"whitespace" + 0.018*"space" + 0.018*"convert"
INFO: topic #2 (1.000): 0.042*"line" + 0.027*"print" + 0.022*"function" + 0.019*"file" + 0.018*"\n" + 0.014*"write" + 0.014*"way" + 0.013*"character" + 0.012*"end" + 0.012*"code"
INFO: topic diff=0.174026, rho=0.301511
DEBUG: bound: at document #0
INFO: -6.751 per-word bound, 107.7 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"line" + 0.035*"operator" + 0.033*"string" + 0.027*"long" + 0.023*"continuation" + 0.020*"number" + 0.018*"code" + 0.015*"binary" + 0.015*"expression" + 0.015*"way"
INFO: topic #1 (1.000): 0.027*"list" + 0.025*"split" + 0.019*"syntactic" + 0.019*"question" + 0.019*"quoting" + 0.019*"similar" + 0.019*"pov" + 0.019*"simple_stmt" + 0.019*"interpret" + 0.019*"problem"
INFO: topic #2 (1.000): 0.043*"line" + 0.026*"print" + 0.021*"function" + 0.019*"\n" + 0.018*"file" + 0.013*"way" + 0.013*"write" + 0.013*"character" + 0.012*"end" + 0.012*"code"
INFO: topic diff=0.167780, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 74.18984493020642
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -4.091326807812007
DEBUG: bound: at document #0
INFO: -6.136 per-word bound, 70.3 perplexity estimate based on a held-out corpus of 5 documents with 630 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.069*"line" + 0.033*"operator" + 0.029*"string" + 0.022*"long" + 0.021*"number" + 0.019*"continuation" + 0.017*"code" + 0.014*"statement" + 0.014*"list" + 0.014*"result"
INFO: topic #1 (1.000): 0.037*"list" + 0.035*"split" + 0.019*"first" + 0.018*"argument" + 0.018*"second" + 0.018*"word" + 0.018*"unique" + 0.018*"whitespace" + 0.018*"space" + 0.018*"convert"
INFO: topic #2 (1.000): 0.042*"line" + 0.027*"print" + 0.022*"function" + 0.019*"file" + 0.018*"\n" + 0.014*"write" + 0.014*"way" + 0.013*"character" + 0.012*"end" + 0.012*"code"
INFO: topic diff=0.159505, rho=0.288675
DEBUG: bound: at document #0
INFO: -6.742 per-word bound, 107.0 perplexity estimate based on a held-out corpus of 5 documents with 215 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.074*"line" + 0.035*"operator" + 0.032*"string" + 0.026*"long" + 0.022*"continuation" + 0.020*"number" + 0.018*"code" + 0.015*"binary" + 0.015*"expression" + 0.015*"way"
INFO: topic #1 (1.000): 0.027*"list" + 0.025*"split" + 0.019*"simple_stmt" + 0.019*"least" + 0.019*"pov" + 0.019*"interpret" + 0.019*"https://docs.python.org/2/reference/simple_stmts.html#grammar-token-simple_stmt" + 0.019*"funny" + 0.019*"syntactic" + 0.019*"problem"
INFO: topic #2 (1.000): 0.043*"line" + 0.026*"print" + 0.021*"function" + 0.019*"\n" + 0.018*"file" + 0.013*"way" + 0.013*"write" + 0.013*"character" + 0.012*"end" + 0.012*"code"
INFO: topic diff=0.154650, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 74.1115099319723
DEBUG: Setting topics to those of the model: LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -4.091326807812007
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=389, num_topics=3, decay=0.5, chunksize=5> in 0.19s', 'datetime': '2023-04-18T14:16:33.289568', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/cos_threshold/13/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-18T14:16:33.289807', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/cos_threshold/13/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/13/model.state
DEBUG: {'uri': 'model/cos_threshold/13/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/cos_threshold/13/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['state', 'id2word', 'dispatcher'], 'datetime': '2023-04-18T14:16:33.295341', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/cos_threshold/13/model.expElogbeta.npy
INFO: not storing attribute state
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
DEBUG: {'uri': 'model/cos_threshold/13/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/13/model
INFO: topic #0 (1.000): 0.074*"line" + 0.035*"operator" + 0.032*"string" + 0.026*"long" + 0.022*"continuation" + 0.020*"number" + 0.018*"code" + 0.015*"binary" + 0.015*"expression" + 0.015*"way"
INFO: topic #1 (1.000): 0.027*"list" + 0.025*"split" + 0.019*"simple_stmt" + 0.019*"least" + 0.019*"pov" + 0.019*"interpret" + 0.019*"https://docs.python.org/2/reference/simple_stmts.html#grammar-token-simple_stmt" + 0.019*"funny" + 0.019*"syntactic" + 0.019*"problem"
INFO: topic #2 (1.000): 0.043*"line" + 0.026*"print" + 0.021*"function" + 0.019*"\n" + 0.018*"file" + 0.013*"way" + 0.013*"write" + 0.013*"character" + 0.012*"end" + 0.012*"code"
INFO: Question Similarity: [0.10190123319625854, 0.022274792194366455, 0.09113484621047974, 0.09393662214279175, 0.19111818075180054, 0.13491439819335938, 0.24958574771881104, 0.11726987361907959, 0.21989881992340088, 0.18629783391952515]
INFO: 39474750: -0.17445096629820234
INFO: 6159912: -0.17652380753447847
INFO: 6165711: -0.17714870535840485
INFO: 63796747: -0.17808362113450035
INFO: 56901429: -0.1781497318380996
INFO: 39168994: -0.17831556125989967
INFO: 52290101: -0.18030154220817599
INFO: 6160082: -0.18088968645292922
INFO: 12871858: -0.18110235987404286
INFO: 56594378: -0.18298565834974698
INFO: 6159915: -0.19166466914860802
INFO: 66576132: -0.19384204769696653
INFO: 75427193: -0.19528351799961377
INFO: 6159910: -0.1958200821317128
INFO: 59444846: -0.1959946615256278
INFO: 52080154: -0.20006942452478046
INFO: 42309842: -0.2576682423808537
INFO: 42309840: -0.2683589414851419
INFO: 42309846: -0.27445626492144704
INFO: 4172466: -0.2964372245106405
INFO: 36882925: -0.3102945118421473
INFO: 38224926: -0.310302457556019
INFO: 46326379: -0.3128596569183923
INFO: 4172475: -0.31488451765117004
INFO: 4172487: -0.3165107046531896
INFO: 4172465: -0.31829252828562515
INFO: 67349311: -0.41551647471864517
INFO: 39068229: -0.41688698490121234
INFO: 39067866: -0.41753695643746863
INFO: 67347879: -0.4199295539560525
INFO: 39067798: -0.43208739509980243
INFO: 67347936: -0.4434865950979521
INFO: 41772854: -0.5177871243175318
INFO: 58550900: -0.5738001980258286
INFO: 58550959: -0.5753951701956581
INFO: Recommended Keywords
INFO: possible score: -0.7411071
INFO: example score: -0.73990184
INFO: set score: -0.7377318
INFO: continuous score: -0.7248167
INFO: interpret score: -0.70174557
INFO: least score: -0.69498473
INFO: way score: -0.69469804
INFO: multiple score: -0.6890661
INFO: result score: -0.6817394
INFO: write score: -0.66265833
INFO: question score: -0.66260016
INFO: continuation score: -0.658269
INFO: simple score: -0.6541539
INFO: long score: -0.65356797
INFO: other score: -0.6453289
INFO: equal score: -0.6434089
INFO: number score: -0.64260024
INFO: point score: -0.6418781
INFO: correct score: -0.6356072
INFO: similar score: -0.6341325
INFO: code score: -0.63332593
INFO: equivalent score: -0.6314594
INFO: latter score: -0.630847
INFO: insert score: -0.62940854
INFO: easy score: -0.6277217
INFO: effect score: -0.6237975
INFO: case score: -0.61795676
INFO: loop score: -0.6102467
INFO: object score: -0.6079077
INFO: argument score: -0.6002579
INFO: difference score: -0.59611595
INFO: pair score: -0.5952226
INFO: context score: -0.5944887
INFO: special score: -0.592419
INFO: extra score: -0.59143543
INFO: key score: -0.5886529
INFO: necessary score: -0.5864894
INFO: create score: -0.5852575
INFO: exact score: -0.5769118
INFO: important score: -0.5764531
INFO: much score: -0.572457
INFO: unique score: -0.5718004
INFO: default score: -0.56887597
INFO: file score: -0.56823826
INFO: basic score: -0.566352
INFO: purpose score: -0.5648027
INFO: related score: -0.563662
INFO: source score: -0.56331074
INFO: enough score: -0.5620028
INFO: solution score: -0.5611517
INFO: approach score: -0.561148
INFO: open score: -0.5597538
INFO: operation score: -0.55943936
INFO: system score: -0.5591483
INFO: advantage score: -0.55861795
INFO: function score: -0.5492951
INFO: negative score: -0.54862463
INFO: error score: -0.5475987
INFO: expression score: -0.5474861
INFO: useful score: -0.54709333
INFO: concept score: -0.5441705
INFO: bit score: -0.54360783
INFO: update score: -0.54285777
INFO: instant score: -0.54112357
INFO: note score: -0.5406744
INFO: alternative score: -0.5406615
INFO: block score: -0.54043067
INFO: variable score: -0.5399552
INFO: condition score: -0.53942966
INFO: reason score: -0.538426
INFO: keyword score: -0.5379613
INFO: list score: -0.5356736
INFO: exception score: -0.53538656
INFO: time score: -0.5346262
INFO: end score: -0.533736
INFO: reading score: -0.53194344
INFO: compact score: -0.5312057
INFO: item score: -0.53103095
INFO: current score: -0.5303545
INFO: operator score: -0.5285641
INFO: method score: -0.5280243
INFO: many score: -0.52686524
INFO: new score: -0.52576417
INFO: parenthesis score: -0.524235
INFO: string score: -0.52288866
INFO: word score: -0.52288026
INFO: side score: -0.52059066
INFO: one score: -0.51724255
INFO: print score: -0.51666087
INFO: mode score: -0.5145963
INFO: quick score: -0.51304436
INFO: append score: -0.5127901
INFO: binary score: -0.51118493
INFO: triple score: -0.5095104
INFO: drop score: -0.50385654
INFO: newline score: -0.50066674
INFO: short score: -0.49860492
INFO: ternary score: -0.49811527
INFO: right score: -0.49499425
INFO: feature score: -0.49394062
INFO: implicit score: -0.49351385
INFO: break score: -0.48680428
INFO: creation score: -0.48420206
INFO: quoting score: -0.4821328
INFO: good score: -0.4814061
INFO: dealing score: -0.47878087
INFO: syntactic score: -0.47647375
INFO: statement score: -0.4744086
INFO: info score: -0.47345433
INFO: counter score: -0.47122177
INFO: split score: -0.4699025
INFO: dependency score: -0.46574333
INFO: work score: -0.46515658
INFO: line score: -0.4625468
INFO: directory score: -0.4620406
INFO: indent score: -0.4612154
INFO: character score: -0.4610632
INFO: digits score: -0.45901918
INFO: support score: -0.457967
INFO: outcome score: -0.457416
INFO: output score: -0.4567854
INFO: yield score: -0.454755
INFO: guide score: -0.45180598
INFO: comment score: -0.44830444
INFO: thing score: -0.44360805
INFO: delimiter score: -0.44134828
INFO: handy score: -0.44133335
INFO: test score: -0.4396615
INFO: idea score: -0.4392699
INFO: writing score: -0.43514806
INFO: value score: -0.43508804
INFO: multiline score: -0.43316036
INFO: option score: -0.43302032
INFO: cursor score: -0.43151128
INFO: practice score: -0.43117973
INFO: single score: -0.4302898
INFO: bracket score: -0.42982435
INFO: server score: -0.4293655
INFO: analysis score: -0.42907637
INFO: available score: -0.42900142
INFO: install score: -0.42751077
INFO: benefit score: -0.42714775
INFO: web score: -0.42673862
INFO: convert score: -0.42306593
INFO: careful score: -0.4204534
INFO: data score: -0.42041972
INFO: false score: -0.42002222
INFO: format score: -0.41823906
INFO: documentation score: -0.41758895
INFO: module score: -0.41592318
INFO: lot score: -0.41547802
INFO: count score: -0.4152767
INFO: section score: -0.41400295
INFO: pass score: -0.41200852
INFO: look score: -0.40770316
INFO: interpreter score: -0.40628588
INFO: close score: -0.40504947
INFO: grep score: -0.40502197
INFO: integer score: -0.40417048
INFO: awkward score: -0.40352157
INFO: information score: -0.40330473
INFO: whitespace score: -0.40325776
INFO: none score: -0.39620495
INFO: common score: -0.39527708
INFO: concern score: -0.39501464
INFO: button score: -0.393164
INFO: total score: -0.39049032
INFO: init score: -0.38739318
INFO: boolean score: -0.38712382
INFO: import score: -0.3838558
INFO: bash score: -0.3834145
INFO: stream score: -0.38207206
INFO: text score: -0.37375188
INFO: generator score: -0.37288317
INFO: window score: -0.3728411
INFO: first score: -0.36996233
INFO: comma score: -0.3699438
INFO: iterable score: -0.36863008
INFO: decimal score: -0.36107627
INFO: heredoc score: -0.3604786
INFO: last score: -0.3602961
INFO: eye score: -0.3596469
INFO: indentation score: -0.35635042
INFO: space score: -0.35383055
INFO: snippet score: -0.351988
INFO: terminator score: -0.35193247
INFO: performance score: -0.3516372
INFO: tuple score: -0.35026368
INFO: class score: -0.34533322
INFO: backslash score: -0.33851105
INFO: filter score: -0.33778936
INFO: commas score: -0.33617714
INFO: unedited score: -0.3328908
INFO: readable score: -0.33052766
INFO: query score: -0.32899523
INFO: encourage score: -0.32747722
INFO: nice score: -0.32561114
INFO: division score: -0.32512712
INFO: funny score: -0.32329857
INFO: small score: -0.32049662
INFO: evaluation score: -0.31946763
INFO: suite score: -0.31556702
INFO: datum score: -0.30569154
INFO: stuff score: -0.30545783
INFO: return score: -0.2994558
INFO: lazy score: -0.29616743
INFO: today score: -0.29045698
INFO: style score: -0.28862962
INFO: unpack score: -0.2808389
INFO: program score: -0.28071436
INFO: multi score: -0.27950704
INFO: speed score: -0.27774417
INFO: pov score: -0.27567923
INFO: article score: -0.2721374
INFO: letter score: -0.27159095
INFO: pronounced score: -0.26656374
INFO: session score: -0.26329023
INFO: second score: -0.25169197
INFO: mind score: -0.2509738
INFO: trick score: -0.24088997
INFO: lexical score: -0.23297003
INFO: edit score: -0.23075908
INFO: command score: -0.2304762
INFO: w score: -0.22365367
INFO: giant score: -0.21736841
INFO: len score: -0.20798185
INFO: port score: -0.20648189
INFO: shell score: -0.19803727
INFO: doc score: -0.19387408
INFO: liner score: -0.19069834
INFO: serialized score: -0.17957726
INFO: top score: -0.1782001
INFO: quote score: -0.17761679
INFO: op score: -0.1767397
INFO: pip score: -0.17485535
INFO: brace score: -0.16741018
INFO: indented score: -0.16576509
INFO: str score: -0.16076344
INFO: bourne score: -0.15716498
INFO: flask score: -0.14736487
INFO: lambda score: -0.1350061
INFO: = score: -0.12747204
INFO: ts score: -0.122143626
INFO: average score: -0.108444825
INFO: toady score: -0.09746857
INFO: evening score: -0.08353149
INFO: manager score: -0.060239233
INFO: tim score: -0.042220637
INFO: f.write('\n score: -0.0
INFO: \n score: -0.0
INFO: os.linesep score: -0.0
INFO: writeline score: -0.0
INFO: pathlib score: -0.0
INFO: path.write_text(data score: -0.0
INFO: docs.python.org score: -0.0
INFO: georgy score: -0.0
INFO: filewriter score: -0.0
INFO: my_file.txt score: -0.0
INFO: f.write score: -0.0
INFO: there\r\n score: -0.0
INFO: there\n score: -0.0
INFO: tkinter score: -0.0
INFO: stmt1 score: -0.0
INFO: stmt2 score: -0.0
INFO: expr1][2 score: -0.0
INFO: boolexpr score: -0.0
INFO: line.count("t score: -0.0
INFO: len(line score: -0.0
INFO: t"s score: -0.0
INFO: @kaya3 score: -0.0
INFO: ts[0 score: -0.0
INFO: pythonic score: -0.0
INFO: acgtyrant score: -0.0
INFO: pep8 score: -0.0
INFO: demo score: 0.0079700565
INFO: pep score: 0.024409847
INFO: memoriam score: 0.05234651
INFO: ============================================================
INFO: --------------------
INFO: What does the slash(/) in the parameter list of a function mean?
INFO: --------------------
INFO: exist
INFO: adding document #0 to Dictionary<0 unique tokens: []>
INFO: built Dictionary<416 unique tokens: ['\\n', "\\n'.join", 'actual', 'alternative', 'answer']...> from 10 documents (total 1124 corpus positions)
DEBUG: starting a new internal lifecycle event log for Dictionary
INFO: Dictionary lifecycle event {'msg': 'built Dictionary<416 unique tokens: [\'\\\\n\', "\\\\n\'.join", \'actual\', \'alternative\', \'answer\']...> from 10 documents (total 1124 corpus positions)', 'datetime': '2023-04-18T14:16:38.500678', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO: using serial LDA version on this node
INFO: running online (multi-pass) LDA training, 3 topics, 10 passes over the supplied corpus of 10 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 2000x with a convergence threshold of 0.001000
DEBUG: bound: at document #0
INFO: -7.650 per-word bound, 200.9 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 0, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.066*"positional" + 0.059*"parameter" + 0.054*"argument" + 0.031*"string" + 0.028*"f" + 0.026*"function" + 0.021*"keyword" + 0.017*"name" + 0.013*"pep" + 0.011*"code"
INFO: topic #1 (1.000): 0.057*"argument" + 0.055*"parameter" + 0.027*"positional" + 0.025*"function" + 0.017*"f" + 0.016*"code" + 0.016*"keyword" + 0.015*"string" + 0.014*"new" + 0.013*"name"
INFO: topic #2 (1.000): 0.058*"parameter" + 0.056*"argument" + 0.048*"function" + 0.034*"positional" + 0.024*"name" + 0.021*"keyword" + 0.019*"example" + 0.014*"code" + 0.013*"path" + 0.013*"case"
INFO: topic diff=4.040215, rho=1.000000
DEBUG: bound: at document #0
INFO: -11.046 per-word bound, 2114.3 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 0, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.075*"parameter" + 0.070*"positional" + 0.058*"string" + 0.045*"argument" + 0.035*"function" + 0.025*"list" + 0.019*"syntax" + 0.017*"example" + 0.016*"keyword" + 0.015*"pep"
INFO: topic #1 (1.000): 0.033*"argument" + 0.030*"path" + 0.030*"parameter" + 0.030*"string" + 0.025*"slash" + 0.018*"example" + 0.016*"function" + 0.015*"positional" + 0.014*"code" + 0.012*"file"
INFO: topic #2 (1.000): 0.054*"parameter" + 0.050*"path" + 0.050*"function" + 0.043*"argument" + 0.029*"positional" + 0.021*"example" + 0.020*"directory" + 0.018*"syntax" + 0.018*"file" + 0.017*"name"
INFO: topic diff=3.421192, rho=0.707107
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 0: Perplexity estimate: 84.10594830423831
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 0: Coherence estimate: -2.6126591514688875
DEBUG: bound: at document #0
INFO: -6.213 per-word bound, 74.2 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 1, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.067*"parameter" + 0.067*"positional" + 0.054*"argument" + 0.042*"string" + 0.031*"function" + 0.025*"f" + 0.020*"keyword" + 0.017*"pep" + 0.016*"name" + 0.014*"syntax"
INFO: topic #1 (1.000): 0.025*"argument" + 0.023*"slash" + 0.022*"parameter" + 0.022*"path" + 0.022*"string" + 0.018*"code" + 0.014*"example" + 0.014*"discord" + 0.012*"function" + 0.011*"problem"
INFO: topic #2 (1.000): 0.056*"parameter" + 0.052*"argument" + 0.047*"function" + 0.034*"path" + 0.025*"positional" + 0.022*"example" + 0.020*"name" + 0.019*"directory" + 0.017*"keyword" + 0.016*"os.sep"
INFO: topic diff=1.464772, rho=0.500000
DEBUG: bound: at document #0
INFO: -7.355 per-word bound, 163.8 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 1, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.080*"parameter" + 0.074*"positional" + 0.052*"argument" + 0.042*"string" + 0.041*"function" + 0.021*"syntax" + 0.020*"list" + 0.019*"pep" + 0.019*"keyword" + 0.016*"f"
INFO: topic #1 (1.000): 0.039*"string" + 0.038*"path" + 0.022*"slash" + 0.021*"component" + 0.021*"absolute" + 0.017*"sequence" + 0.017*"tab" + 0.016*"example" + 0.016*"file" + 0.015*"drive"
INFO: topic #2 (1.000): 0.053*"parameter" + 0.048*"argument" + 0.047*"function" + 0.035*"path" + 0.023*"positional" + 0.021*"directory" + 0.021*"example" + 0.019*"value" + 0.018*"name" + 0.017*"window"
INFO: topic diff=1.401901, rho=0.500000
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 1: Perplexity estimate: 60.56187555711167
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 1: Coherence estimate: -4.615276488989953
DEBUG: bound: at document #0
INFO: -5.940 per-word bound, 61.4 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 2, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.070*"parameter" + 0.068*"positional" + 0.055*"argument" + 0.037*"string" + 0.034*"function" + 0.025*"f" + 0.021*"keyword" + 0.018*"pep" + 0.016*"name" + 0.015*"syntax"
INFO: topic #1 (1.000): 0.034*"string" + 0.033*"path" + 0.022*"slash" + 0.018*"component" + 0.018*"absolute" + 0.015*"sequence" + 0.015*"tab" + 0.014*"example" + 0.014*"file" + 0.013*"drive"
INFO: topic #2 (1.000): 0.056*"parameter" + 0.054*"argument" + 0.046*"function" + 0.027*"path" + 0.022*"positional" + 0.022*"example" + 0.021*"name" + 0.019*"directory" + 0.018*"value" + 0.018*"os.sep"
INFO: topic diff=0.865452, rho=0.447214
DEBUG: bound: at document #0
INFO: -6.227 per-word bound, 74.9 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 2, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.083*"parameter" + 0.075*"positional" + 0.055*"argument" + 0.043*"function" + 0.030*"string" + 0.022*"syntax" + 0.021*"pep" + 0.020*"keyword" + 0.018*"list" + 0.017*"f"
INFO: topic #1 (1.000): 0.050*"string" + 0.041*"path" + 0.022*"component" + 0.022*"absolute" + 0.021*"slash" + 0.018*"sequence" + 0.018*"tab" + 0.017*"file" + 0.016*"example" + 0.016*"drive"
INFO: topic #2 (1.000): 0.053*"parameter" + 0.052*"argument" + 0.046*"function" + 0.025*"path" + 0.023*"value" + 0.021*"example" + 0.021*"positional" + 0.020*"name" + 0.018*"directory" + 0.017*"case"
INFO: topic diff=0.678336, rho=0.447214
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 2: Perplexity estimate: 55.938565744250006
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 2: Coherence estimate: -4.182237238845409
DEBUG: bound: at document #0
INFO: -5.834 per-word bound, 57.1 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 3, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.072*"parameter" + 0.069*"positional" + 0.056*"argument" + 0.035*"function" + 0.031*"string" + 0.024*"f" + 0.021*"keyword" + 0.019*"pep" + 0.016*"syntax" + 0.016*"name"
INFO: topic #1 (1.000): 0.046*"string" + 0.038*"path" + 0.020*"absolute" + 0.020*"component" + 0.020*"slash" + 0.017*"sequence" + 0.017*"tab" + 0.017*"file" + 0.015*"example" + 0.014*"drive"
INFO: topic #2 (1.000): 0.056*"parameter" + 0.055*"argument" + 0.045*"function" + 0.023*"path" + 0.022*"example" + 0.022*"name" + 0.021*"positional" + 0.020*"value" + 0.019*"os.sep" + 0.018*"directory"
INFO: topic diff=0.570012, rho=0.408248
DEBUG: bound: at document #0
INFO: -6.030 per-word bound, 65.3 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 3, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.084*"parameter" + 0.075*"positional" + 0.056*"argument" + 0.044*"function" + 0.025*"string" + 0.023*"syntax" + 0.021*"pep" + 0.021*"keyword" + 0.018*"f" + 0.016*"list"
INFO: topic #1 (1.000): 0.055*"string" + 0.042*"path" + 0.022*"component" + 0.022*"absolute" + 0.020*"slash" + 0.019*"sequence" + 0.019*"tab" + 0.018*"file" + 0.017*"example" + 0.016*"drive"
INFO: topic #2 (1.000): 0.054*"argument" + 0.053*"parameter" + 0.046*"function" + 0.025*"value" + 0.021*"path" + 0.021*"example" + 0.021*"name" + 0.020*"positional" + 0.018*"case" + 0.017*"directory"
INFO: topic diff=0.445013, rho=0.408248
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 3: Perplexity estimate: 54.1124001501487
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 3: Coherence estimate: -4.183740504356496
DEBUG: bound: at document #0
INFO: -5.783 per-word bound, 55.1 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 4, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.072*"parameter" + 0.069*"positional" + 0.056*"argument" + 0.036*"function" + 0.028*"string" + 0.024*"f" + 0.021*"keyword" + 0.019*"pep" + 0.017*"syntax" + 0.016*"name"
INFO: topic #1 (1.000): 0.052*"string" + 0.040*"path" + 0.020*"component" + 0.020*"absolute" + 0.019*"slash" + 0.018*"file" + 0.017*"sequence" + 0.017*"tab" + 0.016*"example" + 0.015*"drive"
INFO: topic #2 (1.000): 0.056*"argument" + 0.056*"parameter" + 0.045*"function" + 0.022*"name" + 0.022*"example" + 0.022*"path" + 0.021*"value" + 0.021*"positional" + 0.020*"os.sep" + 0.018*"case"
INFO: topic diff=0.439752, rho=0.377964
DEBUG: bound: at document #0
INFO: -5.955 per-word bound, 62.0 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 4, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.084*"parameter" + 0.075*"positional" + 0.057*"argument" + 0.045*"function" + 0.023*"syntax" + 0.022*"string" + 0.021*"pep" + 0.021*"keyword" + 0.018*"f" + 0.016*"list"
INFO: topic #1 (1.000): 0.058*"string" + 0.042*"path" + 0.022*"absolute" + 0.022*"component" + 0.019*"slash" + 0.019*"tab" + 0.019*"sequence" + 0.018*"file" + 0.017*"example" + 0.015*"drive"
INFO: topic #2 (1.000): 0.055*"argument" + 0.054*"parameter" + 0.045*"function" + 0.026*"value" + 0.022*"name" + 0.021*"example" + 0.020*"path" + 0.020*"positional" + 0.019*"case" + 0.018*"os.sep"
INFO: topic diff=0.355951, rho=0.377964
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 4: Perplexity estimate: 53.42382987205144
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 4: Coherence estimate: -4.7826883385782795
DEBUG: bound: at document #0
INFO: -5.761 per-word bound, 54.2 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 5, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.073*"parameter" + 0.070*"positional" + 0.057*"argument" + 0.037*"function" + 0.027*"string" + 0.024*"f" + 0.021*"keyword" + 0.019*"pep" + 0.017*"syntax" + 0.016*"name"
INFO: topic #1 (1.000): 0.055*"string" + 0.040*"path" + 0.020*"absolute" + 0.020*"component" + 0.018*"slash" + 0.018*"file" + 0.017*"tab" + 0.017*"sequence" + 0.017*"example" + 0.015*"drive"
INFO: topic #2 (1.000): 0.057*"argument" + 0.056*"parameter" + 0.045*"function" + 0.022*"name" + 0.022*"example" + 0.022*"value" + 0.021*"path" + 0.020*"positional" + 0.020*"os.sep" + 0.019*"case"
INFO: topic diff=0.357847, rho=0.353553
DEBUG: bound: at document #0
INFO: -5.920 per-word bound, 60.6 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 5, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.084*"parameter" + 0.075*"positional" + 0.057*"argument" + 0.045*"function" + 0.023*"syntax" + 0.021*"string" + 0.021*"pep" + 0.021*"keyword" + 0.018*"f" + 0.015*"list"
INFO: topic #1 (1.000): 0.059*"string" + 0.042*"path" + 0.021*"component" + 0.021*"absolute" + 0.019*"slash" + 0.019*"file" + 0.018*"tab" + 0.018*"sequence" + 0.018*"example" + 0.015*"drive"
INFO: topic #2 (1.000): 0.056*"argument" + 0.054*"parameter" + 0.045*"function" + 0.026*"value" + 0.022*"name" + 0.022*"example" + 0.020*"path" + 0.019*"positional" + 0.019*"case" + 0.018*"os.sep"
INFO: topic diff=0.308343, rho=0.353553
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 5: Perplexity estimate: 53.16226588946401
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 5: Coherence estimate: -4.803226032817093
DEBUG: bound: at document #0
INFO: -5.750 per-word bound, 53.8 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 6, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.074*"parameter" + 0.070*"positional" + 0.057*"argument" + 0.038*"function" + 0.026*"string" + 0.024*"f" + 0.021*"keyword" + 0.019*"pep" + 0.018*"syntax" + 0.016*"name"
INFO: topic #1 (1.000): 0.057*"string" + 0.040*"path" + 0.020*"component" + 0.020*"absolute" + 0.018*"file" + 0.018*"slash" + 0.017*"sequence" + 0.017*"tab" + 0.017*"example" + 0.015*"drive"
INFO: topic #2 (1.000): 0.057*"argument" + 0.056*"parameter" + 0.045*"function" + 0.022*"name" + 0.022*"value" + 0.022*"example" + 0.021*"path" + 0.021*"os.sep" + 0.020*"positional" + 0.019*"case"
INFO: topic diff=0.307899, rho=0.333333
DEBUG: bound: at document #0
INFO: -5.903 per-word bound, 59.9 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 6, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.084*"parameter" + 0.075*"positional" + 0.057*"argument" + 0.045*"function" + 0.023*"syntax" + 0.021*"keyword" + 0.021*"pep" + 0.021*"string" + 0.019*"f" + 0.015*"list"
INFO: topic #1 (1.000): 0.059*"string" + 0.042*"path" + 0.021*"component" + 0.021*"absolute" + 0.019*"slash" + 0.019*"file" + 0.018*"tab" + 0.018*"sequence" + 0.018*"example" + 0.015*"drive"
INFO: topic #2 (1.000): 0.057*"argument" + 0.054*"parameter" + 0.045*"function" + 0.026*"value" + 0.022*"name" + 0.022*"example" + 0.019*"case" + 0.019*"path" + 0.019*"positional" + 0.018*"os.sep"
INFO: topic diff=0.281848, rho=0.333333
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 6: Perplexity estimate: 53.03583683698511
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 6: Coherence estimate: -4.822983278791774
DEBUG: bound: at document #0
INFO: -5.742 per-word bound, 53.5 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 7, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.074*"parameter" + 0.070*"positional" + 0.057*"argument" + 0.038*"function" + 0.025*"string" + 0.024*"f" + 0.021*"keyword" + 0.019*"pep" + 0.018*"syntax" + 0.016*"name"
INFO: topic #1 (1.000): 0.058*"string" + 0.040*"path" + 0.020*"component" + 0.020*"absolute" + 0.019*"file" + 0.018*"slash" + 0.017*"sequence" + 0.017*"tab" + 0.017*"example" + 0.015*"drive"
INFO: topic #2 (1.000): 0.058*"argument" + 0.056*"parameter" + 0.045*"function" + 0.023*"name" + 0.022*"value" + 0.022*"example" + 0.021*"path" + 0.021*"os.sep" + 0.020*"positional" + 0.019*"case"
INFO: topic diff=0.278872, rho=0.316228
DEBUG: bound: at document #0
INFO: -5.893 per-word bound, 59.4 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 7, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.083*"parameter" + 0.075*"positional" + 0.057*"argument" + 0.044*"function" + 0.023*"syntax" + 0.021*"keyword" + 0.021*"pep" + 0.021*"string" + 0.019*"f" + 0.015*"list"
INFO: topic #1 (1.000): 0.060*"string" + 0.042*"path" + 0.021*"component" + 0.021*"absolute" + 0.019*"slash" + 0.019*"file" + 0.018*"tab" + 0.018*"sequence" + 0.018*"example" + 0.015*"drive"
INFO: topic #2 (1.000): 0.057*"argument" + 0.054*"parameter" + 0.046*"function" + 0.026*"value" + 0.023*"name" + 0.022*"example" + 0.019*"case" + 0.019*"path" + 0.019*"positional" + 0.019*"os.sep"
INFO: topic diff=0.265812, rho=0.316228
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 7: Perplexity estimate: 52.95970867370107
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 7: Coherence estimate: -4.822983278791774
DEBUG: bound: at document #0
INFO: -5.736 per-word bound, 53.3 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 8, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.075*"parameter" + 0.070*"positional" + 0.057*"argument" + 0.038*"function" + 0.025*"string" + 0.024*"f" + 0.021*"keyword" + 0.020*"pep" + 0.018*"syntax" + 0.016*"name"
INFO: topic #1 (1.000): 0.058*"string" + 0.040*"path" + 0.020*"absolute" + 0.020*"component" + 0.019*"file" + 0.018*"slash" + 0.017*"sequence" + 0.017*"tab" + 0.017*"example" + 0.015*"drive"
INFO: topic #2 (1.000): 0.058*"argument" + 0.056*"parameter" + 0.045*"function" + 0.023*"name" + 0.022*"value" + 0.022*"example" + 0.021*"os.sep" + 0.021*"path" + 0.020*"positional" + 0.019*"case"
INFO: topic diff=0.259267, rho=0.301511
DEBUG: bound: at document #0
INFO: -5.886 per-word bound, 59.1 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 8, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.083*"parameter" + 0.075*"positional" + 0.057*"argument" + 0.044*"function" + 0.023*"syntax" + 0.021*"keyword" + 0.021*"pep" + 0.021*"string" + 0.019*"f" + 0.015*"name"
INFO: topic #1 (1.000): 0.060*"string" + 0.042*"path" + 0.021*"component" + 0.021*"absolute" + 0.019*"file" + 0.019*"slash" + 0.018*"sequence" + 0.018*"tab" + 0.018*"example" + 0.015*"drive"
INFO: topic #2 (1.000): 0.058*"argument" + 0.054*"parameter" + 0.046*"function" + 0.026*"value" + 0.023*"name" + 0.022*"example" + 0.020*"case" + 0.019*"path" + 0.019*"positional" + 0.019*"os.sep"
INFO: topic diff=0.251575, rho=0.301511
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 8: Perplexity estimate: 52.909184746314196
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 8: Coherence estimate: -4.814064961722706
DEBUG: bound: at document #0
INFO: -5.731 per-word bound, 53.1 perplexity estimate based on a held-out corpus of 5 documents with 647 words
INFO: PROGRESS: pass 9, at document #5/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.075*"parameter" + 0.071*"positional" + 0.057*"argument" + 0.038*"function" + 0.025*"string" + 0.023*"f" + 0.021*"keyword" + 0.020*"pep" + 0.018*"syntax" + 0.016*"name"
INFO: topic #1 (1.000): 0.059*"string" + 0.040*"path" + 0.020*"absolute" + 0.020*"component" + 0.019*"file" + 0.018*"slash" + 0.017*"sequence" + 0.017*"tab" + 0.017*"example" + 0.015*"character"
INFO: topic #2 (1.000): 0.058*"argument" + 0.056*"parameter" + 0.045*"function" + 0.023*"name" + 0.022*"value" + 0.022*"example" + 0.021*"os.sep" + 0.020*"path" + 0.020*"positional" + 0.019*"case"
INFO: topic diff=0.244099, rho=0.288675
DEBUG: bound: at document #0
INFO: -5.881 per-word bound, 58.9 perplexity estimate based on a held-out corpus of 5 documents with 477 words
INFO: PROGRESS: pass 9, at document #10/10
DEBUG: performing inference on a chunk of 5 documents
DEBUG: 5/5 documents converged within 2000 iterations
DEBUG: updating topics
INFO: merging changes from 5 documents into a model of 10 documents
INFO: topic #0 (1.000): 0.083*"parameter" + 0.075*"positional" + 0.057*"argument" + 0.044*"function" + 0.022*"syntax" + 0.021*"keyword" + 0.021*"pep" + 0.021*"string" + 0.019*"f" + 0.015*"name"
INFO: topic #1 (1.000): 0.060*"string" + 0.042*"path" + 0.021*"component" + 0.021*"absolute" + 0.019*"file" + 0.019*"slash" + 0.018*"sequence" + 0.018*"tab" + 0.018*"example" + 0.015*"drive"
INFO: topic #2 (1.000): 0.058*"argument" + 0.055*"parameter" + 0.046*"function" + 0.026*"value" + 0.023*"name" + 0.022*"example" + 0.020*"case" + 0.019*"path" + 0.019*"positional" + 0.019*"os.sep"
INFO: topic diff=0.238665, rho=0.288675
DEBUG: bound: at document #0
DEBUG: bound: at document #5
INFO: Epoch 9: Perplexity estimate: 52.87198926677171
DEBUG: Setting topics to those of the model: LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5>
INFO: Epoch 9: Coherence estimate: -4.814064961722706
DEBUG: starting a new internal lifecycle event log for LdaModel
INFO: LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=416, num_topics=3, decay=0.5, chunksize=5> in 0.22s', 'datetime': '2023-04-18T14:16:38.720396', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
DEBUG: starting a new internal lifecycle event log for LdaState
INFO: LdaState lifecycle event {'fname_or_handle': 'model/cos_threshold/14/model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-18T14:16:38.720559', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
DEBUG: {'uri': 'model/cos_threshold/14/model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/14/model.state
DEBUG: {'uri': 'model/cos_threshold/14/model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: LdaModel lifecycle event {'fname_or_handle': 'model/cos_threshold/14/model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['state', 'id2word', 'dispatcher'], 'datetime': '2023-04-18T14:16:38.724062', 'gensim': '4.3.1', 'python': '3.9.2 (default, Mar  4 2021, 10:15:47) \n[Clang 10.0.0 (clang-1000.10.44.4)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}
INFO: storing np array 'expElogbeta' to model/cos_threshold/14/model.expElogbeta.npy
INFO: not storing attribute state
INFO: not storing attribute id2word
INFO: not storing attribute dispatcher
DEBUG: {'uri': 'model/cos_threshold/14/model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
INFO: saved model/cos_threshold/14/model
INFO: topic #0 (1.000): 0.083*"parameter" + 0.075*"positional" + 0.057*"argument" + 0.044*"function" + 0.022*"syntax" + 0.021*"keyword" + 0.021*"pep" + 0.021*"string" + 0.019*"f" + 0.015*"name"
INFO: topic #1 (1.000): 0.060*"string" + 0.042*"path" + 0.021*"component" + 0.021*"absolute" + 0.019*"file" + 0.019*"slash" + 0.018*"sequence" + 0.018*"tab" + 0.018*"example" + 0.015*"drive"
INFO: topic #2 (1.000): 0.058*"argument" + 0.055*"parameter" + 0.046*"function" + 0.026*"value" + 0.023*"name" + 0.022*"example" + 0.020*"case" + 0.019*"path" + 0.019*"positional" + 0.019*"os.sep"
INFO: Question Similarity: [0.12553083896636963, 0.10954254865646362, 0.6439432203769684, 0.1365172266960144, 0.12598299980163574, 0.18281638622283936, 0.0537380576133728, 0.18379920721054077, 0.026678740978240967, 0.25701236724853516]
INFO: 59642921: -0.1684191307930756
INFO: 24735582: -0.16856124303343492
INFO: 56212520: -0.17120020337114594
INFO: 44780467: -0.19523461627341032
INFO: 44781006: -0.19932133309277303
INFO: 69762290: -0.20032564344741943
INFO: 44780840: -0.20788545211069415
INFO: 68678495: -0.21294384681220083
INFO: 44781133: -0.21784952930751525
INFO: 75404785: -0.23659261823467898
INFO: 16011098: -0.310866169890251
INFO: 50522959: -0.31628220812492847
INFO: 16011057: -0.31628220812492847
INFO: 16011031: -0.31628220812492847
INFO: 16011039: -0.3186911260519554
INFO: 44189631: -0.32710242553985563
INFO: 16011083: -0.3304007966524256
INFO: 59661122: -0.33130064067910586
INFO: 59661137: -0.343949129764498
INFO: 67585662: -0.3451355211094931
INFO: 38923690: -0.36274113317307194
INFO: 16011123: -0.36501042058532246
INFO: 67751005: -0.36790198994407486
INFO: 56514307: -0.40538021316545364
INFO: 47363488: -0.4083608957049435
INFO: 25559273: -0.4115891554982448
INFO: 1945936: -0.4272909984217492
INFO: 58588281: -0.4272930408134783
INFO: 57826848: -0.43065608425721486
INFO: 1946192: -0.435849981444993
INFO: 4488585: -0.4404026918166038
INFO: 65945746: -0.44963124643124347
INFO: 60416293: -0.46400313616664896
INFO: 4488586: -0.466648912001895
INFO: 74229426: -0.4689228003594217
INFO: 1945939: -0.4736541616846914
INFO: 14962135: -0.47390510405973685
INFO: 49961041: -0.4779959844389727
INFO: 4488596: -0.48294534478864165
INFO: 1945935: -0.4874652923673651
INFO: 1948595: -0.49754231688701384
INFO: 62445955: -0.5011490884334378
INFO: 37556617: -0.5051543357131822
INFO: 24296743: -0.5066669032069617
INFO: 69469685: -0.5095720079951512
INFO: 1945930: -0.5256387830567946
INFO: 43390891: -0.5290996215640303
INFO: 74845836: -1.039500954109571
INFO: Recommended Keywords
INFO: example score: -0.8406875
INFO: case score: -0.79183304
INFO: function score: -0.77117664
INFO: parameter score: -0.74950856
INFO: notation score: -0.72802645
INFO: define score: -0.7278411
INFO: component score: -0.7166698
INFO: useful score: -0.7141629
INFO: sequence score: -0.7098534
INFO: specific score: -0.7010777
INFO: value score: -0.6927555
INFO: form score: -0.690113
INFO: binary score: -0.68842334
INFO: keyword score: -0.6821433
INFO: error score: -0.6672207
INFO: variable score: -0.66707903
INFO: positional score: -0.6669408
INFO: method score: -0.66656274
INFO: reference score: -0.6665429
INFO: syntax score: -0.6640176
INFO: simple score: -0.660821
INFO: relevant score: -0.65882206
INFO: problem score: -0.64575857
INFO: choice score: -0.6455999
INFO: backward score: -0.6400863
INFO: approach score: -0.6384515
INFO: definition score: -0.63667697
INFO: reset score: -0.63177186
INFO: relative score: -0.62729543
INFO: similar score: -0.6246431
INFO: need score: -0.62106943
INFO: application score: -0.6163915
INFO: point score: -0.6122686
INFO: space score: -0.5944912
INFO: newline score: -0.59307617
INFO: extra score: -0.586467
INFO: expression score: -0.58601063
INFO: root score: -0.585418
INFO: remove score: -0.58302677
INFO: path score: -0.5829841
INFO: code score: -0.5823164
INFO: interface score: -0.58066314
INFO: readability score: -0.57154393
INFO: output score: -0.56937444
INFO: consider score: -0.5624778
INFO: valid score: -0.56195563
INFO: redundant score: -0.56068057
INFO: slash score: -0.56047416
INFO: see score: -0.5582768
INFO: tab score: -0.55637705
INFO: item score: -0.55637133
INFO: absolute score: -0.54761773
INFO: extension score: -0.5475276
INFO: note score: -0.5469251
INFO: special score: -0.54647726
INFO: string score: -0.54564047
INFO: argument score: -0.5453515
INFO: key score: -0.54056764
INFO: convert score: -0.5378632
INFO: factor score: -0.53169554
INFO: f score: -0.53056777
INFO: actual score: -0.5293712
INFO: link score: -0.5280544
INFO: whitespace score: -0.5260611
INFO: conjunction score: -0.51790917
INFO: append score: -0.5145885
INFO: sense score: -0.511162
INFO: prevent score: -0.51014876
INFO: cross score: -0.50744826
INFO: current score: -0.5053774
INFO: file score: -0.5040618
INFO: module score: -0.5024706
INFO: drive score: -0.5006899
INFO: test score: -0.50014126
INFO: default score: -0.4965889
INFO: punctuation score: -0.49605277
INFO: literal score: -0.49523702
INFO: readable score: -0.4933096
INFO: workaround score: -0.49248832
INFO: manual score: -0.48926753
INFO: separator score: -0.48067272
INFO: kind score: -0.4722163
INFO: length score: -0.472187
INFO: horizontal score: -0.46959275
INFO: self score: -0.46843573
INFO: folder score: -0.4604501
INFO: field score: -0.45693606
INFO: update score: -0.4503331
INFO: behavior score: -0.44691133
INFO: pure score: -0.44475678
INFO: dot score: -0.44196633
INFO: question score: -0.43631223
INFO: parent score: -0.43604422
INFO: rationale score: -0.43339875
INFO: config score: -0.43034965
INFO: alternative score: -0.42491814
INFO: property score: -0.4228044
INFO: statement score: -0.42058054
INFO: py score: -0.42049915
INFO: implementation score: -0.41430628
INFO: c score: -0.4122342
INFO: sandbox score: -0.41092968
INFO: client score: -0.40809378
INFO: raw score: -0.40642884
INFO: directory score: -0.39659625
INFO: idea score: -0.39468545
INFO: answer score: -0.39429954
INFO: allow score: -0.39389816
INFO: call score: -0.39361155
INFO: forward score: -0.3901197
INFO: result score: -0.3887879
INFO: priority score: -0.38734823
INFO: well score: -0.38382462
INFO: foo score: -0.3833081
INFO: formatter score: -0.38158277
INFO: len score: -0.38058326
INFO: platform score: -0.37936145
INFO: front score: -0.3789156
INFO: sub score: -0.37710363
INFO: reading score: -0.3770251
INFO: understanding score: -0.37277973
INFO: usable score: -0.3656903
INFO: least score: -0.36368138
INFO: option score: -0.3602143
INFO: window score: -0.3595875
INFO: portable score: -0.35890508
INFO: documentation score: -0.35540923
INFO: thing score: -0.3540746
INFO: future score: -0.35381815
INFO: latter score: -0.35312757
INFO: char score: -0.34971568
INFO: enable score: -0.34445387
INFO: tabulation score: -0.3423837
INFO: pathname score: -0.34091523
INFO: full score: -0.34088105
INFO: right score: -0.3403747
INFO: uninstall score: -0.3385974
INFO: way score: -0.3369211
INFO: hello score: -0.3323075
INFO: build score: -0.32922173
INFO: surprising score: -0.32619414
INFO: previous score: -0.32536268
INFO: edit score: -0.32427084
INFO: global score: -0.32183623
INFO: line score: -0.32036823
INFO: natural score: -0.3147409
INFO: format score: -0.31406957
INFO: optional score: -0.31096196
INFO: b score: -0.30575213
INFO: text score: -0.30520144
INFO: linux score: -0.30110922
INFO: split score: -0.29921386
INFO: lash score: -0.2940872
INFO: version score: -0.2936942
INFO: help score: -0.2901756
INFO: character score: -0.2880799
INFO: filename score: -0.28699812
INFO: snippet score: -0.2866425
INFO: other score: -0.2828672
INFO: foobar score: -0.280812
INFO: comment score: -0.2781656
INFO: list score: -0.2778537
INFO: = score: -0.27412653
INFO: exotic score: -0.2735357
INFO: entry score: -0.27034378
INFO: program score: -0.26823267
INFO: sep score: -0.2647749
INFO: print score: -0.2615853
INFO: new score: -0.25805628
INFO: strip score: -0.257593
INFO: speed score: -0.25471154
INFO: letter score: -0.2540999
INFO: separate score: -0.2515436
INFO: combo score: -0.247698
INFO: one score: -0.24230929
INFO: bite score: -0.24097694
INFO: tree score: -0.23828635
INFO: issue score: -0.2340562
INFO: course score: -0.23358184
INFO: script score: -0.23224771
INFO: replace score: -0.22599132
INFO: escape score: -0.22306395
INFO: end score: -0.22028044
INFO: return score: -0.21993801
INFO: align score: -0.21485952
INFO: position score: -0.20807534
INFO: curly score: -0.20798133
INFO: guido score: -0.20736396
INFO: pip score: -0.19838792
INFO: entire score: -0.19776188
INFO: op score: -0.19484426
INFO: name score: -0.19471668
INFO: faq score: -0.19453827
INFO: api score: -0.1936005
INFO: none score: -0.18712866
INFO: pep score: -0.18550923
INFO: opposite score: -0.18307681
INFO: mark score: -0.17657267
INFO: work score: -0.17125976
INFO: strange score: -0.17085466
INFO: install score: -0.16664961
INFO: throw score: -0.1662607
INFO: windows score: -0.1603386
INFO: heh score: -0.16020656
INFO: cord score: -0.15850793
INFO: util score: -0.15230247
INFO: companion score: -0.1477452
INFO: recent score: -0.14323586
INFO: raise score: -0.13470635
INFO: command score: -0.13209929
INFO: fortunate score: -0.1258553
INFO: event score: -0.12547497
INFO: recap score: -0.12301317
INFO: proposal score: -0.12169622
INFO: brace score: -0.10153572
INFO: hope score: -0.100820415
INFO: rick score: -0.09861374
INFO: library score: -0.09630495
INFO: join score: -0.08485277
INFO: discord score: -0.08435773
INFO: uplevel score: -0.08156172
INFO: doc score: -0.07091647
INFO: portion score: -0.07082043
INFO: rest score: -0.06613114
INFO: ruin score: -0.04720995
INFO: top score: -0.042623345
INFO: terrible score: -0.025578003
INFO: next score: -0.020425977
INFO: author score: -0.0069495104
INFO: alex score: -0.0056181317
INFO: syntaxerror score: -0.0
INFO: \n score: -0.0
INFO: str.join()/str.format score: -0.0
INFO: backslashe score: -0.0
INFO: os.linesep score: -0.0
INFO: typeerror score: -0.0
INFO: python3.8 score: -0.0
INFO: signifie score: -0.0
INFO: discord.ext score: -0.0
INFO: pycord score: -0.0
INFO: https://guide.pycord.dev/installation score: -0.0
INFO: os.sep score: -0.0
INFO: \utils\properties.ini score: -0.0
INFO: pathlib score: -0.0
INFO: pathlib.os.sep score: -0.0
INFO: os.path.normpath(pathname score: -0.0
INFO: foo/ score: -0.0
INFO: a/./b score: -0.0
INFO: b. score: -0.0
INFO: os.path score: -0.0
INFO: larry score: -0.0
INFO: os.path.join(a score: -0.0
INFO: path(__file__).resolve().parent score: -0.0
INFO: split("/ score: -0.0
INFO: http://docs.python.org/library/os.path.html#os.path.join score: -0.0
INFO: os.environ['home score: -0.0
INFO: os.path.dirname(__file score: -0.0
INFO: os.path.sep score: -0.0
INFO: foobar.jpg score: -0.0
INFO: new_sandbox score: -0.0
INFO: myapp.conf score: -0.0
INFO: foo.conf score: -0.0
INFO: myapp score: -0.0
INFO: /some score: -0.0
INFO: /new_sandbox/ score: -0.0
INFO: eq__(self score: -0.0
INFO: file.write("hello\talex score: -0.0
INFO: hello\n{tab}alex score: -0.0
INFO: tabulation}alex score: -0.0
INFO: hello\n{ht}alex score: -0.0
INFO: hello\n{character score: -0.0
INFO: hello\n{horizontal score: -0.0
INFO: hello\x09alex score: -0.0
INFO: hello\u0009alex score: -0.0
INFO: hello\u00000009alex score: -0.0
INFO: \t score: -0.0
INFO: hello\talex score: -0.0
INFO: hello--->alex score: -0.0
INFO: slash(/ score: -0.0
INFO: divmod score: -0.0
INFO: cpython score: -0.0
INFO: clinic score: 0.024950873
INFO: home score: 0.071149945
INFO: ============================================================
