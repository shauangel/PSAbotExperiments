[{"link": "https://stackoverflow.com/questions/42339876/error-unicodedecodeerror-utf-8-codec-cant-decode-byte-0xff-in-position-0-in", "keywords": [], "tags": ["python", "python-3.x", "utf-8"], "question": {"id": 42339876, "title": "Error UnicodeDecodeError: &#39;utf-8&#39; codec can&#39;t decode byte 0xff in position 0: invalid start byte", "content": "https://github.com/affinelayer/pix2pix-tensorflow/tree/master/tools An error occurred when compiling \"process.py\" on the above site. What is the cause of the error?\nPython's version is 3.5.2.", "abstract": ""}, "answers": [{"id": 72673322, "score": -3, "vote": 0, "content": "Following code worked in my case: df = pd.read_csv(filename,sep = '\\t', encoding='cp1252')", "abstract": ""}, {"id": 70504654, "score": 5, "vote": 0, "content": "I had this UnicodeDecodeError while trying to read a '.csv' file using pandas.read_csv(). In my case, I could not manage to overcome this issue using other encoder types. But instead of using I used: which just seems working fine for me. Note that: In open() function, use 'r' instead of 'rb'. Because 'rb' returns bytes object that causes to happen this decoder error in the first place, that is the same problem in the read_csv(). But 'r' returns str which is needed since our data is in .csv, and using the default encoding='utf-8' parameter, we can easily parse the data using read_csv() function.", "abstract": ""}, {"id": 68889180, "score": 11, "vote": 0, "content": "Those getting similar errors while handling Pandas for data frames use the following solution. example solution.", "abstract": ""}, {"id": 64037458, "score": 7, "vote": 0, "content": "This is due to the different encoding method when read the file. In python, it defaultly\nencode the data with unicode. However, it may not works in various platforms. I propose an encoding method which can help you solve this if 'utf-8' not works. It should works if you change the encoding method here. Also, you can find other encoding method here standard-encodings , if above doesn't work for you.", "abstract": ""}, {"id": 64985441, "score": 9, "vote": 0, "content": "I had a similar issue with PNG files. and I tried the solutions above without success.\nthis one worked for me in python 3.8", "abstract": ""}, {"id": 63423929, "score": -1, "vote": 0, "content": "You have to use the encoding as latin1 to read this file as there are some special character in this file, use the below code snippet to read the file. The problem here is the encoding type. When Python can't convert the data to be read, it gives an error. You can you latin1 or other encoding values. I say try and test to find the right one for your dataset.", "abstract": ""}, {"id": 63183024, "score": 2, "vote": 0, "content": "I had a similar issue and searched all the internet for this problem if you have this problem just copy your HTML code in a new HTML file and use the normal  <meta charset=\"UTF-8\">\nand it will work.... just create a new HTML file in the same location and use a different name", "abstract": ""}, {"id": 61885804, "score": -2, "vote": 0, "content": "I have the same issue when processing a file generated from Linux. It turns out it was related with files containing question marks..", "abstract": ""}, {"id": 58792216, "score": 8, "vote": 0, "content": "It simply means that one chose the wrong encoding to read the file. On Mac, use file -I file.txt to find the correct encoding. On Linux, use file -i file.txt.", "abstract": ""}, {"id": 58657942, "score": 0, "vote": 0, "content": "I had a similar problem. Solved it by: However, I had another problem. Some html files (in my case) were not utf-8, so I received a similar error. When I excluded those html files, everything worked smoothly. So, except from fixing the code, check also the files you are reading from, maybe there is an incompatibility there indeed.", "abstract": ""}, {"id": 56450616, "score": 78, "vote": 0, "content": "Use encoding format ISO-8859-1 to solve the issue.", "abstract": ""}, {"id": 55760534, "score": 2, "vote": 0, "content": "if you are receiving data from a serial port, make sure you are using the right baudrate (and the other configs ) :  decoding using (utf-8) but the wrong config will generate the same error UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte to check your serial port config on linux use : stty -F /dev/ttyUSBX -a", "abstract": ""}, {"id": 54296883, "score": 1, "vote": 0, "content": "If you are on a mac check if you for a hidden file, .DS_Store. After removing the file my program worked. ", "abstract": ""}, {"id": 42340744, "score": 374, "vote": 0, "content": "Python tries to convert a byte-array (a bytes which it assumes to be a utf-8-encoded string) to a unicode string (str).  This process of course is a decoding according to utf-8 rules.  When it tries this, it encounters a byte sequence which is not allowed in utf-8-encoded strings (namely this 0xff at position 0). Since you did not provide any code we could look at, we only could guess on the rest. From the stack trace we can assume that the triggering action was the reading from a file (contents = open(path).read()).  I propose to recode this in a fashion like this: That b in the mode specifier in the open() states that the file shall be treated as binary, so contents will remain a bytes.  No decoding attempt will happen this way.", "abstract": ""}, {"id": 50897169, "score": 7, "vote": 0, "content": "use only  instead of ", "abstract": ""}, {"id": 48556203, "score": 163, "vote": 0, "content": "Use this solution it will strip out (ignore) the characters and return the string without them. Only use this if your need is to strip them not convert them. Using errors='ignore'\nYou'll just lose some characters. but if your don't care about them as they seem to be extra characters originating from a the bad formatting and programming of the clients connecting to my socket server.\nThen its a easy direct solution.\nreference", "abstract": ""}, {"id": 47634048, "score": 25, "vote": 0, "content": "I've come across this thread when suffering the same error, after doing some research I can confirm, this is an error that happens when you try to decode a UTF-16 file with UTF-8. With UTF-16 the first characther (2 bytes in UTF-16) is a Byte Order Mark (BOM), which is used as a decoding hint and doesn't appear as a character in the decoded string. This means the first byte will be either FE or FF and the second, the other. Heavily edited after I found out the real answer", "abstract": ""}, {"id": 45717703, "score": 36, "vote": 0, "content": "Had an issue similar to this, Ended up using UTF-16 to decode. my code is below. this would take the file contents as an import, but it would return the code in UTF format. from there it would be decoded and seperated by lines.", "abstract": ""}, {"id": 45661057, "score": -6, "vote": 0, "content": "If possible, open the file in a text editor and try to change the encoding to UTF-8. Otherwise do it programatically at the OS level. ", "abstract": ""}, {"id": 44908369, "score": 1, "vote": 0, "content": "Check the path of the file to be read. My code kept on giving me errors until I changed the path name to present working directory. The error was:", "abstract": ""}]}, {"link": "https://stackoverflow.com/questions/21129020/how-to-fix-unicodedecodeerror-ascii-codec-cant-decode-byte", "keywords": [], "tags": ["python", "python-2.7", "chinese-locale"], "question": {"id": 21129020, "title": "How to fix: &quot;UnicodeDecodeError: &#39;ascii&#39; codec can&#39;t decode byte&quot;", "content": "How to fix it? In some other python-based static blog apps, Chinese post can be published successfully.\nSuch as this app: http://github.com/vrypan/bucket3. In my site http://bc3.brite.biz/, Chinese post can be published successfully.", "abstract": ""}, "answers": [{"id": 65886584, "score": 0, "vote": 0, "content": "I experienced this error with Python2.7. It happened to me while trying to run many python programs, but I managed to reproduce it with this simple script: On success, it should print out 'foo' and 'bar', and probably an error message if you're not in a svn folder. On failure, it should print 'UnicodeDecodeError: 'ascii' codec can't decode byte 0xc4 in position 39: ordinal not in range(128)'. After trying to regenerate my locales and many other solutions posted in this question, I learned the error was happening because I had a special character (\u013a) encoded in my PATH environment variable. After fixing the PATH in '~/.bashrc', and exiting my session and entering again, (apparently sourcing '~/.bashrc' didn't work), the issue was gone.", "abstract": ""}, {"id": 35444608, "score": 654, "vote": 0, "content": "Without seeing the source it's difficult to know the root cause, so I'll have to speak generally. UnicodeDecodeError: 'ascii' codec can't decode byte generally happens when you try to convert a Python 2.x str that contains non-ASCII to a Unicode string without specifying the encoding of the original string. In brief, Unicode strings are an entirely separate type of Python string that does not contain any encoding. They only hold Unicode point codes and therefore can hold any Unicode point from across the entire spectrum. Strings contain encoded text, beit UTF-8, UTF-16, ISO-8895-1, GBK, Big5 etc. Strings are decoded to Unicode and Unicodes are encoded to strings. Files and text data are always transferred in encoded strings. The Markdown module authors probably use unicode() (where the exception is thrown) as a quality gate to the rest of the code - it will convert ASCII or re-wrap existing Unicodes strings to a new Unicode string. The Markdown authors can't know the encoding of the incoming string so will rely on you to decode strings to Unicode strings before passing to Markdown. Unicode strings can be declared in your code using the u prefix to strings. E.g. Unicode strings may also come from file, databases and network modules. When this happens, you don't need to worry about the encoding. Conversion from str to Unicode can happen even when you don't explicitly call unicode(). The following scenarios cause UnicodeDecodeError exceptions: In the following diagram, you can see how the word caf\u00e9 has been encoded in either \"UTF-8\" or \"Cp1252\" encoding depending on the terminal type. In both examples, caf is just regular ascii. In UTF-8, \u00e9 is encoded using two bytes. In \"Cp1252\", \u00e9 is 0xE9 (which is also happens to be the Unicode point value (it's no coincidence)). The correct decode() is invoked and conversion to a Python Unicode is successfull:\n In this diagram, decode() is called with ascii (which is the same as calling unicode() without an encoding given). As ASCII can't contain bytes greater than 0x7F, this will throw a UnicodeDecodeError exception:  It's good practice to form a Unicode sandwich in your code, where you decode all incoming data to Unicode strings, work with Unicodes, then encode to strs on the way out. This saves you from worrying about the encoding of strings in the middle of your code. If you need to bake non-ASCII into your source code, just create Unicode strings by prefixing the string with a u. E.g. To allow Python to decode your source code, you will need to add an encoding header to match the actual encoding of your file. For example, if your file was encoded as 'UTF-8', you would use: This is only necessary when you have non-ASCII in your source code. Usually non-ASCII data is received from a file. The io module provides a TextWrapper that decodes your file on the fly, using a given encoding. You must use the correct encoding for the file - it can't be easily guessed. For example, for a UTF-8 file: my_unicode_string would then be suitable for passing to Markdown. If a UnicodeDecodeError from the read() line, then you've probably used the wrong encoding value. The Python 2.7 CSV module does not support non-ASCII characters \ud83d\ude29. Help is at hand, however, with https://pypi.python.org/pypi/backports.csv. Use it like above but pass the opened file to it: Most Python database drivers can return data in Unicode, but usually require a little configuration. Always use Unicode strings for SQL queries. In the connection string add: E.g. Add: Web pages can be encoded in just about any encoding. The Content-type header should contain a charset field to hint at the encoding. The content can then be decoded manually against this value. Alternatively, Python-Requests returns Unicodes in response.text. If you must decode strings manually, you can simply do my_string.decode(encoding), where encoding is the appropriate encoding. Python 2.x supported codecs are given here: Standard Encodings. Again, if you get UnicodeDecodeError then you've probably got the wrong encoding. Work with Unicodes as you would normal strs. print writes through the stdout stream. Python tries to configure an encoder on stdout so that Unicodes are encoded to the console's encoding. For example, if a Linux shell's locale is en_GB.UTF-8, the output will be encoded to UTF-8. On Windows, you will be limited to an 8bit code page. An incorrectly configured console, such as corrupt locale, can lead to unexpected print errors. PYTHONIOENCODING environment variable can force the encoding for stdout.  Just like input, io.open can be used to transparently convert Unicodes to encoded byte strings. The same configuration for reading will allow Unicodes to be written directly. Python 3 is no more Unicode capable than Python 2.x is, however it is slightly less confused on the topic. E.g the regular str is now a Unicode string and the old str is now bytes.  The default encoding is UTF-8, so if you .decode() a byte string without giving an encoding, Python 3 uses UTF-8 encoding. This probably fixes 50% of people's Unicode problems. Further, open() operates in text mode by default, so returns decoded str (Unicode ones). The encoding is derived from your locale, which tends to be UTF-8 on Un*x systems or an 8-bit code page, such as windows-1251, on Windows boxes. It's a nasty hack (there's a reason you have to use reload) that will only mask problems and hinder your migration to Python 3.x. Understand the problem, fix the root cause and enjoy Unicode zen.\nSee Why should we NOT use sys.setdefaultencoding(\"utf-8\") in a py script? for further details", "abstract": ""}, {"id": 51450311, "score": 7, "vote": 0, "content": "I had the same error, with URLs containing non-ascii chars (bytes with values > 128), my solution: Note: utf-8, utf8 are simply aliases . Using only 'utf8' or 'utf-8' should work in the same way In my case, worked for me, in Python 2.7, I suppose this assignment changed 'something' in the str internal representation--i.e., it forces the right decoding of the backed byte sequence in url and finally puts the string into a utf-8 str with all the magic in the right place.\nUnicode in Python is black magic for me.\nHope useful", "abstract": ""}, {"id": 21129492, "score": 131, "vote": 0, "content": "This is the classic \"unicode issue\".   I believe that explaining this is beyond the scope of a StackOverflow answer to completely explain what is happening.   It is well explained here. In very brief summary, you have passed something that is being interpreted as a string of bytes to something that needs to decode it into Unicode characters, but the default codec (ascii) is failing. The presentation I pointed you to provides advice for avoiding this.   Make your code a \"unicode sandwich\".   In Python 2, the use of from __future__ import unicode_literals helps. Update: how can the code be fixed: OK - in your variable \"source\" you have some bytes.  It is not clear from your question how they got in there - maybe you read them from a web form?   In any case, they are not encoded with ascii, but python is trying to convert them to unicode assuming that they are.  You need to explicitly tell it what the encoding is.   This means that you need to know what the encoding is!   That is not always easy, and it depends entirely on where this string came from.   You could experiment with some common encodings - for example UTF-8.   You tell unicode() the encoding as a second parameter:", "abstract": ""}, {"id": 56594708, "score": 7, "vote": 0, "content": "This worked for me:", "abstract": ""}, {"id": 56355083, "score": 9, "vote": 0, "content": "Got a same error and this solved my error. Thanks!\npython 2 and python 3 differing in unicode handling is making pickled files quite incompatible to load. So Use python pickle's encoding argument. Link below helped me solve the similar problem when I was trying to open pickled data from my python 3.7, while my file was saved originally in python 2.x version.\nhttps://blog.modest-destiny.com/posts/python-2-and-3-compatible-pickle-save-and-load/\nI copy the load_pickle function in my script and called the load_pickle(pickle_file) while loading my input_data like this: The load_pickle function is here:", "abstract": ""}, {"id": 54790348, "score": 17, "vote": 0, "content": "In order to resolve this on an operating system level in an Ubuntu installation check the following: If you get instead of then set LC_CTYPE and LC_ALL like this:", "abstract": ""}, {"id": 54510517, "score": 0, "vote": 0, "content": "Specify: # encoding= utf-8  at the top of your Python File, It should fix the issue", "abstract": ""}, {"id": 45723026, "score": 18, "vote": 0, "content": "Cause of this error: input_string must be unicode but str was given Cause of this error: trying to convert unicode input_string into unicode So first check that your input_string is str and convert to unicode if necessary: Secondly, the above just changes the type but does not remove non ascii characters. If you want to remove non-ascii characters:", "abstract": ""}, {"id": 52269622, "score": 0, "vote": 0, "content": "Here is my solution, just add the encoding. \nwith open(file, encoding='utf8') as f And because reading glove file will take a long time, I recommend to the glove file to a numpy file. When netx time you read the embedding weights, it will save your time.  Gist link: https://gist.github.com/BrambleXu/634a844cdd3cd04bb2e3ba3c83aef227", "abstract": ""}, {"id": 51532584, "score": 1, "vote": 0, "content": "This error occurs when there are some non ASCII characters in our string and we are performing any operations on that string without proper decoding.\nThis helped me solve my problem.\nI am reading a CSV file with columns ID,Text and decoding characters in it as below:", "abstract": ""}, {"id": 49131427, "score": 31, "vote": 0, "content": "I was searching to solve the following error message: unicodedecodeerror: 'ascii' codec can't decode byte 0xe2 in position 5454: ordinal not in range(128) I finally got it fixed by specifying 'encoding': Wish it could help you too.", "abstract": ""}, {"id": 48933989, "score": 3, "vote": 0, "content": "In short, to ensure proper unicode handling in Python 2: For explanations, see @Alastair McCormack's detailed answer.", "abstract": ""}, {"id": 46282412, "score": 7, "vote": 0, "content": "Encode converts a unicode object in to a string object. I think you are trying to encode a string object. first convert your result into unicode object and then encode that unicode object into 'utf-8'.\nfor example", "abstract": ""}, {"id": 45722214, "score": 5, "vote": 0, "content": "I had the same problem but it didn't work for Python 3. I followed this and it solved my problem: You have to set the encoding when you are reading/writing the file.", "abstract": ""}, {"id": 44238225, "score": 3, "vote": 0, "content": "I got the same problem with the string \"Pasteler\u00c3\u00ada Mallorca\" and I solved with:", "abstract": ""}, {"id": 41631583, "score": 1, "vote": 0, "content": "In a Django (1.9.10)/Python 2.7.5 project I have frequent UnicodeDecodeError exceptions; mainly when I try to feed unicode strings to logging. I made a helper function for arbitrary objects to basically format to 8-bit ascii strings and replacing any characters not in the table to '?'. I think it's not the best solution but since the default encoding is ascii (and i don't want to change it) it will do: \ndef encode_for_logging(c, encoding='ascii'):\n    if isinstance(c, basestring):\n        return c.encode(encoding, 'replace')\n    elif isinstance(c, Iterable):\n        c_ = []\n        for v in c:\n            c_.append(encode_for_logging(v, encoding))\n        return c_\n    else:\n        return encode_for_logging(unicode(c))\n`", "abstract": ""}, {"id": 21190382, "score": 509, "vote": 0, "content": "Finally I got it: Let me check: The above shows the default encoding of python is utf8. Then the error is no more.", "abstract": ""}, {"id": 27745947, "score": 9, "vote": 0, "content": "I find the best is to always convert to unicode - but this is difficult to achieve because in practice you'd have to check and convert every argument to every function and method you ever write that includes some form of string processing. So I came up with the following approach to either guarantee unicodes or byte strings, from either input. In short, include and use the following lambdas: Examples: Here's some more reasoning about this.", "abstract": ""}, {"id": 26767972, "score": 45, "vote": 0, "content": "In some cases, when you check your default encoding (print sys.getdefaultencoding()), it returns that you are using ASCII. If you change to UTF-8, it doesn't work, depending on the content of your variable.\nI found another way:    ", "abstract": ""}]}, {"link": "https://stackoverflow.com/questions/9644099/why-does-encoding-a-string-result-in-a-decoding-error-unicodedecodeerror", "keywords": [], "tags": ["python", "python-2.7", "unicode", "python-2.x", "python-unicode"], "question": {"id": 9644099, "title": "Why does ENcoding a string result in a DEcoding error (UnicodeDecodeError)?", "content": "I'm really confused. I tried to encode but the error said can't decode....  I know how to avoid the error with \"u\" prefix on the string. I'm just wondering why the error is \"can't decode\" when encode was called.  What is Python doing under the hood?", "abstract": ""}, "answers": [{"id": 52546101, "score": 2, "vote": 0, "content": "If you are starting the python interpreter from a shell on Linux or similar systems (BSD, not sure about Mac), you should also check the default encoding for the shell.  Call locale charmap from the shell (not the python interpreter) and you should see If this is not the case, and you see something else, e.g.  Python will (at least in some cases such as in mine) inherit the shell's encoding and will not be able to print (some? all?) unicode characters. Python's own default encoding that you see and control via sys.getdefaultencoding() and sys.setdefaultencoding() is in this case ignored. If you find that you have this problem, you can fix that by  (Or alternatively choose whichever keymap you want instead of en_EN.) You can also edit /etc/locale.conf (or whichever file governs the locale definition in your system) to correct this.", "abstract": ""}, {"id": 44229656, "score": 4, "vote": 0, "content": "In case you're dealing with Unicode, sometimes instead of encode('utf-8'), you can also try to ignore the special characters, e.g. or as something.decode('unicode_escape').encode('ascii','ignore') as suggested here. Not particularly useful in this example, but can work better in other scenarios when it's not possible to convert some special characters. Alternatively you can consider replacing particular character using replace().", "abstract": ""}, {"id": 9644115, "score": 55, "vote": 0, "content": "Always encode from unicode to bytes.\nIn this direction, you get to choose the encoding.   The other way is to decode from bytes to unicode.\nIn this direction, you have to know what the encoding is. This point can't be stressed enough.  If you want to avoid playing unicode \"whack-a-mole\", it's important to understand what's happening at the data level.  Here it is explained another way: Now, on seeing .encode on a byte string, Python 2 first tries to implicitly convert it to text (a unicode object).  Similarly, on seeing .decode on a unicode string, Python 2 implicitly tries to convert it to bytes (a str object).   These implicit conversions are why you can get UnicodeDecodeError when you've called encode.  It's because encoding usually accepts a parameter of type unicode; when receiving a str parameter, there's an implicit decoding into an object of type unicode before re-encoding it with another encoding.  This conversion chooses a default 'ascii' decoder\u2020, giving you the decoding error inside an encoder. In fact, in Python 3 the methods str.decode and bytes.encode don't even exist.  Their removal was a [controversial] attempt to avoid this common confusion. \u2020 ...or whatever coding sys.getdefaultencoding() mentions; usually this is 'ascii'", "abstract": ""}, {"id": 34591774, "score": 42, "vote": 0, "content": "You can try this  Or You can also try following Add following line at top of your .py file.", "abstract": ""}, {"id": 20673035, "score": 3, "vote": 0, "content": "You use u\"\u4f60\u597d\".encode('utf8') to encode an unicode string.\nBut if you want to represent \"\u4f60\u597d\", you should decode it. Just like: You will get what you want. Maybe you should learn more about encode & decode.", "abstract": ""}, {"id": 9644206, "score": 171, "vote": 0, "content": "encode converts a unicode object to a string object. But here you have invoked it on a string object (because you don't have the u). So python has to convert the string to a unicode object first. So it does the equivalent of But the decode fails because the string isn't valid ascii. That's why you get a complaint about not being able to decode.", "abstract": ""}, {"id": 9644116, "score": 8, "vote": 0, "content": "If you're using Python < 3, you'll need to tell the interpreter that your string literal is Unicode by prefixing it with a u: Further reading: Unicode HOWTO.", "abstract": ""}]}, {"link": "https://stackoverflow.com/questions/368805/python-unicodedecodeerror-am-i-misunderstanding-encode", "keywords": [], "tags": ["python", "unicode", "ascii", "encode"], "question": {"id": 368805, "title": "Python UnicodeDecodeError - Am I misunderstanding encode?", "content": "Any thoughts on why this isn't working?  I really thought 'ignore' would do the right thing.", "abstract": ""}, "answers": [{"id": 370199, "score": 214, "vote": 0, "content": "\u2026 There's a reason they're called \"encodings\" \u2026 A little preamble: think of unicode as the norm, or the ideal state. Unicode is just a table of characters. \u211665 is latin capital A. \u2116937 is greek capital omega. Just that. In order for a computer to store and-or manipulate Unicode, it has to encode it into bytes. The most straightforward encoding of Unicode is UCS-4; every character occupies 4 bytes, and all ~1000000 characters are available. The 4 bytes contain the number of the character in the Unicode tables as a 4-byte integer. Another very useful encoding is UTF-8, which can encode any Unicode character with one to four bytes. But there also are some limited encodings, like \"latin1\", which include a very limited range of characters, mostly used by Western countries. Such encodings use only one byte per character. Basically, Unicode can be encoded with many encodings, and encoded strings can be decoded to Unicode. The thing is, Unicode came quite late, so all of us that grew up using an 8-bit character set learned too late that all this time we worked with encoded strings. The encoding could be ISO8859-1, or windows CP437, or CP850, or, or, or, depending on our system default. So when, in your source code, you enter the string \"add \u201cMonitoring\u201c to list\" (and I think you wanted the string \"add \u201cMonitoring\u201d to list\", note the second quote), you actually are using a string already encoded according to your system's default codepage (by the byte \\x93 I assume you use Windows codepage 1252, \u201cWestern\u201d). If you want to get Unicode from that, you need to decode the string from the \"cp1252\" encoding. So, what you meant to do, was: It's unfortunate that Python 2.x includes an .encode method for strings too; this is a convenience function for \"special\" encodings, like the \"zip\" or \"rot13\" or \"base64\" ones, which have nothing to do with Unicode. Anyway, all you have to remember for your to-and-fro Unicode conversions is: In both cases, you need to specify the encoding that will be used. I'm not very clear, I'm sleepy, but I sure hope I help. PS A humorous side note: Mayans didn't have Unicode; ancient Romans, ancient Greeks, ancient Egyptians didn't too. They all had their own \"encodings\", and had little to no respect for other cultures. All these civilizations crumbled to dust. Think about it people! Make your apps Unicode-aware, for the good of mankind. :) PS2 Please don't spoil the previous message by saying \"But the Chinese\u2026\". If you feel inclined or obligated to do so, though, delay it by thinking that the Unicode BMP is populated mostly by chinese ideograms, ergo Chinese is the basis of Unicode. I can go on inventing outrageous lies, as long as people develop Unicode-aware applications.", "abstract": ""}, {"id": 62672428, "score": -2, "vote": 0, "content": "And the magic line is: The one liner that wont raise exceptions when it is most needed (remove bad Unicode characters...)", "abstract": ""}, {"id": 368859, "score": -3, "vote": 0, "content": "This seems to work: Any issues with that?  I wonder when 'ignore', 'replace' and other such encode error handling comes in?", "abstract": ""}, {"id": 368828, "score": 4, "vote": 0, "content": "encode is available to unicode strings, but the string you have there does not seems unicode (try with u'add \\x93Monitoring\\x93 to list ')", "abstract": ""}]}, {"link": "https://stackoverflow.com/questions/38518023/unicodedecodeerror-utf8-codec-cant-decode-byte-0x80-in-position-3131-invali", "keywords": [], "tags": ["json", "python-2.7", "utf-8", "ascii", "python-unicode"], "question": {"id": 38518023, "title": "UnicodeDecodeError: &#39;utf8&#39; codec can&#39;t decode byte 0x80 in position 3131: invalid start byte", "content": "I am trying to read twitter data from json file using python 2.7.12. Code I used is such: Result I got: I went through all the answers from similar issues and came up with this code and it worked last time. I have no clue why it isn't working now.", "abstract": ""}, "answers": [{"id": 74323493, "score": 0, "vote": 0, "content": "I got a similar error by accidentally trying to read a parquet file as a csv pd.read_csv(file.parquet) pd.read_parquet(file.parquet)", "abstract": ""}, {"id": 71499676, "score": 9, "vote": 0, "content": "For others who come across this question due to the error message, I ran into this error trying to open a pickle file when I opened the file in text mode instead of binary mode. This was the original code: And this fixed the error:", "abstract": ""}, {"id": 46786903, "score": 133, "vote": 0, "content": "In my case(mac os), there was .DS_store file in my data folder which was a hidden and auto generated file and it caused the issue. I was able to fix the problem after removing it.", "abstract": ""}, {"id": 38534992, "score": 26, "vote": 0, "content": "It doesn't help that you have sys.setdefaultencoding('utf-8'), which is confusing things further - It's a nasty hack and you need to remove it from your code. \nSee https://stackoverflow.com/a/34378962/1554386 for more information The error is happening because line is a string and you're calling encode(). encode() only makes sense if the string is a Unicode, so Python tries to convert it Unicode first using the default encoding, which in your case is UTF-8, but should be ASCII. Either way, 0x80 is not valid ASCII or UTF-8 so fails.  0x80 is valid in some characters sets. In windows-1252/cp1252 it's \u20ac. The trick here is to understand the encoding of your data all the way through your code. At the moment, you're leaving too much up to chance. Unicode String types are a handy Python feature that allows you to decode encoded Strings and forget about the encoding until you need to write or transmit the data. Use the io module to open the file in text mode and decode the file as it goes - no more .decode()! You need to make sure the encoding of your incoming data is consistent. You can either re-encode it externally or change the encoding in your script. Here's I've set the encoding to windows-1252. The io module also provide Universal Newlines. This means \\r\\n are detected as newlines, so you don't have to watch for them.", "abstract": ""}, {"id": 38520171, "score": -1, "vote": 0, "content": "The error occurs when you are trying to read a tweet containing sentence like \"@Mike http:\\www.google.com \\A8&^)((&() how are&^%()( you \". Which cannot be read as a String instead you are suppose to read it as raw String .\nbut Converting to raw String Still gives error  so i better i suggest you to  read a json file something like this: which will get you the data load from json file . You can also write it to a csv using Pandas. Then read from csv to avoid the encoding and decoding problem hope this will help you solving you problem. Midhun", "abstract": ""}]}, {"link": "https://stackoverflow.com/questions/51026315/how-to-solve-unicodedecodeerror-in-python-3-6", "keywords": [], "tags": ["python", "python-3.x", "linux", "ubuntu", "unicode"], "question": {"id": 51026315, "title": "How to solve UnicodeDecodeError in Python 3.6?", "content": "I am switched from Python 2.7 to Python 3.6. I have scripts that deal with some non-English content. I usually run scripts via Cron and also in Terminal. I had UnicodeDecodeError in my Python 2.7 scripts and I solved by this. Now in Python 3.6, it doesnt work. I have print statements like print(\"Here %s\" % (myvar)) and it throws error. I can solve this issue by replacing it to myvar.encode(\"utf-8\") but I don't want to write with each print statement. I did PYTHONIOENCODING=utf-8 in my terminal and I have still that issue. Is there a cleaner way to solve UnicodeDecodeError issue in Python 3.6? is there any way to tell Python3 to print everything in utf-8? just like I did in Python2?", "abstract": ""}, "answers": [{"id": 72163700, "score": -1, "vote": 0, "content": "for docker with python3.6, use LANG=C.UTF-8 python or jupyter xxx works for me, thanks to @Daniel and @zhy", "abstract": ""}, {"id": 67116385, "score": 4, "vote": 0, "content": "To everyone using pickle to load a file previously saved in python 2 and getting an UnicodeDecodeError, try setting pickle encoding parameter:", "abstract": ""}, {"id": 58173981, "score": 6, "vote": 0, "content": "I had this issue when using Python inside a Docker container based on Ubuntu 18.04.\nIt appeared to be a locale issue, which was solved by adding the following to the Dockerfile:", "abstract": ""}, {"id": 51027262, "score": 26, "vote": 0, "content": "It sounds like your locale is broken and have another bytes->Unicode issue. The thing you did for Python 2.7 is a hack that only masked the real problem (there's a reason why you have to reload sys to make it work). To fix your locale, try typing locale from the command line. It should look something like: locale depends on LANG being set properly. Python effectively uses locale to work out what encoding to use when writing to stdout in. If it can't work it out, it defaults to ASCII. You should first attempt to fix your locale. If locale errors, make sure you've installed the correct language pack for your region. If all else fails, you can always fix Python by setting PYTHONIOENCODING=UTF-8. This should be used as a last resort as you'll be masking problems once again. If Python is still throwing an error after setting PYTHONIOENCODING then please update your question with the stacktrace. Chances are you've got an implied conversion going on.", "abstract": ""}, {"id": 51026585, "score": 1, "vote": 0, "content": "For a Python-only solution you will have to recreate your sys.stdout object: After this, a normal print(\"hello world\") should be encoded to UTF-8 automatically. But you should try to find out why your terminal is set to such a strange encoding (which Python just tries to adopt to).  Maybe your operating system is configured wrong somehow. EDIT: In my tests unsetting the env variable LANG produced this strange setting for the stdout encoding for me: printed 'ANSI_X3.4-1968'. So I guess you might want to set your LANG to something like \nen_US.UTF-8.  Your terminal program doesn't seem to do this.", "abstract": ""}, {"id": 51026508, "score": -1, "vote": 0, "content": "Python 3 (including 3.6) is already Unicode supported. Here is the doc - https://docs.python.org/3/howto/unicode.html  So you don't need to force Unicode support like Python 2.7. Try to run your code normally. If you get any error reading a Unicode text file you need to use the encoding='utf-8' parameter while reading the file.", "abstract": ""}, {"id": 51026384, "score": -3, "vote": 0, "content": "I mean you could write an custom function like this:\n(Not optimal i know)", "abstract": ""}]}, {"link": "https://stackoverflow.com/questions/45432467/unicode-decode-error-when-trying-to-read-csv-file-in-python", "keywords": [], "tags": ["python", "csv", "unicode", "utf-8"], "question": {"id": 45432467, "title": "Unicode Decode Error when trying to read csv file in python", "content": "I am new to python and stackoverflow. My code first looked like this : Then this error came out : Here is how I tried to fix unicode error : And this error came out : During handling of the above exception, another exception occurred: File '2010_1_1.csv' definitely exists in my directory ('C:/dataset/*.csv') When I try to open this file individually using open('C:/dataset/2010_1_1.csv','r',encoding='utf8') it works but there is '\\ufeff' next to filename. I am not sure but my guess is that this file is being opened in try: and not yet closed thus python can't open this file at except.  How can I edit my code to solve this Unicode problem? Error :", "abstract": ""}, "answers": [{"id": 59470000, "score": 0, "vote": 0, "content": "Error Comes Out in Form of Unicode Decode Error its just Somewhere Missed Decoding it Could be both due to Format is Not Supported in Decoding the Particular File or Decoding is perfect but Error in file while it was Written in Whatever Format it had been ex:>json,xml,csv.... The Only way to Avoid when Stuck in this Problem is to Ignore errors in Decode in first part of Code by using errors='ignore' argument in open():>", "abstract": ""}, {"id": 45442590, "score": 0, "vote": 0, "content": "It looks like your file is not written in cp949 if it won't decode properly.  You'll have to figure out the correct encoding.  A module like chardet can help. On Windows, when reading a file open it with the encoding it was written in.  If UTF-8, use utf-8-sig, which will automatically handle and remove the byte-order-mark (BOM) U+FEFF character if present.  When writing, the best bet is to use utf-8-sig because it handles all possible Unicode characters and will add a BOM so Windows tools like Notepad and Excel will recognize UTF-8-encoded files.  Without it, most Windows tools will assume the ANSI encoding, which varies per localized version of Windows.", "abstract": ""}, {"id": 45433024, "score": 0, "vote": 0, "content": "I'm not very experienced with Python so call me out of this is not possible, but you could simply attempt ignoring the encoding of the file when opening it. I'm a Java programmer and from my experience, encoding only needs to be specifyed when creating a new file, and not when opening one.", "abstract": ""}]}, {"link": "https://stackoverflow.com/questions/53562170/unicodedecodeerror-error-when-opening-random-file", "keywords": [], "tags": ["python"], "question": {"id": 53562170, "title": "UnicodeDecodeError error when opening random file?", "content": "I am trying to open a random file in a directory and search for a string. However, I get an error. Is the path I'm using wrong or the way I am trying to read the file wrong?  UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 9502: character maps to ", "abstract": ""}, "answers": [{"id": 53566351, "score": 1, "vote": 0, "content": "First off, your code as provided does not run; you forgot a few necessary import statements. You get that UnicodeDecodeError because the default encoding for Python text files is UTF-8, and if you select any random file from your computer, it may not be UTF-8 encoded at all \u2013 or not even a text file to begin with. At that point the Unicode UTF8 character decoder fails to decode the input. If you specify the encoding as latin1, then Python assumes a one-to-one encoding of bytes to characters, and it will not try to decode \"as if\" it's UTF-8 anymore. That takes care of one problem. After fixing that, another one popped up in my random experimentation: os.listdir returns not only a list of files, but it may also include folders. You could have the program stop with the appropriate error message, but you can also remove the folders from your list before picking one. There are several methods to do so \u2013 os.walk, for example \u2013 but I found a magic line to get a list of just files out of os.listdir from How do I list all files of a directory?. The following code works without errors on my system; running it several times after another, once in a while it will say \"true\" (admittedly, I had to change the test text for that; your original text xpression occurs way too infrequent in my own files to test with). This works with the encoding set to latin1 because it treats plain ASCII data as such and doesn't bother with any binary content. However, it will randomly fail or succeed if your search text contains a not-ASCII character such as an accented letter. (It will only succeed when that random file happens to be encoded as Latin-1 as well, but fail if it was UTF-8.)", "abstract": ""}]}, {"link": "https://stackoverflow.com/questions/53458883/unicodedecodeerror-position-of-the-error", "keywords": [], "tags": ["python", "python-unicode"], "question": {"id": 53458883, "title": "UnicodeDecodeError : position of the error", "content": "I often face the \"UnicodeDecodeError\" when I'm writing some calculating programs. It says for example : My question is : how can I locate which word in my code causes the error ? I have no idea how to know were this 'position 57' is situated. And by the way, what means 'invalid continuation byte' ? Thanks for the answers. PS : this error comes from this code where I try to apply the 4th order Runge-Kutta method to the Lorenz equations :", "abstract": ""}, "answers": [{"id": 53459314, "score": 2, "vote": 0, "content": "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 57: invalid continuation byte The 57 is the byte position of complaint in your Python source file.\nIn your case it seems to be the position of the \u00e9 in # Date cr\u00e9ation fichier. 0xe9 is the byte at that position. I recognize it as the ISO-8859-1\n(a.k.a. ISO-Latin-1) representation of the character \u00e9. So it seems your Python source file is actually encoded in ISO-8859-1,\nbut the Python interpreter for some reason assumes it to be encoded in UTF-8. By the way:\nIn UTF-8 characters above 128 are encoded by 2 or more bytes,\nthe first being called the start byte, the others called continuation bytes.\nFor more explanation see the UTF-8 examples. To understand the error I need to elaborate more.\nConsider the bytes 0xe9 0x61 0x74, as occuring in your Python file:\nDecoding the 3 bytes as ISO-8859-1 (being a single-byte encoding) would result in 3 characters: \u00e9at.\nDecoding the same bytes as UTF-8 is more complicated.\nThe byte 0xe9 (because beginning with the bits 1110) is a starting byte\nto be followed by 2 continuation bytes.\nEach continuation byte needs to begin with the bits 10,\nBut the next 2 bytes (0x61 0x74) violate this condition.\nThus, a UnicodeError saying invalid continuation byte is thrown. To avoid this kind of problem you have some alternative options: Keep your Python source encoded in ISO-8859-1\nand add the line at the beginning of the file\nas described in PEP 263 -- Defining Python Source Code Encodings. Save your Python source in UTF-8.\nand add the line I would prefer the first or third option.", "abstract": ""}]}, {"link": "https://stackoverflow.com/questions/8781661/how-to-solve-a-unicodedecodeerror", "keywords": [], "tags": ["google-app-engine", "unicode", "python-2.7", "jinja2", "webapp2"], "question": {"id": 8781661, "title": "How to solve a UnicodeDecodeError?", "content": "I get a strange error message when trying to read non-ascii from the datastore: The loop that used to work is ordinary: What can I do to resolve this error? My handler looks like this And my model definition is the User model from webapp2. Here is also my custom filer makeid: The workaround is strange, I just make a .decode('utf-8') which is shouldn't need to be doing: Is there any way to decode the all of the variables of the user object at once instead of one by one?", "abstract": ""}, "answers": [{"id": 8856304, "score": 7, "vote": 0, "content": "The best was is to get the string converted to ASCII character set. You may use the python encode cgi function to convert to ASCII Example", "abstract": ""}, {"id": 8782280, "score": 9, "vote": 0, "content": "You're attempting to interpolate a raw (byte) string into a Unicode template. This is done by attempting to decode the raw string into unicode using some encoding - here, the default 'ascii' encoding - which is failing because it's encountering a codepoint that isn't valid for ASCII. To fix this, you need to pass only unicode strings into your template - decode the string using the correct codec before passing it in.", "abstract": ""}, {"id": 8782143, "score": 3, "vote": 0, "content": "Cast the text/HTML you pass to the template as Unicode and you should see it go away. Have had this problem before with Django templates in GAE with webapp2.", "abstract": ""}]}]